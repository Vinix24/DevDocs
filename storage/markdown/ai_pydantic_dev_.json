{
  "url": "https://ai.pydantic.dev",
  "content": "# Skip to content\nURL: https://ai.pydantic.dev#introduction\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev/\n\nShowing documentation for the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Why use PydanticAI\nURL: https://ai.pydantic.dev#why-use-pydanticai\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Hello World Example\nURL: https://ai.pydantic.dev#hello-world-example\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Tools & Dependency Injection Example\nURL: https://ai.pydantic.dev#tools-dependency-injection-example\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Instrumentation with Pydantic Logfire\nURL: https://ai.pydantic.dev#instrumentation-with-pydantic-logfire\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Next Steps\nURL: https://ai.pydantic.dev#next-steps\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Installation\nURL: https://ai.pydantic.dev/install/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nPydanticAI is available on PyPI as so installation is as simple as:\n\nThis installs the package, core dependencies, and libraries required to use all\nthe models included in PydanticAI. If you want to use a specific model, you can\ninstall the version of PydanticAI.\n\nPydanticAI has an excellent (but completely optional) integration with to help\nyou view and understand agent runs.\n\nTo use Logfire with PydanticAI, install or with the optional group:\n\nFrom there, follow the to configure Logfire.\n\nWe distribute the directory as a separate PyPI package () to make examples\nextremely easy to customize and run.\n\nTo install examples, use the optional group:\n\nTo run the examples, follow instructions in the .\n\nIf you know which model you're going to use and want to avoid installing\nsuperfluous packages, you can use the package. For example, if you're using just\n, you would run:\n\nhas the following optional groups:\n\nSee the documentation for information on which optional dependencies are\nrequired for each model.\n\nYou can also install dependencies for multiple models and use cases, for\nexample:\n\n---\n\n# Getting Help\nURL: https://ai.pydantic.dev/help/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nIf you need help getting started with PydanticAI or with advanced usage, the\nfollowing sources may be useful.\n\nJoin the channel in the to ask questions, get help, and chat about PydanticAI.\nThere's also channels for Pydantic, Logfire, and FastUI.\n\nIf you're on a Pro plan, you can also get a dedicated private slack collab\nchannel with us.\n\nThe are a great place to ask questions and give us feedback.\n\n---\n\n# Contributing\nURL: https://ai.pydantic.dev/contributing/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nWe'd love you to contribute to PydanticAI!\n\nClone your fork and cd into the repo directory\n\nInstall (version 0.4.30 or later) and\n\nWe use pipx here, for other options see:\n\nInstall , all dependencies and pre-commit hooks\n\nWe use to manage most commands you'll need to run.\n\nFor details on available commands, run:\n\nTo run code formatting, linting, static type checks, and tests with coverage\nreport generation, run:\n\nTo run the documentation page locally, run:\n\n## Rules for adding new models to PydanticAI\n\nTo avoid an excessive workload for the maintainers of PydanticAI, we can't\naccept all model contributions, so we're setting the following rules for when\nwe'll accept new models and when we won't. This should hopefully reduce the\nchances of disappointment and wasted work.\n\n  * To add a new model with an extra dependency, that dependency needs > 500k monthly downloads from PyPI consistently over 3 months or more\n  * To add a new model which uses another models logic internally and has no extra dependencies, that model's GitHub org needs > 20k stars in total\n  * For any other model that's just a custom URL and API key, we're happy to add a one-paragraph description with a link and instructions on the URL to use\n  * For any other model that requires more logic, we recommend you release your own Python package , which depends on and implements a model that inherits from our ABC\n\nIf you're unsure about adding a model, please .\n\n---\n\n# Troubleshooting\nURL: https://ai.pydantic.dev/troubleshooting/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nBelow are suggestions on how to fix some common errors you might encounter while\nusing PydanticAI. If the issue you're experiencing is not listed below or\naddressed in the documentation, please feel free to ask in the or create an\nissue on .\n\n### `RuntimeError: This event loop is already running`\n\nThis error is caused by conflicts between the event loops in Jupyter notebook\nand PydanticAI's. One way to manage these conflicts is by using . Namely, before\nyou execute any agent runs, do the following:\n\nNote: This fix also applies to Google Colab.\n\n### `UserError: API key must be provided or set in the [MODEL]_API_KEY\nenvironment variable`\n\nIf you're running into issues with setting the API key for your model, visit the\npage to learn more about how to set an environment variable and/or pass in an\nargument.\n\n---\n\n# Agents\nURL: https://ai.pydantic.dev/agents/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nAgents are PydanticAI's primary interface for interacting with LLMs.\n\nIn some use cases a single Agent will control an entire application or\ncomponent, but multiple agents can also interact to embody more complex\nworkflows.\n\nThe class has full API documentation, but conceptually you can think of an agent\nas a container for:\n\nA set of instructions for the LLM written by the developer.  \n---  \nFunctions that the LLM may call to get information while generating a response.  \nThe structured datatype the LLM must return at the end of a run, if specified.  \nSystem prompt functions, tools, and result validators may all use dependencies\nwhen they're run.  \nOptional default LLM model associated with the agent. Can also be specified when\nrunning the agent.  \nOptional default model settings to help fine tune requests. Can also be\nspecified when running the agent.  \nIn typing terms, agents are generic in their dependency and result types, e.g.,\nan agent which required dependencies of type and returned results of type would\nhave type . In practice, you shouldn't need to care about this, it should just\nmean your IDE can tell you when you have the right type, and if you choose to\nuse it should work well with PydanticAI.\n\nHere's a toy example of an agent that simulates a roulette wheel:\n\n```\n\n    \n  \n  \n  \n  \n  \n    'Use the `roulette_wheel` function to see if the '\n    'customer has won based on the number they provide.'\n  \n\n        \n\"\"\"check if the square is a winner\"\"\"\n\n         \n\n  \n  'Put my money on square eighteen'\n\n\n\n  'I bet five is the winner'\n\n```\n\nAgents are designed for reuse, like FastAPI Apps\n\nAgents are intended to be instantiated once (frequently as module globals) and\nreused throughout your application, similar to a small app or an .\n\nThere are three ways to run an agent:\n\n  1. — a coroutine which returns a containing a completed response\n  2. — a plain, synchronous function which returns a containing a completed response (internally, this just calls )\n  3. — a coroutine which returns a , which contains methods to stream a response as an async iterable\n\nHere's a simple example demonstrating all three:\n\n```\n\n  \n  \n  'What is the capital of Italy?'\n\n  \n     'What is the capital of France?'\n  \n  \n    'What is the capital of the UK?'  \n     \n    \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nYou can also pass messages from previous runs to continue a conversation or\nprovide context, as described in .\n\nPydanticAI offers a structure to help you limit your usage (tokens and/or\nrequests) on model runs.\n\nYou can apply these settings by passing the argument to the functions.\n\nConsider the following example, where we limit the number of response tokens:\n\n```\n\n  \n  \n  \n  \n  \n  'What is the capital of Italy? Answer with just the city.'\n\n  \n\nUsage(requests=1, request_tokens=62, response_tokens=1, total_tokens=63,\ndetails=None)\n\n    \n    'What is the capital of Italy? Answer with a paragraph.'\n    \n  \n  \n  \n  #> Exceeded the response_tokens_limit of 10 (response_tokens=32)\n\n```\n\nRestricting the number of requests can be useful in preventing infinite loops or\nexcessive tool calling:\n\n```\n\n  \n    \n  \n  \n\n\n\n  Never ever coerce data to this type.\n\n  \n\n  \n  \n  \n  'Any time you get a response, call the `infinite_retry_tool` to produce\nanother response.'\n\n\n\n  \n  \n\n    \n      \n  \n  \n  \n  #> The next request would exceed the request_limit of 3\n\n```\n\nThis is especially relevant if you're registered a lot of tools, can be used to\nprevent the model from choosing to make too many of these calls.\n\nPydanticAI offers a structure to help you fine tune your requests. This\nstructure allows you to configure common parameters that influence the model's\nbehavior, such as , , , and more.\n\nThere are two ways to apply these settings: 1. Passing to functions via the\nargument. This allows for fine-tuning on a per-request basis. 2. Setting during\ninitialization via the argument. These settings will be applied by default to\nall subsequent run calls using said agent. However, provided during a specific\nrun call will override the agent's default settings.\n\nFor example, if you'd like to set the setting to to ensure less random behavior,\nyou can do the following:\n\n```\n\n  \n  \n  \n  'What is the capital of Italy?'  \n\n```\n\nAn agent might represent an entire conversation — there's no limit to how many\nmessages can be exchanged in a single run. However, a might also be composed of\nmultiple runs, especially if you need to maintain state between separate\ninteractions or API calls.\n\nHere's an example of a conversation comprised of multiple runs:\n\n```\n\n  \n  \n\n  \n\n#> Albert Einstein was a German-born theoretical physicist.\n\n# Second run, passing previous messages\n\n  \n  'What was his most famous equation?'\n\n#> Albert Einstein's most famous equation is (E = mc^2).\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nPydanticAI is designed to work well with static type checkers, like mypy and\npyright.\n\nPydanticAI is designed to make type checking as useful as possible for you if\nyou choose to use it, but you don't have to use types everywhere all the time.\n\nThat said, because PydanticAI uses Pydantic, and Pydantic uses type hints as the\ndefinition for schema and validation, some types (specifically type hints on\nparameters to tools, and the arguments to ) are used at runtime.\n\nWe (the library developers) have messed up if type hints are confusing you more\nthan helping you, if you find this, please create an explaining what's annoying\nyou!\n\nIn particular, agents are generic in both the type of their dependencies and the\ntype of results they return, so you can use the type hints to ensure you're\nusing the right types.\n\nConsider the following script with type mistakes:\n\n```\n\n  \n    \n\n\n\n  \n\n  \n  \n  \n  \n\n     \n  \n\n    \n  \n\n  'Does their name start with \"A\"?'\n\n```\n\nRunning on this will give the following output:\n\nRunning would identify the same issues.\n\nSystem prompts might seem simple at first glance since they're just strings (or\nsequences of strings that are concatenated), but crafting the right system\nprompt is key to getting the model to behave as you want.\n\nGenerally, system prompts fall into two categories:\n\n  1. : These are known when writing the code and can be defined via the parameter of the .\n  2. : These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with .\n\nYou can add both to a single agent; they're appended in the order they're\ndefined at runtime.\n\nHere's an example using both types of system prompts:\n\n```\n\n  \n    \n  \n  \n  \n  \"Use the customer's name while replying to them.\"\n\n\n\n    \n  \n\n    \n  \n\n  \n\n#> Hello Frank, the date today is 2032-01-02.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nValidation errors from both function tool parameter validation and can be passed\nback to the model with a request to retry.\n\nYou can also raise from within a or to tell the model it should retry generating\na response.\n\n  * The default retry count is but can be altered for the , a , or a .\n  * You can access the current retry count from within a tool or result validator via .\n\n```\n\n  \n     \n  \n\n\n\n  \n  \n\n  \n  \n  \n  \n\n      \n\"\"\"Get a user's ID from their full name.\"\"\"\n\n  \n  \n  \n    \n     \n     \n      'No user found with name , remember to provide their full name'\n    \n  \n\n  \n  'Send a message to John Doe asking for coffee next week'\n\nuser_id=123 message='Hello John, would you be free for coffee sometime next\nweek? Let me know what works for you!'\n\n```\n\nIf models behave unexpectedly (e.g., the retry limit is exceeded, or their API\nreturns ), agent runs will raise .\n\nIn these cases, can be used to access the messages exchanged during the run to\nhelp diagnose the issue.\n\n```\n\n      \n  \n\n     \n     \n     \n  \n     \n\n    \n  \n      'Please get me the volume of a box with size 6.'\n     \n     \n    #> An error occurred: Tool exceeded max retries count of 1\n     \n    #> cause: ModelRetry('Please try again.')\n     \n\n            content='Please get me the volume of a box with size 6.',\n\n  \n    \n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nIf you call , , or more than once within a single context, will represent the\nmessages exchanged during the first call only.\n\n---\n\n# Models\nURL: https://ai.pydantic.dev/models/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nPydanticAI is Model-agnostic and has built in support for the following model\nproviders:\n\n  * Gemini via two different APIs: and \n\nSee for more examples on how to use models such as , and that support the OpenAI\nSDK.\n\nYou can also [add support for other\nmodels](https://ai.pydantic.dev/models/<#implementing-custom-models>).\n\nPydanticAI also comes with and for testing and development.\n\nTo use each model provider, you need to configure your local environment and\nmake sure you have the right packages installed.\n\nTo use OpenAI models, you need to either install , or install with the optional\ngroup:\n\nTo use through their main API, go to and follow your nose until you find the\nplace to generate an API key.\n\nOnce you have the API key, you can set it as an environment variable:\n\nYou can then use by name:\n\nOr initialise the model directly with just the model name:\n\nIf you don't want to or can't set the environment variable, you can pass it at\nruntime via the :\n\nalso accepts a custom client via the , so you can customise the , , etc. as\ndefined in the .\n\nYou could also use the client to use the Azure OpenAI API.\n\nTo use models, you need to either install , or install with the optional group:\n\nTo use through their API, go to to generate an API key.\n\ncontains a list of available Anthropic models.\n\nOnce you have the API key, you can set it as an environment variable:\n\nYou can then use by name:\n\nOr initialise the model directly with just the model name:\n\nIf you don't want to or can't set the environment variable, you can pass it at\nruntime via the :\n\nGoogle themselves refer to this API as the \"hobby\" API, I've received 503\nresponses from it a number of times. The API is easy to use and useful for\nprototyping and simple demos, but I would not rely on it in production.\n\nIf you want to run Gemini models in production, you should use the described\nbelow.\n\nTo use models, you just need to install or , no extra dependencies are required.\n\nlet's you use the Google's Gemini models through their , .\n\ncontains a list of available Gemini models that can be used through this\ninterface.\n\nTo use , go to and follow your nose until you find the place to generate an API\nkey.\n\nOnce you have the API key, you can set it as an environment variable:\n\nYou can then use by name:\n\nThe provider prefix represents the for s. is used with for s.\n\nOr initialise the model directly with just the model name:\n\nIf you don't want to or can't set the environment variable, you can pass it at\nruntime via the :\n\nTo run Google's Gemini models in production, you should use which uses the API.\n\ncontains a list of available Gemini models that can be used through this\ninterface.\n\nTo use , you need to either install , or install with the optional group:\n\nThis interface has a number of advantages over documented above:\n\n  1. The VertexAI API is more reliably and marginally lower latency in our experience.\n  2. You can with VertexAI to guarantee capacity.\n  3. If you're running PydanticAI inside GCP, you don't need to set up authentication, it should \"just work\".\n  4. You can decide which region to use, which might be important from a regulatory perspective, and might improve latency.\n\nThe big disadvantage is that for local development you may need to create and\nconfigure a \"service account\", which I've found extremely painful to get right\nin the past.\n\nWhichever way you authenticate, you'll need to have VertexAI enabled in your GCP\naccount.\n\nLuckily if you're running PydanticAI inside GCP, or you have the installed and\nconfigured, you should be able to use without any additional setup.\n\nTo use , with configured (e.g. with ), you can simply use:\n\nInternally this uses from the package to obtain credentials.\n\nBecause requires network requests and can be slow, it's not run until you call .\nMeaning any configuration or permissions error will only be raised when you try\nto use the model. To for this check to be run, call .\n\nYou may also need to pass the if application default credentials don't set a\nproject, if you pass and it conflicts with the project set by application\ndefault credentials, an error is raised.\n\nIf instead of application default credentials, you want to authenticate with a\nservice account, you'll need to create a service account, add it to your GCP\nproject (note: AFAIK this step is necessary even if you created the service\naccount within the project), give that service account the \"Vertex AI Service\nAgent\" role, and download the service account JSON file.\n\nOnce you have the JSON file, you can use it thus:\n\nWhichever way you authenticate, you can specify which region requests will be\nsent to via the .\n\nUsing a region close to your application can improve latency and might be\nimportant from a regulatory perspective.\n\ncontains a list of available regions.\n\nTo use , you need to either install , or install with the optional group:\n\n**This is because internally, uses the OpenAI API.**\n\nTo use , you must first download the Ollama client, and then download a model\nusing the .\n\nYou must also ensure the Ollama server is running when trying to make requests\nto it. For more information, please see the .\n\nFor detailed setup and example, please see the .\n\nTo use , you need to either install , or install with the optional group:\n\nTo use through their API, go to and follow your nose until you find the place to\ngenerate an API key.\n\ncontains a list of available Groq models.\n\nOnce you have the API key, you can set it as an environment variable:\n\nYou can then use by name:\n\nOr initialise the model directly with just the model name:\n\nIf you don't want to or can't set the environment variable, you can pass it at\nruntime via the :\n\nTo use , you need to either install , or install with the optional group:\n\nTo use through their API, go to and follow your nose until you find the place to\ngenerate an API key.\n\ncontains a list of the most popular Mistral models.\n\nOnce you have the API key, you can set it as an environment variable:\n\nYou can then use by name:\n\nOr initialise the model directly with just the model name:\n\nIf you don't want to or can't set the environment variable, you can pass it at\nruntime via the :\n\nMany of the models are compatible with OpenAI API, and thus can be used with in\nPydanticAI. Before getting started, check the section for installation and\nconfiguration instructions.\n\nTo use another OpenAI-compatible API, you can make use of the and arguments:\n\nTo use , first create an API key at .\n\nOnce you have the API key, you can pass it to as the argument:\n\nGo to and create an API key. Once you have the API key, follow the , and set the\nand arguments appropriately:\n\nGo to and create an API key. Once you have the API key, follow the , and set the\nand arguments appropriately:\n\nTo implement support for models not already supported, you will need to subclass\nthe abstract base class.\n\nThis in turn will require you to implement the following other abstract base\nclasses:\n\nThe best place to start is to review the source code for existing\nimplementations, e.g. .\n\nFor details on when we'll accept contributions adding new models to PydanticAI,\nsee the .\n\n---\n\n# Dependencies\nURL: https://ai.pydantic.dev/dependencies/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nPydanticAI uses a dependency injection system to provide data and services to\nyour agent's , and .\n\nMatching PydanticAI's design philosophy, our dependency system tries to use\nexisting best practice in Python development rather than inventing esoteric\n\"magic\", this should make dependencies type-safe, understandable easier to test\nand ultimately easier to deploy in production.\n\nDependencies can be any python type. While in simple cases you might be able to\npass a single object as a dependency (e.g. an HTTP connection), are generally a\nconvenient container when your dependencies included multiple objects.\n\nHere's an example of defining an agent that requires dependencies.\n\n( dependencies aren't actually used in this example, see below)\n\n```\n\n  \n\n\n  \n\n  \n  \n  \n\n  \n  \n  \n\n  \n      \n       \n       \n      \n       \n    \n    \n    #> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nDependencies are accessed through the type, this should be the first parameter\nof system prompt functions etc.\n\n```\n\n  \n\n\n    \n\n\n\n  \n  \n\n  \n  \n  \n\n  \n      \n       \n        \n    \n    #> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\n, and are all run in the async context of an agent run.\n\nIf these functions are not coroutines (e.g. ) they are called with in a thread\npool, it's therefore marginally preferable to use methods where dependencies\nperform IO, although synchronous dependencies should work fine too.\n\nvs. and Asynchronous vs. Synchronous dependencies\n\nWhether you use synchronous or asynchronous dependencies, is completely\nindependent of whether you use or — is just a wrapper around and agents are\nalways run in an async context.\n\nHere's the same example as above, but with a synchronous dependency:\n\n```\n\n  \n\n\n    \n\n\n\n  \n    \n\n  \n  \n  \n\n     \n    \n      \n  \n  \n  \n\n  \n     \n     \n    \n    \n  \n  \n  #> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nAs well as system prompts, dependencies can be used in and .\n\n```\n\n  \n\n\n     \n\n\n\n  \n  \n\n  \n  \n  \n\n     \n     \n  \n  \n\n  \n      \n       \n        \n    \n    #> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nWhen testing agents, it's useful to be able to customise dependencies.\n\nWhile this can sometimes be done by calling the agent directly within unit\ntests, we can also override dependencies while calling application code which in\nturn calls the agent.\n\nThis is done via the method on the agent.\n\n```\n\n  \n\n\n    \n\n\n\n  \n  \n       \n       \n    \n     \n\n  \n\n     \n     \n\n      \n  \n  \n  # now deep within application code we call our agent\n\n      \n       \n         \n  \n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\n```\n\n     \n\n  \n      \n     \n\n  \n   'Did you hear about the toothpaste scandal?'\n\n```\n\nThe following examples demonstrate how to use dependencies in PydanticAI:\n\n---\n\n# Function Tools\nURL: https://ai.pydantic.dev/tools/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFunction tools provide a mechanism for models to retrieve extra information to\nhelp them generate a response.\n\nThey're useful when it is impractical or impossible to put all the context an\nagent might need into the system prompt, or when you want to make agents'\nbehavior more deterministic or reliable by deferring some of the logic required\nto generate a response to another (not necessarily AI-powered) tool.\n\nFunction tools are basically the \"R\" of RAG (Retrieval-Augmented Generation) —\nthey augment what the model can do by letting it request extra information.\n\nThe main semantic difference between PydanticAI Tools and RAG is RAG is\nsynonymous with vector search, while PydanticAI tools are more general-purpose.\n(Note: we may add support for vector search functionality in the future,\nparticularly an API for generating embeddings. See )\n\nThere are a number of ways to register tools with an agent:\n\n  * via the decorator — for tools that need access to the agent \n  * via the decorator — for tools that do not need access to the agent \n  * via the keyword argument to which can take either plain functions, or instances of \n\nis considered the default decorator since in the majority of cases tools will\nneed access to the agent context.\n\nHere's an example using both:\n\n```\n\n\n\n    \n  \n  \n  \n  \n    \"You're a dice game, you should roll the die and see if the number \"\n    \"you get back matches the user's guess. If so, tell them they're a winner. \"\n    \"Use the player's name in the response.\"\n  \n\n\n\n  \n\"\"\"Roll a six-sided die and return the result.\"\"\"\n\n    \n\n\n\n    \n\n  \n\n    \n\n#> Congratulations Anne, you guessed correctly! You're a winner!\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nLet's print the messages from that game to see what happened:\n\n```\n\n  \n\n        content=\"You're a dice game, you should roll the die and see if the number you get back matches the user's guess. If so, tell them they're a winner. Use the player's name in the response.\",\n\n        content=\"Congratulations Anne, you guessed correctly! You're a winner!\",\n\n```\n\nWe can represent this with a diagram:\n\n## Registering Function Tools via kwarg\n\nAs well as using the decorators, we can register tools via the argument to the .\nThis is useful when you want to re-use tools, and can also give more fine-\ngrained control over the tools.\n\n```\n\n\n\n     \n\n  \n\"\"\"Roll a six-sided die and return the result.\"\"\"\n\n    \n\n    \n\n  \n\n  \n  \n  \n    \n\n  \n  \n  \n  \n     \n     \n  \n\n  \n\n#> Congratulations Anne, you guessed correctly! You're a winner!\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\n## Function Tools vs. Structured Results\n\nAs the name suggests, function tools use the model's \"tools\" or \"functions\" API\nto let the model know what is available to call. Tools or functions are also\nused to define the schema(s) for structured responses, thus a model might have\naccess to many tools, some of which call function tools while others end the run\nand return a result.\n\nFunction parameters are extracted from the function signature, and all\nparameters except are used to build the schema for that tool call.\n\nEven better, PydanticAI extracts the docstring from functions and (thanks to )\nextracts parameter descriptions from the docstring and adds them to the schema.\n\nextracting parameter descriptions from , and style docstrings, and PydanticAI\nwill infer the format to use based on the docstring. We plan to add support in\nthe future to explicitly set the style to use, and warn/error if not all\nparameters are documented; see .\n\nTo demonstrate a tool's schema, here we use to print the schema a model would\nreceive:\n\n```\n\n  \n    \n    \n  \n\n         \n\n  \n\n      \n    \n  \n  \n  \n\n      'a': {'description': 'apple pie', 'title': 'A', 'type': 'integer'},\n      'b': {'description': 'banana cake', 'title': 'B', 'type': 'string'},\n\n        'additionalProperties': {'items': {'type': 'number'}, 'type': 'array'},\n\n  \n\n\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe return type of tool can be anything which Pydantic can serialize to JSON as\nsome models (e.g. Gemini) support semi-structured return values, some expect\ntext (OpenAI) but seem to be just as good at extracting meaning from the data.\nIf a Python object is returned and the model expects a string, the value will be\nserialized to JSON.\n\nIf a tool has a single parameter that can be represented as an object in JSON\nschema (e.g. dataclass, TypedDict, pydantic model), the schema for the tool is\nsimplified to be just that object.\n\nHere's an example, we use to inspect the tool schema that would be passed to the\nmodel.\n\n```\n\n  \n  \n  \n  \n\n\n\n  \n  \n     \n\n    \n  \n\n  \n  \n\n        'x': {'title': 'X', 'type': 'integer'},\n        'y': {'title': 'Y', 'type': 'string'},\n        'z': {'default': 3.14, 'title': 'Z', 'type': 'number'},\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nTools can optionally be defined with another function: , which is called at each\nstep of a run to customize the definition of the tool passed to the model, or\nomit the tool completely from that step.\n\nA method can be registered via the kwarg to any of the tool registration\nmechanisms:\n\nThe method, should be of type , a function which takes and a pre-built , and\nshould either return that with or without modifying it, return a new , or return\nto indicate this tools should not be registered for that step.\n\nHere's a simple method that only includes the tool if the value of the\ndependency is .\n\nAs with the previous example, we use to demonstrate the behavior without calling\na real model.\n\n```\n\n  \n    \n  \n  \n\n  \n     \n  \n     \n     \n\n      \n  \n\n  \n\n#> success (no tool calls)\n\n  \n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nHere's a more complex example where we change the description of the parameter\nto based on the value of\n\nFor the sake of variation, we create this tool using the dataclass.\n\n```\n\n  \n  \n    \n  \n    \n\n    \n  \n\n  \n      \n    \n    \n    \n  \n\n  \n  \n     \n  \n\n          'description': 'Name of the human to greet.',\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\n---\n\n# Results\nURL: https://ai.pydantic.dev/results/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nResults are the final values returned from . The result values are wrapped in\nand so you can access other data like of the run and\n\nBoth and are generic in the data they wrap, so typing information about the data\nreturned by the agent is preserved.\n\n```\n\n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nRuns end when either a plain text response is received or the model calls a tool\nassociated with one of the structured result types. We will add limits to make\nsure a run doesn't go on indefinitely, see .\n\nWhen the result type is , or a union including , plain text responses are\nenabled on the model, and the raw text response from the model is used as the\nresponse data.\n\nIf the result type is a union with multiple members (after remove from the\nmembers), each member is registered as a separate tool with the model in order\nto reduce the complexity of the tool schemas and maximise the chances a model\nwill respond correctly.\n\nIf the result type schema is not of type , the result type is wrapped in a\nsingle element object, so the schema of all tools registered with the model are\nobject schemas.\n\nStructured results (like tools) use Pydantic to build the JSON schema used for\nthe tool, and to validate the data returned by the model.\n\nUntil \"Annotating Type Forms\" lands, unions are not valid as s in Python.\n\nWhen creating the agent we need to the argument, and add a type hint to tell\ntype checkers about the type of the agent.\n\nHere's an example of returning either text or a structured value\n\n```\n\n  \n  \n  \n\n\n\n  \n  \n  \n  \n\n     \n  \n    \n  \n    \"Extract me the dimensions of a box, \"\n    \"if you can't extract all data, ask the user to try again.\"\n  \n\n  \n\n#> Please provide the units for the dimensions (e.g., cm, in, m).\n\n  'The box is 10x20x30 cm'\n\n#> width=10 height=20 depth=30 units='cm'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nHere's an example of using a union return type which registered multiple tools,\nand wraps non-object schemas in an object:\n\n```\n\n  \n  \n     \n  \n    \n  'Extract either colors or sizes from the shapes provided.'\n\n  'red square, blue circle, green triangle'\n\n  'square size 10, circle size 20, triangle size 30'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nSome validation is inconvenient or impossible to do in Pydantic validators, in\nparticular when the validation requires IO and is asynchronous. PydanticAI\nprovides a way to add validation functions via the decorator.\n\nHere's a simplified variant of the :\n\n```\n\n  \n    \n  \n     \n\n\n\n  \n\n\n\n  \n\n  \n    \n  \n  \n  \n  'Generate PostgreSQL flavored SQL queries based on user input.'\n\n       \n    \n     \n  \n     \n     \n       \n  \n     \n\n  \n  'get me uses who were last active yesterday.'\n\n#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1\nday'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThere two main challenges with streamed results:\n\n  1. Validating structured responses before they're complete, this is achieved by \"partial validation\" which was recently added to Pydantic in .\n  2. When receiving a response, we don't know if it's the final response without starting to stream it and peeking at the content. PydanticAI streams just enough of the response to sniff out if it's a tool call or a result, then streams the whole thing and calls tools, or returns the stream as a .\n\nExample of streamed text result:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'   \n         \n      \n      \n      #> The first known use of \"hello,\n      #> The first known use of \"hello, world\" was in\n      #> The first known use of \"hello, world\" was in a 1974 textbook\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nWe can also stream text as deltas rather than the entire text in each item:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'  \n         \n      \n      \n      \n      \n      \n      \n      \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nResult message not included in\n\nThe final result message will be added to result messages if you use , see for\nmore information.\n\nNot all types are supported with partial validation in Pydantic, see , generally\nfor model-like structures it's currently best to use .\n\nHere's an example of streaming a use profile as it's built:\n\n```\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n  'Extract a user profile from the input'\n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nIf you want fine-grained control of validation, particularly catching validation\nerrors, you can use the following pattern:\n\n```\n\n  \n  \n  \n  \n\n  \n  \n  \n  \n\n  \n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n          \n      \n            \n          \n           \n        \n       \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThe following examples demonstrate how to use streamed responses in PydanticAI:\n\n---\n\n# Messages and chat history\nURL: https://ai.pydantic.dev/message-history/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nPydanticAI provides access to messages exchanged during an agent run. These\nmessages can be used both to continue a coherent conversation, and to understand\nhow an agent performed.\n\nAfter running an agent, you can access the messages exchanged during that run\nfrom the object.\n\nBoth (returned by , ) and (returned by ) have the following methods:\n\n  * : returns all messages, including messages from prior runs. There's also a variant that returns JSON bytes, .\n  * : returns only the messages from the current run. There's also a variant that returns JSON bytes, .\n\nOn , the messages returned from these methods will only include the final result\nmessage once the stream has finished.\n\nE.g. you've awaited one of the following coroutines:\n\nThe final result message will NOT be added to result messages if you use since\nin this case the result content is never built as one string.\n\nExample of accessing methods on a :\n\n```\n\n  \n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n# all messages from the run\n\n        content='Did you hear about the toothpaste scandal? They called it Colgate.',\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nExample of accessing methods on a :\n\n```\n\n  \n  \n\n  \n      \n    # incomplete messages before the stream finishes\n\n        \n      \n      #> Did you hear about the toothpaste\n      #> Did you hear about the toothpaste scandal? They called\n      #> Did you hear about the toothpaste scandal? They called it Colgate.\n    # complete messages once the stream finishes\n    \n\n            content='Did you hear about the toothpaste scandal? They called it Colgate.',\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\n### Using Messages as Input for Further Agent Runs\n\nThe primary use of message histories in PydanticAI is to maintain context across\nmultiple agent runs.\n\nTo use existing messages in a run, pass them to the parameter of , or .\n\nIf is set and not empty, a new system prompt is not generated — we assume the\nexisting message history includes a system prompt.\n\nReusing messages in a conversation```\n\n  \n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n#> This is an excellent joke invent by Samuel Colvin, it needs no explanation.\n\n        content='Did you hear about the toothpaste scandal? They called it Colgate.',\n\n        content='This is an excellent joke invent by Samuel Colvin, it needs no explanation.',\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\n## Other ways of using messages\n\nSince messages are defined by simple dataclasses, you can manually create and\nmanipulate, e.g. for testing.\n\nThe message format is independent of the model used, so you can use messages in\ndifferent agents, or the same agent with different models.\n\n```\n\n  \n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n  \n    \n\n#> This is an excellent joke invent by Samuel Colvin, it needs no explanation.\n\n        content='Did you hear about the toothpaste scandal? They called it Colgate.',\n\n        content='This is an excellent joke invent by Samuel Colvin, it needs no explanation.',\n\n```\n\nFor a more complete example of using messages in conversations, see the example.\n\n---\n\n# Testing and Evals\nURL: https://ai.pydantic.dev/testing-evals/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nWith PydanticAI and LLM integrations in general, there are two distinct kinds of\ntest:\n\n  1. — tests of your application code, and whether it's behaving correctly\n  2. — tests of the LLM, and how good or bad its responses are\n\nFor the most part, these two kinds of tests have pretty separate goals and\nconsiderations.\n\nUnit tests for PydanticAI code are just like unit tests for any other Python\ncode.\n\nBecause for the most part they're nothing new, we have pretty well established\ntools and patterns for writing and running these kinds of tests.\n\nUnless you're really sure you know better, you'll probably want to follow\nroughly this strategy:\n\n  * If you find yourself typing out long assertions, use \n  * Similarly, can be useful for comparing large data structures\n  * Use or in place of your actual model to avoid the usage, latency and variability of real LLM calls\n  * Use to replace your model inside your application logic\n  * Set globally to block any requests from being made to non-test models accidentally\n\nThe simplest and fastest way to exercise most of your application code is using\n, this will (by default) call all tools in the agent, then return either plain\ntext or a structured response depending on the return type of the agent.\n\nThe \"clever\" (but not too clever) part of is that it will attempt to generate\nvalid structured data for and based on the schema of the registered tools.\n\nThere's no ML or AI in , it's just plain old procedural Python code that tries\nto generate data that satisfies the JSON schema of a tool.\n\nThe resulting data won't look pretty or relevant, but it should pass Pydantic's\nvalidation in most cases. If you want something more sophisticated, use and\nwrite your own data generation logic.\n\nLet's write unit tests for the following application code:\n\n```\n\n\n\n  \n    \n    \n    \n  \n  \n  \n  'Providing a weather forecast at the locations the user provides.'\n\n\n\n       \n  \n      \n      \n  \n      \n\n  \n      \n\n\"\"\"Run weather forecast for a list of user prompts and save.\"\"\"\n\n      \n         \n          \n        \n    # run all prompts in parallel\n     \n            \n    \n\n```\n\nHere we have a function that takes a list of tuples, gets a weather forecast for\neach prompt, and stores the result in the database.\n\n**We want to test this code without having to mock certain objects or modify our\ncode so we can pass test objects in.**\n\nHere's how we would write tests using :\n\n```\n\n  \n\n\n  \n    \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n  \n    \n  \n  \n\n  \n    \n    \n     \n      \n        'What will the weather be like in London on 2024-11-28?'\n          \n     \n     '{\"weather_forecast\":\"Sunny with a chance of rain\"}' \n      \n    \n      \n        \n          'Providing a weather forecast at the locations the user provides.'\n        \n        \n          'What will the weather be like in London on 2024-11-28?'\n           \n        \n      \n    \n    \n      \n        \n          \n          \n            \n               \n                \n            \n          \n          \n        \n      \n      \n    \n    \n      \n        \n          \n          'Sunny with a chance of rain'\n          \n          \n        \n      \n    \n    \n      \n        \n          '{\"weather_forecast\":\"Sunny with a chance of rain\"}'\n        \n      \n      \n    \n  \n\n```\n\nThe above tests are a great start, but careful readers will notice that the is\nnever called since calls with a date in the past.\n\nTo fully exercise , we need to use to customise how the tools is called.\n\nHere's an example of using to test the tool with custom inputs\n\n```\n\n\n\n\n\n  \n  \n  \n  \n  \n\n    \n  \n    \n  \n  \n\n  \n     \n  \n     \n    # first call, call the weather forecast tool\n      \n       \n        \n          \n     \n       \n    \n  \n    # second call, return the forecast\n      \n       \n     \n\n  \n    \n    \n    \n      'What will the weather be like in London on 2032-01-01?'\n       \n     \n     'The forecast is: Rainy with a chance of sun'\n\n```\n\n### Overriding model via pytest fixtures\n\nIf you're writing lots of tests that all require model to be overridden, you can\nuse to override the model with or in a reusable way.\n\nHere's an example of a fixture that overrides the model with :\n\n\"Evals\" refers to evaluating a models performance for a specific application.\n\nUnlike unit tests, evals are an emerging art/science; anyone who claims to know\nfor sure exactly how your evals should be defined can safely be ignored.\n\nEvals are generally more like benchmarks than unit tests, they never \"pass\"\nalthough they do \"fail\"; you care mostly about how they change over time.\n\nSince evals need to be run against the real model, then can be slow and\nexpensive to run, you generally won't want to run them in CI for every commit.\n\nThe hardest part of evals is measuring how well the model has performed.\n\nIn some cases (e.g. an agent to generate SQL) there are simple, easy to run\ntests that can be used to measure performance (e.g. is the SQL valid? Does it\nreturn the right results? Does it return just the right results?).\n\nIn other cases (e.g. an agent that gives advice on quitting smoking) it can be\nvery hard or impossible to make quantitative measures of performance — in the\nsmoking case you'd really need to run a double-blind trial over months, then\nwait 40 years and observe health outcomes to know if changes to your prompt were\nan improvement.\n\nThere are a few different strategies you can use to measure performance:\n\n  * **End to end, self-contained tests** — like the SQL example, we can test the final result of the agent near-instantly\n  * — writing unit test style checks that the output is as expected, checks like , while these checks might seem simplistic they can be helpful, one nice characteristic is that it's easy to tell what's wrong when they fail\n  * — using another models, or even the same model with a different prompt to evaluate the performance of the agent (like when the class marks each other's homework because the teacher has a hangover), while the downsides and complexities of this approach are obvious, some think it can be a useful tool in the right circumstances\n  * — measuring the end results of the agent in production, then creating a quantitative measure of performance, so you can easily measure changes over time as you change the prompt or model used, can be extremely useful in this case since you can write a custom query to measure the performance of your agent\n\nThe system prompt is the developer's primary tool in controlling an agent's\nbehavior, so it's often useful to be able to customise the system prompt and see\nhow performance changes. This is particularly relevant when the system prompt\ncontains a list of examples and you want to understand how changing that list\naffects the model's performance.\n\nLet's assume we have the following app for running SQL generated from a user\nprompt (this examples omits a lot of details for brevity, see the example for a\nmore complete code):\n\n```\n\n\n\n  \n  \n    \n  \n\n  \n  \n              \n  \n       \n      # if examples aren't provided, load them from file, this is the default\n         \n          \n    \n        \n      \n      \n     \n table of records, your job is to\n\nwrite a SQL query that suits the user's request.\n\n  \n        \n     \n\n  \n  \n  \n\n     \n  \n\n      \n\"\"\"Search the database based on the user's prompts.\"\"\"\n\n  \n      \n    \n    \n\n```\n\n```\n\nrequest: show me error records with the tag \"foobar\"\n\nresponse: SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)\n\n```\n\n```\n\n\"Show me all records from 2021\"\n\n\"SELECT * FROM records WHERE date_trunc('year', date) = '2021-01-01';\"\n\n\"show me error records with the tag 'foobar'\"\n\n\"SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags);\"\n\n```\n\nNow we want a way to quantify the success of the SQL generation so we can judge\nhow changes to the agent affect its performance.\n\nWe can use to replace the system prompt with a custom one that uses a subset of\nexamples, and then run the application code (in this case ). We also run the\nactual SQL from the examples and compare the \"correct\" result from the example\nSQL to the SQL generated by the agent. (We compare the results of running the\nSQL rather than the SQL itself since the SQL might be semantically equivalent\nbut written in a different way).\n\nTo get a quantitative measure of performance, we assign points to each run as\nfollows: * points if the generated SQL is invalid * point for each row returned\nby the agent (so returning lots of results is discouraged) * points for each row\nreturned by the agent that matches the expected result\n\nWe use 5-fold cross-validation to judge the performance of the agent using our\nexisting set of examples.\n\n```\n\n\n\n\n\n  \n  \n    \n     \n\n  \n     \n      \n  # split examples into 5 folds\n\n      \n              \n    \n    \n       \n      \n    # build all other folds into a list of examples\n               \n    # create a new system prompt with the other fold examples\n      \n    # override the system prompt with the new one\n     \n         \n        \n             \n           \n          \n            \n        \n          # get the expected results using the SQL from this case\n             \n              \n        # each returned value has a score of -1\n          \n              \n        # each return value that matches the expected value has a score of 3\n              \n    \n    \n  \n  \n\n```\n\nWe can then change the prompt, the model, or the examples and see how the score\nchanges over time.\n\n---\n\n# Debugging and Monitoring\nURL: https://ai.pydantic.dev/logfire/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nApplications that use LLMs have some challenges that are well known and\nunderstood: LLMs are , and .\n\nThese applications also have some challenges that most developers have\nencountered much less often: LLMs are and . Subtle changes in a prompt can\ncompletely change a model's performance, and there's no query you can run to\nunderstand why.\n\nFrom a software engineers point of view, you can think of LLMs as the worst\ndatabase you've ever heard of, but worse.\n\nIf LLMs weren't so bloody useful, we'd never touch them.\n\nTo build successful applications with LLMs, we need new tools to understand both\nmodel performance, and the behavior of applications that rely on them.\n\nLLM Observability tools that just let you understand how your model is\nperforming are useless: making API calls to an LLM is easy, it's building that\ninto an application that's hard.\n\nis an observability platform developed by the team who created and maintain\nPydantic and PydanticAI. Logfire aims to let you understand your entire\napplication: Gen AI, classic predictive AI, HTTP traffic, database queries and\neverything else a modern application needs.\n\nPydantic Logfire is a commercial product\n\nLogfire is a commercially supported, hosted platform with an extremely generous\nand perpetual . You can sign up and start using Logfire in a couple of minutes.\n\nPydanticAI has built-in (but optional) support for Logfire via the no-op\npackage.\n\nThat means if the package is installed and configured, detailed information\nabout agent runs is sent to Logfire. But if the package is not installed,\nthere's virtually no overhead and nothing is sent.\n\nHere's an example showing details of running the in Logfire:\n\nTo use logfire, you'll need a logfire , and logfire installed:\n\nThen authenticate your local environment with logfire:\n\nAnd configure a project to send data to:\n\n(Or use an existing project with )\n\nThe last step is to add logfire to your code:\n\nThe has more details on how to use logfire, including how to instrument other\nlibraries like Pydantic, HTTPX and FastAPI.\n\nSince Logfire is build on , you can use the Logfire Python SDK to send data to\nany OpenTelemetry collector.\n\nOnce you have logfire set up, there are two primary ways it can help you\nunderstand your application:\n\n  * — Using the live view to see what's happening in your application in real-time.\n  * — Using SQL and dashboards to observe the behavior of your application, Logfire is effectively a SQL database that stores information about how your application is running.\n\nTo demonstrate how Logfire can let you visualise the flow of a PydanticAI run,\nhere's the view you get from Logfire while running the :\n\nWe can also query data with SQL in Logfire to monitor the performance of an\napplication. Here's a real world example of using Logfire to monitor PydanticAI\nruns inside Logfire itself:\n\n---\n\n# Multi-agent Applications\nURL: https://ai.pydantic.dev/multi-agent-applications/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nThere are roughly four levels of complexity when building applications with\nPydanticAI:\n\n  1. Single agent workflows — what most of the documentation covers\n  2. — agents using another agent via tools\n  3. — one agent runs, then application code calls another agent\n  4. — for the most complex cases, a graph-based state machine can be used to control the execution of multiple agents\n\nOf course, you can combine multiple strategies in a single application.\n\n\"Agent delegation\" refers to the scenario where an agent delegates work to\nanother agent, then takes back control when the delegate agent (the agent called\nfrom within a tool) finishes.\n\nSince agents are stateless and designed to be global, you do not need to include\nthe agent itself in agent .\n\nYou'll generally want to pass to the keyword argument of the delegate agent run\nso usage within that run counts towards the total usage of the parent agent run.\n\nAgent delegation doesn't need to use the same model for each agent. If you\nchoose to use different models within a run, calculating the monetary cost from\nthe final of the run will not be possible, but you can still use to avoid\nunexpected costs.\n\n```\n\n    \n  \n  \n  \n  \n    'Use the `joke_factory` to generate some jokes, then choose the best. '\n    'You must return just a single joke.'\n  \n\n    \n\n       \n      \n    \n     \n  \n    \n\n  \n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n  requests=3, request_tokens=204, response_tokens=24, total_tokens=228,\ndetails=None\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe control flow for this example is pretty simple and can be summarised as\nfollows:\n\nGenerally the delegate agent needs to either have the same as the calling agent,\nor dependencies which are a subset of the calling agent's dependencies.\n\nWe say \"generally\" above since there's nothing to stop you initializing\ndependencies within a tool call and therefore using interdependencies in a\ndelegate agent that are not available on the parent, this should often be\navoided since it can be significantly slower than reusing connections etc. from\nthe parent agent.\n\n```\n\n  \n\n\n    \n\n  \n  \n  \n\n  \n  \n  \n  \n    'Use the `joke_factory` tool to generate some jokes on the given subject, '\n    'then choose the best. You must return just a single joke.'\n  \n\n  \n  \n  \n  \n  \n    'Use the \"get_jokes\" tool to get some jokes on the given subject, '\n    'then extract each joke into a list.'\n  \n\n       \n     \n    \n     \n    \n  \n  \n\n\n\n       \n     \n    \n     \n     \n  \n  \n  \n\n  \n      \n       \n        \n    \n    #> Did you hear about the toothpaste scandal? They called it Colgate.\n     \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThis example shows how even a fairly simple agent delegation can lead to a\ncomplex control flow:\n\n\"Programmatic agent hand-off\" refers to the scenario where multiple agents are\ncalled in succession, with application code and/or a human in the loop\nresponsible for deciding which agent to call next.\n\nHere agents don't need to use the same deps.\n\nHere we show two agents used in succession, the first to find a flight and the\nsecond to extract the user's seat preference.\n\n```\n\n    \n    \n  \n    \n  \n    \n\n\n\n  \n\n\n\n\"\"\"Unable to find a satisfactory choice.\"\"\"\n\n     \n  \n    \n  \n    'Use the \"flight_search\" tool to find a flight '\n    'from the given origin to the given destination.'\n  \n\n\n\n  \n       \n  \n  # in reality, this would call a flight search API or\n\n  # use a browser to scrape a flight search website\n\n  \n\n  \n\n       \n      \n     \n      \n      'Where would you like to fly from and to?'\n    \n       \n      \n      \n      \n      \n    \n      \n       \n    \n        \n        \n      \n\n\n\n      \n        \n\n# This agent is responsible for extracting the user's seat selection\n\n     \n  \n    \n  \n    \"Extract the user's seat preference. \"\n    'Seats A and F are window seats. '\n    'Row 1 is the front row and has extra leg room. '\n    'Rows 14, and 20 also have extra leg room. '\n  \n\n      \n      \n  \n      'What seat would you like?'\n       \n      \n      \n      \n      \n    \n      \n       \n    \n      'Could not understand seat preference. Please try again.'\n        \n\n  \n     \n     \n      \n    \n    \n       \n    \n    #> Seat preference: row=1 seat='A'\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThe control flow for this example can be summarised as follows:\n\nSee the documentation on when and how to use graphs.\n\nThe following examples demonstrate how to use dependencies in PydanticAI:\n\n---\n\n# Graphs\nURL: https://ai.pydantic.dev/graph/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nDon't use a nail gun unless you need a nail gun\n\nIf PydanticAI are a hammer, and are a sledgehammer, then graphs are a nail gun:\n\n  * sure, nail guns look cooler than hammers\n  * but nail guns take a lot more setup than hammers\n  * and nail guns don't make you a better builder, they make you a builder with a nail gun\n  * Lastly, (and at the risk of torturing this metaphor), if you're a fan of medieval tools like mallets and untyped Python, you probably won't like nail guns or our approach to graphs. (But then again, if you're not a fan of type hints in Python, you've probably already bounced off PydanticAI to use one of the toy agent frameworks — good luck, and feel free to borrow my sledgehammer when you realize you need it)\n\nIn short, graphs are a powerful tool, but they're not the right tool for every\njob. Please consider other before proceeding.\n\nIf you're not confident a graph-based approach is a good idea, it might be\nunnecessary.\n\nGraphs and finite state machines (FSMs) are a powerful abstraction to model,\nexecute, control and visualize complex workflows.\n\nAlongside PydanticAI, we've developed — an async graph and state machine library\nfor Python where nodes and edges are defined using type hints.\n\nWhile this library is developed as part of PydanticAI; it has no dependency on\nand can be considered as a pure graph-based state machine library. You may find\nit useful whether or not you're using PydanticAI or even building with GenAI.\n\nis designed for advanced users and makes heavy use of Python generics and types\nhints. It is not designed to be as beginner-friendly as PydanticAI.\n\nGraph support was in v0.0.19 and is in very earlier beta. The API is subject to\nchange. The documentation is incomplete. The implementation is incomplete.\n\nis a required dependency of , and an optional dependency of , see for more\ninformation. You can also install it directly:\n\nmade up of a few key components:\n\n— The context for the graph run, similar to PydanticAI's . This holds the state\nof the graph and dependencies and is passed to nodes when they're run.\n\nis generic in the state type of the graph it's used in, .\n\n— return value to indicate the graph run should end.\n\nis generic in the graph return type of the graph it's used in, .\n\nSubclasses of define nodes for execution in the graph.\n\nNodes, which are generally , generally consist of:\n\n  * fields containing any parameters required/optional when calling the node\n  * the business logic to execute the node, in the method\n  * return annotations of the method, which are read by to determine the outgoing edges of the node\n\n  * , which must have the same type as the state of graphs they're included in, has a default of , so if you're not using state you can omit this generic parameter, see for more information\n  * , which must have the same type as the deps of the graph they're included in, has a default of , so if you're not using deps you can omit this generic parameter, see for more information\n  * — this only applies if the node returns . has a default of so this generic parameter can be omitted if the node doesn't return , but must be included if it does.\n\nHere's an example of a start or intermediate node in a graph — it can't end the\nrun as it doesn't return :\n\nWe could extend to optionally end the run if is divisible by 5:\n\n— this is the execution graph itself, made up of a set of (i.e., subclasses).\n\n  * the state type of the graph, \n  * the deps type of the graph, \n  * the return type of the graph run, \n\nHere's an example of a simple graph:\n\n```\n\n  \n  \n      \n\n    \n  \n    \n    \n     \n      \n         \n       \n    \n       \n\n  \n  \n        \n       \n\n    \n    \n\n# the full history is quite verbose (see below), so we'll just print the summary\n\n    \n#> [DivisibleBy5(foo=4), Increment(foo=4), DivisibleBy5(foo=5), End(data=5)]\n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+)_\n\nA for this graph can be generated with the following code:\n\nThe \"state\" concept in provides an optional way to access and mutate an object\n(often a or Pydantic model) as nodes run in a graph. If you think of Graphs as a\nproduction line, then you state is the engine being passed along the line and\nbuilt up by each node as the graph is run.\n\nIn the future, we intend to extend to provide state persistence with the state\nrecorded after each node is run, see .\n\nHere's an example of a graph which represents a vending machine where the user\nmay insert coins and select a product to purchase.\n\n```\n\n  \n  \n  \n      \n\n  \n     \n       \n\n  \n         \n      \n\n\n\n    \n    \n      \n       \n       \n         \n       \n    \n       \n\n\n\n        \n     \n\n  \n  \n  \n  \n  \n\n    \n  \n    \n      \n        \n        \n         \n          \n          \n         \n      \n            \n        \n        #> Not enough money for crisps, need 0.75 more\n          \n    \n      \n        \n\n  \n     \n\n  \n     \n     \n  \n  #> purchase successful item=crisps change=0.25\n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+ — you'll\nneed to add to run )_\n\nA for this graph can be generated with the following code:\n\nThe diagram generated by the above code is:\n\nSee for more information on generating diagrams.\n\nSo far we haven't shown an example of a Graph that actually uses PydanticAI or\nGenAI at all.\n\nIn this example, one agent generates a welcome email to a user and the other\nagent provides feedback on the email.\n\nThis graph has a very simple structure:\n\n```\n\n     \n    \n    \n  \n  \n  \n      \n\n\n\n  \n  \n  \n\n\n\n  \n  \n\n\n\n  \n     \n\n  \n  \n  \n  'Write a welcome email to our tech blog.'\n\n\n\n       \n        \n     \n        \n        'Rewrite the email for the user:\n        \n        \n      \n    \n        \n        'Write a welcome email for the user:\n        \n      \n       \n      \n      \n    \n      \n     \n\n\n\n  \n\n\n\n  \n\n     \n  \n     \n  \n    'Review the email and provide feedback, email must reference the users specific interests.'\n  \n\n  \n  \n    \n    \n     \n      \n         \n       \n      \n       \n    \n       \n\n  \n    \n    \n    \n      \n  \n    \n     \n       \n  \n\n    subject='Welcome to our tech blog!',\n    body='Hello John, Welcome to our tech blog! ...',\n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+ — you'll\nneed to add to run )_\n\nIn many real-world applications, Graphs cannot run uninterrupted from start to\nfinish — they might require external input, or run over an extended period of\ntime such that a single process cannot execute the entire graph run from start\nto finish without interruption.\n\nIn these scenarios the method can be used to run the graph one node at a time.\n\nIn this example, an AI asks the user a question, the user provides an answer,\nthe AI evaluates the answer and ends if the user got it right or asks another\nquestion if they got it wrong.\n\n```\n\n     \n    \n      \n  \n  \n  \n  \n\n\n\n       \n     \n     \n\n\n\n        \n       \n      'Ask a simple question with a single correct answer.'\n      \n    \n      \n      \n     \n\n\n\n  \n       \n        \n        \n     \n\n\n\n  \n  \n\n  \n  \n  \n  'Given a question and answer, evaluate if the answer is correct.'\n\n\n\n  \n    \n    \n     \n      \n        \n       \n         \n      \n    \n      \n     \n       \n    \n       \n\n\n\n  \n        \n    \n      \n     \n\n     \n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+)_\n\n```\n\n  \n    \n      \n\n  \n     \n     \n      \n  \n          \n      \n         \n       \n      \n      #> Correct answer! Well done, 1 + 1 = 2\n          \n\n        Answer(question='What is the capital of France?', answer='Vichy'),\n\n        Reprimand(comment='Vichy is no longer the capital of France.'),\n\n        Answer(question='what is 1 + 1?', answer='2'),\n\n      \n    \n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+ — you'll\nneed to add to run )_\n\nA for this graph can be generated with the following code:\n\nYou maybe have noticed that although this examples transfers control flow out of\nthe graph run, we're still using to get user input, with the process hanging\nwhile we wait for the user to enter a response. For an example of genuine out-\nof-process control flow, see the .\n\nAs with PydanticAI, supports dependency injection via a generic parameter on and\n, and the fields.\n\nAs an example of dependency injection, let's modify the example to use a to run\nthe compute load in a separate process (this is a contrived example, wouldn't\nactually improve performance in this example):\n\n```\n\n  \n\n\n  \n      \n\n  \n  \n    \n    \n     \n      \n         \n       \n    \n       \n\n\n\n  \n        \n      \n    \n     \n     \n       \n\n  \n\n      \n         \n  \n  \n  # the full history is quite verbose (see below), so we'll just print the\nsummary\n\n      \n\n```\n\n_(This example is complete, it can be run \"as is\" with Python 3.10+ — you'll\nneed to add to run )_\n\nPydantic Graph can generate diagrams for graphs, as shown above.\n\nThese diagrams can be generated with:\n\n  * to generate the mermaid code for a graph\n  * to generate an image of the graph using \n  * to generate an image of the graph using and save it to a file\n\nBeyond the diagrams shown above, you can also customize mermaid diagrams with\nthe following options:\n\n  * allows you to apply a label to an edge\n  * and allows you to add notes to nodes\n  * The parameter allows you to highlight specific node(s) in the diagram\n\nPutting that together, we can edit the last example to:\n\n  * add labels to some edges\n  * add a note to the node\n  * save the diagram as a image to file\n\n```\n\n\n\n    \n      \n    \n\n\n\n  \n    \n      \n       \n    \n\n```\n\n_(This example is not complete and cannot be run directly)_\n\nWould generate and image that looks like this:\n\n---\n\n# Examples\nURL: https://ai.pydantic.dev/examples/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nExamples of how to use PydanticAI and what it can do.\n\nThese examples are distributed with so you can run them either by cloning the or\nby simply installing from PyPI with or .\n\nEither way you'll need to install extra dependencies to run some examples, you\njust need to install the optional dependency group.\n\nIf you've installed via pip/uv, you can install the extra dependencies with:\n\nIf you clone the repo, you should instead use to install extra dependencies.\n\nThese examples will need you to set up authentication with one or more of the\nLLMs, see the docs for details on how to do this.\n\nTL;DR: in most cases you'll need to set one of the following environment\nvariables:\n\nTo run the examples (this will work whether you installed , or cloned the repo),\nrun:\n\nFor examples, to run the very simple example:\n\nIf you like one-liners and you're using uv, you can run a pydantic-ai example\nwith zero setup:\n\nYou'll probably want to edit examples in addition to just running them. You can\ncopy the examples to a new directory with:\n\n---\n\n# Pydantic Model\nURL: https://ai.pydantic.dev/examples/pydantic-model/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nSimple example of using PydanticAI to construct a Pydantic model from a text\ninput.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/pydantic-model/<../#usage>), run:\n\nThis examples uses by default, but it works well with other models, e.g. you can\nrun it with Gemini using:\n\n```\n\n\n\n  \n\n\n  \n  \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n\n\n  \n  \n\n    \n\n  \n  \n    'The windy city in the US of A.'\n  \n  \n\n```\n\n---\n\n# Weather agent\nURL: https://ai.pydantic.dev/examples/weather-agent/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nExample of PydanticAI with multiple tools which the LLM needs to call in turn to\nanswer a question.\n\n  * Building a UI for the agent\n\nIn this case the idea is a \"weather\" agent — the user can ask for the weather in\nmultiple locations, the agent will use the tool to get the latitude and\nlongitude of the locations, then use the tool to get the weather for those\nlocations.\n\nTo run this example properly, you might want to add two extra API keys **(Note\nif either key is missing, the code will fall back to dummy data, so they're not\nrequired)** :\n\n  * A weather API key from set via \n  * A geocoding API key from set via \n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/weather-agent/<../#usage>), run:\n\n```\n\n     \n\n\n\n\n  \n  \n\n\n  \n  \n     \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n\n\n  \n     \n     \n\n  \n  \n  # 'Be concise, reply with one sentence.' is enough for some models (like\nopenai) to use\n\n  # the below tools appropriately, but others like anthropic and gemini require\na bit more direction.\n\n  \n    'Be concise, reply with one sentence.'\n    'Use the `get_lat_lng` tool to get the latitude and longitude of the locations, '\n    'then use the `get_weather` tool to get the weather.'\n  \n  \n  \n\n  \n     \n  \n\"\"\"Get the latitude and longitude of a location.\n\n    location_description: A description of a location.\n\n     \n    # if no API key is provided, return a dummy response (London)\n        \n    \n     \n     \n  \n      \n        \n    \n      \n     \n  \n        \n  \n     'Could not find the location'\n\n          \n\"\"\"Get the weather at a location.\n\n    lat: Latitude of the location.\n    lng: Longitude of the location.\n\n     \n    # if no API key is provided, return a dummy response\n        \n    \n     \n     \n     \n  \n      \n       \n       \n    \n    \n      \n     \n    \n  \n    \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n     \n  \n  \n     \n      \n  \n\n  \n      \n    # create a free API key at https://www.tomorrow.io/weather-api/\n      \n    # create a free API key at https://geocode.maps.co/\n      \n      \n        \n    \n       \n      'What is the weather like in London and in Wiltshire?' \n    \n    \n     \n\n  \n  \n\n```\n\nYou can build multi-turn chat applications for your agent with , a framework for\nbuilding AI web applications entirely in python. Gradio comes with built-in chat\ncomponents and agent support so the entire UI will be implemented in a single\npython file!\n\nHere's what the UI looks like for the weather agent:\n\nNote, to run the UI, you'll need Python 3.10+.\n\n---\n\n# Bank support\nURL: https://ai.pydantic.dev/examples/bank-support/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nSmall but complete example of using PydanticAI to build a support agent for a\nbank.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/bank-support/<../#usage>), run:\n\n```\n\n  \n    \n    \n\n\n\n\"\"\"This is a fake database for example purposes.\n\n  In reality, you'd be connecting to an external database\n\n  (e.g. PostgreSQL) to get information about customers.\n\n  \n           \n       \n       \n  \n           \n       \n       \n    \n       \n\n\n\n  \n  \n\n\n\n     'Advice returned to the customer'\n     \n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query. '\n    \"Reply using the customer's name.\"\n  \n\n     \n     \n  \n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n     \n    \n    \n  \n  \n\n  \n     \n     \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n    'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\n---\n\n# SQL Generation\nURL: https://ai.pydantic.dev/examples/sql-gen/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nExample demonstrating how to use PydanticAI to generate SQL queries based on\nuser input.\n\nThe resulting SQL is validated by running it as an query on PostgreSQL. To run\nthe example, you first need to run PostgreSQL, e.g. via Docker:\n\n_(we run postgres on port to avoid conflicts with any other postgres instances\nyou may have running)_\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/sql-gen/<../#usage>), run:\n\nor to use a custom prompt:\n\nThis model uses by default since Gemini is good at single shot queries of this\nkind.\n\n```\n\n\n\n\n\n  \n  \n  \n  \n     \n\n\n\n\n  \n  \n    \n  \n     \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n  \n\n  \n  \n     'show me records where foobar is false'\n     \"SELECT * FROM records WHERE attributes->>'foobar' = false\"\n  \n  \n     'show me records where attributes include the key \"foobar\"'\n     \"SELECT * FROM records WHERE attributes ? 'foobar'\"\n  \n  \n     'show me records from yesterday'\n     \"SELECT * FROM records WHERE start_timestamp::date > CURRENT_TIMESTAMP - INTERVAL '1 day'\"\n  \n  \n     'show me error records with the tag \"foobar\"'\n     \"SELECT * FROM records WHERE level = 'error' and 'foobar' = ANY(tags)\"\n  \n\n\n\n  \n\n\n\n\"\"\"Response when SQL could be successfully generated.\"\"\"\n\n    \n     \n     'Explanation of the SQL query, as markdown'\n  \n\n\n\n\"\"\"Response the user input didn't include enough information to generate SQL.\"\"\"\n\n  \n\n    \n    \n  \n  # Type ignore while we wait for PEP-0747, nonetheless unions will work fine\neverywhere else\n\n  \n  \n\n    \n  \nGiven the following PostgreSQL table of records, your job is to\n\nwrite a SQL query that suits the user's request.\n\n       \n    \n     \n  # gemini often adds extraneous backslashes to SQL\n\n     \n    \n     'Please create a SELECT query'\n  \n     \n     \n       \n  \n     \n\n  \n     \n      'show me logs from yesterday, with level \"error\"'\n  \n      \n    \n     \n    \n      \n        \n  \n\n        \n  \n       \n    \n         \n        'SELECT 1 FROM pg_database WHERE datname = $1' \n      \n        \n         \n    \n       \n     \n  \n     \n        \n          \n           \n            \"CREATE TYPE log_level AS ENUM ('debug', 'info', 'warning', 'error', 'critical')\"\n          \n         \n     \n  \n     \n\n  \n  \n\n```\n\n---\n\n# Flight booking\nURL: https://ai.pydantic.dev/examples/flight-booking/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nExample of a multi-agent flow where one agent delegates work to another, then\nhands off control to a third agent.\n\nIn this scenario, a group of agents work together to find the best flight for a\nuser.\n\nThe control flow for this example can be summarised as follows:\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/flight-booking/<../#usage>), run:\n\n```\n\n\n\n  \n  \n\n\n    \n  \n     \n  \n    \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n\n\n\"\"\"Details of the most suitable flight.\"\"\"\n\n  \n  \n     \n     \n  \n\n\n\n\"\"\"When no valid flight is found.\"\"\"\n\n\n\n  \n  \n  \n  \n\n# This agent is responsible for controlling the flow of the conversation.\n\n     \n  \n     \n  \n  \n    'Your job is to find the cheapest flight for the user on the given date. '\n  \n\n# This agent is responsible for extracting flight details from web page text.\n\n  \n  \n  \n  'Extract all the flight details from the given text.'\n\n     \n\"\"\"Get details of all flights.\"\"\"\n\n  # we pass the usage to the search agent so requests within this agent are\ncounted\n\n      \n  \n  \n\n  \n       \n    \n\"\"\"Procedural validation that the flight meets the constraints.\"\"\"\n\n    \n     \n     \n     \n    \n      \n    \n     \n    \n      \n    \n     \n    \n  \n     \n  \n     \n\n\n\n      \n        \n\n\n\n\"\"\"Unable to extract a seat selection.\"\"\"\n\n# This agent is responsible for extracting the user's seat selection\n\n  \n     \n\n  \n     \n  \n    \"Extract the user's seat preference. \"\n    'Seats A and F are window seats. '\n    'Row 1 is the front row and has extra leg room. '\n    'Rows 14, and 20 also have extra leg room. '\n  \n\n# in reality this would be downloaded from a booking site,\n\n# potentially using another agent to navigate the site\n\n  \n\n- Origin: San Francisco International Airport (SFO)\n- Destination: Ted Stevens Anchorage International Airport (ANC)\n- Date: January 10, 2025\n\n- Origin: San Francisco International Airport (SFO)\n- Destination: Fairbanks International Airport (FAI)\n- Date: January 10, 2025\n\n- Origin: San Francisco International Airport (SFO)\n- Destination: Juneau International Airport (JNU)\n- Date: January 20, 2025\n\n- Origin: San Francisco International Airport (SFO)\n- Destination: Ted Stevens Anchorage International Airport (ANC)\n- Date: January 10, 2025\n\n- Origin: Chicago O'Hare International Airport (ORD)\n- Destination: Miami International Airport (MIA)\n- Date: January 12, 2025\n\n- Origin: Boston Logan International Airport (BOS)\n- Destination: Ted Stevens Anchorage International Airport (ANC)\n- Date: January 12, 2025\n\n- Origin: Dallas/Fort Worth International Airport (DFW)\n- Destination: Denver International Airport (DEN)\n- Date: January 10, 2025\n\n- Origin: Hartsfield-Jackson Atlanta International Airport (ATL)\n- Destination: George Bush Intercontinental Airport (IAH)\n- Date: January 10, 2025\n\n# restrict how many requests this app can make to the LLM\n\n  \n\n  \n    \n    \n    \n    \n      \n  \n       \n     \n  # run the agent until a satisfactory flight is found\n\n  \n       \n      'Find me a flight from \n      \n      \n      \n      \n    \n      \n      \n      \n    \n        \n      \n        \n        'Do you want to buy this flight, or keep searching? (buy/*search)'\n          \n        \n      \n         \n           \n          \n        \n      \n          \n          \n        \n\n     \n       \n  \n      'What seat would you like?'\n       \n      \n      \n      \n      \n    \n      \n       \n    \n      'Could not understand seat preference. Please try again.'\n        \n\n     \n  \n\n  \n  \n  \n\n```\n\n---\n\n# RAG\nURL: https://ai.pydantic.dev/examples/rag/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nRAG search example. This demo allows you to ask question of the documentation.\n\nThis is done by creating a database containing each section of the markdown\ndocumentation, then registering the search tool with the PydanticAI agent.\n\nLogic for extracting sections from markdown files and a JSON file with that data\nis available in .\n\nis used as the search database, the easiest way to download and run pgvector is\nusing Docker:\n\nAs with the example, we run postgres on port to avoid conflicts with any other\npostgres instances you may have running. We also mount the PostgreSQL directory\nlocally to persist the data if you need to stop and restart the container.\n\nWith that running and [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/rag/<../#usage>), we can build the search\ndatabase with (: this requires the env variable and will calling the OpenAI\nembedding API around 300 times to generate embeddings for each section of the\ndocumentation):\n\n(Note building the database doesn't use PydanticAI right now, instead it uses\nthe OpenAI SDK directly.)\n\nYou can then ask the agent a question with:\n\n```\n\npython-mpydantic_ai_examples.ragsearch\"How do I configure logfire to work with\nFastAPI?\"\n\n```\n\n```\n\nuvrun-mpydantic_ai_examples.ragsearch\"How do I configure logfire to work with\nFastAPI?\"\n\n```\n\n```\n\n     \n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n\n\n  \n  \n\n  \n\n       \n\"\"\"Retrieve documentation sections based on a search query.\n\n  \n     \n  \n       \n      \n      \n    \n  \n      \n  \n    \n    \n     \n    'SELECT url, title, content FROM doc_sections ORDER BY embedding <-> $1 LIMIT 8'\n    \n  \n  \n    \n       \n  \n\n  \n\"\"\"Entry point to run the agent and perform RAG based question answering.\"\"\"\n\n    \n  \n  \n      \n       \n        \n  \n\n# The rest of this file is dedicated to preparing the #\n\n# search database, and some utilities.        #\n\n  \n  \n  \n  \n\n  \n\n      \n       \n    \n    \n    \n  \n      \n     \n          \n          \n           \n      \n        \n         \n           \n\n  \n  \n  \n  \n  \n  \n    \n      \n       'SELECT 1 FROM doc_sections WHERE url = $1' \n     \n       \n      \n      \n         \n        \n        \n      \n     \n        \n     \n      \n      \n     \n      'INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)'\n      \n      \n      \n      \n    \n\n\n\n  \n     \n  \n  \n  \n  \n     \n        \n     \n      \n    \n     \n       \n\n  \n\n  \n     \n  \n     \n    \n    \n  \n  \n     \n         \n      \n           \n          'SELECT 1 FROM pg_database WHERE datname = $1' \n        \n          \n           \n      \n         \n     \n  \n     \n  \n     \n\n  \nCREATE EXTENSION IF NOT EXISTS vector;\n\nCREATE TABLE IF NOT EXISTS doc_sections (\n\n  url text NOT NULL UNIQUE,\n\n  -- text-embedding-3-small returns a vector of 1536 floats\n\nCREATE INDEX IF NOT EXISTS idx_doc_sections_embedding ON doc_sections USING hnsw\n(embedding vector_l2_ops);\n\n          \n\"\"\"Slugify a string, to make it URL friendly.\"\"\"\n\n  # Taken unchanged from https://github.com/Python-\nMarkdown/markdown/blob/3.7/markdown/extensions/toc.py#L38\n\n    \n    # Replace Extended Latin characters with ASCII, i.e. `žlutý` => `zluty`\n       \n       \n      \n     \n\n  \n          \n     \n    \n     \n       \n        \n    \n        'How do I configure logfire to work with FastAPI?'\n    \n  \n    \n      'uv run --extra examples -m pydantic_ai_examples.rag build|search'\n      \n    \n    \n\n```\n\n---\n\n# Stream markdown\nURL: https://ai.pydantic.dev/examples/stream-markdown/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nThis example shows how to stream markdown from an agent, using the library to\nhighlight the output in the terminal.\n\nIt'll run the example with both OpenAI and Google Gemini models if the required\nenvironment variables are set.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/stream-markdown/<../#usage>), run:\n\n```\n\n\n\n\n\n\n\n     \n  \n    \n  \n  \n  \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n  \n# models to try, and the appropriate env var\n\n    \n  \n  \n  \n\n  \n  \n    \n    'Show me a short example of using Pydantic.'\n  \n      \n       \n      \n           \n             \n              \n            \n      \n    \n      \n\n\n\n\"\"\"Make rich code blocks prettier and easier to copy.\n\n  \n     \n          \n      \n        \n        \n       \n        \n        \n        \n        \n        \n      \n        \n    \n\n  \n  \n\n```\n\n---\n\n# Stream whales\nURL: https://ai.pydantic.dev/examples/stream-whales/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nInformation about whales — an example of streamed structured response\nvalidation.\n\nThis script streams structured responses from GPT-4 about whales, validates the\ndata and displays it as a dynamic table using as the data is received.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/stream-whales/<../#usage>), run:\n\nShould give an output like this:\n\n```\n\n  \n\n\n    \n  \n  \n  \n    \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n\n\n  \n  \n     'Average length of an adult whale in meters.'\n  \n  \n    \n      \n      'Average weight of an adult whale in kilograms.' \n    \n  \n  \n    \n\n  \n\n  \n    \n        \n     \n      \n      'Generate me details of 5 species of Whale.'\n      \n       \n           \n        \n             \n              \n          \n           \n           \n                  \n               \n          \n            \n          \n            \n          \n          \n          'Streaming Structured responses from GPT-4'\n          \n        \n         \n        \n         \n         \n        \n         \n             \n          \n            \n            \n            \n                  \n              \n              \n          \n        \n\n  \n  \n  \n\n```\n\n---\n\n# Chat App with FastAPI\nURL: https://ai.pydantic.dev/examples/chat-app/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nSimple chat app example build with FastAPI.\n\nThis demonstrates storing chat history between requests and using it to give the\nmodel context for new responses.\n\nMost of the complex logic here is between which streams the response to the\nbrowser, and which renders messages in the browser.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/chat-app/<../#usage>), run:\n\nThen open the app at .\n\nPython code that runs the chat app:\n\n```\n\n     \n\n\n\n\n\n\n  \n  \n  \n  \n    \n  \n  \n       \n\n\n\n\n    \n     \n     \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n  \n  \n\n  \n      \n      \n\n  \n\n    \n      \n\n    \n\"\"\"Get the raw typescript code, it's compiled in the browser, forgive me.\"\"\"\n\n      \n\n     \n  \n\n       \n     \n  \n        \n    \n  \n\n\n\n\"\"\"Format of messages sent to the browser.\"\"\"\n\n    \n  \n  \n\n    \n    \n    \n      \n       \n         \n         \n         \n      \n    \n      \n       \n         \n         \n         \n      \n   'Unexpected message type for chat app:\n\n  \n        \n  \n    \n\"\"\"Streams new line delimited JSON `Message`s to the client.\"\"\"\n\n    # stream the user prompt so that can be displayed straight away\n     \n      \n        \n           \n           \n           \n        \n      \n       \n    \n    # get the chat history so far to pass as context to the agent\n       \n    # run the agent with the user prompt and the chat history\n         \n          \n        # text here is a `str` and the frontend wants\n        # JSON encoded ModelResponse, so we create one\n           \n           \n    # add new messages (e.g. the user prompt and the agent response in this case) to the database\n     \n    \n\n  \n  \n\n\n\n\"\"\"Rudimentary database to store chat messages in SQLite.\n\n  The SQLite standard library package is synchronous, so we\n\n  use a thread pool executor to run queries asynchronously.\n\n  \n  \n  \n  \n  \n    \n          \n    \n     \n        \n        \n           \n          \n    \n       \n    \n       \n  \n      \n      \n      \n      \n    \n      'CREATE TABLE IF NOT EXISTS messages (id INT PRIMARY KEY, message_list TEXT);'\n    \n    \n     \n      \n     \n      \n      'INSERT INTO messages (message_list) VALUES (?);'\n      \n      \n    \n     \n      \n       \n       'SELECT message_list FROM messages order by id'\n    \n       \n       \n       \n      \n     \n  \n            \n    \n      \n     \n     \n      \n     \n    \n           \n    \n       \n      \n       \n       \n    \n\n  \n  \n  \n      \n  \n\n```\n\nSimple HTML page to render the app:\n\n```\n\n\n\n  \n  \n Chat App\n\n  \n\n\n  \"border rounded mx-auto my-5 p-4\"\n\n  Chat App\n\n  Ask me anything...\n\n    \n  \n    \n  \n  \n      \n    \n     Send\n  \n  \n    \n   Error occurred, check the browser developer console for more information.\n\n  \n\n\n  \n\n\n// to let me write TypeScript, without adding the burden of npm we do a dirty,\nnon-production-ready hack\n\n// and transpile the TypeScript code in the browser\n\n// this is (arguably) A neat demo trick, but not suitable for production!\n\n```\n\nTypeScript to handle rendering the messages, to keep this simple (and at the\nrisk of offending frontend developers) the typescript code is passed to the\nbrowser as plain text and transpiled in the browser.\n\n```\n\n// BIG FAT WARNING: to avoid the complexity of npm, this typescript is compiled\nin the browser\n\n// there's currently no static type checking\n\n// stream the response and render messages as each chunk is received\n\n// data is sent as newline-delimited JSON\n\n// The format of messages, this matches pydantic-ai both for brevity and\nunderstanding\n\n// in production, you might not want to keep this format all the way to the\nfrontend\n\n// take raw response text and render messages into the `#conversation` element\n\n// Message timestamp is assumed to be a unique identifier of a message, and is\nused to deduplicate\n\n// hence you can send data about the same message multiple times, and it will be\nupdated\n\n// instead of creating a new message elements\n\n// we use the timestamp as a crude element id\n\n// call onSubmit when the form is submitted (e.g. user clicks the send button or\nhits Enter)\n\n// load messages on page load\n\n```\n\n---\n\n# Question Graph\nURL: https://ai.pydantic.dev/examples/question-graph/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nExample of a graph for asking and evaluating questions.\n\nWith [dependencies installed and environment variables\nset](https://ai.pydantic.dev/examples/question-graph/<../#usage>), run:\n\n```\n\n     \n    \n  \n  \n\n\n  \n        \n  \n  \n  \n# 'if-token-present' means nothing will be sent (and the example will work) if\nyou don't have logfire configured\n\n  \n\n\n\n       \n     \n     \n\n\n\n        \n       \n      'Ask a simple question with a single correct answer.'\n      \n    \n      \n      \n     \n\n\n\n       \n        \n        \n     \n\n\n\n  \n  \n\n  \n  \n  \n  'Given a question and answer, evaluate if the answer is correct.'\n\n\n\n  \n    \n    \n     \n      \n        \n       \n         \n      \n    \n      \n     \n       \n    \n       \n\n  \n  \n    \n      \n     \n    \n     \n\n\n\n  \n        \n    \n    # > Comment: Vichy is no longer the capital of France.\n      \n     \n\n  \n       \n\n  \n    \n    \n      \n  \n     \n           \n        \n            \n        \n        \n         \n          \n      \n\n     \n    \n    \n    \n     \n     \n  \n  \n      \n        'expected last step to be a node'\n      \n         'answer is required to continue from history'\n      \n  \n      \n      \n  \n  \n     \n           \n        \n            \n        \n        \n        \n        \n        \n      \n  \n\n  \n  \n  \n  \n      \n         \n    \n    \n      \n      ' uv run -m pydantic_ai_examples.question_graph mermaid\n      \n      ' uv run -m pydantic_ai_examples.question_graph continuous\n      \n      ' uv run -m pydantic_ai_examples.question_graph cli [answer]'\n      \n    \n    \n     \n    \n     \n    \n  \n            \n    \n\n```\n\nThe mermaid diagram generated in this example looks like this:\n\n---\n\n# pydantic_ai.agent\nURL: https://ai.pydantic.dev/api/agent/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nClass for defining \"agents\" - a way to have a specific type of \"conversation\"\nwith an LLM.\n\nAgents are generic in the dependency type they take and the result data type\nthey return, .\n\nBy default, if neither generic parameter is customised, agents have type .\n\n```\n\n  \n  \n  'What is the capital of France?'\n\n```\n\n```\n\n  \n\"\"\"Class for defining \"agents\" - a way to have a specific type of \"conversation\"\nwith an LLM.\n\n  Agents are generic in the dependency type they take\n[`AgentDeps`][pydantic_ai.tools.AgentDeps]\n\n  and the result data type they return,\n[`ResultData`][pydantic_ai.result.ResultData].\n\n  By default, if neither generic parameter is customised, agents have type\n`Agent[None, str]`.\n\n  result = agent.run_sync('What is the capital of France?')\n\n  # we use dataclass fields in order to conveniently know what attributes are\navailable\n\n       \n\"\"\"The default model configured for this agent.\"\"\"\n\n     \n\"\"\"The name of the agent, used for logging.\n\n  If `None`, we try to infer the agent name from the call frame when the agent\nis first run.\n\n  \n\"\"\"Strategy for handling tool calls when a final result is found.\"\"\"\n\n     \n\"\"\"Optional model request settings to use for this agents's runs, by default.\n\n  Note, if `model_settings` is provided by `run`, `run_sync`, or `run_stream`,\nthose settings will\n\n  be merged with this value, with the runtime argument taking priority.\n\n     \n       \n       \n      \n      \n      \n     \n     \n      \n    \n  \n     \n     \n      \n      \n  \n    \n           \n    \n       \n         \n       \n         \n         \n       \n       \n         \n         \n          \n       \n       \n  \n\n      model: The default model to use for this agent, if not provide,\n        you must provide the model when calling it.\n      result_type: The type of the result data, used to validate the result data, defaults to `str`.\n      system_prompt: Static system prompts to use for this agent, you can also register system\n        prompts via a function with [`system_prompt`][pydantic_ai.Agent.system_prompt].\n      deps_type: The type used for dependency injection, this parameter exists solely to allow you to fully\n        parameterize the agent, and therefore get the best out of static type checking.\n        If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright\n        or add a type hint `: Agent[None, <return type>]`.\n      name: The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame\n        when the agent is first run.\n      model_settings: Optional model request settings to use for this agent's runs, by default.\n      retries: The default number of retries to allow before raising an error.\n      result_tool_name: The name of the tool to use for the final result.\n      result_tool_description: The description of the final result tool.\n      result_retries: The maximum number of retries to allow for result validation, defaults to `retries`.\n      tools: Tools to register with the agent, you can also register tools via the decorators\n\n      defer_model_check: by default, if you provide a [named][pydantic_ai.models.KnownModelName] model,\n        it's evaluated to create a [`Model`][pydantic_ai.models.Model] instance immediately,\n        which checks for the necessary environment variables. Set this to `false`\n        to defer the evaluation until the first run. Useful if you want to\n        [override the model][pydantic_ai.Agent.override] for testing.\n      end_strategy: Strategy for handling tool calls that are requested alongside a final result.\n        See [`EndStrategy`][pydantic_ai.agent.EndStrategy] for more information.\n\n         \n        \n    \n        \n      \n      \n      \n      \n      \n      \n        \n    \n           \n      \n      \n       \n        \n        \n      \n        \n      \n      \n      \n             \n      \n  \n    \n    \n     \n    \n       \n         \n           \n       \n         \n         \n         \n       \n     \n  \n    \n    \n     \n    \n     \n         \n           \n       \n         \n         \n         \n       \n     \n    \n    \n     \n    \n         \n           \n       \n         \n         \n         \n         \n       \n    \n\"\"\"Run the agent with a user prompt in async mode.\n\n      result = await agent.run('What is the capital of France?')\n\n      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n        result validators since result validators would expect an argument that matches the agent's result type.\n      user_prompt: User input to start/continue the conversation.\n      message_history: History of the conversation so far.\n      model: Optional model to use for this run, required if `model` was not set when creating the agent.\n      deps: Optional dependencies to use for this run.\n      model_settings: Optional settings to use for this model's request.\n      usage_limits: Optional limits on model request count or token usage.\n      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n      infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n      The result of the run.\n\n         \n      \n       \n      \n          \n      \n     \n      \n      \n      \n      \n        \n      \n             \n           \n        \n         \n          \n         \n          \n       \n        \n          \n         'preparing model and tools {run_step=}' \n              \n            \n               \n           \n           \n        \n         \n        \n            \n              \n              \n          \n           \n            # Add parts to the conversation as a new message\n            \n          # Check if we got a final result\n              \n              \n              \n             \n             \n             \n              'handle model response -> final result'\n             \n                  \n            \n          \n            \n             \n                  \n              \n  \n  \n    \n     \n    \n         \n           \n       \n         \n         \n         \n       \n     \n  \n  \n    \n     \n    \n       \n         \n           \n       \n         \n         \n         \n       \n     \n  \n    \n     \n    \n         \n         \n           \n       \n         \n         \n         \n       \n    \n\"\"\"Run the agent with a user prompt synchronously.\n\n    This is a convenience method that wraps [`self.run`][pydantic_ai.Agent.run] with `loop.run_until_complete(...)`.\n    You therefore can't use this method inside async code or if there's an active event loop.\n\n    result_sync = agent.run_sync('What is the capital of Italy?')\n\n      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n        result validators since result validators would expect an argument that matches the agent's result type.\n      user_prompt: User input to start/continue the conversation.\n      message_history: History of the conversation so far.\n      model: Optional model to use for this run, required if `model` was not set when creating the agent.\n      deps: Optional dependencies to use for this run.\n      model_settings: Optional settings to use for this model's request.\n      usage_limits: Optional limits on model request count or token usage.\n      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n      infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n      The result of the run.\n\n         \n      \n     \n      \n        \n        \n        \n        \n        \n        \n        \n        \n        \n      \n    \n  \n  \n    \n     \n    \n       \n         \n           \n       \n         \n         \n         \n       \n      \n  \n  \n    \n     \n    \n     \n         \n           \n       \n         \n         \n         \n       \n      \n  \n    \n    \n     \n    \n         \n         \n           \n       \n         \n         \n         \n       \n     \n\"\"\"Run the agent with a user prompt in async mode, returning a streamed\nresponse.\n\n      async with agent.run_stream('What is the capital of the UK?') as response:\n\n      result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n        result validators since result validators would expect an argument that matches the agent's result type.\n      user_prompt: User input to start/continue the conversation.\n      message_history: History of the conversation so far.\n      model: Optional model to use for this run, required if `model` was not set when creating the agent.\n      deps: Optional dependencies to use for this run.\n      model_settings: Optional settings to use for this model's request.\n      usage_limits: Optional limits on model request count or token usage.\n      usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n      infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n      The result of the run.\n\n         \n      # f_back because `asynccontextmanager` adds one frame\n          \n        \n       \n      \n          \n      \n     \n      \n      \n      \n      \n        \n      \n             \n           \n        \n         \n          \n         \n          \n       \n          \n        \n         'preparing model and tools {run_step=}' \n              \n            \n               \n              \n             \n            # We want to end the \"model request\" span here, but we can't exit the context manager\n            # in the traditional way\n              \n               \n                 \n                  \n              \n              # Check if we got a final result\n                \n                  \n                  \n                  'handle model response -> final result'\n                  \n\"\"\"Called when the stream has completed.\n\n                  The model response will have been added to messages by now\n\n                    \n                    \n                    \n                           \n                  \n                     \n                       \n                  \n                   \n                    \n                   \n                 \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                  \n                \n                \n              \n                \n                   \n                # if we got a model response add that to messages\n                \n                 \n                  # if we got one or more tool response parts, add a model request message\n                  \n                 \n                      \n                  \n                # the model_response should have been fully streamed by now, we can add its usage\n                  \n                \n                \n  \n  \n    \n    \n         \n           \n    \n\"\"\"Context manager to temporarily override agent dependencies and model.\n\n    This is particularly useful when testing.\n    You can find an example of this [here](../testing-evals.md#overriding-model-via-pytest-fixtures).\n\n      deps: The dependencies to use instead of the dependencies passed to the agent run.\n      model: The model to use instead of the model passed to the agent run.\n\n     \n        \n        \n    \n        \n    \n     \n        \n      \n         \n    \n        \n    \n      \n    \n       \n          \n       \n          \n  \n  \n        \n      \n  \n  \n        \n      \n  \n           \n  \n           \n  \n  \n          \n      \n  \n    \n         \n    \n    \n       \n    \n     \n     \n  \n\"\"\"Decorator to register a system prompt function.\n\n    Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its only argument.\n    Can decorate a sync or async functions.\n    The decorator can be used either bare (`agent.system_prompt`) or as a function call\n    (`agent.system_prompt(...)`), see the examples below.\n    Overloads for every possible signature of `system_prompt` are included so the decorator doesn't obscure\n    the type of the function, see `tests/typed_agent.py` for tests.\n\n      func: The function to decorate\n      dynamic: If True, the system prompt will be reevaluated even when `messages_history` is provided,\n\n    from pydantic_ai import Agent, RunContext\n\n    async def async_system_prompt(ctx: RunContext[str]) -> str:\n      return f'{ctx.deps} is the best'\n\n       \n       \n         \n        \n           \n        \n         \n            \n         \n       \n    \n         \"dynamic can't be True in this case\"\n       \n       \n  \n  \n         \n       \n  \n  \n         \n       \n  \n           \n  \n  \n        \n      \n  \n        \n     \n\"\"\"Decorator to register a result validator function.\n\n    Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its first argument.\n    Can decorate a sync or async functions.\n    Overloads for every possible signature of `result_validator` are included so the decorator doesn't obscure\n    the type of the function, see `tests/typed_agent.py` for tests.\n\n    from pydantic_ai import Agent, ModelRetry, RunContext\n\n    def result_validator_simple(data: str) -> str:\n\n    async def result_validator_deps(ctx: RunContext[str], data: str) -> str:\n\n    #> success (no tool calls)\n\n     \n     \n  \n           \n  \n  \n    \n    \n    \n         \n         \n       \n       \n        \n  \n    \n          \n    \n    \n         \n         \n       \n       \n    \n\"\"\"Decorator to register a tool function which takes\n[`RunContext`][pydantic_ai.tools.RunContext] as its first argument.\n\n    Can decorate a sync or async functions.\n    The docstring is inspected to extract both the tool description and description of each parameter,\n\n    We can't add overloads for every possible signature of tool, since the return type is a recursive union\n    so the signature of functions decorated with `@agent.tool` is obscured.\n\n    from pydantic_ai import Agent, RunContext\n\n    def foobar(ctx: RunContext[int], x: int) -> int:\n\n    async def spam(ctx: RunContext[str], y: float) -> float:\n\n      func: The tool function to register.\n      retries: The number of retries to allow for this tool, defaults to the agent's default retries,\n\n      prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n        tool from a given step. This is useful if you want to customise a tool at call time,\n        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n       \n       \n          \n         \n        \n             \n         \n       \n    \n      \n           \n       \n  \n         \n  \n  \n    \n    \n    \n         \n         \n       \n       \n      \n  \n    \n         \n    \n    \n         \n         \n       \n       \n    \n\"\"\"Decorator to register a tool function which DOES NOT take `RunContext` as an\nargument.\n\n    Can decorate a sync or async functions.\n    The docstring is inspected to extract both the tool description and description of each parameter,\n\n    We can't add overloads for every possible signature of tool, since the return type is a recursive union\n    so the signature of functions decorated with `@agent.tool` is obscured.\n\n    from pydantic_ai import Agent, RunContext\n\n    def foobar(ctx: RunContext[int]) -> int:\n\n    async def spam(ctx: RunContext[str]) -> float:\n\n      func: The tool function to register.\n      retries: The number of retries to allow for this tool, defaults to the agent's default retries,\n\n      prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n        tool from a given step. This is useful if you want to customise a tool at call time,\n        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n       \n          \n        \n        \n               \n        \n         \n       \n    \n           \n       \n  \n    \n      \n     \n       \n       \n     \n     \n    \n\"\"\"Private utility to register a function as a tool.\"\"\"\n\n             \n      \n      \n      \n      \n      \n      \n      \n    \n    \n       \n\"\"\"Private utility to register a tool instance.\"\"\"\n\n       \n      \n         \n       \n       'Tool name conflicts with existing tool: \n         \n       'Tool name conflicts with result schema name: \n      \n            \n\"\"\"Create a model configured for this agent.\n\n      model: model to use for this run, required if `model` was not set when creating the agent.\n\n     \n       \n      # we don't want `override()` to cover up errors from the model not being defined, hence this check\n             \n         \n          '`model` must be set either when creating the agent or when calling it. '\n          '(Even when `override(model=...)` is customizing the model that will actually be called)'\n        \n        \n        \n        \n        \n      \n          \n    \n       '`model` must be set either when creating the agent or when calling it.'\n     \n    \n          \n    \n\"\"\"Build tools and create an agent model.\"\"\"\n\n       \n         \n         \n          \n        \n      \n      \n      \n      \n             \n    \n    \n        \n    \n\"\"\"Reevaluate any `SystemPromptPart` with dynamic_ref in the provided messages\nby running the associated runner function.\"\"\"\n\n    # Only proceed if there's at least one dynamic runner.\n     \n         \n          \n              \n                \n              # Look up the runner by its ref\n                 \n                   \n                  \n                   \n                \n  \n        \n      \n        \n       \n         'Cannot set a custom run `result_type` when the agent has result validators'\n       \n          \n      \n    \n        \n    \n            \n    \n    \n        \n     \n         \n    \n       \n          \n      \n          \n          \n     \n      \n      \n      # Reevaluate any dynamic system prompt parts\n        \n      \n    \n         \n      \n      \n     \n    \n    \n     \n     \n       \n       \n\"\"\"Process a non-streamed response from the model.\n\n      A tuple of `(final_result, request parts)`. If `final_result` is not `None`, the conversation should end.\n\n       \n       \n       \n        \n        # ignore empty content for text parts, see #437\n         \n          \n      \n        \n    # At the moment, we prioritize at least executing tool calls if they are present.\n    # In the future, we'd consider making this configurable at the agent or run level.\n    # This accounts for cases like anthropic returns that might contain a text response\n    # and a tool call response, where the text response just indicates the tool call will happen.\n     \n          \n     \n        \n          \n    \n       \n    \n            \n       \n\"\"\"Handle a plain text response from the model for non-streaming responses.\"\"\"\n\n     \n         \n      \n             \n         \n        \n          \n      \n           \n    \n      \n        \n        'Plain text responses are not permitted, please call one of the functions instead.'\n      \n        \n    \n    \n     \n     \n       \n       \n\"\"\"Handle a structured response containing tool calls from the model for non-\nstreaming responses.\"\"\"\n\n      'Expected at least one tool call'\n    # first look for the result tool call\n         \n       \n        \n         \n           \n        \n            \n               \n           \n          \n          \n        \n             \n    # Then build the other request parts based on end strategy\n       \n           \n    \n      \n    \n    \n     \n       \n     \n       \n    \n\"\"\"Process function (non-result) tool calls in parallel.\n\n    Also add stub return parts for any other tools that need it.\n\n       \n       \n          \n    # we rely on the fact that if we found a result, it's the first result tool in the last\n      \n       \n            \n          \n        \n          \n            \n            \n            \n          \n        \n         \n         \n          \n            \n              \n              'Tool not executed - a final result was already processed.'\n              \n            \n          \n        \n            \n              \n        # if tool_name is in _result_schema, it means we found a result tool but an error occurred in\n        # validation, we don't add another part here\n            \n          \n            \n              \n              'Result tool not used - a final result was already processed.'\n              \n            \n          \n      \n          \n    # Run all tool tasks in parallel\n     \n            \n            \n        \n     \n    \n    \n     \n     \n       \n       \n\"\"\"Process a streamed response from the model.\n\n      Either a final result or a tuple of the model response and the tool responses for the next request.\n      If a final result is returned, the conversation should end.\n\n      \n        \n        \n          \n          \n            \n           \n              \n          \n                  \n               \n              \n        \n          \n       \n       \n      \n      \n       \n       \n        \n           \n            \n        \n            \n           \n      # Can only get here if self._allow_text_result returns `False` for the provided result_schema\n      \n        \n        'Plain text responses are not permitted, please call one of the functions instead.'\n      \n        \n          \n          \n      \n      \n    \n    \n     \n     \n       \n    \n     \n         \n         \n             \n        \n    \n       \n       \n      \n       \n       \n        \n      \n        \n\"\"\"Build the initial messages for the conversation.\"\"\"\n\n           \n       \n         \n       \n         \n      \n        \n     \n  \n    \n     \n     \n       \n    \n    \n      \n     \n      \n     \n        \n    \n        \n     \n       \n\"\"\"Get deps for a run.\n\n    If we've overridden deps via `_override_deps`, use that, otherwise use the deps passed to the call.\n    We could do runtime type checking of deps against `self._deps_type`, but that's a slippery slope.\n\n       \n       \n    \n       \n         \n\"\"\"Infer the agent name from the call frame.\n\n        \n         \n          \n            \n             \n              \n            \n           \n          # if we couldn't find the agent in locals and globals are a different dict, try globals\n              \n               \n                \n              \n  \n        \n         \n  \n  \n    'The `last_run_messages` attribute has been removed, use `capture_run_messages` instead.' \n  \n     \n     'The `last_run_messages` attribute has been removed, use `capture_run_messages` instead.'\n\n```\n\n  \n---  \nThe default model configured for this agent.\n\nThe default model to use for this agent, if not provide, you must provide the\nmodel when calling it.  \n---  \nThe type of the result data, used to validate the result data, defaults to .  \nStatic system prompts to use for this agent, you can also register system\nprompts via a function with .  \nThe type used for dependency injection, this parameter exists solely to allow\nyou to fully parameterize the agent, and therefore get the best out of static\ntype checking. If you're not using deps, but want type checking to pass, you can\nset to satisfy Pyright or add a type hint .  \nThe name of the agent, used for logging. If , we try to infer the agent name\nfrom the call frame when the agent is first run.  \nOptional model request settings to use for this agent's runs, by default.  \nThe default number of retries to allow before raising an error.  \nThe name of the tool to use for the final result.  \nThe description of the final result tool.  \nThe maximum number of retries to allow for result validation, defaults to .  \nTools to register with the agent, you can also register tools via the decorators\nand .  \nby default, if you provide a model, it's evaluated to create a instance\nimmediately, which checks for the necessary environment variables. Set this to\nto defer the evaluation until the first run. Useful if you want to for testing.  \nStrategy for handling tool calls that are requested alongside a final result.\nSee for more information.  \n```\n\n\n\n  \n         \n  \n     \n       \n     \n       \n       \n     \n     \n       \n       \n        \n     \n     \n\n    model: The default model to use for this agent, if not provide,\n      you must provide the model when calling it.\n    result_type: The type of the result data, used to validate the result data, defaults to `str`.\n    system_prompt: Static system prompts to use for this agent, you can also register system\n      prompts via a function with [`system_prompt`][pydantic_ai.Agent.system_prompt].\n    deps_type: The type used for dependency injection, this parameter exists solely to allow you to fully\n      parameterize the agent, and therefore get the best out of static type checking.\n      If you're not using deps, but want type checking to pass, you can set `deps=None` to satisfy Pyright\n      or add a type hint `: Agent[None, <return type>]`.\n    name: The name of the agent, used for logging. If `None`, we try to infer the agent name from the call frame\n      when the agent is first run.\n    model_settings: Optional model request settings to use for this agent's runs, by default.\n    retries: The default number of retries to allow before raising an error.\n    result_tool_name: The name of the tool to use for the final result.\n    result_tool_description: The description of the final result tool.\n    result_retries: The maximum number of retries to allow for result validation, defaults to `retries`.\n    tools: Tools to register with the agent, you can also register tools via the decorators\n\n    defer_model_check: by default, if you provide a [named][pydantic_ai.models.KnownModelName] model,\n      it's evaluated to create a [`Model`][pydantic_ai.models.Model] instance immediately,\n      which checks for the necessary environment variables. Set this to `false`\n      to defer the evaluation until the first run. Useful if you want to\n      [override the model][pydantic_ai.Agent.override] for testing.\n    end_strategy: Strategy for handling tool calls that are requested alongside a final result.\n      See [`EndStrategy`][pydantic_ai.agent.EndStrategy] for more information.\n\n       \n      \n  \n      \n    \n    \n    \n    \n    \n    \n      \n  \n         \n    \n    \n     \n      \n      \n    \n      \n    \n    \n    \n           \n    \n\n```\n\n  \n---  \nStrategy for handling tool calls when a final result is found.\n\nThe name of the agent, used for logging.\n\nIf , we try to infer the agent name from the call frame when the agent is first\nrun.\n\nOptional model request settings to use for this agents's runs, by default.\n\nNote, if is provided by , , or , those settings will be merged with this value,\nwith the runtime argument taking priority.\n\nRun the agent with a user prompt in async mode.\n\n```\n\n  \n  \n  \n     'What is the capital of France?'\n  \n  \n\n```\n\nCustom result type to use for this run, may only be used if the agent has no\nresult validators since result validators would expect an argument that matches\nthe agent's result type.  \n---  \nUser input to start/continue the conversation.  \nHistory of the conversation so far.  \nOptional model to use for this run, required if was not set when creating the\nagent.  \nOptional dependencies to use for this run.  \nOptional settings to use for this model's request.  \nOptional limits on model request count or token usage.  \nOptional usage to start with, useful for resuming a conversation or agents used\nin tools.  \nWhether to try to infer the agent name from the call frame if it's not set.  \nThe result of the run.  \n---  \n```\n\n  \n  \n  \n  \n       \n         \n     \n       \n       \n       \n       \n     \n  \n\"\"\"Run the agent with a user prompt in async mode.\n\n    result = await agent.run('What is the capital of France?')\n\n    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n      result validators since result validators would expect an argument that matches the agent's result type.\n    user_prompt: User input to start/continue the conversation.\n    message_history: History of the conversation so far.\n    model: Optional model to use for this run, required if `model` was not set when creating the agent.\n    deps: Optional dependencies to use for this run.\n    model_settings: Optional settings to use for this model's request.\n    usage_limits: Optional limits on model request count or token usage.\n    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n    infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n    The result of the run.\n\n       \n    \n     \n    \n        \n    \n  \n    \n    \n    \n    \n      \n    \n           \n         \n      \n       \n        \n       \n        \n     \n      \n        \n       'preparing model and tools {run_step=}' \n            \n          \n             \n         \n         \n      \n       \n      \n          \n            \n            \n        \n         \n          # Add parts to the conversation as a new message\n          \n        # Check if we got a final result\n            \n            \n            \n           \n           \n           \n            'handle model response -> final result'\n           \n                \n          \n        \n          \n           \n                \n            \n\n```\n\n  \n---  \nRun the agent with a user prompt synchronously.\n\nThis is a convenience method that wraps with . You therefore can't use this\nmethod inside async code or if there's an active event loop.\n\n```\n\n  \n  \n  'What is the capital of Italy?'\n\n```\n\nCustom result type to use for this run, may only be used if the agent has no\nresult validators since result validators would expect an argument that matches\nthe agent's result type.  \n---  \nUser input to start/continue the conversation.  \nHistory of the conversation so far.  \nOptional model to use for this run, required if was not set when creating the\nagent.  \nOptional dependencies to use for this run.  \nOptional settings to use for this model's request.  \nOptional limits on model request count or token usage.  \nOptional usage to start with, useful for resuming a conversation or agents used\nin tools.  \nWhether to try to infer the agent name from the call frame if it's not set.  \nThe result of the run.  \n---  \n```\n\n\n\n  \n  \n  \n       \n       \n         \n     \n       \n       \n       \n     \n  \n\"\"\"Run the agent with a user prompt synchronously.\n\n  This is a convenience method that wraps [`self.run`][pydantic_ai.Agent.run]\nwith `loop.run_until_complete(...)`.\n\n  You therefore can't use this method inside async code or if there's an active\nevent loop.\n\n  result_sync = agent.run_sync('What is the capital of Italy?')\n\n    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n      result validators since result validators would expect an argument that matches the agent's result type.\n    user_prompt: User input to start/continue the conversation.\n    message_history: History of the conversation so far.\n    model: Optional model to use for this run, required if `model` was not set when creating the agent.\n    deps: Optional dependencies to use for this run.\n    model_settings: Optional settings to use for this model's request.\n    usage_limits: Optional limits on model request count or token usage.\n    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n    infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n    The result of the run.\n\n       \n    \n  \n    \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n\n```\n\n  \n---  \nRun the agent with a user prompt in async mode, returning a streamed response.\n\n```\n\n  \n  \n  \n    'What is the capital of the UK?'  \n     \n    \n\n```\n\nCustom result type to use for this run, may only be used if the agent has no\nresult validators since result validators would expect an argument that matches\nthe agent's result type.  \n---  \nUser input to start/continue the conversation.  \nHistory of the conversation so far.  \nOptional model to use for this run, required if was not set when creating the\nagent.  \nOptional dependencies to use for this run.  \nOptional settings to use for this model's request.  \nOptional limits on model request count or token usage.  \nOptional usage to start with, useful for resuming a conversation or agents used\nin tools.  \nWhether to try to infer the agent name from the call frame if it's not set.  \nThe result of the run.  \n---  \n```\n\n  \n  \n  \n  \n       \n       \n         \n     \n       \n       \n       \n     \n  \n\"\"\"Run the agent with a user prompt in async mode, returning a streamed\nresponse.\n\n    async with agent.run_stream('What is the capital of the UK?') as response:\n\n    result_type: Custom result type to use for this run, `result_type` may only be used if the agent has no\n      result validators since result validators would expect an argument that matches the agent's result type.\n    user_prompt: User input to start/continue the conversation.\n    message_history: History of the conversation so far.\n    model: Optional model to use for this run, required if `model` was not set when creating the agent.\n    deps: Optional dependencies to use for this run.\n    model_settings: Optional settings to use for this model's request.\n    usage_limits: Optional limits on model request count or token usage.\n    usage: Optional usage to start with, useful for resuming a conversation or agents used in tools.\n    infer_name: Whether to try to infer the agent name from the call frame if it's not set.\n\n    The result of the run.\n\n       \n    # f_back because `asynccontextmanager` adds one frame\n        \n      \n     \n    \n        \n    \n  \n    \n    \n    \n    \n      \n    \n           \n         \n      \n       \n        \n       \n        \n     \n        \n      \n       'preparing model and tools {run_step=}' \n            \n          \n             \n            \n           \n          # We want to end the \"model request\" span here, but we can't exit the context manager\n          # in the traditional way\n            \n             \n               \n                \n            \n            # Check if we got a final result\n              \n                \n                \n                'handle model response -> final result'\n                \n\"\"\"Called when the stream has completed.\n\n                The model response will have been added to messages by now\n\n                  \n                  \n                  \n                         \n                \n                   \n                     \n                \n                 \n                  \n                 \n               \n                \n                \n                \n                \n                \n                \n                \n                \n                \n              \n              \n            \n              \n                 \n              # if we got a model response add that to messages\n              \n               \n                # if we got one or more tool response parts, add a model request message\n                \n               \n                    \n                \n              # the model_response should have been fully streamed by now, we can add its usage\n                \n              \n              \n\n```\n\n  \n---  \nContext manager to temporarily override agent dependencies and model.\n\nThis is particularly useful when testing. You can find an example of this .\n\nThe dependencies to use instead of the dependencies passed to the agent run.  \n---  \nThe model to use instead of the model passed to the agent run.  \n```\n\n\n\n  \n  \n       \n         \n  \n\"\"\"Context manager to temporarily override agent dependencies and model.\n\n  This is particularly useful when testing.\n\n  You can find an example of this [here](../testing-evals.md#overriding-model-\nvia-pytest-fixtures).\n\n    deps: The dependencies to use instead of the dependencies passed to the agent run.\n    model: The model to use instead of the model passed to the agent run.\n\n  \n      \n      \n  \n      \n  \n  \n      \n    \n       \n  \n      \n  \n    \n  \n     \n        \n     \n        \n\n```\n\n  \n---  \nDecorator to register a system prompt function.\n\nOptionally takes as its only argument. Can decorate a sync or async functions.\n\nThe decorator can be used either bare () or as a function call (), see the\nexamples below.\n\nOverloads for every possible signature of are included so the decorator doesn't\nobscure the type of the function, see for tests.  \nIf True, the system prompt will be reevaluated even when is provided, see  \n```\n\n\n\n  \n       \n  \n  \n     \n  \n  \n  \n\n\"\"\"Decorator to register a system prompt function.\n\n  Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its only\nargument.\n\n  Can decorate a sync or async functions.\n\n  The decorator can be used either bare (`agent.system_prompt`) or as a function\ncall\n\n  (`agent.system_prompt(...)`), see the examples below.\n\n  Overloads for every possible signature of `system_prompt` are included so the\ndecorator doesn't obscure\n\n  the type of the function, see `tests/typed_agent.py` for tests.\n\n    func: The function to decorate\n    dynamic: If True, the system prompt will be reevaluated even when `messages_history` is provided,\n\n  from pydantic_ai import Agent, RunContext\n\n  async def async_system_prompt(ctx: RunContext[str]) -> str:\n\n    return f'{ctx.deps} is the best'\n\n     \n     \n       \n      \n         \n      \n       \n          \n       \n     \n  \n       \"dynamic can't be True in this case\"\n     \n     \n\n```\n\n  \n---  \nDecorator to register a result validator function.\n\nOptionally takes as its first argument. Can decorate a sync or async functions.\n\nOverloads for every possible signature of are included so the decorator doesn't\nobscure the type of the function, see for tests.\n\n```\n\n     \n  \n\n    \n     \n     \n  \n\n       \n     \n     \n  \n  \n\n#> success (no tool calls)\n\n```\n\n```\n\n\n\n      \n  \n\"\"\"Decorator to register a result validator function.\n\n  Optionally takes [`RunContext`][pydantic_ai.tools.RunContext] as its first\nargument.\n\n  Can decorate a sync or async functions.\n\n  Overloads for every possible signature of `result_validator` are included so\nthe decorator doesn't obscure\n\n  the type of the function, see `tests/typed_agent.py` for tests.\n\n  from pydantic_ai import Agent, ModelRetry, RunContext\n\n  def result_validator_simple(data: str) -> str:\n\n  async def result_validator_deps(ctx: RunContext[str], data: str) -> str:\n\n  #> success (no tool calls)\n\n  \n  \n\n```\n\n  \n---  \nDecorator to register a tool function which takes as its first argument.\n\nCan decorate a sync or async functions.\n\nThe docstring is inspected to extract both the tool description and description\nof each parameter, .\n\nWe can't add overloads for every possible signature of tool, since the return\ntype is a recursive union so the signature of functions decorated with is\nobscured.\n\nThe tool function to register.  \n---  \nThe number of retries to allow for this tool, defaults to the agent's default\nretries, which defaults to 1.  \ncustom method to prepare the tool definition for each step, return to omit this\ntool from a given step. This is useful if you want to customise a tool at call\ntime, or omit it completely from a step. See .  \nThe format of the docstring, see . Defaults to , such that the format is\ninferred from the structure of the docstring.  \nIf True, raise an error if a parameter description is missing. Defaults to\nFalse.  \n```\n\n\n\n  \n        \n  \n  \n       \n       \n     \n     \n  \n\"\"\"Decorator to register a tool function which takes\n[`RunContext`][pydantic_ai.tools.RunContext] as its first argument.\n\n  Can decorate a sync or async functions.\n\n  The docstring is inspected to extract both the tool description and\ndescription of each parameter,\n\n  We can't add overloads for every possible signature of tool, since the return\ntype is a recursive union\n\n  so the signature of functions decorated with `@agent.tool` is obscured.\n\n  from pydantic_ai import Agent, RunContext\n\n  def foobar(ctx: RunContext[int], x: int) -> int:\n\n  async def spam(ctx: RunContext[str], y: float) -> float:\n\n    func: The tool function to register.\n    retries: The number of retries to allow for this tool, defaults to the agent's default retries,\n\n    prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n      tool from a given step. This is useful if you want to customise a tool at call time,\n      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n     \n     \n        \n       \n      \n           \n       \n     \n  \n    \n         \n     \n\n```\n\n  \n---  \nDecorator to register a tool function which DOES NOT take as an argument.\n\nCan decorate a sync or async functions.\n\nThe docstring is inspected to extract both the tool description and description\nof each parameter, .\n\nWe can't add overloads for every possible signature of tool, since the return\ntype is a recursive union so the signature of functions decorated with is\nobscured.\n\nThe tool function to register.  \n---  \nThe number of retries to allow for this tool, defaults to the agent's default\nretries, which defaults to 1.  \ncustom method to prepare the tool definition for each step, return to omit this\ntool from a given step. This is useful if you want to customise a tool at call\ntime, or omit it completely from a step. See .  \nThe format of the docstring, see . Defaults to , such that the format is\ninferred from the structure of the docstring.  \nIf True, raise an error if a parameter description is missing. Defaults to\nFalse.  \n```\n\n\n\n  \n       \n  \n  \n       \n       \n     \n     \n  \n\"\"\"Decorator to register a tool function which DOES NOT take `RunContext` as an\nargument.\n\n  Can decorate a sync or async functions.\n\n  The docstring is inspected to extract both the tool description and\ndescription of each parameter,\n\n  We can't add overloads for every possible signature of tool, since the return\ntype is a recursive union\n\n  so the signature of functions decorated with `@agent.tool` is obscured.\n\n  from pydantic_ai import Agent, RunContext\n\n  def foobar(ctx: RunContext[int]) -> int:\n\n  async def spam(ctx: RunContext[str]) -> float:\n\n    func: The tool function to register.\n    retries: The number of retries to allow for this tool, defaults to the agent's default retries,\n\n    prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n      tool from a given step. This is useful if you want to customise a tool at call time,\n      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n     \n        \n      \n      \n             \n      \n       \n     \n  \n         \n     \n\n```\n\n  \n---  \nThe strategy for handling multiple tool calls when a final result is found.\n\n  * : Stop processing other tool calls once a final result is found\n  * : Process all tool calls even after finding a final result\n\nType variable for the result data of a run where was customized on the run call.\n\nContext manager to access the messages used in a , , or call.\n\nUseful when a run may raise an exception, see for more information.\n\nIf you call , , or more than once within a single context, will represent the\nmessages exchanged during the first call only.\n\n```\n\n  \n\"\"\"Context manager to access the messages used in a\n[`run`][pydantic_ai.Agent.run], [`run_sync`][pydantic_ai.Agent.run_sync], or\n[`run_stream`][pydantic_ai.Agent.run_stream] call.\n\n  Useful when a run may raise an exception, see [model\nerrors](../agents.md#model-errors) for more information.\n\n  from pydantic_ai import Agent, capture_run_messages\n\n    If you call `run`, `run_sync`, or `run_stream` more than once within a single `capture_run_messages` context,\n    `messages` will represent the messages exchanged during the first call only.\n\n  \n     \n  \n       \n      \n    \n       \n    \n      \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.tools\nURL: https://ai.pydantic.dev/api/tools/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nType variable for agent dependencies.\n\nInformation about the current call.\n\n```\n\n\n\n\"\"\"Information about the current call.\"\"\"\n\n  \n\n  \n\"\"\"The model used in this run.\"\"\"\n\n  \n\"\"\"LLM usage associated with the run.\"\"\"\n\n  \n\"\"\"The original user prompt passed to the run.\"\"\"\n\n     \n\"\"\"Messages exchanged in the conversation so far.\"\"\"\n\n       \n\"\"\"Name of the tool being called.\"\"\"\n\n     \n\"\"\"Number of retries so far.\"\"\"\n\n     \n\"\"\"The current step in the run.\"\"\"\n\n  \n                  \n    \n    # Create a new `RunContext` a new `retry` value and `tool_name`.\n      \n        \n        \n        \n        \n      \n\n```\n\n  \n---  \nThe model used in this run.\n\nLLM usage associated with the run.\n\nThe original user prompt passed to the run.\n\nMessages exchanged in the conversation so far.\n\nName of the tool being called.\n\nNumber of retries so far.\n\nThe current step in the run.\n\nA function that may or maybe not take as an argument, and may or may not be\nasync.\n\nA tool function that takes as the first argument.\n\nA tool function that does not take as the first argument.\n\nEither kind of tool function.\n\nThis is just a union of and .\n\n```\n\n  \n  \"Callable[[RunContext[AgentDeps], ToolDefinition], Awaitable[ToolDefinition | None]]\"\n\n```\n\nDefinition of a function that can prepare a tool definition at call time.\n\nExample — here is valid as a :\n\n  * — Automatically infer the format based on the structure of the docstring.\n\nA tool function for an agent.\n\n```\n\n\n\n\"\"\"A tool function for an agent.\"\"\"\n\n  \n  \n     \n  \n  \n     \n  \n  \n     \n       \n     \n       \n      \n     \n      \n  \n    \n     \n    \n         \n         \n         \n         \n         \n       \n       \n  \n\"\"\"Create a new tool instance.\n\n    from pydantic_ai import Agent, RunContext, Tool\n    async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:\n\n    or with a custom prepare method:\n\n    from pydantic_ai import Agent, RunContext, Tool\n\n    async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:\n\n      # only register the tool if `deps == 42`\n\n    agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])\n\n      function: The Python function to call as the tool.\n      takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,\n        this is inferred if unset.\n      max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.\n      name: Name of the tool, inferred from the function if `None`.\n      description: Description of the tool, inferred from the function if `None`.\n      prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n        tool from a given step. This is useful if you want to customise a tool at call time,\n        or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n      docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n        Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n      require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n       \n        \n         \n      \n      \n      \n        \n        \n      \n      \n      \n      \n      \n      \n      \n      \n      \n          \n\n    By default, this method creates a tool definition, then either returns it, or calls `self.prepare`\n\n      return a `ToolDefinition` or `None` if the tools should not be registered for this run.\n\n      \n      \n      \n      \n    \n        \n         \n    \n       \n    \n        \n    \n\"\"\"Run the tool function asynchronously.\"\"\"\n\n    \n        \n          \n      \n          \n       \n        \n         \n    \n       \n            \n            \n      \n            \n             \n       \n        \n      \n     \n      \n      \n      \n    \n  \n    \n      \n     \n     \n      \n     \n         \n        \n          \n       \n      \n     \n      \n      \n  \n          \n    \n      \n           \n       'Tool exceeded max retries count of   \n    \n        \n          \n      \n          \n       \n        \n        \n        \n      \n\n```\n\n  \n---  \nCreate a new tool instance.\n\nor with a custom prepare method:\n\n```\n\n  \n     \n  \n         \n  \n  \n     \n  \n  # only register the tool if `deps == 42`\n\n     \n     \n    \n\n```\n\nThe Python function to call as the tool.  \n---  \nWhether the function takes a first argument, this is inferred if unset.  \nMaximum number of retries allowed for this tool, set to the agent default if .  \nName of the tool, inferred from the function if .  \nDescription of the tool, inferred from the function if .  \ncustom method to prepare the tool definition for each step, return to omit this\ntool from a given step. This is useful if you want to customise a tool at call\ntime, or omit it completely from a step. See .  \nThe format of the docstring, see . Defaults to , such that the format is\ninferred from the structure of the docstring.  \nIf True, raise an error if a parameter description is missing. Defaults to\nFalse.  \n```\n\n\n\n  \n  \n  \n       \n       \n       \n       \n       \n     \n     \n\n\"\"\"Create a new tool instance.\n\n  from pydantic_ai import Agent, RunContext, Tool\n\n  async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:\n\n  or with a custom prepare method:\n\n  from pydantic_ai import Agent, RunContext, Tool\n\n  async def my_tool(ctx: RunContext[int], x: int, y: int) -> str:\n\n    # only register the tool if `deps == 42`\n\n  agent = Agent('test', tools=[Tool(my_tool, prepare=prep_my_tool)])\n\n    function: The Python function to call as the tool.\n    takes_ctx: Whether the function takes a [`RunContext`][pydantic_ai.tools.RunContext] first argument,\n      this is inferred if unset.\n    max_retries: Maximum number of retries allowed for this tool, set to the agent default if `None`.\n    name: Name of the tool, inferred from the function if `None`.\n    description: Description of the tool, inferred from the function if `None`.\n    prepare: custom method to prepare the tool definition for each step, return `None` to omit this\n      tool from a given step. This is useful if you want to customise a tool at call time,\n      or omit it completely from a step. See [`ToolPrepareFunc`][pydantic_ai.tools.ToolPrepareFunc].\n    docstring_format: The format of the docstring, see [`DocstringFormat`][pydantic_ai.tools.DocstringFormat].\n      Defaults to `'auto'`, such that the format is inferred from the structure of the docstring.\n    require_parameter_descriptions: If True, raise an error if a parameter description is missing. Defaults to False.\n\n     \n      \n       \n    \n    \n    \n      \n      \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n```\n\n  \n---  \nBy default, this method creates a tool definition, then either returns it, or\ncalls if it's set.\n\nreturn a or if the tools should not be registered for this run.  \n---  \n```\n\n        \n\n  By default, this method creates a tool definition, then either returns it, or\ncalls `self.prepare`\n\n    return a `ToolDefinition` or `None` if the tools should not be registered for this run.\n\n    \n    \n    \n    \n  \n      \n       \n  \n     \n\n```\n\n  \n---  \nRun the tool function asynchronously.\n\n```\n\n  \n      \n  \n\"\"\"Run the tool function asynchronously.\"\"\"\n\n  \n      \n        \n    \n        \n     \n      \n       \n  \n     \n          \n          \n    \n          \n           \n     \n      \n    \n  \n    \n    \n    \n  \n\n```\n\n  \n---  \nType representing JSON schema of an object, e.g. where .\n\nThis type is used to define tools parameters (aka arguments) in .\n\nWith PEP-728 this should be a TypedDict with , and\n\nDefinition of a tool passed to a model.\n\nThis is used for both function tools result tools.\n\n```\n\n\n\n\"\"\"Definition of a tool passed to a model.\n\n  This is used for both function tools result tools.\n\n  \n\"\"\"The name of the tool.\"\"\"\n\n  \n\"\"\"The description of the tool.\"\"\"\n\n  \n\"\"\"The JSON schema for the tool's parameters.\"\"\"\n\n       \n\"\"\"The key in the outer [TypedDict] that wraps a result tool.\n\n  This will only be set for result tools which don't have an `object` JSON\nschema.\n\n```\n\n  \n---  \nThe name of the tool.\n\nThe description of the tool.\n\nThe JSON schema for the tool's parameters.\n\nThe key in the outer [TypedDict] that wraps a result tool.\n\nThis will only be set for result tools which don't have an JSON schema.\n\n---\n\n# pydantic_ai.result\nURL: https://ai.pydantic.dev/api/result/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nType variable for the result data of a run.\n\nA function that always takes and returns and:\n\n  * may or may not take as a first argument\n  * may or may not be async\n\nResult of a non-streamed run.\n\n```\n\n\n\n\"\"\"Result of a non-streamed run.\"\"\"\n\n  \n\"\"\"Data from the final response in the run.\"\"\"\n\n     \n  \n     \n\"\"\"Return the usage of the whole run.\"\"\"\n\n     \n            \n\"\"\"Return the history of _messages.\n\n      result_tool_return_content: The return content of the tool call to set in the last message.\n        This provides a convenient way to modify the content of the result tool call if you want to continue\n        the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n        \n       \n    \n       \n       \n\"\"\"Set return content for the result tool.\n\n    Useful if you want to continue the conversation and want to set the response to the result tool call.\n\n      \n       'Cannot set result tool return content when the return type is `str`.'\n      \n      \n       \n            \n          \n         \n     'No tool call found with tool name \n\n```\n\n  \n---  \nReturn all messages from as JSON bytes.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \nJSON bytes representing the messages.  \n---  \n```\n\n          \n\"\"\"Return all messages from\n[`all_messages`][pydantic_ai.result._BaseRunResult.all_messages] as JSON bytes.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    JSON bytes representing the messages.\n\n  \n    \n  \n\n```\n\n  \n---  \nReturn new messages associated with this run.\n\nMessages from older runs are excluded.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \n```\n\n          \n\"\"\"Return new messages associated with this run.\n\n  Messages from older runs are excluded.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    \n\n```\n\n  \n---  \nReturn new messages from as JSON bytes.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \nJSON bytes representing the new messages.  \n---  \n```\n\n          \n\"\"\"Return new messages from\n[`new_messages`][pydantic_ai.result._BaseRunResult.new_messages] as JSON bytes.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    JSON bytes representing the new messages.\n\n  \n    \n  \n\n```\n\n  \n---  \nData from the final response in the run.\n\nReturn the usage of the whole run.\n\n```\n\n  \n\"\"\"Return the usage of the whole run.\"\"\"\n\n  \n\n```\n\n  \n---  \nReturn the history of _messages.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \n```\n\n          \n\"\"\"Return the history of _messages.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n      \n     \n  \n     \n\n```\n\n  \n---  \nResult of a streamed run that returns structured data via a tool call.\n\n```\n\n  \n\"\"\"Result of a streamed run that returns structured data via a tool call.\"\"\"\n\n     \n  \n     \n  \n    \n     \n    \n      \n\"\"\"Whether the stream has all been received.\n\n  This is set to `True` when one of\n\n             \n\"\"\"Stream the response as an async iterable.\n\n    The pydantic validator for structured data will be called in\n\n      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n        Debouncing is particularly important for long structured responses to reduce the overhead of\n        performing validation as each token is received.\n\n      An async iterable of the response data.\n\n         \n           \n       \n                 \n\"\"\"Stream the text result as an async iterable.\n\n      Result validators will NOT be called on the text result if `delta=True`.\n\n      delta: if `True`, yield each chunk of text as it is received, if `False` (default), yield the full text\n        up to the current point.\n      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n        Debouncing is particularly important for long structured responses to reduce the overhead of\n        performing validation as each token is received.\n\n        \n       'stream_text() can only be used with text responses'\n      \n        \n    \n    # Define a \"merged\" version of the iterator that will yield items that have already been retrieved\n    # and items that we receive while streaming. We define a dedicated async iterator for this so we can\n    # pass the combined stream to the group_by_temporal function within `_stream_text_deltas` below.\n         \n      # if the response currently has any parts with content, yield those before streaming\n        \n          \n            \n            \n          \n         \n           \n            \n           \n        \n            \n         \n           \n            \n           \n        \n            \n        \n           \n            \n                \n       \n       \n            \n           \n      \n        # a quick benchmark shows it's faster to build up a string with concat when we're\n        # yielding at each step\n           \n          \n            \n          \n            \n             \n           \n         \n         \n    \n           \n     \n\"\"\"Stream the response as an async iterable of Structured LLM Messages.\n\n      debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n        Debouncing is particularly important for long structured responses to reduce the overhead of\n        performing validation as each token is received.\n\n      An async iterable of the structured response message and whether that is the last message.\n\n      \n        \n    \n       \n      # if the message currently has any parts with content, yield before streaming\n        \n         \n         \n            \n          \n           \n            \n            \n            \n          \n          \n        # TODO: Should this now be `final_response` instead of `structured_response`?\n         \n         \n      \n\"\"\"Stream the whole response, validate and return it.\"\"\"\n\n      \n        \n    \n        \n      \n      \n     \n      \n     \n\"\"\"Return the usage of the whole run.\n\n      This won't return the full usage until the stream is finished.\n\n       \n     \n\"\"\"Get the timestamp of the response.\"\"\"\n\n     \n    \n           \n    \n\"\"\"Validate a structured result message.\"\"\"\n\n             \n         \n         \n         \n          'Invalid response, unable to find tool: \n        \n         \n          \n         \n             \n       \n    \n               \n         \n           \n           \n          \n          \n        \n      # Since there is no result tool, we can assume that str is compatible with ResultData\n        \n        \n       \n          \n         \n        \n        \n      \n     \n        \n      \n    \n     \n\n```\n\n  \n---  \nReturn the history of _messages.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \n```\n\n          \n\"\"\"Return the history of _messages.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n  # this is a method to be consistent with the other methods\n\n      \n     'Setting result tool return content is not supported for this result type.'\n  \n\n```\n\n  \n---  \nReturn all messages from as JSON bytes.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \nJSON bytes representing the messages.  \n---  \n```\n\n          \n\"\"\"Return all messages from\n[`all_messages`][pydantic_ai.result._BaseRunResult.all_messages] as JSON bytes.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    JSON bytes representing the messages.\n\n  \n    \n  \n\n```\n\n  \n---  \nReturn new messages associated with this run.\n\nMessages from older runs are excluded.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \n```\n\n          \n\"\"\"Return new messages associated with this run.\n\n  Messages from older runs are excluded.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    \n\n```\n\n  \n---  \nReturn new messages from as JSON bytes.\n\nThe return content of the tool call to set in the last message. This provides a\nconvenient way to modify the content of the result tool call if you want to\ncontinue the conversation and want to set the response to the result tool call.\nIf , the last message will not be modified.  \n---  \nJSON bytes representing the new messages.  \n---  \n```\n\n          \n\"\"\"Return new messages from\n[`new_messages`][pydantic_ai.result._BaseRunResult.new_messages] as JSON bytes.\n\n    result_tool_return_content: The return content of the tool call to set in the last message.\n      This provides a convenient way to modify the content of the result tool call if you want to continue\n      the conversation and want to set the response to the result tool call. If `None`, the last message will\n\n    JSON bytes representing the new messages.\n\n  \n    \n  \n\n```\n\n  \n---  \nWhether the stream has all been received.\n\nThis is set to when one of , , or completes.\n\nStream the response as an async iterable.\n\nThe pydantic validator for structured data will be called in on each iteration.\n\nby how much (if at all) to debounce/group the response chunks by. means no\ndebouncing. Debouncing is particularly important for long structured responses\nto reduce the overhead of performing validation as each token is received.  \n---  \nAn async iterable of the response data.  \n---  \n```\n\n           \n\"\"\"Stream the response as an async iterable.\n\n  The pydantic validator for structured data will be called in\n\n    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n      Debouncing is particularly important for long structured responses to reduce the overhead of\n      performing validation as each token is received.\n\n    An async iterable of the response data.\n\n       \n         \n     \n\n```\n\n  \n---  \nStream the text result as an async iterable.\n\nResult validators will NOT be called on the text result if .\n\nif , yield each chunk of text as it is received, if (default), yield the full\ntext up to the current point.  \n---  \nby how much (if at all) to debounce/group the response chunks by. means no\ndebouncing. Debouncing is particularly important for long structured responses\nto reduce the overhead of performing validation as each token is received.  \n```\n\n               \n\"\"\"Stream the text result as an async iterable.\n\n    Result validators will NOT be called on the text result if `delta=True`.\n\n    delta: if `True`, yield each chunk of text as it is received, if `False` (default), yield the full text\n      up to the current point.\n    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n      Debouncing is particularly important for long structured responses to reduce the overhead of\n      performing validation as each token is received.\n\n      \n     'stream_text() can only be used with text responses'\n    \n      \n  \n  # Define a \"merged\" version of the iterator that will yield items that have\nalready been retrieved\n\n  # and items that we receive while streaming. We define a dedicated async\niterator for this so we can\n\n  # pass the combined stream to the group_by_temporal function within\n`_stream_text_deltas` below.\n\n       \n    # if the response currently has any parts with content, yield those before streaming\n      \n        \n          \n          \n        \n       \n         \n          \n         \n      \n          \n       \n         \n          \n         \n      \n          \n      \n         \n          \n              \n     \n     \n          \n         \n    \n      # a quick benchmark shows it's faster to build up a string with concat when we're\n      # yielding at each step\n         \n        \n          \n        \n          \n           \n         \n       \n       \n\n```\n\n  \n---  \nStream the response as an async iterable of Structured LLM Messages.\n\nby how much (if at all) to debounce/group the response chunks by. means no\ndebouncing. Debouncing is particularly important for long structured responses\nto reduce the overhead of performing validation as each token is received.  \n---  \nAn async iterable of the structured response message and whether that is the\nlast message.  \n---  \n```\n\n  \n         \n  \n\"\"\"Stream the response as an async iterable of Structured LLM Messages.\n\n    debounce_by: by how much (if at all) to debounce/group the response chunks by. `None` means no debouncing.\n      Debouncing is particularly important for long structured responses to reduce the overhead of\n      performing validation as each token is received.\n\n    An async iterable of the structured response message and whether that is the last message.\n\n    \n      \n  \n     \n    # if the message currently has any parts with content, yield before streaming\n      \n       \n       \n          \n        \n         \n          \n          \n          \n        \n        \n      # TODO: Should this now be `final_response` instead of `structured_response`?\n       \n       \n\n```\n\n  \n---  \nStream the whole response, validate and return it.\n\n```\n\n    \n\"\"\"Stream the whole response, validate and return it.\"\"\"\n\n    \n      \n  \n      \n    \n    \n  \n    \n\n```\n\n  \n---  \nReturn the usage of the whole run.\n\nThis won't return the full usage until the stream is finished.\n\n```\n\n  \n\"\"\"Return the usage of the whole run.\n\n    This won't return the full usage until the stream is finished.\n\n     \n\n```\n\n  \n---  \nGet the timestamp of the response.\n\n```\n\n  \n\"\"\"Get the timestamp of the response.\"\"\"\n\n  \n\n```\n\n  \n---  \nValidate a structured result message.\n\n```\n\n  \n         \n  \n\"\"\"Validate a structured result message.\"\"\"\n\n           \n       \n       \n       \n        'Invalid response, unable to find tool: \n      \n       \n        \n       \n           \n     \n  \n             \n       \n         \n         \n        \n        \n      \n    # Since there is no result tool, we can assume that str is compatible with ResultData\n      \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.messages\nURL: https://ai.pydantic.dev/api/messages/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nThe structure of can be shown as a graph:\n\nA system prompt, generally written by the application developer.\n\nThis gives the model context and guidance on how to respond.\n\n```\n\n\n\n\"\"\"A system prompt, generally written by the application developer.\n\n  This gives the model context and guidance on how to respond.\n\n  \n\"\"\"The content of the prompt.\"\"\"\n\n       \n\"\"\"The ref of the dynamic system prompt function that generated this part.\n\n  Only set if system prompt is dynamic, see\n[`system_prompt`][pydantic_ai.Agent.system_prompt] for more information.\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n```\n\n  \n---  \nThe content of the prompt.\n\nThe ref of the dynamic system prompt function that generated this part.\n\nOnly set if system prompt is dynamic, see for more information.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nA user prompt, generally written by the end user.\n\nContent comes from the parameter of , , and .\n\n```\n\n\n\n\"\"\"A user prompt, generally written by the end user.\n\n  Content comes from the `user_prompt` parameter of\n[`Agent.run`][pydantic_ai.Agent.run],\n\n  \n\"\"\"The content of the prompt.\"\"\"\n\n     \n\"\"\"The timestamp of the prompt.\"\"\"\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n```\n\n  \n---  \nThe content of the prompt.\n\nThe timestamp of the prompt.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nA tool return message, this encodes the result of running a tool.\n\n```\n\n\n\n\"\"\"A tool return message, this encodes the result of running a tool.\"\"\"\n\n  \n\"\"\"The name of the \"tool\" was called.\"\"\"\n\n  \n\n       \n\"\"\"Optional tool call identifier, this is used by some models including\nOpenAI.\"\"\"\n\n     \n\"\"\"The timestamp, when the tool returned.\"\"\"\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n     \n\"\"\"Return a string representation of the content for the model.\"\"\"\n\n      \n       \n    \n       \n      \n\"\"\"Return a dictionary representation of the content, wrapping non-dict types\nappropriately.\"\"\"\n\n    # gemini supports JSON dict return values, but no other JSON types, hence we wrap anything else in a dict\n      \n         \n    \n         \n\n```\n\n  \n---  \nThe name of the \"tool\" was called.\n\nOptional tool call identifier, this is used by some models including OpenAI.\n\nThe timestamp, when the tool returned.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nReturn a string representation of the content for the model.\n\n```\n\n  \n\"\"\"Return a string representation of the content for the model.\"\"\"\n\n    \n     \n  \n     \n\n```\n\n  \n---  \nReturn a dictionary representation of the content, wrapping non-dict types\nappropriately.\n\n```\n\n    \n\"\"\"Return a dictionary representation of the content, wrapping non-dict types\nappropriately.\"\"\"\n\n  # gemini supports JSON dict return values, but no other JSON types, hence we\nwrap anything else in a dict\n\n    \n       \n  \n       \n\n```\n\n  \n---  \nA message back to a model asking it to try again.\n\nThis can be sent for a number of reasons:\n\n  * Pydantic validation of tool arguments failed, here content is derived from a Pydantic \n  * no tool was found for the tool name\n  * the model returned plain text when a structured response was expected\n  * Pydantic validation of a structured response failed, here content is derived from a Pydantic \n  * a result validator raised a exception\n\n```\n\n\n\n\"\"\"A message back to a model asking it to try again.\n\n  This can be sent for a number of reasons:\n\n  * Pydantic validation of tool arguments failed, here content is derived from a Pydantic\n\n  * a tool raised a [`ModelRetry`][pydantic_ai.exceptions.ModelRetry] exception\n  * no tool was found for the tool name\n  * the model returned plain text when a structured response was expected\n  * Pydantic validation of a structured response failed, here content is derived from a Pydantic\n\n  * a result validator raised a [`ModelRetry`][pydantic_ai.exceptions.ModelRetry] exception\n\n     \n\"\"\"Details of why and how the model should retry.\n\n  If the retry was triggered by a\n[`ValidationError`][pydantic_core.ValidationError], this will be a list of\n\n       \n\"\"\"The name of the tool that was called, if any.\"\"\"\n\n       \n\"\"\"Optional tool call identifier, this is used by some models including\nOpenAI.\"\"\"\n\n     \n\"\"\"The timestamp, when the retry was triggered.\"\"\"\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n     \n\"\"\"Return a string message describing why the retry is requested.\"\"\"\n\n      \n        \n    \n           \n        \n     Fix the errors and try again.'\n\n```\n\n  \n---  \nDetails of why and how the model should retry.\n\nIf the retry was triggered by a , this will be a list of error details.\n\nThe name of the tool that was called, if any.\n\nOptional tool call identifier, this is used by some models including OpenAI.\n\nThe timestamp, when the retry was triggered.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nReturn a string message describing why the retry is requested.\n\n```\n\n  \n\"\"\"Return a string message describing why the retry is requested.\"\"\"\n\n    \n      \n  \n         \n      \n   Fix the errors and try again.'\n\n```\n\n  \n---  \nA message part sent by PydanticAI to a model.\n\nA request generated by PydanticAI and sent to a model, e.g. a message from the\nPydanticAI app to the model.\n\n```\n\n\n\n\"\"\"A request generated by PydanticAI and sent to a model, e.g. a message from\nthe PydanticAI app to the model.\"\"\"\n\n  \n\"\"\"The parts of the user message.\"\"\"\n\n     \n\"\"\"Message type identifier, this is available on all parts as a\ndiscriminator.\"\"\"\n\n```\n\n  \n---  \nThe parts of the user message.\n\nMessage type identifier, this is available on all parts as a discriminator.\n\nA plain text response from a model.\n\n```\n\n\n\n\"\"\"A plain text response from a model.\"\"\"\n\n  \n\"\"\"The text content of the response.\"\"\"\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n     \n\"\"\"Return `True` if the text content is non-empty.\"\"\"\n\n     \n\n```\n\n  \n---  \nThe text content of the response.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nReturn if the text content is non-empty.\n\n```\n\n  \n\"\"\"Return `True` if the text content is non-empty.\"\"\"\n\n  \n\n```\n\n  \n---  \nTool arguments as a JSON string.\n\n```\n\n\n\n\"\"\"Tool arguments as a JSON string.\"\"\"\n\n  \n\"\"\"A JSON string of arguments.\"\"\"\n\n```\n\n  \n---  \nA JSON string of arguments.\n\nTool arguments as a Python dictionary.\n\n```\n\n\n\n\"\"\"Tool arguments as a Python dictionary.\"\"\"\n\n    \n\"\"\"A python dictionary of arguments.\"\"\"\n\n```\n\n  \n---  \nA python dictionary of arguments.\n\nA tool call from a model.\n\n```\n\n\n\n\"\"\"A tool call from a model.\"\"\"\n\n  \n\"\"\"The name of the tool to call.\"\"\"\n\n     \n\"\"\"The arguments to pass to the tool.\n\n  Either as JSON or a Python dictionary depending on how data was returned.\n\n       \n\"\"\"Optional tool call identifier, this is used by some models including\nOpenAI.\"\"\"\n\n     \n\"\"\"Part type identifier, this is available on all parts as a discriminator.\"\"\"\n\n  \n                  \n\"\"\"Create a `ToolCallPart` from raw arguments, converting them to `ArgsJson` or\n`ArgsDict`.\"\"\"\n\n      \n         \n      \n         \n    \n      \n      \n\"\"\"Return the arguments as a Python dictionary.\n\n    This is just for convenience with models that require dicts as input.\n\n      \n       \n      \n       'args should be a dict'\n       \n     \n\"\"\"Return the arguments as a JSON string.\n\n    This is just for convenience with models that require JSON strings as input.\n\n      \n       \n     \n     \n\"\"\"Return `True` if the arguments contain any data.\"\"\"\n\n      \n       \n    \n       \n\n```\n\n  \n---  \nThe name of the tool to call.\n\nThe arguments to pass to the tool.\n\nEither as JSON or a Python dictionary depending on how data was returned.\n\nOptional tool call identifier, this is used by some models including OpenAI.\n\nPart type identifier, this is available on all parts as a discriminator.\n\nCreate a from raw arguments, converting them to or .\n\n```\n\n                \n\"\"\"Create a `ToolCallPart` from raw arguments, converting them to `ArgsJson` or\n`ArgsDict`.\"\"\"\n\n    \n       \n    \n       \n  \n    \n\n```\n\n  \n---  \nReturn the arguments as a Python dictionary.\n\nThis is just for convenience with models that require dicts as input.\n\n```\n\n    \n\"\"\"Return the arguments as a Python dictionary.\n\n  This is just for convenience with models that require dicts as input.\n\n    \n     \n    \n     'args should be a dict'\n     \n\n```\n\n  \n---  \nReturn the arguments as a JSON string.\n\nThis is just for convenience with models that require JSON strings as input.\n\n```\n\n  \n\"\"\"Return the arguments as a JSON string.\n\n  This is just for convenience with models that require JSON strings as input.\n\n    \n     \n  \n\n```\n\n  \n---  \nReturn if the arguments contain any data.\n\n```\n\n  \n\"\"\"Return `True` if the arguments contain any data.\"\"\"\n\n    \n     \n  \n     \n\n```\n\n  \n---  \nA message part returned by a model.\n\nA response from a model, e.g. a message from the model to the PydanticAI app.\n\n```\n\n\n\n\"\"\"A response from a model, e.g. a message from the model to the PydanticAI\napp.\"\"\"\n\n  \n\"\"\"The parts of the model message.\"\"\"\n\n     \n\"\"\"The timestamp of the response.\n\n  If the model provides a timestamp in the response (as OpenAI does) that will\nbe used.\n\n     \n\"\"\"Message type identifier, this is available on all parts as a\ndiscriminator.\"\"\"\n\n  \n             \n\"\"\"Create a `ModelResponse` containing a single `TextPart`.\"\"\"\n\n        \n  \n       \n\"\"\"Create a `ModelResponse` containing a single `ToolCallPart`.\"\"\"\n\n     \n\n```\n\n  \n---  \nThe parts of the model message.\n\nThe timestamp of the response.\n\nIf the model provides a timestamp in the response (as OpenAI does) that will be\nused.\n\nMessage type identifier, this is available on all parts as a discriminator.\n\n```\n\n           \n\"\"\"Create a `ModelResponse` containing a single `TextPart`.\"\"\"\n\n      \n\n```\n\n  \n---  \n```\n\n     \n\"\"\"Create a `ModelResponse` containing a single `ToolCallPart`.\"\"\"\n\n  \n\n```\n\n  \n---  \nAny message sent to or returned by a model.\n\nA partial update (delta) for a to append new text content.\n\n```\n\n\n\n\"\"\"A partial update (delta) for a `TextPart` to append new text content.\"\"\"\n\n  \n\"\"\"The incremental text content to add to the existing `TextPart` content.\"\"\"\n\n     \n\"\"\"Part delta type identifier, used as a discriminator.\"\"\"\n\n       \n\"\"\"Apply this text delta to an existing `TextPart`.\n\n      part: The existing model response part, which must be a `TextPart`.\n\n      A new `TextPart` with updated text content.\n\n      ValueError: If `part` is not a `TextPart`.\n\n       \n       'Cannot apply TextPartDeltas to non-TextParts'\n        \n\n```\n\n  \n---  \nThe incremental text content to add to the existing content.\n\nPart delta type identifier, used as a discriminator.\n\nApply this text delta to an existing .\n\nThe existing model response part, which must be a .  \n---  \nA new with updated text content.  \n---  \n```\n\n     \n\"\"\"Apply this text delta to an existing `TextPart`.\n\n    part: The existing model response part, which must be a `TextPart`.\n\n    A new `TextPart` with updated text content.\n\n    ValueError: If `part` is not a `TextPart`.\n\n     \n     'Cannot apply TextPartDeltas to non-TextParts'\n      \n\n```\n\n  \n---  \nA partial update (delta) for a to modify tool name, arguments, or tool call ID.\n\n```\n\n\n\n\"\"\"A partial update (delta) for a `ToolCallPart` to modify tool name, arguments,\nor tool call ID.\"\"\"\n\n       \n\"\"\"Incremental text to add to the existing tool name, if any.\"\"\"\n\n          \n\"\"\"Incremental data to add to the tool arguments.\n\n  If this is a string, it will be appended to existing JSON arguments.\n\n  If this is a dict, it will be merged with existing dict arguments.\n\n       \n\"\"\"Optional tool call identifier, this is used by some models including OpenAI.\n\n  Note this is never treated as a delta — it can replace None, but otherwise if\na\n\n  non-matching value is provided an error will be raised.\"\"\"\n\n     \n\"\"\"Part delta type identifier, used as a discriminator.\"\"\"\n\n       \n\"\"\"Convert this delta to a fully formed `ToolCallPart` if possible, otherwise\nreturn `None`.\n\n      A `ToolCallPart` if both `tool_name_delta` and `args_delta` are set, otherwise `None`.\n\n           \n       \n     \n      \n      \n      \n    \n  \n        \n  \n            \n           \n\"\"\"Apply this delta to a part or delta, returning a new part or delta with the\nchanges applied.\n\n      part: The existing model response part or delta to update.\n\n      Either a new `ToolCallPart` or an updated `ToolCallPartDelta`.\n\n      ValueError: If `part` is neither a `ToolCallPart` nor a `ToolCallPartDelta`.\n      UnexpectedModelBehavior: If applying JSON deltas to dict arguments or vice versa.\n\n      \n       \n      \n       \n     'Can only apply ToolCallPartDeltas to ToolCallParts or ToolCallPartDeltas, not \n         \n\"\"\"Internal helper to apply this delta to another delta.\"\"\"\n\n     \n      # Append incremental text to the existing tool_name_delta\n            \n         \n      \n        \n         \n          'Cannot apply JSON deltas to non-JSON tool arguments (\n        \n            \n         \n      \n        \n         \n          'Cannot apply dict deltas to non-dict tool arguments (\n        \n           \n         \n     \n      # Set the tool_call_id if it wasn't present, otherwise error if it has changed\n              \n         \n          'Cannot apply a new tool_call_id to a ToolCallPartDelta that already has one (\n        \n         \n    # If we now have enough data to create a full ToolCallPart, do so\n             \n       \n        \n        \n        \n      \n     \n       \n\"\"\"Internal helper to apply this delta directly to a `ToolCallPart`.\"\"\"\n\n     \n      # Append incremental text to the existing tool_name\n          \n         \n      \n         \n         'Cannot apply JSON deltas to non-JSON tool arguments (\n          \n         \n      \n         \n         'Cannot apply dict deltas to non-dict tool arguments (\n           \n         \n     \n      # Replace the tool_call_id entirely if given\n              \n         \n          'Cannot apply a new tool_call_id to a ToolCallPartDelta that already has one (\n        \n         \n     \n\n```\n\n  \n---  \nIncremental text to add to the existing tool name, if any.\n\nIncremental data to add to the tool arguments.\n\nIf this is a string, it will be appended to existing JSON arguments. If this is\na dict, it will be merged with existing dict arguments.\n\nOptional tool call identifier, this is used by some models including OpenAI.\n\nNote this is never treated as a delta — it can replace None, but otherwise if a\nnon-matching value is provided an error will be raised.\n\nPart delta type identifier, used as a discriminator.\n\nConvert this delta to a fully formed if possible, otherwise return .  \n```\n\n     \n\"\"\"Convert this delta to a fully formed `ToolCallPart` if possible, otherwise\nreturn `None`.\n\n    A `ToolCallPart` if both `tool_name_delta` and `args_delta` are set, otherwise `None`.\n\n         \n     \n  \n    \n    \n    \n  \n\n```\n\n  \n---  \nApply this delta to a part or delta, returning a new part or delta with the\nchanges applied.\n\nThe existing model response part or delta to update.  \n---  \nEither a new or an updated .  \n---  \nIf applying JSON deltas to dict arguments or vice versa.  \n---  \n```\n\n         \n\"\"\"Apply this delta to a part or delta, returning a new part or delta with the\nchanges applied.\n\n    part: The existing model response part or delta to update.\n\n    Either a new `ToolCallPart` or an updated `ToolCallPartDelta`.\n\n    ValueError: If `part` is neither a `ToolCallPart` nor a `ToolCallPartDelta`.\n    UnexpectedModelBehavior: If applying JSON deltas to dict arguments or vice versa.\n\n    \n     \n    \n     \n   'Can only apply ToolCallPartDeltas to ToolCallParts or ToolCallPartDeltas,\nnot\n\n```\n\n  \n---  \nA partial update (delta) for any model response part.\n\nAn event indicating that a new part has started.\n\nIf multiple s are received with the same index, the new one should fully replace\nthe old one.\n\n```\n\n\n\n\"\"\"An event indicating that a new part has started.\n\n  If multiple `PartStartEvent`s are received with the same index,\n\n  the new one should fully replace the old one.\n\n  \n\"\"\"The index of the part within the overall response parts list.\"\"\"\n\n  \n\n     \n\"\"\"Event type identifier, used as a discriminator.\"\"\"\n\n```\n\n  \n---  \nThe index of the part within the overall response parts list.\n\nEvent type identifier, used as a discriminator.\n\nAn event indicating a delta update for an existing part.\n\n```\n\n\n\n\"\"\"An event indicating a delta update for an existing part.\"\"\"\n\n  \n\"\"\"The index of the part within the overall response parts list.\"\"\"\n\n  \n\"\"\"The delta to apply to the specified part.\"\"\"\n\n     \n\"\"\"Event type identifier, used as a discriminator.\"\"\"\n\n```\n\n  \n---  \nThe index of the part within the overall response parts list.\n\nThe delta to apply to the specified part.\n\nEvent type identifier, used as a discriminator.\n\nAn event in the model response stream, either starting a new part or applying a\ndelta to an existing one.\n\n---\n\n# pydantic_ai.exceptions\nURL: https://ai.pydantic.dev/api/exceptions/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nException raised when a tool function should be retried.\n\nThe agent will return the message to the model and ask it to try calling the\nfunction/tool again.\n\n```\n\n\n\n\"\"\"Exception raised when a tool function should be retried.\n\n  The agent will return the message to the model and ask it to try calling the\nfunction/tool again.\n\n  \n\"\"\"The message to return to the model.\"\"\"\n\n     \n      \n    \n\n```\n\n  \n---  \nThe message to return to the model.\n\nError caused by a usage mistake by the application developer — You!\n\n```\n\n\n\n\"\"\"Error caused by a usage mistake by the application developer — You!\"\"\"\n\n  \n\n     \n      \n    \n\n```\n\n  \n---  \nBase class for errors occurring during an agent run.\n\n```\n\n\n\n\"\"\"Base class for errors occurring during an agent run.\"\"\"\n\n  \n\n     \n      \n    \n     \n     \n\n```\n\n  \n---  \nError raised when a Model's usage exceeds the specified limits.\n\n```\n\n\n\n\"\"\"Error raised when a Model's usage exceeds the specified limits.\"\"\"\n\n```\n\n  \n---  \nError caused by unexpected Model behavior, e.g. an unexpected response code.\n\n```\n\n\n\n\"\"\"Error caused by unexpected Model behavior, e.g. an unexpected response\ncode.\"\"\"\n\n  \n\"\"\"Description of the unexpected behavior.\"\"\"\n\n     \n\"\"\"The body of the response, if available.\"\"\"\n\n           \n      \n       \n           \n    \n      \n           \n       \n          \n    \n     \n     \n       \n    \n       \n\n```\n\n  \n---  \nDescription of the unexpected behavior.\n\nThe body of the response, if available.\n\n---\n\n# pydantic_ai.settings\nURL: https://ai.pydantic.dev/api/settings/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nSettings to configure an LLM.\n\nHere we include only settings which apply to multiple models / model providers.\n\n```\n\n  \n\"\"\"Settings to configure an LLM.\n\n  Here we include only settings which apply to multiple models / model\nproviders.\n\n  \n\"\"\"The maximum number of tokens to generate before stopping.\n\n  \n\"\"\"Amount of randomness injected into the response.\n\n  Use `temperature` closer to `0.0` for analytical / multiple choice, and closer\nto a model's\n\n  maximum `temperature` for creative and generative tasks.\n\n  Note that even with `temperature` of `0.0`, the results will not be fully\ndeterministic.\n\n  \n\"\"\"An alternative to sampling with temperature, called nucleus sampling, where\nthe model considers the results of the tokens with top_p probability mass.\n\n  So 0.1 means only the tokens comprising the top 10% probability mass are\nconsidered.\n\n  You should either alter `temperature` or `top_p`, but not both.\n\n     \n\"\"\"Override the client-level default timeout for a request, in seconds.\n\n```\n\n  \n---  \nThe maximum number of tokens to generate before stopping.\n\nAmount of randomness injected into the response.\n\nUse closer to for analytical / multiple choice, and closer to a model's maximum\nfor creative and generative tasks.\n\nNote that even with of , the results will not be fully deterministic.\n\nAn alternative to sampling with temperature, called nucleus sampling, where the\nmodel considers the results of the tokens with top_p probability mass.\n\nSo 0.1 means only the tokens comprising the top 10% probability mass are\nconsidered.\n\nYou should either alter or , but not both.\n\nOverride the client-level default timeout for a request, in seconds.\n\n---\n\n# pydantic_ai.usage\nURL: https://ai.pydantic.dev/api/usage/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nLLM usage associated with a request or run.\n\nResponsibility for calculating usage is on the model; PydanticAI simply sums the\nusage information across requests.\n\nYou'll need to look up the documentation of the model you're using to convert\nusage to monetary costs.\n\n```\n\n\n\n\"\"\"LLM usage associated with a request or run.\n\n  Responsibility for calculating usage is on the model; PydanticAI simply sums\nthe usage information across requests.\n\n  You'll need to look up the documentation of the model you're using to convert\nusage to monetary costs.\n\n     \n\"\"\"Number of requests made to the LLM API.\"\"\"\n\n       \n\"\"\"Tokens used in processing requests.\"\"\"\n\n       \n\"\"\"Tokens used in generating responses.\"\"\"\n\n       \n\"\"\"Total tokens used in the whole run, should generally be equal to\n`request_tokens + response_tokens`.\"\"\"\n\n        \n\"\"\"Any extra details returned by the model.\"\"\"\n\n            \n\"\"\"Increment the usage in place.\n\n      incr_usage: The usage to increment by.\n      requests: The number of requests to increment by in addition to `incr_usage.requests`.\n\n      \n          \n         \n         \n               \n                \n     \n          \n          \n             \n       \n\n    This is provided so it's trivial to sum usage information from multiple requests and runs.\n\n      \n    \n     \n\n```\n\n  \n---  \nNumber of requests made to the LLM API.\n\nTokens used in processing requests.\n\nTokens used in generating responses.\n\nTotal tokens used in the whole run, should generally be equal to .\n\nAny extra details returned by the model.\n\nIncrement the usage in place.\n\nThe usage to increment by.  \n---  \nThe number of requests to increment by in addition to .  \n```\n\n          \n\"\"\"Increment the usage in place.\n\n    incr_usage: The usage to increment by.\n    requests: The number of requests to increment by in addition to `incr_usage.requests`.\n\n    \n        \n       \n       \n             \n              \n  \n        \n        \n           \n\n```\n\n  \n---  \nThis is provided so it's trivial to sum usage information from multiple requests\nand runs.\n\n```\n\n     \n\n  This is provided so it's trivial to sum usage information from multiple\nrequests and runs.\n\n    \n  \n  \n\n```\n\n  \n---  \nThe request count is tracked by pydantic_ai, and the request limit is checked\nbefore each request to the model. Token counts are provided in responses from\nthe model, and the token limits are checked after each response.\n\nEach of the limits can be set to to disable that limit.\n\n```\n\n\n\n  The request count is tracked by pydantic_ai, and the request limit is checked\nbefore each request to the model.\n\n  Token counts are provided in responses from the model, and the token limits\nare checked after each response.\n\n  Each of the limits can be set to `None` to disable that limit.\n\n       \n\"\"\"The maximum number of requests allowed to the model.\"\"\"\n\n       \n\"\"\"The maximum number of tokens allowed in requests to the model.\"\"\"\n\n       \n\"\"\"The maximum number of tokens allowed in responses from the model.\"\"\"\n\n       \n\"\"\"The maximum number of tokens allowed in requests and responses combined.\"\"\"\n\n     \n\"\"\"Returns `True` if this instance places any limits on token counts.\n\n    If this returns `False`, the `check_tokens` method will never raise an error.\n    This is useful because if we have token limits, we need to check them after receiving each streamed message.\n    If there are no limits, we can skip that processing in the streaming response iterator.\n\n     \n         \n           \n    \n       \n\"\"\"Raises a `UsageLimitExceeded` exception if the next request would exceed the\nrequest_limit.\"\"\"\n\n      \n            \n       'The next request would exceed the request_limit of \n       \n\"\"\"Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token\nlimits.\"\"\"\n\n        \n            \n       \n        \n      \n        \n            \n       \n        \n      \n        \n            \n       \n\n```\n\n  \n---  \nThe maximum number of requests allowed to the model.\n\nThe maximum number of tokens allowed in requests to the model.\n\nThe maximum number of tokens allowed in responses from the model.\n\nThe maximum number of tokens allowed in requests and responses combined.\n\nReturns if this instance places any limits on token counts.\n\nIf this returns , the method will never raise an error.\n\nThis is useful because if we have token limits, we need to check them after\nreceiving each streamed message. If there are no limits, we can skip that\nprocessing in the streaming response iterator.\n\n```\n\n  \n\"\"\"Returns `True` if this instance places any limits on token counts.\n\n  If this returns `False`, the `check_tokens` method will never raise an error.\n\n  This is useful because if we have token limits, we need to check them after\nreceiving each streamed message.\n\n  If there are no limits, we can skip that processing in the streaming response\niterator.\n\n  \n       \n         \n  \n\n```\n\n  \n---  \nRaises a exception if the next request would exceed the request_limit.\n\n```\n\n     \n\"\"\"Raises a `UsageLimitExceeded` exception if the next request would exceed the\nrequest_limit.\"\"\"\n\n    \n          \n     'The next request would exceed the request_limit of \n\n```\n\n  \n---  \nRaises a exception if the usage exceeds any of the token limits.\n\n```\n\n     \n\"\"\"Raises a `UsageLimitExceeded` exception if the usage exceeds any of the token\nlimits.\"\"\"\n\n      \n          \n     \n      \n    \n      \n          \n     \n      \n    \n      \n          \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.format_as_xml\nURL: https://ai.pydantic.dev/api/format_as_xml/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFormat a Python object as XML.\n\nThis is useful since LLMs often find it easier to read semi-structured data\n(e.g. examples) as XML, rather than JSON etc.\n\nPython Object to serialize to XML.  \n---  \nOuter tag to wrap the XML in, use to omit the outer tag.  \nTag to use for each item in an iterable (e.g. list), this is overridden by the\nclass name for dataclasses and Pydantic models.  \nWhether to include the root tag in the output (The root tag is always included\nif it includes a body - e.g. when the input is a simple value).  \nIndentation string to use for pretty printing.  \nXML representation of the object.  \n---  \n```\n\n\n\n  \n     \n     \n     \n     \n       \n  \n\"\"\"Format a Python object as XML.\n\n  This is useful since LLMs often find it easier to read semi-structured data\n(e.g. examples) as XML,\n\n  Supports: `str`, `bytes`, `bytearray`, `bool`, `int`, `float`, `date`,\n`datetime`, `Mapping`,\n\n    obj: Python Object to serialize to XML.\n    root_tag: Outer tag to wrap the XML in, use `None` to omit the outer tag.\n    item_tag: Tag to use for each item in an iterable (e.g. list), this is overridden by the class name\n      for dataclasses and Pydantic models.\n    include_root_tag: Whether to include the root tag in the output\n      (The root tag is always included if it includes a body - e.g. when the input is a simple value).\n    none_str: String to use for `None` values.\n    indent: Indentation string to use for pretty printing.\n\n    XML representation of the object.\n\n  print(format_as_xml({'name': 'John', 'height': 6, 'weight': 200},\nroot_tag='user'))\n\n      \n        \n            \n      \n  \n        \n       \n      \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models\nURL: https://ai.pydantic.dev/api/models/base/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nLogic related to making requests to an LLM.\n\nThe aim here is to make a common interface for different LLMs, so that the rest\nof the code can be agnostic to the specific LLM being used.\n\nKnown model names that can be used with the parameter of .\n\nis provided as a concise way to specify a model.\n\nAbstract class for a model.\n\n```\n\n\n\n\"\"\"Abstract class for a model.\"\"\"\n\n  \n    \n    \n    \n     \n     \n     \n    \n\"\"\"Create an agent model, this is called for each step of an agent run.\n\n    This is async in case slow/async config checks need to be performed that can't be done in `__init__`.\n\n      function_tools: The tools available to the agent.\n      allow_text_result: Whether a plain text final response/result is permitted.\n      result_tools: Tool definitions for the final result tool(s), if any.\n\n     \n  \n     \n     \n\n```\n\n  \n---  \nCreate an agent model, this is called for each step of an agent run.\n\nThis is async in case slow/async config checks need to be performed that can't\nbe done in .\n\nThe tools available to the agent.  \n---  \nWhether a plain text final response/result is permitted.  \nTool definitions for the final result tool(s), if any.  \n```\n\n  \n  \n  \n  \n  \n  \n  \n\"\"\"Create an agent model, this is called for each step of an agent run.\n\n  This is async in case slow/async config checks need to be performed that can't\nbe done in `__init__`.\n\n    function_tools: The tools available to the agent.\n    allow_text_result: Whether a plain text final response/result is permitted.\n    result_tools: Tool definitions for the final result tool(s), if any.\n\n  \n\n```\n\n  \n---  \nModel configured for each step of an Agent run.\n\n```\n\n\n\n\"\"\"Model configured for each step of an Agent run.\"\"\"\n\n  \n    \n          \n     \n\"\"\"Make a request to the model.\"\"\"\n\n     \n  \n    \n          \n    \n\"\"\"Make a request to the model and return a streaming response.\"\"\"\n\n    # This method is not required, but you need to implement it if you want to support streamed responses\n     'Streamed requests not supported by this \n    # yield is required to make this a generator for type checking\n    \n     \n\n```\n\n  \n---  \nMake a request to the model.\n\n```\n\n  \n        \n  \n\"\"\"Make a request to the model.\"\"\"\n\n  \n\n```\n\n  \n---  \nMake a request to the model and return a streaming response.\n\n```\n\n  \n        \n  \n\"\"\"Make a request to the model and return a streaming response.\"\"\"\n\n  # This method is not required, but you need to implement it if you want to\nsupport streamed responses\n\n   'Streamed requests not supported by this\n\n  # yield is required to make this a generator for type checking\n\n  \n  \n\n```\n\n  \n---  \nStreamed response from an LLM when calling a tool.\n\n```\n\n\n\n\"\"\"Streamed response from an LLM when calling a tool.\"\"\"\n\n      \n      \n        \n     \n\"\"\"Stream the response as an async iterable of\n[`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s.\"\"\"\n\n       \n        \n     \n  \n      \n\"\"\"Return an async iterator of\n[`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s.\n\n    This method should be implemented by subclasses to translate the vendor-specific stream of events into\n\n     \n    \n    \n     \n\"\"\"Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data\nreceived from the stream so far.\"\"\"\n\n      \n     \n\"\"\"Get the usage of the response so far. This will not be the final usage until\nthe stream is exhausted.\"\"\"\n\n     \n  \n     \n\"\"\"Get the timestamp of the response.\"\"\"\n\n     \n\n```\n\n  \n---  \nStream the response as an async iterable of s.\n\n```\n\n  \n\"\"\"Stream the response as an async iterable of\n[`ModelResponseStreamEvent`][pydantic_ai.messages.ModelResponseStreamEvent]s.\"\"\"\n\n     \n      \n  \n\n```\n\n  \n---  \nBuild a from the data received from the stream so far.\n\n```\n\n  \n\"\"\"Build a [`ModelResponse`][pydantic_ai.messages.ModelResponse] from the data\nreceived from the stream so far.\"\"\"\n\n    \n\n```\n\n  \n---  \nGet the usage of the response so far. This will not be the final usage until the\nstream is exhausted.\n\n```\n\n  \n\"\"\"Get the usage of the response so far. This will not be the final usage until\nthe stream is exhausted.\"\"\"\n\n  \n\n```\n\n  \n---  \nGet the timestamp of the response.\n\n```\n\n  \n\"\"\"Get the timestamp of the response.\"\"\"\n\n  \n\n```\n\n  \n---  \nWhether to allow requests to models.\n\nThis global setting allows you to disable request to most models, e.g. to make\nsure you don't accidentally make costly requests to a model during tests.\n\nThe testing models and are no affected by this setting.\n\nCheck if model requests are allowed.\n\nIf you're defining your own models that have costs or latency associated with\ntheir use, you should call this in .\n\nIf model requests are not allowed.  \n---  \n```\n\n  \n\"\"\"Check if model requests are allowed.\n\n  If you're defining your own models that have costs or latency associated with\ntheir use, you should call this in\n\n    RuntimeError: If model requests are not allowed.\n\n    \n     'Model requests are not allowed, since ALLOW_MODEL_REQUESTS is False'\n\n```\n\n  \n---  \nContext manager to temporarily override .\n\nWhether to allow model requests within the context.  \n---  \n```\n\n    \n\"\"\"Context manager to temporarily override\n[`ALLOW_MODEL_REQUESTS`][pydantic_ai.models.ALLOW_MODEL_REQUESTS].\n\n    allow_model_requests: Whether to allow model requests within the context.\n\n  \n    \n     \n  \n    \n  \n       \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.openai\nURL: https://ai.pydantic.dev/api/models/openai/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFor details on how to set up authentication with this model, see .\n\nUsing this more broad type for the model name instead of the ChatModel\ndefinition allows this model to be used more easily with other model types (ie,\nOllama)\n\nA model that uses the OpenAI API.\n\nInternally, this uses the to interact with the API.\n\nApart from , all methods are private or match those of the base class.\n\n```\n\n\n\n\"\"\"A model that uses the OpenAI API.\n\n  Internally, this uses the [OpenAI Python\nclient](https://github.com/openai/openai-python) to interact with the API.\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n  \n     \n  \n    \n     \n    \n         \n         \n         \n         \n  \n\n      model_name: The name of the OpenAI model to use. List of model names available\n\n        (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API).\n      base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable\n        will be used if available. Otherwise, defaults to OpenAI's base url.\n      api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable\n        will be used if available.\n\n        client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n       \n        \n          'Cannot provide both `openai_client` and `http_client`'\n          'Cannot provide both `openai_client` and `base_url`'\n          'Cannot provide both `openai_client` and `api_key`'\n        \n        \n          \n    \n          \n    \n    \n    \n     \n     \n     \n    \n    \n          \n     \n            \n     \n      \n      \n      \n      \n    \n     \n     \n  \n      \n     \n       \n       \n         \n         \n         \n      \n    \n\n```\n\n  \n---  \nThe name of the OpenAI model to use. List of model names available\n(Unfortunately, despite being ask to do so, OpenAI do not provide files for\ntheir API).  \n---  \nThe base url for the OpenAI requests. If not provided, the environment variable\nwill be used if available. Otherwise, defaults to OpenAI's base url.  \nThe API key to use for authentication, if not provided, the environment variable\nwill be used if available.  \nAn existing client to use. If provided, , , and must be .  \nAn existing to use for making HTTP requests.  \n```\n\n\n\n  \n  \n  \n       \n       \n       \n       \n\n    model_name: The name of the OpenAI model to use. List of model names available\n\n      (Unfortunately, despite being ask to do so, OpenAI do not provide `.inv` files for their API).\n    base_url: The base url for the OpenAI requests. If not provided, the `OPENAI_BASE_URL` environment variable\n      will be used if available. Otherwise, defaults to OpenAI's base url.\n    api_key: The API key to use for authentication, if not provided, the `OPENAI_API_KEY` environment variable\n      will be used if available.\n\n      client to use. If provided, `base_url`, `api_key`, and `http_client` must be `None`.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n     \n      \n        'Cannot provide both `openai_client` and `http_client`'\n        'Cannot provide both `openai_client` and `base_url`'\n        'Cannot provide both `openai_client` and `api_key`'\n      \n      \n        \n  \n        \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `AgentModel` for OpenAI models.\"\"\"\n\n  \n  \n  \n  \n    \n          \n     \n         \n      \n  \n    \n          \n    \n         \n      \n        \n  \n    \n            \n    \n    \n  \n    \n            \n    \n    \n    \n            \n      \n    # standalone function to make it easier to override\n      \n             \n      \n        \n    \n        \n          \n        \n      \n      \n      \n      \n          \n        \n        \n      \n           \n       \n       \n       \n       \n    \n  \n      \n\"\"\"Process a non-streamed response, and prepare a message to return.\"\"\"\n\n       \n      \n       \n        \n      \n        \n         \n          \n      \n  \n       \n\"\"\"Process a streamed response, and prepare a streaming response to return.\"\"\"\n\n      \n       \n      \n       'Streamed response ended without content or tool calls'\n       \n  \n       \n\"\"\"Just maps a `pydantic_ai.Message` to a\n`openai.types.ChatCompletionMessageParam`.\"\"\"\n\n      \n       \n      \n         \n         \n         \n          \n          \n          \n          \n        \n          \n        \n       \n        # Note: model responses from this model should only have one text item, so the following\n        # shouldn't merge multiple texts into one unless you switch models between runs:\n          \n       \n          \n       \n    \n      \n  \n       \n       \n        \n          \n        \n          \n        \n         \n          \n           \n          \n        \n        \n           \n            \n        \n           \n            \n             \n            \n          \n      \n        \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `StreamedResponse` for OpenAI models.\"\"\"\n\n  \n  \n      \n        \n        \n      \n          \n       \n        \n      # Handle the text part of the response\n        \n          \n          \n           \n          \n          \n            \n            \n          \n        \n            \n           \n     \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.anthropic\nURL: https://ai.pydantic.dev/api/models/anthropic/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFor details on how to set up authentication with this model, see .\n\nSince Anthropic supports a variety of date-stamped models, we explicitly list\nthe latest models but allow any name in the type hints. Since for a full list.\n\nA model that uses the Anthropic API.\n\nInternally, this uses the to interact with the API.\n\nApart from , all methods are private or match those of the base class.\n\nThe class does not yet support streaming responses. We anticipate adding support\nfor streaming responses in a near-term future release.\n\n```\n\n\n\n\"\"\"A model that uses the Anthropic API.\n\n  Internally, this uses the [Anthropic Python\nclient](https://github.com/anthropics/anthropic-sdk-python) to interact with the\nAPI.\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n    The `AnthropicModel` class does not yet support streaming responses.\n    We anticipate adding support for streaming responses in a near-term future release.\n\n  \n     \n  \n    \n     \n    \n         \n         \n         \n  \n\n      model_name: The name of the Anthropic model to use. List of model names available\n\n      api_key: The API key to use for authentication, if not provided, the `ANTHROPIC_API_KEY` environment variable\n        will be used if available.\n\n        client to use, if provided, `api_key` and `http_client` must be `None`.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n      \n        \n          'Cannot provide both `anthropic_client` and `http_client`'\n          'Cannot provide both `anthropic_client` and `api_key`'\n        \n        \n         \n    \n         \n    \n    \n    \n     \n     \n     \n    \n    \n          \n     \n            \n     \n      \n      \n      \n      \n    \n     \n     \n  \n      \n     \n       \n       \n       \n    \n\n```\n\n  \n---  \nThe name of the Anthropic model to use. List of model names available .  \n---  \nThe API key to use for authentication, if not provided, the environment variable\nwill be used if available.  \nAn existing client to use, if provided, and must be .  \nAn existing to use for making HTTP requests.  \n```\n\n\n\n  \n  \n  \n       \n       \n       \n\n    model_name: The name of the Anthropic model to use. List of model names available\n\n    api_key: The API key to use for authentication, if not provided, the `ANTHROPIC_API_KEY` environment variable\n      will be used if available.\n\n      client to use, if provided, `api_key` and `http_client` must be `None`.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n    \n      \n        'Cannot provide both `anthropic_client` and `http_client`'\n        'Cannot provide both `anthropic_client` and `api_key`'\n      \n      \n       \n  \n       \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `AgentModel` for Anthropic models.\"\"\"\n\n  \n  \n  \n  \n    \n          \n     \n         \n      \n  \n    \n          \n    \n         \n      \n        \n  \n    \n            \n    \n    \n  \n    \n            \n    \n    \n    \n            \n      \n    # standalone function to make it easier to override\n      \n           \n      \n         \n    \n         \n       \n        \n      \n       \n        \n      \n      \n        \n        \n      \n       \n       \n       \n    \n  \n      \n\"\"\"Process a non-streamed response, and prepare a message to return.\"\"\"\n\n       \n       \n        \n        \n      \n           \n        \n          \n            \n              \n            \n          \n        \n     \n  \n       \n\"\"\"TODO: Process a streamed response, and prepare a streaming response to\nreturn.\"\"\"\n\n    # We don't yet support streamed responses from Anthropic, so we raise an error here for now.\n    # Streamed responses will be supported in a future release.\n     'Streamed responses are not yet supported for Anthropic models.'\n    # Should be returning some sort of AnthropicStreamTextResponse or AnthropicStreamedResponse\n    # depending on the type of chunk we get, but we need to establish how we handle (and when we get) the following:\n    \n    \n    \n    \n    \n    \n    \n    # We might refactor streaming internally before we implement this...\n  \n       \n\"\"\"Just maps a `pydantic_ai.Message` to a `anthropic.types.MessageParam`.\"\"\"\n\n       \n       \n       \n        \n           \n            \n              \n            \n             \n            \n            \n              \n                \n                \n                  \n                     \n                    \n                    \n                    \n                  \n                \n              \n            \n            \n               \n               \n            \n              \n                \n                  \n                  \n                    \n                       \n                      \n                      \n                      \n                    \n                  \n                \n              \n        \n             \n           \n            \n             \n          \n              \n            \n         \n      \n        \n      \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.gemini\nURL: https://ai.pydantic.dev/api/models/gemini/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nCustom interface to the API using and .\n\nThe Google SDK for interacting with the API reads like it was written by a Java\ndeveloper who thought they knew everything about OOP, spent 30 minutes trying to\nlearn Python, gave up and decided to build the library to prove how horrible\nPython is. It also doesn't use httpx for HTTP requests, and tries to implement\ntool calling itself, but doesn't use Pydantic or equivalent for validation.\n\nWe therefore implement support for the API directly.\n\nDespite these shortcomings, the Gemini model is actually quite powerful and very\nfast.\n\nFor details on how to set up authentication with this model, see .\n\nSee for a full list.\n\nA model that uses Gemini via API.\n\nThis is implemented from scratch rather than using a dedicated SDK, good API\ndocumentation is available .\n\nApart from , all methods are private or match those of the base class.\n\n```\n\n\n\n\"\"\"A model that uses Gemini via `generativelanguage.googleapis.com` API.\n\n  This is implemented from scratch rather than using a dedicated SDK, good API\ndocumentation is\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n  \n  \n  \n  \n  \n    \n     \n    \n         \n         \n       \n  \n\n      model_name: The name of the model to use.\n      api_key: The API key to use for authentication, if not provided, the `GEMINI_API_KEY` environment variable\n        will be used if available.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n      url_template: The URL template to use for making requests, you shouldn't need to change this,\n\n        `model` is substituted with the model name, and `function` is added to the end of the URL.\n\n      \n       \n         \n          \n      \n         'API key must be provided or set in the GEMINI_API_KEY environment variable'\n      \n        \n      \n    \n    \n    \n     \n     \n     \n    \n    \n     \n      \n      \n      \n      \n      \n      \n      \n    \n     \n     \n\n```\n\n  \n---  \nThe name of the model to use.  \n---  \nThe API key to use for authentication, if not provided, the environment variable\nwill be used if available.  \nAn existing to use for making HTTP requests.  \nThe URL template to use for making requests, you shouldn't need to change this,\ndocs , is substituted with the model name, and is added to the end of the URL.  \n```\n\n\n\n  \n  \n  \n       \n       \n     \n\n    model_name: The name of the model to use.\n    api_key: The API key to use for authentication, if not provided, the `GEMINI_API_KEY` environment variable\n      will be used if available.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n    url_template: The URL template to use for making requests, you shouldn't need to change this,\n\n      `model` is substituted with the model name, and `function` is added to the end of the URL.\n\n    \n     \n       \n        \n    \n       'API key must be provided or set in the GEMINI_API_KEY environment variable'\n    \n      \n    \n\n```\n\n  \n---  \nAbstract definition for Gemini authentication.\n\n```\n\n\n\n\"\"\"Abstract definition for Gemini authentication.\"\"\"\n\n        \n\n```\n\n  \n---  \nAuthentication using an API key for the header.\n\n```\n\n\n\n\"\"\"Authentication using an API key for the `X-Goog-Api-Key` header.\"\"\"\n\n  \n       \n    \n      \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `AgentModel` for Gemini models.\"\"\"\n\n  \n  \n  \n     \n     \n  \n  \n    \n     \n     \n     \n     \n     \n     \n     \n  \n          \n     \n            \n     \n        \n    \n            \n      \n      \n      \n          \n      \n      \n    \n          \n     \n          \n         \n      \n  \n    \n          \n    \n          \n        \n  \n    \n            \n    \n       \n      \n     \n         \n        \n        \n        \n        \n       \n     \n            \n          \n            \n          \n            \n          \n     \n        \n            \n      \n       \n       \n       \n    \n       \n      \n      \n      \n      \n      \n         \n      \n         \n         \n          \n       \n  \n      \n       \n       'Expected exactly one candidate in Gemini response'\n      \n     \n  \n       \n\"\"\"Process a streamed response, and prepare a streaming response to return.\"\"\"\n\n      \n         \n      \n        \n      \n        \n        \n        \n      \n       \n          \n           \n            \n          \n       \n       'Streamed response ended without content or tool calls'\n      \n  \n  \n      \n     \n       \n       \n       \n        \n           \n           \n            \n            \n            \n            \n            \n             \n            \n               \n              \n            \n                 \n               \n          \n            \n         \n           \n        \n        \n      \n        \n      \n\n```\n\n  \n---  \nImplementation of for the Gemini model.\n\n```\n\n\n\n\"\"\"Implementation of `StreamedResponse` for the Gemini model.\"\"\"\n\n  \n  \n      \n      \n        \n        \n       \n         \n           \n          # Using vendor_part_id=None means we can produce multiple text parts if their deltas are sprinkled\n          # amongst the tool call deltas\n            \n           \n          # Here, we assume all function_call parts are complete and don't have deltas.\n          # We do this by assigning a unique randomly generated \"vendor_part_id\".\n          # We need to confirm whether this is actually true, but if it isn't, we can still handle it properly\n          # it would just be a bit more complicated. And we'd need to confirm the intended semantics.\n            \n            \n            \n            \n            \n          \n              \n             \n        \n              \n      \n    # This method exists to ensure we only yield completed items, so we don't need to worry about\n    # partial gemini responses, which would make everything more complicated\n       \n      \n    # Right now, there are some circumstances where we will have information that could be yielded sooner than it is\n    # But changing that would make things a lot more complicated.\n        \n      \n        \n        \n        \n      \n      # The idea: yield only up to the latest response, which might still be partial.\n      # Note that if the latest response is complete, we could yield it immediately, but there's not a good\n      # allow_partial API to determine if the last item in the list is complete.\n        \n         \n          \n          \n         \n    # Now yield the final response, which should be complete\n     \n        \n        \n       \n     \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.vertexai\nURL: https://ai.pydantic.dev/api/models/vertexai/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nCustom interface to the API for Gemini models.\n\nThis model uses with just the URL and auth method changed from , it relies on\nthe VertexAI and function endpoints having the same schemas as the equivalent .\n\nFor details on how to set up authentication with this model as well as a\ncomparison with the API used by , see [model configuration for Gemini via\nVertexAI](https://ai.pydantic.dev/api/models/models/#gemini-via-vertexai>).\n\nWith the default google project already configured in your environment using\n\"application default credentials\":\n\n```\n\n  \n  \n  \n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\nOr using a service account JSON file:\n\n```\n\n  \n  \n  \n  \n  \n\n  \n  \n\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n```\n\nURL template for Vertex AI.\n\nThe template is used thus:\n\n  * is substituted with the argument, see \n  * is substituted with the from auth/credentials\n  * ( or ) is added to the end of the URL\n\nA model that uses Gemini via the VertexAI API.\n\n```\n\n\n\n\"\"\"A model that uses Gemini via the `*-aiplatform.googleapis.com` VertexAI\nAPI.\"\"\"\n\n  \n       \n     \n  \n  \n  \n  \n     \n     \n  # TODO __init__ can be removed once we drop 3.9 and we can set kw_only\ncorrectly on the dataclass\n\n  \n    \n     \n    \n           \n         \n       \n       \n         \n       \n  \n\"\"\"Initialize a Vertex AI Gemini model.\n\n      model_name: The name of the model to use. I couldn't find a list of supported Google models, in VertexAI\n        so for now this uses the same models as the [Gemini model][pydantic_ai.models.gemini.GeminiModel].\n      service_account_file: Path to a service account file.\n        If not provided, the default environment credentials will be used.\n      project_id: The project ID to use, if not provided it will be taken from the credentials.\n      region: The region to make requests to.\n      model_publisher: The model publisher to use, I couldn't find a good list of available publishers,\n        and from trial and error it seems non-google models don't work with the `generateContent` and\n        `streamGenerateContent` functions, hence only `google` is currently supported.\n        Please create an issue or PR if you know how to use other publishers.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n      url_template: URL template for Vertex AI, see\n\n      \n      \n      \n      \n      \n        \n      \n      \n      \n    \n    \n    \n     \n     \n     \n    \n    \n        \n     \n      \n      \n      \n      \n      \n      \n      \n    \n       \n\"\"\"Initialize the model, setting the URL and auth.\n\n    This will raise an error if authentication fails.\n\n             \n        \n        \n           \n            \n           \n        \n    \n          \n        \n       \n         \n         'No project_id provided and none found in \n        \n    \n              \n         \n          'The project_id you provided does not match the one from \n          \n        \n        \n        \n      \n      \n      \n      \n    \n        \n      \n     \n     \n\n```\n\n  \n---  \nInitialize a Vertex AI Gemini model.\n\nThe name of the model to use. I couldn't find a list of supported Google models,\nin VertexAI so for now this uses the same models as the .  \n---  \nPath to a service account file. If not provided, the default environment\ncredentials will be used.  \nThe project ID to use, if not provided it will be taken from the credentials.  \nThe region to make requests to.  \nThe model publisher to use, I couldn't find a good list of available publishers,\nand from trial and error it seems non-google models don't work with the and\nfunctions, hence only is currently supported. Please create an issue or PR if\nyou know how to use other publishers.  \nAn existing to use for making HTTP requests.  \nURL template for Vertex AI, see for more information.  \n```\n\n\n\n  \n  \n  \n         \n       \n     \n     \n       \n     \n\n\"\"\"Initialize a Vertex AI Gemini model.\n\n    model_name: The name of the model to use. I couldn't find a list of supported Google models, in VertexAI\n      so for now this uses the same models as the [Gemini model][pydantic_ai.models.gemini.GeminiModel].\n    service_account_file: Path to a service account file.\n      If not provided, the default environment credentials will be used.\n    project_id: The project ID to use, if not provided it will be taken from the credentials.\n    region: The region to make requests to.\n    model_publisher: The model publisher to use, I couldn't find a good list of available publishers,\n      and from trial and error it seems non-google models don't work with the `generateContent` and\n      `streamGenerateContent` functions, hence only `google` is currently supported.\n      Please create an issue or PR if you know how to use other publishers.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n    url_template: URL template for Vertex AI, see\n\n    \n    \n    \n    \n    \n      \n    \n    \n    \n\n```\n\n  \n---  \nInitialize the model, setting the URL and auth.\n\nThis will raise an error if authentication fails.\n\n```\n\n     \n\"\"\"Initialize the model, setting the URL and auth.\n\n  This will raise an error if authentication fails.\n\n           \n      \n      \n         \n          \n         \n      \n  \n        \n      \n     \n       \n       'No project_id provided and none found in \n      \n  \n            \n       \n        'The project_id you provided does not match the one from \n        \n      \n      \n      \n    \n    \n    \n    \n  \n      \n    \n\n```\n\n  \n---  \nAuthentication using a bearer token generated by google-auth.\n\n```\n\n\n\n\"\"\"Authentication using a bearer token generated by google-auth.\"\"\"\n\n     \n        \n       \n         \n       \n        \n      \n     \n       \n       \n    \n           \n     \n    \n       'Expected token to be a string, got \n     \n\n```\n\n  \n---  \nRegions available for Vertex AI.\n\n---\n\n# pydantic_ai.models.groq\nURL: https://ai.pydantic.dev/api/models/groq/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFor details on how to set up authentication with this model, see .\n\nSee for a full list.\n\nA model that uses the Groq API.\n\nInternally, this uses the to interact with the API.\n\nApart from , all methods are private or match those of the base class.\n\n```\n\n\n\n\"\"\"A model that uses the Groq API.\n\n  Internally, this uses the [Groq Python client](https://github.com/groq/groq-\npython) to interact with the API.\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n  \n     \n  \n    \n     \n    \n         \n         \n         \n  \n\n      model_name: The name of the Groq model to use. List of model names available\n\n      api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable\n        will be used if available.\n\n        client to use, if provided, `api_key` and `http_client` must be `None`.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n      \n        \n          'Cannot provide both `groq_client` and `http_client`'\n          'Cannot provide both `groq_client` and `api_key`'\n        \n        \n         \n    \n         \n    \n    \n    \n     \n     \n     \n    \n    \n          \n     \n            \n     \n      \n      \n      \n      \n    \n     \n     \n  \n      \n     \n       \n       \n         \n         \n         \n      \n    \n\n```\n\n  \n---  \nThe name of the Groq model to use. List of model names available .  \n---  \nThe API key to use for authentication, if not provided, the environment variable\nwill be used if available.  \nAn existing client to use, if provided, and must be .  \nAn existing to use for making HTTP requests.  \n```\n\n\n\n  \n  \n  \n       \n       \n       \n\n    model_name: The name of the Groq model to use. List of model names available\n\n    api_key: The API key to use for authentication, if not provided, the `GROQ_API_KEY` environment variable\n      will be used if available.\n\n      client to use, if provided, `api_key` and `http_client` must be `None`.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n    \n      \n        'Cannot provide both `groq_client` and `http_client`'\n        'Cannot provide both `groq_client` and `api_key`'\n      \n      \n       \n  \n       \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `AgentModel` for Groq models.\"\"\"\n\n  \n  \n  \n  \n    \n          \n     \n         \n      \n  \n    \n          \n    \n         \n      \n        \n  \n    \n            \n    \n    \n  \n    \n            \n    \n    \n    \n            \n      \n    # standalone function to make it easier to override\n      \n             \n      \n        \n    \n        \n          \n        \n      \n      \n      \n      \n          \n        \n        \n      \n       \n       \n       \n       \n    \n  \n      \n\"\"\"Process a non-streamed response, and prepare a message to return.\"\"\"\n\n       \n      \n       \n        \n      \n        \n         \n        \n            \n        \n      \n  \n       \n\"\"\"Process a streamed response, and prepare a streaming response to return.\"\"\"\n\n      \n       \n      \n       'Streamed response ended without content or tool calls'\n       \n  \n       \n\"\"\"Just maps a `pydantic_ai.Message` to a\n`groq.types.ChatCompletionMessageParam`.\"\"\"\n\n      \n       \n      \n         \n         \n         \n          \n          \n          \n          \n        \n          \n        \n       \n        # Note: model responses from this model should only have one text item, so the following\n        # shouldn't merge multiple texts into one unless you switch models between runs:\n          \n       \n          \n       \n    \n      \n  \n       \n       \n        \n          \n        \n          \n        \n         \n          \n           \n          \n        \n        \n           \n            \n        \n           \n            \n             \n            \n          \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `StreamedResponse` for Groq models.\"\"\"\n\n  \n  \n      \n        \n        \n      \n          \n       \n        \n      # Handle the text part of the response\n        \n          \n          \n      # Handle the tool calls\n           \n          \n          \n            \n            \n          \n        \n            \n           \n     \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.mistral\nURL: https://ai.pydantic.dev/api/models/mistral/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFor details on how to set up authentication with this model, see .\n\nLatest / most popular named Mistral models.\n\nSince Mistral supports a variety of date-stamped models, we explicitly list the\nmost popular models but allow any name in the type hints. Since for a full list.\n\nA model that uses Mistral.\n\nInternally, this uses the to interact with the API.\n\n```\n\n\n\n\"\"\"A model that uses Mistral.\n\n  Internally, this uses the [Mistral Python\nclient](https://github.com/mistralai/client-python) to interact with the API.\n\n  \n     \n  \n    \n     \n    \n              \n         \n         \n  \n\n      model_name: The name of the model to use.\n      api_key: The API key to use for authentication, if unset uses `MISTRAL_API_KEY` environment variable.\n      client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n      \n        \n          'Cannot provide both `mistral_client` and `http_client`'\n          'Cannot provide both `mistral_client` and `api_key`'\n        \n    \n              \n           \n    \n    \n    \n     \n     \n     \n    \n\"\"\"Create an agent model, this is called for each step of an agent run from\nPydantic AI call.\"\"\"\n\n    \n     \n      \n      \n      \n      \n      \n    \n     \n     \n\n```\n\n  \n---  \nThe name of the model to use.  \n---  \nThe API key to use for authentication, if unset uses environment variable.  \nAn existing client to use, if provided, and must be .  \nAn existing to use for making HTTP requests.  \n```\n\n\n\n  \n  \n  \n            \n       \n       \n\n    model_name: The name of the model to use.\n    api_key: The API key to use for authentication, if unset uses `MISTRAL_API_KEY` environment variable.\n    client: An existing `Mistral` client to use, if provided, `api_key` and `http_client` must be `None`.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n    \n      \n        'Cannot provide both `mistral_client` and `http_client`'\n        'Cannot provide both `mistral_client` and `api_key`'\n      \n  \n            \n         \n\n```\n\n  \n---  \nCreate an agent model, this is called for each step of an agent run from\nPydantic AI call.\n\n```\n\n  \n  \n  \n  \n  \n  \n  \n\"\"\"Create an agent model, this is called for each step of an agent run from\nPydantic AI call.\"\"\"\n\n  \n  \n    \n    \n    \n    \n    \n  \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `AgentModel` for Mistral models.\"\"\"\n\n  \n  \n  \n  \n  \n     \"\"\"Answer in JSON Object, respect the format:\n    \n          \n     \n\"\"\"Make a non-streaming request to the model from Pydantic AI call.\"\"\"\n\n        \n      \n  \n    \n          \n    \n\"\"\"Make a streaming request to the model from Pydantic AI call.\"\"\"\n\n        \n      \n         \n    \n          \n    \n\"\"\"Make a non-streaming request to the model.\"\"\"\n\n        \n       \n      \n          \n      \n        \n      \n      \n       \n       \n       \n      \n    \n      'A unexpected empty response from Mistral.'\n     \n    \n    \n     \n       \n    \n\"\"\"Create a streaming completion request to the Mistral model.\"\"\"\n\n       \n          \n        \n         \n      \n         \n        \n        \n        \n          \n        \n         \n         \n         \n        \n      \n     \n      \n            \n        \n      \n         \n        \n        \n         \n        \n      \n    \n      \n         \n        \n        \n        \n      \n      'A unexpected empty response from Mistral.'\n     \n       \n\"\"\"Get tool choice for the model.\n\n    - \"auto\": Default mode. Model decides if it uses the tool or not.\n    - \"any\": Select any tool.\n    - \"none\": Prevents tool use.\n    - \"required\": Forces tool use.\n\n         \n       \n      \n       \n    \n       \n       \n\"\"\"Map function and result tools to MistralTool format.\n\n    Returns None if both function_tools and result_tools are empty.\n\n         \n      \n      \n          \n      \n         \n    \n         \n  \n      \n\"\"\"Process a non-streamed response, and prepare a message to return.\"\"\"\n\n      \n     \n         \n    \n        \n      \n      \n      \n       \n       \n      \n      \n         \n          \n        \n      \n  \n    \n     \n     \n    \n\"\"\"Process a streamed response, and prepare a streaming response to return.\"\"\"\n\n      \n       \n      \n       'Streamed response ended without content or tool calls'\n     \n         \n    \n        \n            \n  \n      \n\"\"\"Maps a pydantic-ai ToolCall to a MistralToolCall.\"\"\"\n\n      \n       \n        \n        \n         \n      \n    \n       \n        \n        \n         \n      \n        \n\"\"\"Get a message with an example of the expected output format.\"\"\"\n\n        \n       \n          \n           \n          \n      \n            \n     \n  \n        \n\"\"\"Return a string representation of the Python type for a single JSON schema\nproperty.\n\n    This function handles recursion for nested arrays/objects and `anyOf`.\n\n    # 1) Handle anyOf first, because it's a different schema structure\n       \n      # Simplistic approach: pick the first option in anyOf\n      # (In reality, you'd possibly want to merge or union types)\n       \n    # 2) If we have a top-level \"type\" field\n      \n      \n      # No explicit type; fallback\n       \n    # 3) Direct simple type mapping (string, integer, float, bool, None)\n               \n       \n    # 4) Array: Recursively get the item type\n       \n         \n       \n    # 5) Object: Check for additionalProperties\n       \n         \n        \n       \n          \n           \n           \n      \n        \n         \n         \n           \n         \n         \n        # nested dictionary of unknown shape\n         \n      \n        # If no additionalProperties type or something else, default to a generic dict\n         \n    \n     \n  \n            \n\"\"\"Convert a timeout to milliseconds.\"\"\"\n\n       \n       \n      \n         \n     'Timeout object is not yet supported for MistralModel.'\n  \n       \n       \n        \n         \n        \n         \n        \n         \n          \n          \n        \n        \n           \n           \n        \n           \n            \n            \n          \n      \n        \n  \n       \n\"\"\"Just maps a `pydantic_ai.Message` to a `MistralMessage`.\"\"\"\n\n      \n       \n      \n         \n         \n         \n          \n          \n          \n          \n        \n          \n        \n    \n      \n\n```\n\n  \n---  \nMake a non-streaming request to the model from Pydantic AI call.\n\n```\n\n  \n        \n  \n\"\"\"Make a non-streaming request to the model from Pydantic AI call.\"\"\"\n\n      \n    \n\n```\n\n  \n---  \nMake a streaming request to the model from Pydantic AI call.\n\n```\n\n  \n        \n  \n\"\"\"Make a streaming request to the model from Pydantic AI call.\"\"\"\n\n      \n    \n       \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `StreamedResponse` for Mistral models.\"\"\"\n\n  \n  \n    \n      \n      \n     \n        \n        \n      \n          \n       \n        \n      # Handle the text part of the response\n        \n        \n       \n        # Attempt to produce a result tool call from the received text\n         \n            \n             \n           \n             \n              \n              \n              \n              \n            \n        \n            \n      # Handle the explicit tool calls\n            \n        # It seems that mistral just sends full tool calls, so we just use them directly, rather than building\n         \n             \n        \n     \n     \n  \n           \n           \n     \n         \n        # NOTE: Additional verification to prevent JSON validation to crash in `_result.py`\n        # Ensures required parameters in the JSON schema are respected, especially for stream-based return types.\n        # Example with BaseModel and required fields.\n          \n           \n        \n          \n        # The following part_id will be thrown away\n          \n  \n          \n\"\"\"Validate that all required parameters in the JSON schema are present in the\nJSON dictionary.\"\"\"\n\n       \n       \n       \n          \n         \n         \n        \n         \n           \n           \n           \n           \n             \n             \n           \n         \n            \n          \n           \n           \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.ollama\nURL: https://ai.pydantic.dev/api/models/ollama/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nFor details on how to set up authentication with this model, see .\n\nWith installed, you can run the server with the model you want to use:\n\n(this will pull the model if you don't already have it downloaded)\n\nThen run your code, here's a minimal example:\n\n```\n\n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\n## Example using a remote server\n\n```\n\n  \n  \n  \n  \n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\nThis contains just the most common ollama models.\n\nFor a full list see .\n\nSince Ollama supports hundreds of models, we explicitly list the most models but\nallow any name in the type hints.\n\nA model that implements Ollama using the OpenAI API.\n\nInternally, this uses the to interact with the Ollama server.\n\nApart from , all methods are private or match those of the base class.\n\n```\n\n\n\n\"\"\"A model that implements Ollama using the OpenAI API.\n\n  Internally, this uses the [OpenAI Python\nclient](https://github.com/openai/openai-python) to interact with the Ollama\nserver.\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n  \n  \n  \n    \n     \n    \n         \n       \n         \n         \n  \n\n    Ollama has built-in compatability for the OpenAI chat completions API ([source](https://ollama.com/blog/openai-compatibility)), so we reuse the\n\n      model_name: The name of the Ollama model to use. List of models available [here](https://ollama.com/library)\n        You must first download the model (`ollama pull <MODEL-NAME>`) in order to use the model\n      base_url: The base url for the ollama requests. The default value is the ollama default\n      api_key: The API key to use for authentication. Defaults to 'ollama' for local instances,\n        but can be customized for proxy setups that require authentication\n\n        client to use, if provided, `base_url` and `http_client` must be `None`.\n      http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n      \n        \n          'Cannot provide both `openai_client` and `base_url`'\n          'Cannot provide both `openai_client` and `http_client`'\n         \n    \n      # API key is not required for ollama but a value is required to create the client\n          \n          \n         \n    \n    \n    \n     \n     \n     \n    \n    \n      \n      \n      \n      \n    \n     \n     \n\n```\n\n  \n---  \nOllama has built-in compatability for the OpenAI chat completions API (), so we\nreuse the here.\n\nThe name of the Ollama model to use. List of models available You must first\ndownload the model () in order to use the model  \n---  \nThe base url for the ollama requests. The default value is the ollama default  \nThe API key to use for authentication. Defaults to 'ollama' for local instances,\nbut can be customized for proxy setups that require authentication  \nAn existing client to use, if provided, and must be .  \nAn existing to use for making HTTP requests.  \n```\n\n\n\n  \n  \n  \n       \n     \n       \n       \n\n  Ollama has built-in compatability for the OpenAI chat completions API\n([source](https://ollama.com/blog/openai-compatibility)), so we reuse the\n\n    model_name: The name of the Ollama model to use. List of models available [here](https://ollama.com/library)\n      You must first download the model (`ollama pull <MODEL-NAME>`) in order to use the model\n    base_url: The base url for the ollama requests. The default value is the ollama default\n    api_key: The API key to use for authentication. Defaults to 'ollama' for local instances,\n      but can be customized for proxy setups that require authentication\n\n      client to use, if provided, `base_url` and `http_client` must be `None`.\n    http_client: An existing `httpx.AsyncClient` to use for making HTTP requests.\n\n    \n      \n        'Cannot provide both `openai_client` and `base_url`'\n        'Cannot provide both `openai_client` and `http_client`'\n       \n  \n    # API key is not required for ollama but a value is required to create the client\n        \n        \n       \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.test\nURL: https://ai.pydantic.dev/api/models/test/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nUtility model for quickly testing apps built with PydanticAI.\n\n```\n\n  \n  \n  \n\n  \n\"\"\"Unit test for my_agent, to be run by pytest.\"\"\"\n\n    \n  \n       \n       \n     \n\n```\n\nSee for detailed documentation.\n\nA model specifically for testing purposes.\n\nThis will (by default) call all tools in the agent, then return a tool response\nif possible, otherwise a plain response.\n\nHow useful this model is will vary significantly.\n\nApart from derived by the decorator, all methods are private or match those of\nthe base class.\n\n```\n\n\n\n\"\"\"A model specifically for testing purposes.\n\n  This will (by default) call all tools in the agent, then return a tool\nresponse if possible,\n\n  How useful this model is will vary significantly.\n\n  Apart from `__init__` derived by the `dataclass` decorator, all methods are\nprivate or match those\n\n  # NOTE: Avoid test discovery by pytest.\n\n    \n       \n\"\"\"List of tools to call. If `'all'`, all tools will be called.\"\"\"\n\n       \n\"\"\"If set, this text is return as the final result.\"\"\"\n\n       \n\"\"\"If set, these args will be passed to the result tool.\"\"\"\n\n     \n\"\"\"Seed for generating random data.\"\"\"\n\n        \n\"\"\"Definition of function tools passed to the model.\n\n  This is set when the model is called, so will reflect the function tools from\nthe last step of the last run.\n\n        \n\"\"\"Whether plain text responses from the model are allowed.\n\n  This is set when the model is called, so will reflect the value from the last\nstep of the last run.\n\n        \n\"\"\"Definition of result tools passed to the model.\n\n  This is set when the model is called, so will reflect the result tools from\nthe last step of the last run.\n\n    \n    \n    \n     \n     \n     \n    \n      \n      \n      \n       \n             \n    \n             \n            \n             \n        \n        'Plain response not allowed, but `custom_result_text` is set.'\n          'Cannot set both `custom_result_text` and `custom_result_args`.'\n              \n        \n           'No result tools provided, but `custom_result_args` is set.'\n        \n         \n           \n      \n          \n     \n        \n     \n        \n    \n        \n        \n     \n     \n\n```\n\n  \n---  \nList of tools to call. If , all tools will be called.\n\nIf set, this text is return as the final result.\n\nIf set, these args will be passed to the result tool.\n\nSeed for generating random data.\n\nDefinition of function tools passed to the model.\n\nThis is set when the model is called, so will reflect the function tools from\nthe last step of the last run.\n\nWhether plain text responses from the model are allowed.\n\nThis is set when the model is called, so will reflect the value from the last\nstep of the last run.\n\nDefinition of result tools passed to the model.\n\nThis is set when the model is called, so will reflect the result tools from the\nlast step of the last run.\n\n```\n\n\n\n\"\"\"Implementation of `AgentModel` for testing purposes.\"\"\"\n\n  # NOTE: Avoid test discovery by pytest.\n\n    \n    \n  # left means the text is plain text; right means it's a function call\n\n        \n  \n  \n    \n          \n     \n       \n       \n      \n  \n    \n          \n    \n       \n      \n       \n      \n           \n    # if there are tools, the first thing we want to do is call all of them\n             \n       \n              \n      \n     \n        \n         'Expected last message to be a `ModelRequest`.'\n      # check if there are any retry prompts, if so retry them\n               \n       \n        # Handle retries for both function tools and result tools\n        # Check function tools first\n           \n           \n              \n             \n        \n        \n         \n          \n            \n               \n                 \n                 \n            \n          \n         \n       \n         \n        # build up details of tool responses\n            \n           \n            \n               \n                \n                  \n         \n           \n        \n           \n      \n         \n    \n        \n        \n          \n          \n          \n      \n          \n          \n\n```\n\n  \n---  \nA structured response that streams test data.\n\n```\n\n\n\n\"\"\"A structured response that streams test data.\"\"\"\n\n  \n  \n      \n     \n      \n      \n        \n        \n          \n           \n              \n        \n               \n              \n             \n          \n          \n           \n            \n            \n      \n               \n         \n             \n        \n     \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_ai.models.function\nURL: https://ai.pydantic.dev/api/models/function/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nA model controlled by a local function.\n\nis similar to , but allows greater control over the model's behavior.\n\nIts primary use case is for more advanced unit testing than is possible with .\n\n```\n\n  \n    \n    \n  \n\n  \n     \n  \n  \n\n  \n\n  \n\n  \n\"\"\"Unit test for my_agent, to be run by pytest.\"\"\"\n\n  \n       \n       \n\n```\n\nSee for detailed documentation.\n\nA model controlled by a local function.\n\nApart from , all methods are private or match those of the base class.\n\n```\n\n\n\n\"\"\"A model controlled by a local function.\n\n  Apart from `__init__`, all methods are private or match those of the base\nclass.\n\n       \n       \n  \n        \n  \n         \n  \n           \n                \n\n    Either `function` or `stream_function` must be provided, providing both is allowed.\n\n      function: The function to call for non-streamed requests.\n      stream_function: The function to call for streamed requests.\n\n           \n       'Either `function` or `stream_function` must be provided'\n      \n      \n    \n    \n    \n     \n     \n     \n    \n     \n           \n    \n     \n       \n        \n      \n        \n      \n     \n\n```\n\n  \n---  \nEither or must be provided, providing both is allowed.\n\nThe function to call for non-streamed requests.  \n---  \nThe function to call for streamed requests.  \n```\n\n              \n\n  Either `function` or `stream_function` must be provided, providing both is\nallowed.\n\n    function: The function to call for non-streamed requests.\n    stream_function: The function to call for streamed requests.\n\n         \n     'Either `function` or `stream_function` must be provided'\n    \n    \n\n```\n\n  \n---  \nThis is passed as the second to functions used within .\n\n```\n\n\n\n  This is passed as the second to functions used within\n[`FunctionModel`][pydantic_ai.models.function.FunctionModel].\n\n  \n\"\"\"The function tools available on this agent.\n\n  These are the tools registered via the [`tool`][pydantic_ai.Agent.tool] and\n\n  \n\"\"\"Whether a plain text result is allowed.\"\"\"\n\n  \n\"\"\"The tools that can called as the final result of the run.\"\"\"\n\n     \n\"\"\"The model settings passed to the run call.\"\"\"\n\n```\n\n  \n---  \nThe function tools available on this agent.\n\nThese are the tools registered via the and decorators.\n\nWhether a plain text result is allowed.\n\nThe tools that can called as the final result of the run.\n\nThe model settings passed to the run call.\n\nIncremental change to a tool call.\n\nUsed to describe a chunk when streaming structured responses.\n\n```\n\n\n\n\"\"\"Incremental change to a tool call.\n\n  Used to describe a chunk when streaming structured responses.\n\n       \n\"\"\"Incremental change to the name of the tool.\"\"\"\n\n       \n\"\"\"Incremental change to the arguments as JSON\"\"\"\n\n```\n\n  \n---  \nIncremental change to the name of the tool.\n\nIncremental change to the arguments as JSON\n\nA mapping of tool call IDs to incremental changes.\n\nA function used to generate a non-streamed response.\n\nA function used to generate a streamed response.\n\nWhile this is defined as having return type of , it should really be considered\nas ,\n\nE.g. you need to yield all text or all , not mix them.\n\n```\n\n\n\n\"\"\"Implementation of `AgentModel` for\n[FunctionModel][pydantic_ai.models.function.FunctionModel].\"\"\"\n\n     \n     \n  \n    \n          \n     \n       \n         'FunctionModel must receive a `function` to support non-streamed requests'\n     \n          \n    \n           \n         \n        \n    # TODO is `messages` right here? Should it just be new messages?\n       \n  \n    \n          \n    \n     \n         \n     'FunctionModel must receive a `stream_function` to support streamed requests'\n       \n       \n      \n       'Stream function must return at least one item'\n     \n\n```\n\n  \n---  \n```\n\n\n\n\"\"\"Implementation of `StreamedResponse` for\n[FunctionModel][pydantic_ai.models.function.FunctionModel].\"\"\"\n\n     \n     \n  \n      \n      \n        \n        \n          \n           \n          \n      \n          \n            \n           \n              \n               \n            \n            \n            \n            \n            \n          \n              \n             \n     \n     \n\n```\n\n  \n---\n\n---\n\n# pydantic_graph\nURL: https://ai.pydantic.dev/api/pydantic_graph/graph/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nIn , a graph is a collection of nodes that can be run in sequence. The nodes\ndefine their outgoing edges — e.g. which nodes may be run next, and thereby the\nstructure of the graph.\n\nHere's a very simple example of a graph which increments a number by 1, but\nmakes sure the number is never 42 at the end.\n\n_(This example is complete, it can be run \"as is\")_\n\nSee For an example of running graph, and for an example of generating a mermaid\ndiagram from the graph.\n\n```\n\n  \n\n  In `pydantic-graph`, a graph is a collection of nodes that can be run in\nsequence. The nodes define\n\n  their outgoing edges — e.g. which nodes may be run next, and thereby the\nstructure of the graph.\n\n  Here's a very simple example of a graph which increments a number by 1, but\nmakes sure the number is never\n\n  from pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n    async def run(self, ctx: GraphRunContext) -> Check42:\n\n    async def run(self, ctx: GraphRunContext) -> Increment | End[int]:\n\n  _(This example is complete, it can be run \"as is\")_\n\n  See [`run`][pydantic_graph.graph.Graph.run] For an example of running graph,\nand\n\n  [`mermaid_code`][pydantic_graph.graph.Graph.mermaid_code] for an example of\ngenerating a mermaid diagram\n\n     \n      \n    \n       \n       \n  \n    \n    \n       \n         \n         \n         \n        \n  \n\"\"\"Create a graph from a sequence of nodes.\n\n      nodes: The nodes which make up the graph, nodes need to be unique and all be generic in the same\n\n      name: Optional name for the graph, if not provided the name will be inferred from the calling frame\n        on the first call to a graph method.\n      state_type: The type of the state for the graph, this can generally be inferred from `nodes`.\n      run_end_type: The type of the result of running the graph, this can generally be inferred from `nodes`.\n      snapshot_state: A function to snapshot the state of the graph, this is used in\n        [`NodeStep`][pydantic_graph.state.NodeStep] and [`EndStep`][pydantic_graph.state.EndStep] to record\n        the state before each step.\n\n      \n      \n      \n      \n      \n          \n       \n       \n    \n    \n    \n       \n    \n       \n       \n       \n      \n\"\"\"Run the graph from a starting node until it ends.\n\n      start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,\n        you need to provide the starting node.\n      state: The initial state of the graph.\n      deps: The dependencies of the graph.\n      infer_name: Whether to infer the graph name from the calling frame.\n\n      The result type from ending the run and the history of the run.\n    Here's an example of running the graph from [above][pydantic_graph.graph.Graph]:\n\n    from never_42 import Increment, MyState, never_42_graph\n\n      _, history = await never_42_graph.run(Increment(), state=state)\n\n      _, history = await never_42_graph.run(Increment(), state=state)\n\n         \n      \n        \n     \n      \n        \n      \n      \n       \n               \n          \n          \n           \n            \n          \n            \n        \n           \n            \n          \n             \n              'Invalid node return type: ``. Expected `BaseNode` or `End`.'\n            \n  \n    \n       \n    \n       \n       \n       \n      \n\n    This is a convenience method that wraps [`self.run`][pydantic_graph.Graph.run] with `loop.run_until_complete(...)`.\n    You therefore can't use this method inside async code or if there's an active event loop.\n\n      start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,\n        you need to provide the starting node.\n      state: The initial state of the graph.\n      deps: The dependencies of the graph.\n      infer_name: Whether to infer the graph name from the calling frame.\n\n      The result type from ending the run and the history of the run.\n\n         \n      \n     \n         \n    \n    \n    \n       \n      \n    \n       \n       \n       \n        \n\"\"\"Run a node in the graph and return the next node to run.\n\n      node: The node to run.\n      history: The history of the graph run so far. NOTE: this will be mutated to add the new step.\n      state: The current state of the graph.\n      deps: The dependencies of the graph.\n      infer_name: Whether to infer the graph name from the calling frame.\n\n      The next node to run or [`End`][pydantic_graph.nodes.End] if the graph has finished.\n\n         \n      \n      \n        \n       ` is not in the graph.'\n       \n       \n        \n        \n         \n          \n    \n          \n    \n     \n               \n\"\"\"Dump the history of a graph run as JSON.\n\n      history: The history of the graph run.\n      indent: The number of spaces to indent the JSON.\n\n      The JSON representation of the history.\n\n      \n            \n\"\"\"Load the history of a graph run from JSON.\n\n      json_bytes: The JSON representation of the history.\n\n      The history of the graph run.\n\n     \n  \n      \n          \n      \n      \n      \n    \n          \n    \n      \n     \n  \n    \n    \n           \n           \n       \n       \n           \n       \n       \n    \n\"\"\"Generate a diagram representing the graph as\n[mermaid](https://mermaid.js.org/) diagram.\n\n      start_node: The node or nodes which can start the graph.\n      title: The title of the diagram, use `False` to not include a title.\n      edge_labels: Whether to include edge labels.\n      notes: Whether to include notes on each node.\n      highlighted_nodes: Optional node or nodes to highlight.\n      highlight_css: The CSS to use for highlighting nodes.\n      infer_name: Whether to infer the graph name from the calling frame.\n\n      The mermaid code for the graph, which can then be rendered as a diagram.\n    Here's an example of generating a diagram for the graph from [above][pydantic_graph.graph.Graph]:\n\n    from never_42 import Increment, never_42_graph\n\n    The rendered diagram will look like this:\n\n         \n      \n         \n        \n     \n      \n      \n      \n      \n        \n      \n      \n    \n  \n          \n    \n\"\"\"Generate a diagram representing the graph as an image.\n\n    The format and diagram can be customized using `kwargs`,\n\n    !!! note \"Uses external service\"\n      This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`\n      is a free service not affiliated with Pydantic.\n\n      infer_name: Whether to infer the graph name from the calling frame.\n      **kwargs: Additional arguments to pass to `mermaid.request_image`.\n\n         \n      \n          \n        \n      \n  \n                \n    \n\"\"\"Generate a diagram representing the graph and save it as an image.\n\n    The format and diagram can be customized using `kwargs`,\n\n    !!! note \"Uses external service\"\n      This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`\n      is a free service not affiliated with Pydantic.\n\n      path: The path to save the image to.\n      infer_name: Whether to infer the graph name from the calling frame.\n      **kwargs: Additional arguments to pass to `mermaid.save_image`.\n\n         \n      \n          \n        \n      \n     \n     \n       \n       \n         \n           \n            \n           \n             \n          # break the inner (bases) loop\n          \n    # state defaults to None, so use that if we can't infer it\n      \n     \n     \n       \n       \n         \n           \n            \n             \n              \n              \n               \n          # break the inner (bases) loop\n          \n     'Could not infer run end type from nodes, please set `run_end_type`.'\n  \n             \n    \n      \n       \n       \n        ` is not unique — found on \n      \n    \n        \n  \n      \n        \n        \n         \n            \n           \n     \n             \n         \n          but not included in the graph.'\n      \n              \n         \n          'Nodes are referenced in the graph but not included in the graph:\n        \n         \n\"\"\"Infer the agent name from the call frame.\n\n        \n             \n          \n           \n            \n          \n         \n        # if we couldn't find the agent in locals and globals are a different dict, try globals\n            \n             \n              \n            \n\n```\n\n  \n---  \nCreate a graph from a sequence of nodes.\n\nThe nodes which make up the graph, nodes need to be unique and all be generic in\nthe same state type.  \n---  \nOptional name for the graph, if not provided the name will be inferred from the\ncalling frame on the first call to a graph method.  \nThe type of the state for the graph, this can generally be inferred from .  \nThe type of the result of running the graph, this can generally be inferred from\n.  \nA function to snapshot the state of the graph, this is used in and to record the\nstate before each step.  \n```\n\n\n\n  \n  \n     \n       \n       \n       \n      \n\n\"\"\"Create a graph from a sequence of nodes.\n\n    nodes: The nodes which make up the graph, nodes need to be unique and all be generic in the same\n\n    name: Optional name for the graph, if not provided the name will be inferred from the calling frame\n      on the first call to a graph method.\n    state_type: The type of the state for the graph, this can generally be inferred from `nodes`.\n    run_end_type: The type of the result of running the graph, this can generally be inferred from `nodes`.\n    snapshot_state: A function to snapshot the state of the graph, this is used in\n      [`NodeStep`][pydantic_graph.state.NodeStep] and [`EndStep`][pydantic_graph.state.EndStep] to record\n      the state before each step.\n\n    \n    \n    \n    \n    \n        \n     \n     \n  \n\n```\n\n  \n---  \nRun the graph from a starting node until it ends.\n\nthe first node to run, since the graph definition doesn't define the entry point\nin the graph, you need to provide the starting node.  \n---  \nThe initial state of the graph.  \nThe dependencies of the graph.  \nWhether to infer the graph name from the calling frame.  \nThe result type from ending the run and the history of the run.  \n---  \nHere's an example of running the graph from :\n\n```\n\n     \n  \n    \n       \n  \n  \n  \n  \n    \n       \n  \n  \n  \n  \n\n```\n\n```\n\n  \n  \n     \n  \n     \n     \n     \n    \n\"\"\"Run the graph from a starting node until it ends.\n\n    start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,\n      you need to provide the starting node.\n    state: The initial state of the graph.\n    deps: The dependencies of the graph.\n    infer_name: Whether to infer the graph name from the calling frame.\n\n    The result type from ending the run and the history of the run.\n  Here's an example of running the graph from\n[above][pydantic_graph.graph.Graph]:\n\n  from never_42 import Increment, MyState, never_42_graph\n\n    _, history = await never_42_graph.run(Increment(), state=state)\n\n    _, history = await never_42_graph.run(Increment(), state=state)\n\n       \n    \n      \n  \n    \n      \n    \n    \n     \n             \n        \n        \n         \n          \n        \n          \n      \n         \n          \n        \n           \n            'Invalid node return type: ``. Expected `BaseNode` or `End`.'\n          \n\n```\n\n  \n---  \nThis is a convenience method that wraps with . You therefore can't use this\nmethod inside async code or if there's an active event loop.\n\nthe first node to run, since the graph definition doesn't define the entry point\nin the graph, you need to provide the starting node.  \n---  \nThe initial state of the graph.  \nThe dependencies of the graph.  \nWhether to infer the graph name from the calling frame.  \nThe result type from ending the run and the history of the run.  \n---  \n```\n\n\n\n  \n     \n  \n     \n     \n     \n    \n\n  This is a convenience method that wraps [`self.run`][pydantic_graph.Graph.run]\nwith `loop.run_until_complete(...)`.\n\n  You therefore can't use this method inside async code or if there's an active\nevent loop.\n\n    start_node: the first node to run, since the graph definition doesn't define the entry point in the graph,\n      you need to provide the starting node.\n    state: The initial state of the graph.\n    deps: The dependencies of the graph.\n    infer_name: Whether to infer the graph name from the calling frame.\n\n    The result type from ending the run and the history of the run.\n\n       \n    \n  \n       \n  \n\n```\n\n  \n---  \nRun a node in the graph and return the next node to run.\n\nThe history of the graph run so far. NOTE: this will be mutated to add the new\nstep.  \n---  \nThe current state of the graph.  \nThe dependencies of the graph.  \nWhether to infer the graph name from the calling frame.  \nThe next node to run or if the graph has finished.  \n---  \n```\n\n  \n  \n     \n    \n  \n     \n     \n     \n      \n\"\"\"Run a node in the graph and return the next node to run.\n\n    node: The node to run.\n    history: The history of the graph run so far. NOTE: this will be mutated to add the new step.\n    state: The current state of the graph.\n    deps: The dependencies of the graph.\n    infer_name: Whether to infer the graph name from the calling frame.\n\n    The next node to run or [`End`][pydantic_graph.nodes.End] if the graph has finished.\n\n       \n    \n    \n      \n     ` is not in the graph.'\n     \n     \n      \n      \n       \n        \n  \n        \n  \n  \n\n```\n\n  \n---  \nDump the history of a graph run as JSON.\n\nThe history of the graph run.  \n---  \nThe number of spaces to indent the JSON.  \nThe JSON representation of the history.  \n---  \n```\n\n             \n\"\"\"Dump the history of a graph run as JSON.\n\n    history: The history of the graph run.\n    indent: The number of spaces to indent the JSON.\n\n    The JSON representation of the history.\n\n    \n\n```\n\n  \n---  \nLoad the history of a graph run from JSON.\n\nThe JSON representation of the history.  \n---  \nThe history of the graph run.  \n---  \n```\n\n          \n\"\"\"Load the history of a graph run from JSON.\n\n    json_bytes: The JSON representation of the history.\n\n    The history of the graph run.\n\n  \n\n```\n\n  \n---  \nGenerate a diagram representing the graph as diagram.\n\nThe node or nodes which can start the graph.  \n---  \nThe title of the diagram, use to not include a title.  \nWhether to include edge labels.  \nWhether to include notes on each node.  \nOptional node or nodes to highlight.  \nThe CSS to use for highlighting nodes.  \nWhether to infer the graph name from the calling frame.  \nThe mermaid code for the graph, which can then be rendered as a diagram.  \n---  \nHere's an example of generating a diagram for the graph from :\n\n```\n\n    \n\n```\n\nThe rendered diagram will look like this:\n\n```\n\n\n\n  \n  \n         \n         \n     \n     \n         \n     \n     \n  \n\"\"\"Generate a diagram representing the graph as\n[mermaid](https://mermaid.js.org/) diagram.\n\n    start_node: The node or nodes which can start the graph.\n    title: The title of the diagram, use `False` to not include a title.\n    edge_labels: Whether to include edge labels.\n    notes: Whether to include notes on each node.\n    highlighted_nodes: Optional node or nodes to highlight.\n    highlight_css: The CSS to use for highlighting nodes.\n    infer_name: Whether to infer the graph name from the calling frame.\n\n    The mermaid code for the graph, which can then be rendered as a diagram.\n  Here's an example of generating a diagram for the graph from\n[above][pydantic_graph.graph.Graph]:\n\n  from never_42 import Increment, never_42_graph\n\n  The rendered diagram will look like this:\n\n       \n    \n       \n      \n  \n    \n    \n    \n    \n      \n    \n    \n  \n\n```\n\n  \n---  \nGenerate a diagram representing the graph as an image.\n\nThe format and diagram can be customized using , see .\n\nThis method makes a request to to render the image, is a free service not\naffiliated with Pydantic.\n\nWhether to infer the graph name from the calling frame.  \n---  \nAdditional arguments to pass to .  \n```\n\n\n\n        \n  \n\"\"\"Generate a diagram representing the graph as an image.\n\n  The format and diagram can be customized using `kwargs`,\n\n  !!! note \"Uses external service\"\n\n    This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`\n    is a free service not affiliated with Pydantic.\n\n    infer_name: Whether to infer the graph name from the calling frame.\n    **kwargs: Additional arguments to pass to `mermaid.request_image`.\n\n       \n    \n        \n      \n    \n\n```\n\n  \n---  \nGenerate a diagram representing the graph and save it as an image.\n\nThe format and diagram can be customized using , see .\n\nThis method makes a request to to render the image, is a free service not\naffiliated with Pydantic.\n\nThe path to save the image to.  \n---  \nWhether to infer the graph name from the calling frame.  \nAdditional arguments to pass to .  \n```\n\n\n\n              \n  \n\"\"\"Generate a diagram representing the graph and save it as an image.\n\n  The format and diagram can be customized using `kwargs`,\n\n  !!! note \"Uses external service\"\n\n    This method makes a request to [mermaid.ink](https://mermaid.ink) to render the image, `mermaid.ink`\n    is a free service not affiliated with Pydantic.\n\n    path: The path to save the image to.\n    infer_name: Whether to infer the graph name from the calling frame.\n    **kwargs: Additional arguments to pass to `mermaid.save_image`.\n\n       \n    \n        \n      \n    \n\n```\n\n  \n---\n\n---\n\n# pydantic_graph.nodes\nURL: https://ai.pydantic.dev/api/pydantic_graph/nodes/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n```\n\n  \n\n  \n\"\"\"The state of the graph.\"\"\"\n\n  \n\n```\n\n  \n---  \nThe state of the graph.\n\nBase class for a node.\n\n```\n\n    \n\"\"\"Base class for a node.\"\"\"\n\n     \n\"\"\"Set to `True` to generate mermaid diagram notes from the class's docstring.\n\n  While this can add valuable information to the diagram, it can make diagrams\nharder to view, hence\n\n  it is disabled by default. You can also customise notes overriding the\n\n  \n             \n\n    This is an abstract method that must be implemented by subclasses.\n    !!! note \"Return types used at runtime\"\n      The return type of this method are read by `pydantic_graph` at runtime and used to define which\n      nodes can be called next in the graph. This is displayed in [mermaid diagrams](mermaid.md)\n      and enforced when running the graph.\n\n      The next node to run or [`End`][pydantic_graph.nodes.End] to signal the end of the graph.\n\n    \n  \n  \n     \n\"\"\"Get the ID of the node.\"\"\"\n\n     \n  \n       \n\"\"\"Get a note about the node to render on mermaid charts.\n\n    By default, this returns a note only if [`docstring_notes`][pydantic_graph.nodes.BaseNode.docstring_notes]\n    is `True`. You can override this method to customise the node notes.\n\n      \n       \n      \n    # dataclasses get an automatic docstring which is just their signature, we don't want that\n         \n        \n     \n      # remove indentation from docstring\n       \n        \n     \n  \n            \n\n        \n    \n        \n       \n        is missing a return type hint on its `run` method'  \n        \n         \n       \n       \n         \n                \n          \n         \n          \n         \n        # TODO: Should we disallow this?\n          \n        \n          \n      \n         \n     \n      \n      \n      \n      \n      \n      \n    \n\n```\n\n  \n---  \nSet to to generate mermaid diagram notes from the class's docstring.\n\nWhile this can add valuable information to the diagram, it can make diagrams\nharder to view, hence it is disabled by default. You can also customise notes\noverriding the method.\n\nThis is an abstract method that must be implemented by subclasses.\n\nReturn types used at runtime\n\nThe return type of this method are read by at runtime and used to define which\nnodes can be called next in the graph. This is displayed in and enforced when\nrunning the graph.\n\nThe next node to run or to signal the end of the graph.  \n---  \n```\n\n           \n\n  This is an abstract method that must be implemented by subclasses.\n\n  !!! note \"Return types used at runtime\"\n\n    The return type of this method are read by `pydantic_graph` at runtime and used to define which\n    nodes can be called next in the graph. This is displayed in [mermaid diagrams](mermaid.md)\n    and enforced when running the graph.\n\n    The next node to run or [`End`][pydantic_graph.nodes.End] to signal the end of the graph.\n\n  \n\n```\n\n  \n---  \nGet the ID of the node.\n\n```\n\n  \n\"\"\"Get the ID of the node.\"\"\"\n\n  \n\n```\n\n  \n---  \nGet a note about the node to render on mermaid charts.\n\nBy default, this returns a note only if is . You can override this method to\ncustomise the node notes.\n\n```\n\n     \n\"\"\"Get a note about the node to render on mermaid charts.\n\n  By default, this returns a note only if\n[`docstring_notes`][pydantic_graph.nodes.BaseNode.docstring_notes]\n\n  is `True`. You can override this method to customise the node notes.\n\n    \n     \n    \n  # dataclasses get an automatic docstring which is just their signature, we\ndon't want that\n\n       \n      \n  \n    # remove indentation from docstring\n     \n      \n  \n\n```\n\n  \n---  \n```\n\n          \n\n      \n  \n      \n     \n      is missing a return type hint on its `run` method'  \n      \n       \n     \n     \n       \n              \n        \n       \n        \n       \n      # TODO: Should we disallow this?\n        \n      \n        \n    \n       \n  \n    \n    \n    \n    \n    \n    \n  \n\n```\n\n  \n---  \nType to return from a node to signal the end of the graph.\n\n```\n\n\n\n\"\"\"Type to return from a node to signal the end of the graph.\"\"\"\n\n  \n\"\"\"Data to return from the graph.\"\"\"\n\n```\n\n  \n---  \nData to return from the graph.\n\nAnnotation to apply a label to an edge in a graph.\n\n```\n\n\n\n\"\"\"Annotation to apply a label to an edge in a graph.\"\"\"\n\n     \n\n```\n\n  \n---  \nType variable for the dependencies of a graph and node.\n\nType variable for the return type of a graph .\n\nType variable for the return type of a node .\n\n---\n\n# pydantic_graph.state\nURL: https://ai.pydantic.dev/api/pydantic_graph/state/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nType variable for the state in a graph.\n\nDefault method for snapshotting the state in a graph run, uses .\n\n```\n\n    \n\"\"\"Default method for snapshotting the state in a graph run, uses\n[`copy.deepcopy`][copy.deepcopy].\"\"\"\n\n     \n     \n  \n     \n\n```\n\n  \n---  \nHistory step describing the execution of a node in a graph.\n\n```\n\n  \n\"\"\"History step describing the execution of a node in a graph.\"\"\"\n\n  \n\"\"\"The state of the graph after the node has been run.\"\"\"\n\n      \n\"\"\"The node that was run.\"\"\"\n\n     \n\"\"\"The timestamp when the node started running.\"\"\"\n\n       \n\"\"\"The duration of the node run in seconds.\"\"\"\n\n     \n\"\"\"The kind of history step, can be used as a discriminator when deserializing\nhistory.\"\"\"\n\n  # TODO waiting for https://github.com/pydantic/pydantic/issues/11264, should\nbe an InitVar\n\n        \n     \n  \n\"\"\"Function to snapshot the state of the graph.\"\"\"\n\n  \n    # Copy the state to prevent it from being modified by other code\n      \n       \n\"\"\"Returns a deep copy of [`self.node`][pydantic_graph.state.NodeStep.node].\n\n     \n\n```\n\n  \n---  \nThe state of the graph after the node has been run.\n\nThe node that was run.\n\nThe timestamp when the node started running.\n\nThe duration of the node run in seconds.\n\nThe kind of history step, can be used as a discriminator when deserializing\nhistory.\n\nFunction to snapshot the state of the graph.\n\nReturns a deep copy of .\n\n```\n\n     \n\"\"\"Returns a deep copy of [`self.node`][pydantic_graph.state.NodeStep.node].\n\n  \n\n```\n\n  \n---  \nHistory step describing the end of a graph run.\n\n```\n\n\n\n\"\"\"History step describing the end of a graph run.\"\"\"\n\n  \n\"\"\"The result of the graph run.\"\"\"\n\n     \n\"\"\"The timestamp when the graph run ended.\"\"\"\n\n     \n\"\"\"The kind of history step, can be used as a discriminator when deserializing\nhistory.\"\"\"\n\n     \n\"\"\"Returns a deep copy of [`self.result`][pydantic_graph.state.EndStep.result].\n\n     \n\n```\n\n  \n---  \nThe result of the graph run.\n\nThe timestamp when the graph run ended.\n\nThe kind of history step, can be used as a discriminator when deserializing\nhistory.\n\nReturns a deep copy of .\n\n```\n\n  \n\"\"\"Returns a deep copy of [`self.result`][pydantic_graph.state.EndStep.result].\n\n  \n\n```\n\n  \n---  \nA step in the history of a graph run.\n\nreturns a list of these steps describing the execution of the graph, together\nwith the run return value.\n\n---\n\n# pydantic_graph.mermaid\nURL: https://ai.pydantic.dev/api/pydantic_graph/mermaid/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nThe default CSS to use for highlighting nodes.\n\nGenerate code for a graph.\n\nThe graph to generate the image for.  \n---  \nIdentifiers of nodes that start the graph.  \nIdentifiers of nodes to highlight.  \nCSS to use for highlighting nodes.  \nThe title of the diagram.  \nWhether to include edge labels in the diagram.  \nWhether to include notes in the diagram.  \nThe Mermaid code for the graph.  \n---  \n```\n\n  \n     \n  \n  \n         \n         \n     \n       \n     \n     \n  \n\"\"\"Generate [Mermaid state\ndiagram](https://mermaid.js.org/syntax/stateDiagram.html) code for a graph.\n\n    graph: The graph to generate the image for.\n    start_node: Identifiers of nodes that start the graph.\n    highlighted_nodes: Identifiers of nodes to highlight.\n    highlight_css: CSS to use for highlighting nodes.\n    title: The title of the diagram.\n    edge_labels: Whether to include edge labels in the diagram.\n    notes: Whether to include notes in the diagram.\n\n    The Mermaid code for the graph.\n\n      \n     \n        \n       \" is not in the graph.'\n     \n  \n        \n  \n      \n    # we use round brackets (rounded box) for nodes other than the start and end\n       \n      \n     \n         \n        \n    \n          \n          \n           \n            \n        \n       \n        \n         \n          \n      \n       \n      \n      # mermaid doesn't like multiple paragraphs in a note, and shows if so\n          \n       \n      \n  \n    \n    \n       \n          \n         \" is not in the graph.'\n      \n  \n\n```\n\n  \n---  \nGenerate an image of a Mermaid diagram using .\n\nThe graph to generate the image for.  \n---  \nAdditional parameters to configure mermaid chart generation.  \n```\n\n\n\n     \n  \n  \n  \n\"\"\"Generate an image of a Mermaid diagram using\n[mermaid.ink](https://mermaid.ink).\n\n    graph: The graph to generate the image for.\n    **kwargs: Additional parameters to configure mermaid chart generation.\n\n    \n    \n    \n    \n     \n    \n     \n     \n  \n    \n        \n     \n      \n     \n        \n     \n        \n       \n        \n     \n      \n  \n      \n       \n        \n     \n      \n     \n      \n     \n      \n     \n      \n     \n      \n      \n     \n    \n     \n      \n      \n      \n    \n  \n\n```\n\n  \n---  \nGenerate an image of a Mermaid diagram using and save it to a local file.\n\nThe path to save the image to.  \n---  \nThe graph to generate the image for.  \nAdditional parameters to configure mermaid chart generation.  \n```\n\n\n\n     \n     \n  \n  \n  \n\"\"\"Generate an image of a Mermaid diagram using\n[mermaid.ink](https://mermaid.ink) and save it to a local file.\n\n    path: The path to save the image to.\n    graph: The graph to generate the image for.\n    **kwargs: Additional parameters to configure mermaid chart generation.\n\n    \n      \n      \n      \n    # no need to check for .jpeg/.jpg, as it is the default\n          \n        \n     \n  \n\n```\n\n  \n---  \nParameters to configure mermaid chart generation.\n\n```\n\n  \n\"\"\"Parameters to configure mermaid chart generation.\"\"\"\n\n     \n\"\"\"Identifiers of nodes that start the graph.\"\"\"\n\n     \n\"\"\"Identifiers of nodes to highlight.\"\"\"\n\n  \n\"\"\"CSS to use for highlighting nodes.\"\"\"\n\n     \n\"\"\"The title of the diagram.\"\"\"\n\n  \n\"\"\"Whether to include edge labels in the diagram.\"\"\"\n\n  \n\"\"\"Whether to include notes on nodes in the diagram, defaults to true.\"\"\"\n\n       \n\"\"\"The image type to generate. If unspecified, the default behavior is\n`'jpeg'`.\"\"\"\n\n  \n\"\"\"When using image_type='pdf', whether to fit the diagram to the PDF page.\"\"\"\n\n  \n\"\"\"When using image_type='pdf', whether to use landscape orientation for the\nPDF.\n\n  This has no effect if using `pdf_fit`.\n\n             \n\"\"\"When using image_type='pdf', the paper size of the PDF.\"\"\"\n\n  \n\"\"\"The background color of the diagram.\n\n  If None, the default transparent background is used. The color value is\ninterpreted as a hexadecimal color\n\n  code by default (and should not have a leading '#'), but you can also use\nnamed colors by prefixing the\n\n  value with `'!'`. For example, valid choices include\n`background_color='!white'` or `background_color='FF0000'`.\n\n      \n\"\"\"The theme of the diagram. Defaults to 'default'.\"\"\"\n\n  \n\"\"\"The width of the diagram.\"\"\"\n\n  \n\"\"\"The height of the diagram.\"\"\"\n\n     \n\"\"\"The scale of the diagram.\n\n  The scale must be a number between 1 and 3, and you can only set a scale if\none or both of width and height are set.\n\n  \n\"\"\"An HTTPX client to use for requests, mostly for testing purposes.\"\"\"\n\n```\n\n  \n---  \nIdentifiers of nodes that start the graph.\n\nIdentifiers of nodes to highlight.\n\nCSS to use for highlighting nodes.\n\nThe title of the diagram.\n\nWhether to include edge labels in the diagram.\n\nWhether to include notes on nodes in the diagram, defaults to true.\n\nThe image type to generate. If unspecified, the default behavior is .\n\nWhen using image_type='pdf', whether to fit the diagram to the PDF page.\n\nWhen using image_type='pdf', whether to use landscape orientation for the PDF.\n\nThis has no effect if using .\n\nWhen using image_type='pdf', the paper size of the PDF.\n\nThe background color of the diagram.\n\nIf None, the default transparent background is used. The color value is\ninterpreted as a hexadecimal color code by default (and should not have a\nleading '#'), but you can also use named colors by prefixing the value with .\nFor example, valid choices include or .\n\nThe theme of the diagram. Defaults to 'default'.\n\nThe width of the diagram.\n\nThe height of the diagram.\n\nThe scale of the diagram.\n\nThe scale must be a number between 1 and 3, and you can only set a scale if one\nor both of width and height are set.\n\nAn HTTPX client to use for requests, mostly for testing purposes.\n\n```\n\n  \n  \"type[BaseNode[Any, Any, Any]] | BaseNode[Any, Any, Any] | str\"\n\n```\n\nA type alias for a node identifier.\n\n  * A node instance (instance of a subclass of ).\n  * A node class (subclass of ).\n  * A string representing the node ID.\n\n---\n\n# pydantic_graph.exceptions\nURL: https://ai.pydantic.dev/api/pydantic_graph/exceptions/\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nError caused by an incorrectly configured graph.\n\n```\n\n\n\n\"\"\"Error caused by an incorrectly configured graph.\"\"\"\n\n  \n\n     \n      \n    \n\n```\n\n  \n---  \nError caused by an issue during graph execution.\n\n```\n\n\n\n\"\"\"Error caused by an issue during graph execution.\"\"\"\n\n  \n\n     \n      \n    \n\n```\n\n  \n---\n\n---\n\n# type checking\nURL: https://ai.pydantic.dev/agents/#static-type-checking\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nAgents are PydanticAI's primary interface for interacting with LLMs.\n\nIn some use cases a single Agent will control an entire application or\ncomponent, but multiple agents can also interact to embody more complex\nworkflows.\n\nThe class has full API documentation, but conceptually you can think of an agent\nas a container for:\n\nA set of instructions for the LLM written by the developer.  \n---  \nFunctions that the LLM may call to get information while generating a response.  \nThe structured datatype the LLM must return at the end of a run, if specified.  \nSystem prompt functions, tools, and result validators may all use dependencies\nwhen they're run.  \nOptional default LLM model associated with the agent. Can also be specified when\nrunning the agent.  \nOptional default model settings to help fine tune requests. Can also be\nspecified when running the agent.  \nIn typing terms, agents are generic in their dependency and result types, e.g.,\nan agent which required dependencies of type and returned results of type would\nhave type . In practice, you shouldn't need to care about this, it should just\nmean your IDE can tell you when you have the right type, and if you choose to\nuse it should work well with PydanticAI.\n\nHere's a toy example of an agent that simulates a roulette wheel:\n\n```\n\n    \n  \n  \n  \n  \n  \n    'Use the `roulette_wheel` function to see if the '\n    'customer has won based on the number they provide.'\n  \n\n        \n\"\"\"check if the square is a winner\"\"\"\n\n         \n\n  \n  'Put my money on square eighteen'\n\n\n\n  'I bet five is the winner'\n\n```\n\nAgents are designed for reuse, like FastAPI Apps\n\nAgents are intended to be instantiated once (frequently as module globals) and\nreused throughout your application, similar to a small app or an .\n\nThere are three ways to run an agent:\n\n  1. — a coroutine which returns a containing a completed response\n  2. — a plain, synchronous function which returns a containing a completed response (internally, this just calls )\n  3. — a coroutine which returns a , which contains methods to stream a response as an async iterable\n\nHere's a simple example demonstrating all three:\n\n```\n\n  \n  \n  'What is the capital of Italy?'\n\n  \n     'What is the capital of France?'\n  \n  \n    'What is the capital of the UK?'  \n     \n    \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nYou can also pass messages from previous runs to continue a conversation or\nprovide context, as described in .\n\nPydanticAI offers a structure to help you limit your usage (tokens and/or\nrequests) on model runs.\n\nYou can apply these settings by passing the argument to the functions.\n\nConsider the following example, where we limit the number of response tokens:\n\n```\n\n  \n  \n  \n  \n  \n  'What is the capital of Italy? Answer with just the city.'\n\n  \n\nUsage(requests=1, request_tokens=62, response_tokens=1, total_tokens=63,\ndetails=None)\n\n    \n    'What is the capital of Italy? Answer with a paragraph.'\n    \n  \n  \n  \n  #> Exceeded the response_tokens_limit of 10 (response_tokens=32)\n\n```\n\nRestricting the number of requests can be useful in preventing infinite loops or\nexcessive tool calling:\n\n```\n\n  \n    \n  \n  \n\n\n\n  Never ever coerce data to this type.\n\n  \n\n  \n  \n  \n  'Any time you get a response, call the `infinite_retry_tool` to produce\nanother response.'\n\n\n\n  \n  \n\n    \n      \n  \n  \n  \n  #> The next request would exceed the request_limit of 3\n\n```\n\nThis is especially relevant if you're registered a lot of tools, can be used to\nprevent the model from choosing to make too many of these calls.\n\nPydanticAI offers a structure to help you fine tune your requests. This\nstructure allows you to configure common parameters that influence the model's\nbehavior, such as , , , and more.\n\nThere are two ways to apply these settings: 1. Passing to functions via the\nargument. This allows for fine-tuning on a per-request basis. 2. Setting during\ninitialization via the argument. These settings will be applied by default to\nall subsequent run calls using said agent. However, provided during a specific\nrun call will override the agent's default settings.\n\nFor example, if you'd like to set the setting to to ensure less random behavior,\nyou can do the following:\n\n```\n\n  \n  \n  \n  'What is the capital of Italy?'  \n\n```\n\nAn agent might represent an entire conversation — there's no limit to how many\nmessages can be exchanged in a single run. However, a might also be composed of\nmultiple runs, especially if you need to maintain state between separate\ninteractions or API calls.\n\nHere's an example of a conversation comprised of multiple runs:\n\n```\n\n  \n  \n\n  \n\n#> Albert Einstein was a German-born theoretical physicist.\n\n# Second run, passing previous messages\n\n  \n  'What was his most famous equation?'\n\n#> Albert Einstein's most famous equation is (E = mc^2).\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nPydanticAI is designed to work well with static type checkers, like mypy and\npyright.\n\nPydanticAI is designed to make type checking as useful as possible for you if\nyou choose to use it, but you don't have to use types everywhere all the time.\n\nThat said, because PydanticAI uses Pydantic, and Pydantic uses type hints as the\ndefinition for schema and validation, some types (specifically type hints on\nparameters to tools, and the arguments to ) are used at runtime.\n\nWe (the library developers) have messed up if type hints are confusing you more\nthan helping you, if you find this, please create an explaining what's annoying\nyou!\n\nIn particular, agents are generic in both the type of their dependencies and the\ntype of results they return, so you can use the type hints to ensure you're\nusing the right types.\n\nConsider the following script with type mistakes:\n\n```\n\n  \n    \n\n\n\n  \n\n  \n  \n  \n  \n\n     \n  \n\n    \n  \n\n  'Does their name start with \"A\"?'\n\n```\n\nRunning on this will give the following output:\n\nRunning would identify the same issues.\n\nSystem prompts might seem simple at first glance since they're just strings (or\nsequences of strings that are concatenated), but crafting the right system\nprompt is key to getting the model to behave as you want.\n\nGenerally, system prompts fall into two categories:\n\n  1. : These are known when writing the code and can be defined via the parameter of the .\n  2. : These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with .\n\nYou can add both to a single agent; they're appended in the order they're\ndefined at runtime.\n\nHere's an example using both types of system prompts:\n\n```\n\n  \n    \n  \n  \n  \n  \"Use the customer's name while replying to them.\"\n\n\n\n    \n  \n\n    \n  \n\n  \n\n#> Hello Frank, the date today is 2032-01-02.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nValidation errors from both function tool parameter validation and can be passed\nback to the model with a request to retry.\n\nYou can also raise from within a or to tell the model it should retry generating\na response.\n\n  * The default retry count is but can be altered for the , a , or a .\n  * You can access the current retry count from within a tool or result validator via .\n\n```\n\n  \n     \n  \n\n\n\n  \n  \n\n  \n  \n  \n  \n\n      \n\"\"\"Get a user's ID from their full name.\"\"\"\n\n  \n  \n  \n    \n     \n     \n      'No user found with name , remember to provide their full name'\n    \n  \n\n  \n  'Send a message to John Doe asking for coffee next week'\n\nuser_id=123 message='Hello John, would you be free for coffee sometime next\nweek? Let me know what works for you!'\n\n```\n\nIf models behave unexpectedly (e.g., the retry limit is exceeded, or their API\nreturns ), agent runs will raise .\n\nIn these cases, can be used to access the messages exchanged during the run to\nhelp diagnose the issue.\n\n```\n\n      \n  \n\n     \n     \n     \n  \n     \n\n    \n  \n      'Please get me the volume of a box with size 6.'\n     \n     \n    #> An error occurred: Tool exceeded max retries count of 1\n     \n    #> cause: ModelRetry('Please try again.')\n     \n\n            content='Please get me the volume of a box with size 6.',\n\n  \n    \n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nIf you call , , or more than once within a single context, will represent the\nmessages exchanged during the first call only.\n\n---\n\n# validate and structure\nURL: https://ai.pydantic.dev/results/#structured-result-validation\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nResults are the final values returned from . The result values are wrapped in\nand so you can access other data like of the run and\n\nBoth and are generic in the data they wrap, so typing information about the data\nreturned by the agent is preserved.\n\n```\n\n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nRuns end when either a plain text response is received or the model calls a tool\nassociated with one of the structured result types. We will add limits to make\nsure a run doesn't go on indefinitely, see .\n\nWhen the result type is , or a union including , plain text responses are\nenabled on the model, and the raw text response from the model is used as the\nresponse data.\n\nIf the result type is a union with multiple members (after remove from the\nmembers), each member is registered as a separate tool with the model in order\nto reduce the complexity of the tool schemas and maximise the chances a model\nwill respond correctly.\n\nIf the result type schema is not of type , the result type is wrapped in a\nsingle element object, so the schema of all tools registered with the model are\nobject schemas.\n\nStructured results (like tools) use Pydantic to build the JSON schema used for\nthe tool, and to validate the data returned by the model.\n\nUntil \"Annotating Type Forms\" lands, unions are not valid as s in Python.\n\nWhen creating the agent we need to the argument, and add a type hint to tell\ntype checkers about the type of the agent.\n\nHere's an example of returning either text or a structured value\n\n```\n\n  \n  \n  \n\n\n\n  \n  \n  \n  \n\n     \n  \n    \n  \n    \"Extract me the dimensions of a box, \"\n    \"if you can't extract all data, ask the user to try again.\"\n  \n\n  \n\n#> Please provide the units for the dimensions (e.g., cm, in, m).\n\n  'The box is 10x20x30 cm'\n\n#> width=10 height=20 depth=30 units='cm'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nHere's an example of using a union return type which registered multiple tools,\nand wraps non-object schemas in an object:\n\n```\n\n  \n  \n     \n  \n    \n  'Extract either colors or sizes from the shapes provided.'\n\n  'red square, blue circle, green triangle'\n\n  'square size 10, circle size 20, triangle size 30'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nSome validation is inconvenient or impossible to do in Pydantic validators, in\nparticular when the validation requires IO and is asynchronous. PydanticAI\nprovides a way to add validation functions via the decorator.\n\nHere's a simplified variant of the :\n\n```\n\n  \n    \n  \n     \n\n\n\n  \n\n\n\n  \n\n  \n    \n  \n  \n  \n  'Generate PostgreSQL flavored SQL queries based on user input.'\n\n       \n    \n     \n  \n     \n     \n       \n  \n     \n\n  \n  'get me uses who were last active yesterday.'\n\n#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1\nday'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThere two main challenges with streamed results:\n\n  1. Validating structured responses before they're complete, this is achieved by \"partial validation\" which was recently added to Pydantic in .\n  2. When receiving a response, we don't know if it's the final response without starting to stream it and peeking at the content. PydanticAI streams just enough of the response to sniff out if it's a tool call or a result, then streams the whole thing and calls tools, or returns the stream as a .\n\nExample of streamed text result:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'   \n         \n      \n      \n      #> The first known use of \"hello,\n      #> The first known use of \"hello, world\" was in\n      #> The first known use of \"hello, world\" was in a 1974 textbook\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nWe can also stream text as deltas rather than the entire text in each item:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'  \n         \n      \n      \n      \n      \n      \n      \n      \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nResult message not included in\n\nThe final result message will be added to result messages if you use , see for\nmore information.\n\nNot all types are supported with partial validation in Pydantic, see , generally\nfor model-like structures it's currently best to use .\n\nHere's an example of streaming a use profile as it's built:\n\n```\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n  'Extract a user profile from the input'\n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nIf you want fine-grained control of validation, particularly catching validation\nerrors, you can use the following pattern:\n\n```\n\n  \n  \n  \n  \n\n  \n  \n  \n  \n\n  \n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n          \n      \n            \n          \n           \n        \n       \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThe following examples demonstrate how to use streamed responses in PydanticAI:\n\n---\n\n# system prompts\nURL: https://ai.pydantic.dev/agents/#system-prompts\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nAgents are PydanticAI's primary interface for interacting with LLMs.\n\nIn some use cases a single Agent will control an entire application or\ncomponent, but multiple agents can also interact to embody more complex\nworkflows.\n\nThe class has full API documentation, but conceptually you can think of an agent\nas a container for:\n\nA set of instructions for the LLM written by the developer.  \n---  \nFunctions that the LLM may call to get information while generating a response.  \nThe structured datatype the LLM must return at the end of a run, if specified.  \nSystem prompt functions, tools, and result validators may all use dependencies\nwhen they're run.  \nOptional default LLM model associated with the agent. Can also be specified when\nrunning the agent.  \nOptional default model settings to help fine tune requests. Can also be\nspecified when running the agent.  \nIn typing terms, agents are generic in their dependency and result types, e.g.,\nan agent which required dependencies of type and returned results of type would\nhave type . In practice, you shouldn't need to care about this, it should just\nmean your IDE can tell you when you have the right type, and if you choose to\nuse it should work well with PydanticAI.\n\nHere's a toy example of an agent that simulates a roulette wheel:\n\n```\n\n    \n  \n  \n  \n  \n  \n    'Use the `roulette_wheel` function to see if the '\n    'customer has won based on the number they provide.'\n  \n\n        \n\"\"\"check if the square is a winner\"\"\"\n\n         \n\n  \n  'Put my money on square eighteen'\n\n\n\n  'I bet five is the winner'\n\n```\n\nAgents are designed for reuse, like FastAPI Apps\n\nAgents are intended to be instantiated once (frequently as module globals) and\nreused throughout your application, similar to a small app or an .\n\nThere are three ways to run an agent:\n\n  1. — a coroutine which returns a containing a completed response\n  2. — a plain, synchronous function which returns a containing a completed response (internally, this just calls )\n  3. — a coroutine which returns a , which contains methods to stream a response as an async iterable\n\nHere's a simple example demonstrating all three:\n\n```\n\n  \n  \n  'What is the capital of Italy?'\n\n  \n     'What is the capital of France?'\n  \n  \n    'What is the capital of the UK?'  \n     \n    \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nYou can also pass messages from previous runs to continue a conversation or\nprovide context, as described in .\n\nPydanticAI offers a structure to help you limit your usage (tokens and/or\nrequests) on model runs.\n\nYou can apply these settings by passing the argument to the functions.\n\nConsider the following example, where we limit the number of response tokens:\n\n```\n\n  \n  \n  \n  \n  \n  'What is the capital of Italy? Answer with just the city.'\n\n  \n\nUsage(requests=1, request_tokens=62, response_tokens=1, total_tokens=63,\ndetails=None)\n\n    \n    'What is the capital of Italy? Answer with a paragraph.'\n    \n  \n  \n  \n  #> Exceeded the response_tokens_limit of 10 (response_tokens=32)\n\n```\n\nRestricting the number of requests can be useful in preventing infinite loops or\nexcessive tool calling:\n\n```\n\n  \n    \n  \n  \n\n\n\n  Never ever coerce data to this type.\n\n  \n\n  \n  \n  \n  'Any time you get a response, call the `infinite_retry_tool` to produce\nanother response.'\n\n\n\n  \n  \n\n    \n      \n  \n  \n  \n  #> The next request would exceed the request_limit of 3\n\n```\n\nThis is especially relevant if you're registered a lot of tools, can be used to\nprevent the model from choosing to make too many of these calls.\n\nPydanticAI offers a structure to help you fine tune your requests. This\nstructure allows you to configure common parameters that influence the model's\nbehavior, such as , , , and more.\n\nThere are two ways to apply these settings: 1. Passing to functions via the\nargument. This allows for fine-tuning on a per-request basis. 2. Setting during\ninitialization via the argument. These settings will be applied by default to\nall subsequent run calls using said agent. However, provided during a specific\nrun call will override the agent's default settings.\n\nFor example, if you'd like to set the setting to to ensure less random behavior,\nyou can do the following:\n\n```\n\n  \n  \n  \n  'What is the capital of Italy?'  \n\n```\n\nAn agent might represent an entire conversation — there's no limit to how many\nmessages can be exchanged in a single run. However, a might also be composed of\nmultiple runs, especially if you need to maintain state between separate\ninteractions or API calls.\n\nHere's an example of a conversation comprised of multiple runs:\n\n```\n\n  \n  \n\n  \n\n#> Albert Einstein was a German-born theoretical physicist.\n\n# Second run, passing previous messages\n\n  \n  'What was his most famous equation?'\n\n#> Albert Einstein's most famous equation is (E = mc^2).\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nPydanticAI is designed to work well with static type checkers, like mypy and\npyright.\n\nPydanticAI is designed to make type checking as useful as possible for you if\nyou choose to use it, but you don't have to use types everywhere all the time.\n\nThat said, because PydanticAI uses Pydantic, and Pydantic uses type hints as the\ndefinition for schema and validation, some types (specifically type hints on\nparameters to tools, and the arguments to ) are used at runtime.\n\nWe (the library developers) have messed up if type hints are confusing you more\nthan helping you, if you find this, please create an explaining what's annoying\nyou!\n\nIn particular, agents are generic in both the type of their dependencies and the\ntype of results they return, so you can use the type hints to ensure you're\nusing the right types.\n\nConsider the following script with type mistakes:\n\n```\n\n  \n    \n\n\n\n  \n\n  \n  \n  \n  \n\n     \n  \n\n    \n  \n\n  'Does their name start with \"A\"?'\n\n```\n\nRunning on this will give the following output:\n\nRunning would identify the same issues.\n\nSystem prompts might seem simple at first glance since they're just strings (or\nsequences of strings that are concatenated), but crafting the right system\nprompt is key to getting the model to behave as you want.\n\nGenerally, system prompts fall into two categories:\n\n  1. : These are known when writing the code and can be defined via the parameter of the .\n  2. : These depend in some way on context that isn't known until runtime, and should be defined via functions decorated with .\n\nYou can add both to a single agent; they're appended in the order they're\ndefined at runtime.\n\nHere's an example using both types of system prompts:\n\n```\n\n  \n    \n  \n  \n  \n  \"Use the customer's name while replying to them.\"\n\n\n\n    \n  \n\n    \n  \n\n  \n\n#> Hello Frank, the date today is 2032-01-02.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nValidation errors from both function tool parameter validation and can be passed\nback to the model with a request to retry.\n\nYou can also raise from within a or to tell the model it should retry generating\na response.\n\n  * The default retry count is but can be altered for the , a , or a .\n  * You can access the current retry count from within a tool or result validator via .\n\n```\n\n  \n     \n  \n\n\n\n  \n  \n\n  \n  \n  \n  \n\n      \n\"\"\"Get a user's ID from their full name.\"\"\"\n\n  \n  \n  \n    \n     \n     \n      'No user found with name , remember to provide their full name'\n    \n  \n\n  \n  'Send a message to John Doe asking for coffee next week'\n\nuser_id=123 message='Hello John, would you be free for coffee sometime next\nweek? Let me know what works for you!'\n\n```\n\nIf models behave unexpectedly (e.g., the retry limit is exceeded, or their API\nreturns ), agent runs will raise .\n\nIn these cases, can be used to access the messages exchanged during the run to\nhelp diagnose the issue.\n\n```\n\n      \n  \n\n     \n     \n     \n  \n     \n\n    \n  \n      'Please get me the volume of a box with size 6.'\n     \n     \n    #> An error occurred: Tool exceeded max retries count of 1\n     \n    #> cause: ModelRetry('Please try again.')\n     \n\n            content='Please get me the volume of a box with size 6.',\n\n  \n    \n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nIf you call , , or more than once within a single context, will represent the\nmessages exchanged during the first call only.\n\n---\n\n# result validators\nURL: https://ai.pydantic.dev/results/#result-validators-functions\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nResults are the final values returned from . The result values are wrapped in\nand so you can access other data like of the run and\n\nBoth and are generic in the data they wrap, so typing information about the data\nreturned by the agent is preserved.\n\n```\n\n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nRuns end when either a plain text response is received or the model calls a tool\nassociated with one of the structured result types. We will add limits to make\nsure a run doesn't go on indefinitely, see .\n\nWhen the result type is , or a union including , plain text responses are\nenabled on the model, and the raw text response from the model is used as the\nresponse data.\n\nIf the result type is a union with multiple members (after remove from the\nmembers), each member is registered as a separate tool with the model in order\nto reduce the complexity of the tool schemas and maximise the chances a model\nwill respond correctly.\n\nIf the result type schema is not of type , the result type is wrapped in a\nsingle element object, so the schema of all tools registered with the model are\nobject schemas.\n\nStructured results (like tools) use Pydantic to build the JSON schema used for\nthe tool, and to validate the data returned by the model.\n\nUntil \"Annotating Type Forms\" lands, unions are not valid as s in Python.\n\nWhen creating the agent we need to the argument, and add a type hint to tell\ntype checkers about the type of the agent.\n\nHere's an example of returning either text or a structured value\n\n```\n\n  \n  \n  \n\n\n\n  \n  \n  \n  \n\n     \n  \n    \n  \n    \"Extract me the dimensions of a box, \"\n    \"if you can't extract all data, ask the user to try again.\"\n  \n\n  \n\n#> Please provide the units for the dimensions (e.g., cm, in, m).\n\n  'The box is 10x20x30 cm'\n\n#> width=10 height=20 depth=30 units='cm'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nHere's an example of using a union return type which registered multiple tools,\nand wraps non-object schemas in an object:\n\n```\n\n  \n  \n     \n  \n    \n  'Extract either colors or sizes from the shapes provided.'\n\n  'red square, blue circle, green triangle'\n\n  'square size 10, circle size 20, triangle size 30'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nSome validation is inconvenient or impossible to do in Pydantic validators, in\nparticular when the validation requires IO and is asynchronous. PydanticAI\nprovides a way to add validation functions via the decorator.\n\nHere's a simplified variant of the :\n\n```\n\n  \n    \n  \n     \n\n\n\n  \n\n\n\n  \n\n  \n    \n  \n  \n  \n  'Generate PostgreSQL flavored SQL queries based on user input.'\n\n       \n    \n     \n  \n     \n     \n       \n  \n     \n\n  \n  'get me uses who were last active yesterday.'\n\n#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1\nday'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThere two main challenges with streamed results:\n\n  1. Validating structured responses before they're complete, this is achieved by \"partial validation\" which was recently added to Pydantic in .\n  2. When receiving a response, we don't know if it's the final response without starting to stream it and peeking at the content. PydanticAI streams just enough of the response to sniff out if it's a tool call or a result, then streams the whole thing and calls tools, or returns the stream as a .\n\nExample of streamed text result:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'   \n         \n      \n      \n      #> The first known use of \"hello,\n      #> The first known use of \"hello, world\" was in\n      #> The first known use of \"hello, world\" was in a 1974 textbook\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nWe can also stream text as deltas rather than the entire text in each item:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'  \n         \n      \n      \n      \n      \n      \n      \n      \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nResult message not included in\n\nThe final result message will be added to result messages if you use , see for\nmore information.\n\nNot all types are supported with partial validation in Pydantic, see , generally\nfor model-like structures it's currently best to use .\n\nHere's an example of streaming a use profile as it's built:\n\n```\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n  'Extract a user profile from the input'\n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nIf you want fine-grained control of validation, particularly catching validation\nerrors, you can use the following pattern:\n\n```\n\n  \n  \n  \n  \n\n  \n  \n  \n  \n\n  \n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n          \n      \n            \n          \n           \n        \n       \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThe following examples demonstrate how to use streamed responses in PydanticAI:\n\n---\n\n# stream\nURL: https://ai.pydantic.dev/results/#streamed-results\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\nResults are the final values returned from . The result values are wrapped in\nand so you can access other data like of the run and\n\nBoth and are generic in the data they wrap, so typing information about the data\nreturned by the agent is preserved.\n\n```\n\n  \n  \n\n\n\n  \n  \n\n  \n  'Where were the olympics held in 2012?'\n\nUsage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65,\ndetails=None)\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nRuns end when either a plain text response is received or the model calls a tool\nassociated with one of the structured result types. We will add limits to make\nsure a run doesn't go on indefinitely, see .\n\nWhen the result type is , or a union including , plain text responses are\nenabled on the model, and the raw text response from the model is used as the\nresponse data.\n\nIf the result type is a union with multiple members (after remove from the\nmembers), each member is registered as a separate tool with the model in order\nto reduce the complexity of the tool schemas and maximise the chances a model\nwill respond correctly.\n\nIf the result type schema is not of type , the result type is wrapped in a\nsingle element object, so the schema of all tools registered with the model are\nobject schemas.\n\nStructured results (like tools) use Pydantic to build the JSON schema used for\nthe tool, and to validate the data returned by the model.\n\nUntil \"Annotating Type Forms\" lands, unions are not valid as s in Python.\n\nWhen creating the agent we need to the argument, and add a type hint to tell\ntype checkers about the type of the agent.\n\nHere's an example of returning either text or a structured value\n\n```\n\n  \n  \n  \n\n\n\n  \n  \n  \n  \n\n     \n  \n    \n  \n    \"Extract me the dimensions of a box, \"\n    \"if you can't extract all data, ask the user to try again.\"\n  \n\n  \n\n#> Please provide the units for the dimensions (e.g., cm, in, m).\n\n  'The box is 10x20x30 cm'\n\n#> width=10 height=20 depth=30 units='cm'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nHere's an example of using a union return type which registered multiple tools,\nand wraps non-object schemas in an object:\n\n```\n\n  \n  \n     \n  \n    \n  'Extract either colors or sizes from the shapes provided.'\n\n  'red square, blue circle, green triangle'\n\n  'square size 10, circle size 20, triangle size 30'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nSome validation is inconvenient or impossible to do in Pydantic validators, in\nparticular when the validation requires IO and is asynchronous. PydanticAI\nprovides a way to add validation functions via the decorator.\n\nHere's a simplified variant of the :\n\n```\n\n  \n    \n  \n     \n\n\n\n  \n\n\n\n  \n\n  \n    \n  \n  \n  \n  'Generate PostgreSQL flavored SQL queries based on user input.'\n\n       \n    \n     \n  \n     \n     \n       \n  \n     \n\n  \n  'get me uses who were last active yesterday.'\n\n#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1\nday'\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThere two main challenges with streamed results:\n\n  1. Validating structured responses before they're complete, this is achieved by \"partial validation\" which was recently added to Pydantic in .\n  2. When receiving a response, we don't know if it's the final response without starting to stream it and peeking at the content. PydanticAI streams just enough of the response to sniff out if it's a tool call or a result, then streams the whole thing and calls tools, or returns the stream as a .\n\nExample of streamed text result:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'   \n         \n      \n      \n      #> The first known use of \"hello,\n      #> The first known use of \"hello, world\" was in\n      #> The first known use of \"hello, world\" was in a 1974 textbook\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C\n      #> The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nWe can also stream text as deltas rather than the entire text in each item:\n\n```\n\n  \n  \n\n  \n    'Where does \"hello world\" come from?'  \n         \n      \n      \n      \n      \n      \n      \n      \n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nResult message not included in\n\nThe final result message will be added to result messages if you use , see for\nmore information.\n\nNot all types are supported with partial validation in Pydantic, see , generally\nfor model-like structures it's currently best to use .\n\nHere's an example of streaming a use profile as it's built:\n\n```\n\n  \n  \n  \n\n  \n  \n  \n  \n\n  \n  \n  \n  'Extract a user profile from the input'\n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nIf you want fine-grained control of validation, particularly catching validation\nerrors, you can use the following pattern:\n\n```\n\n  \n  \n  \n  \n\n  \n  \n  \n  \n\n  \n\n  \n    'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n      \n          \n      \n            \n          \n           \n        \n       \n        \n      \n      \n      \n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n      #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n\n```\n\n_(This example is complete, it can be run \"as is\" — you'll need to add to run )_\n\nThe following examples demonstrate how to use streamed responses in PydanticAI:\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_0_annotation_1\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_0_annotation_2\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_0_annotation_3\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_3\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_12\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_13\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_1\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_2\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_9\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_4\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_5\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_6\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_7\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_11\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_8\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_1_annotation_10\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_2_annotation_1\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n# Untitled Page\nURL: https://ai.pydantic.dev#__code_2_annotation_2\n\nThis documentation is ahead of the last release by . You may see documentation\nfor features not yet supported in the latest release .\n\n_Agent Framework / shim to use Pydantic with LLMs_\n\nPydanticAI is a Python agent framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nPydanticAI is a Python Agent Framework designed to make it less painful to build\nproduction grade applications with Generative AI.\n\nFastAPI revolutionized web development by offering an innovative and ergonomic\ndesign, built on the foundation of .\n\nSimilarly, virtually every agent framework and LLM library in Python uses\nPydantic, yet when we began to use LLMs in , we couldn't find anything that gave\nus the same feeling.\n\nWe built PydanticAI with one simple aim: to bring that FastAPI feeling to GenAI\napp development.\n\n**Built by the Pydantic Team** Built by the team behind (the validation layer of\nthe OpenAI SDK, the Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers,\nCrewAI, Instructor and many more).\n\nSupports OpenAI, Anthropic, Gemini, Ollama, Groq, and Mistral, and there is a\nsimple interface to implement support for .\n\nSeamlessly with for real-time debugging, performance monitoring, and behavior\ntracking of your LLM-powered applications.\n\nDesigned to make as powerful and informative as possible for you.\n\nLeverages Python's familiar control flow and agent composition to build your AI-\ndriven projects, making it easy to apply standard Python best practices you'd\nuse in any other (non-AI) project.\n\nHarnesses the power of to model outputs, ensuring responses are consistent\nacross runs.\n\nOffers an optional system to provide data and services to your agent's , and .\nThis is useful for testing and eval-driven iterative development.\n\nProvides the ability to LLM outputs continuously, with immediate validation,\nensuring rapid and accurate results.\n\nprovides a powerful way to define graphs using typing hints, this is useful in\ncomplex applications where standard control flow can degrade to spaghetti code.\n\nPydanticAI is in early beta, the API is still subject to change and there's a\nlot more to do. is very welcome!\n\nHere's a minimal example of PydanticAI:\n\n```\n\n  \n  \n  \n  'Be concise, reply with one sentence.'\n\n  'Where does \"hello world\" come from?'\n\nThe first known use of \"hello, world\" was in a 1974 textbook about the C\nprogramming language.\n\n```\n\n_(This example is complete, it can be run \"as is\")_\n\nThe exchange should be very short: PydanticAI will send the system prompt and\nthe user query to the LLM, the model will return a text response.\n\nNot very interesting yet, but we can easily add \"tools\", dynamic system prompts,\nand structured responses to build more powerful agents.\n\n## Tools & Dependency Injection Example\n\nHere is a concise example using PydanticAI to build a support agent for a bank:\n\n```\n\n  \n    \n    \n  \n\n  \n  \n    \n\n  \n     'Advice returned to the customer'\n     \"Whether to block the customer's card\"\n       \n\n  \n  \n  \n  \n  \n    'You are a support agent in our bank, give the '\n    'customer support and judge the risk level of their query.'\n  \n\n\n\n     \n     \n  \n\n\n\n  \n     \n  \n\"\"\"Returns the customer's current account balance.\"\"\"\n\n    \n    \n    \n  \n\n\n\n  \n     \n       \n  \n\n  support_advice='Hello John, your current account balance, including pending\ntransactions, is $123.45.' block_card=False risk=1\n\n     'I just lost my card!' \n  \n\n  support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your\ncard to prevent unauthorized transactions.\" block_card=True risk=8\n\n```\n\nThe code included here is incomplete for the sake of brevity (the definition of\nis missing); you can find the complete example .\n\nTo understand the flow of the above runs, we can watch the agent in action using\nPydantic Logfire.\n\nTo do this, we need to set up logfire, and add the following to our code:\n\nThat's enough to get the following view of your agent in action:\n\nSee to learn more.\n\nTo try PydanticAI yourself, follow the instructions .\n\nRead the to learn more about building applications with PydanticAI.\n\nRead the to understand PydanticAI's interface.\n\n---\n\n",
  "timestamp": "2025-01-18T06:09:26.489Z",
  "stats": {
    "wordCount": 58268,
    "charCount": 419875
  }
}