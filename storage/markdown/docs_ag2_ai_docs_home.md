# AG2 home page
URL: https://docs.ag2.ai/

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)


Navigation
Home
[Documentation](https://docs.ag2.ai/</docs/Home>)[Examples](https://docs.ag2.ai/</notebooks/Examples>)[Blog](https://docs.ag2.ai/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/</docs/Migration-Guide>)


# Home
![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)
## AG2
The Open Source Agent OS
[Getting Started - 3 Minute](https://docs.ag2.ai/</docs/Getting-Started>)
### 
[​](https://docs.ag2.ai/<#key-features>)
Key Features
![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/</docs/Use-Cases/agent_chat>)
AG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.
![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)
AG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.
![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/</docs/Use-Cases/enhanced_inference>)
AG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.
### 
[​](https://docs.ag2.ai/<#explore-content>)
Explore content
## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/</docs/contributor-guide/contributing>)
### 
[​](https://docs.ag2.ai/<#popular-resources>)
Popular resources
[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)
[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)
[Getting Started](https://docs.ag2.ai/</docs/Getting-Started>)
[x](https://docs.ag2.ai/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Documentation
URL: https://docs.ag2.ai/docs/Home

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Home
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


# Home
![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)
## AG2
The Open Source Agent OS
[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)
### 
[​](https://docs.ag2.ai/docs/<#key-features>)
Key Features
![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
AG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.
![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)
AG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.
![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)
AG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.
### 
[​](https://docs.ag2.ai/docs/<#explore-content>)
Explore content
## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/docs/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
### 
[​](https://docs.ag2.ai/docs/<#popular-resources>)
Popular resources
[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)
[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)
[Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Examples
URL: https://docs.ag2.ai/notebooks/Examples

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/notebooks/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)


Navigation
Examples
Examples by Category
[Documentation](https://docs.ag2.ai/notebooks/</docs/Home>)[Examples](https://docs.ag2.ai/notebooks/</notebooks/Examples>)[Blog](https://docs.ag2.ai/notebooks/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/notebooks/</talks/future_talks/index>)
##### Examples
  * [Examples by Category](https://docs.ag2.ai/notebooks/</notebooks/Examples>)
  * Examples by Notebook
  * [Application Gallery](https://docs.ag2.ai/notebooks/</notebooks/Gallery>)


Examples
# Examples by Category
## 
[​](https://docs.ag2.ai/notebooks/<#automated-multi-agent-chat>)
Automated Multi Agent Chat
AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation. Please find documentation about this feature [here](https://docs.ag2.ai/notebooks/</docs/Use-Cases/agent_chat>).
Links to notebook examples:
### 
[​](https://docs.ag2.ai/notebooks/<#code-generation-execution-and-debugging>)
Code Generation, Execution, and Debugging
  * Automated Task Solving with Code Generation, Execution & Debugging - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_auto_feedback_from_code_execution>)
  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_RetrieveChat>)
  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/notebooks/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_RetrieveChat_qdrant>)


### 
[​](https://docs.ag2.ai/notebooks/<#multi-agent-collaboration-3-agents>)
Multi-Agent Collaboration (>3 Agents)
  * Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat>)
  * Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_vis>)
  * Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_research>)
  * Automated Task Solving with Coding & Planning Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_planning>)
  * Automated Task Solving with transition paths specified in a graph - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_finite_state_machine>)
  * Running a group chat as an inner-monolgue via the SocietyOfMindAgent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_society_of_mind>)
  * Running a group chat with custom speaker selection function - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_customized>)


### 
[​](https://docs.ag2.ai/notebooks/<#sequential-multi-agent-chats>)
Sequential Multi-Agent Chats
  * Solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_multi_task_chats>)
  * Async-solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_multi_task_async_chats>)
  * Solving Multiple Tasks in a Sequence of Chats Initiated by Different Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchats_sequential_chats>)


### 
[​](https://docs.ag2.ai/notebooks/<#nested-chats>)
Nested Chats
  * Solving Complex Tasks with Nested Chats - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nestedchat>)
  * Solving Complex Tasks with A Sequence of Nested Chats - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_sequential_chats>)
  * OptiGuide for Solving a Supply Chain Optimization Problem with Nested Chats with a Coding Agent and a Safeguard Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nestedchat_optiguide>)
  * Conversational Chess with Nested Chats and Tool Use - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_chats_chess>)


### 
[​](https://docs.ag2.ai/notebooks/<#swarms>)
Swarms
  * Orchestrating agents in a Swarm - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm>)
  * Orchestrating agents in a Swarm (Enhanced) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm_enhanced>)


### 
[​](https://docs.ag2.ai/notebooks/<#applications>)
Applications
  * Automated Continual Learning from New Data - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_stream>)


  * [AutoAnny](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/auto-anny>) - A Discord bot built using AutoGen


### 
[​](https://docs.ag2.ai/notebooks/<#rag>)
RAG
  * GraphRAG agent using FalkorDB (feat. swarms and Google Maps API) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm_graphrag_trip_planner>)


### 
[​](https://docs.ag2.ai/notebooks/<#tool-use>)
Tool Use
  * **Web Search** : Solve Tasks Requiring Web Info - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_web_info>)
  * Use Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_currency_calculator>)
  * Use Tools via Sync and Async Function Calling - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_async>)
  * Task Solving with Langchain Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_langchain>)
  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_RAG>)
  * Function Inception: Enable AutoGen agents to update/remove functions during conversations. - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_inception_function>)
  * Agent Chat with Whisper - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_video_transcript_translate_with_whisper>)
  * Constrained Responses via Guidance - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_guidance>)
  * Browse the Web with Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_surfer>)
  * **SQL** : Natural Language Text to SQL Query using the [Spider](https://docs.ag2.ai/notebooks/<https:/yale-lily.github.io/spider>) Text-to-SQL Benchmark - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_sql_spider>)
  * **Web Scraping** : Web Scraping with Apify - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_webscraping_with_apify>)
  * **Write a software app, task by task, with specially designed functions.** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_code_writing>).


### 
[​](https://docs.ag2.ai/notebooks/<#human-involvement>)
Human Involvement
  * Simple example in ChatGPT style [View example](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/simple_chat.py>)
  * Auto Code Generation, Execution, Debugging and **Human Feedback** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_human_feedback>)
  * Automated Task Solving with GPT-4 + **Multiple Human Users** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_two_users>)
  * Agent Chat with **Async Human Inputs** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/async_human_input>)


### 
[​](https://docs.ag2.ai/notebooks/<#agent-teaching-and-learning>)
Agent Teaching and Learning
  * Teach Agents New Skills & Reuse via Automated Chat - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teaching>)
  * Teach Agents New Facts, User Preferences and Skills Beyond Coding - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teachability>)
  * Teach OpenAI Assistants Through GPTAssistantAgent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teachable_oai_assistants>)
  * Agent Optimizer: Train Agents in an Agentic Way - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_agentoptimizer>)


### 
[​](https://docs.ag2.ai/notebooks/<#multi-agent-chat-with-openai-assistants-in-the-loop>)
Multi-Agent Chat with OpenAI Assistants in the loop
  * Hello-World Chat with OpenAi Assistant in AutoGen - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_twoagents_basic>)
  * Chat with OpenAI Assistant using Function Call - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_function_call>)
  * Chat with OpenAI Assistant with Code Interpreter - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_code_interpreter>)
  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_retrieval>)
  * OpenAI Assistant in a Group Chat - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_groupchat>)
  * GPTAssistantAgent based Multi-Agent Tool Use - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/gpt_assistant_agent_function_call>)


### 
[​](https://docs.ag2.ai/notebooks/<#non-openai-models>)
Non-OpenAI Models
  * Conversational Chess using non-OpenAI Models - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_chats_chess_altmodels>)


### 
[​](https://docs.ag2.ai/notebooks/<#multimodal-agent>)
Multimodal Agent
  * Multimodal Agent Chat with DALLE and GPT-4V - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_dalle_and_gpt4v>)
  * Multimodal Agent Chat with Llava - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_lmm_llava>)
  * Multimodal Agent Chat with GPT-4V - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_lmm_gpt-4v>)


### 
[​](https://docs.ag2.ai/notebooks/<#long-context-handling>)
Long Context Handling
  * Long Context Handling as A Capability - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_transform_messages>)


### 
[​](https://docs.ag2.ai/notebooks/<#evaluation-and-assessment>)
Evaluation and Assessment
  * AgentEval: A Multi-Agent System for Assess Utility of LLM-powered Applications - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agenteval_cq_math>)


### 
[​](https://docs.ag2.ai/notebooks/<#automatic-agent-building>)
Automatic Agent Building
  * Automatically Build Multi-agent System with AgentBuilder - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/autobuild_basic>)
  * Automatically Build Multi-agent System from Agent Library - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/autobuild_agent_library>)


### 
[​](https://docs.ag2.ai/notebooks/<#observability>)
Observability
  * Track LLM calls, tool usage, actions and errors using AgentOps - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_agentops>)
  * Cost Calculation - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_cost_token_tracking>)


## 
[​](https://docs.ag2.ai/notebooks/<#enhanced-inferences>)
Enhanced Inferences
### 
[​](https://docs.ag2.ai/notebooks/<#utilities>)
Utilities
  * API Unification - [View Documentation with Code Example](https://docs.ag2.ai/notebooks/<https:/docs.ag2.ai/docs/Use-Cases/enhanced_inference#api-unification>)
  * Utility Functions to Help Managing API configurations effectively - [View Notebook](https://docs.ag2.ai/notebooks/</docs/topics/llm_configuration>)


### 
[​](https://docs.ag2.ai/notebooks/<#inference-hyperparameters-tuning>)
Inference Hyperparameters Tuning
AutoGen offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/notebooks/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them. Please find documentation about this feature [here](https://docs.ag2.ai/notebooks/</docs/Use-Cases/enhanced_inference>).
Links to notebook examples:
  * [Optimize for Code Generation](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) | [Open in colab](https://docs.ag2.ai/notebooks/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>)
  * [Optimize for Math](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) | [Open in colab](https://docs.ag2.ai/notebooks/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>)


[Notebooks](https://docs.ag2.ai/notebooks/</notebooks/Notebooks>)
[x](https://docs.ag2.ai/notebooks/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/notebooks/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/notebooks/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/notebooks/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/notebooks/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Automated Multi Agent Chat](https://docs.ag2.ai/notebooks/<#automated-multi-agent-chat>)
  * [Code Generation, Execution, and Debugging](https://docs.ag2.ai/notebooks/<#code-generation-execution-and-debugging>)
  * [Multi-Agent Collaboration (>3 Agents)](https://docs.ag2.ai/notebooks/<#multi-agent-collaboration-3-agents>)
  * [Sequential Multi-Agent Chats](https://docs.ag2.ai/notebooks/<#sequential-multi-agent-chats>)
  * [Nested Chats](https://docs.ag2.ai/notebooks/<#nested-chats>)
  * [Swarms](https://docs.ag2.ai/notebooks/<#swarms>)
  * [Applications](https://docs.ag2.ai/notebooks/<#applications>)
  * [RAG](https://docs.ag2.ai/notebooks/<#rag>)
  * [Tool Use](https://docs.ag2.ai/notebooks/<#tool-use>)
  * [Human Involvement](https://docs.ag2.ai/notebooks/<#human-involvement>)
  * [Agent Teaching and Learning](https://docs.ag2.ai/notebooks/<#agent-teaching-and-learning>)
  * [Multi-Agent Chat with OpenAI Assistants in the loop](https://docs.ag2.ai/notebooks/<#multi-agent-chat-with-openai-assistants-in-the-loop>)
  * [Non-OpenAI Models](https://docs.ag2.ai/notebooks/<#non-openai-models>)
  * [Multimodal Agent](https://docs.ag2.ai/notebooks/<#multimodal-agent>)
  * [Long Context Handling](https://docs.ag2.ai/notebooks/<#long-context-handling>)
  * [Evaluation and Assessment](https://docs.ag2.ai/notebooks/<#evaluation-and-assessment>)
  * [Automatic Agent Building](https://docs.ag2.ai/notebooks/<#automatic-agent-building>)
  * [Observability](https://docs.ag2.ai/notebooks/<#observability>)
  * [Enhanced Inferences](https://docs.ag2.ai/notebooks/<#enhanced-inferences>)
  * [Utilities](https://docs.ag2.ai/notebooks/<#utilities>)
  * [Inference Hyperparameters Tuning](https://docs.ag2.ai/notebooks/<#inference-hyperparameters-tuning>)

---

# Blog
URL: https://docs.ag2.ai/blog/2025-01-10-WebSockets/index

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)


Navigation
Recent posts
Streaming input and output using WebSockets
[Documentation](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/Home>)[Examples](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</notebooks/Examples>)[Blog](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</talks/future_talks/index>)
##### Blog
  * Recent posts
    * [Streaming input and output using WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-10-WebSockets/index>)
    * [Real-Time Voice Interactions over WebRTC](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-09-RealtimeAgent-over-WebRTC/index>)
    * [Real-Time Voice Interactions with the WebSocket Audio Adapter](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-08-RealtimeAgent-over-websocket/index>)
    * [Tools Dependency Injection](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-07-Tools-Dependency-Injection/index>)
    * [Cross-Framework LLM Tool Integration with AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-Tools-interoperability/index>)
    * [ReasoningAgent Update - Beam Search, MCTS, and LATS for LLM Reasoning](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-Reasoning-Update/index>)
    * [Introducing RealtimeAgent Capabilities in AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-RealtimeAgent/index>)
    * [Knowledgeable Agents with FalkorDB Graph RAG](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-06-FalkorDB-Structured/index>)
    * [ReasoningAgent - Tree of Thoughts with Beam Search in AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-02-ReasoningAgent2/index>)
    * [Agentic testing for prompt leakage security](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-27-Prompt-Leakage-Probing/index>)
    * [Building Swarm-based agents with AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-17-Swarm/index>)
    * [Introducing CaptainAgent for Adaptive Team Building](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-15-CaptainAgent/index>)
    * [Unlocking the Power of Agentic Workflows at Nexla with Autogen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-10-23-NOVA/index>)
    * [AgentOps, the Best Tool for AutoGen Agent Observability](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-07-25-AgentOps/index>)
    * [Enhanced Support for Non-OpenAI Models](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-06-24-AltModels-Classes/index>)
    * [AgentEval: A Developer Tool to Assess Utility of LLM-powered Applications](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-06-21-AgentEval/index>)
    * [Agents in AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-05-24-Agent/index>)
    * [AutoDefense - Defend against jailbreak attacks with AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-03-11-AutoDefense/index>)
    * [What's New in AutoGen?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-03-03-AutoGen-Update/index>)
    * [StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-29-StateFlow/index>)
    * [FSM Group Chat -- User-specified agent transitions](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-11-FSM-GroupChat/index>)
    * [Anny: Assisting AutoGen Devs Via AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-02-AutoAnny/index>)
    * [AutoGen with Custom Models: Empowering Users to Use Their Own Inference Mechanism](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-26-Custom-Models/index>)
    * [AutoGenBench -- A Tool for Measuring and Evaluating AutoGen Agents](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-25-AutoGenBench/index>)
    * [Code execution is now by default inside docker container](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-23-Code-execution-in-docker/index>)
    * [All About Agent Descriptions](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-29-AgentDescriptions/index>)
    * [AgentOptimizer - An Agentic Way to Train Your LLM Agent](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-23-AgentOptimizer/index>)
    * [AutoGen Studio: Interactively Explore Multi-Agent Workflows](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-01-AutoGenStudio/index>)
    * [Agent AutoBuild - Automatically Building Multi-agent Systems](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-26-Agent-AutoBuild/index>)
    * [How to Assess Utility of LLM-powered Applications?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-20-AgentEval/index>)
    * [AutoGen Meets GPTs](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-13-OAI-assistants/index>)
    * [EcoAssistant - Using LLM Assistants More Accurately and Affordably](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-09-EcoAssistant/index>)
    * [Multimodal with GPT-4V and LLaVA](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-06-LMM-Agent/index>)
    * [AutoGen's Teachable Agents](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-10-26-TeachableAgent/index>)
    * [Retrieval-Augmented Generation (RAG) Applications with AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-10-18-RetrieveChat/index>)
    * [Use AutoGen for Local LLMs](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-07-14-Local-LLMs/index>)
    * [MathChat - An Conversational Framework to Solve Math Problems](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-06-28-MathChat/index>)
    * [Achieve More, Pay Less - Use GPT-4 Smartly](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-05-18-GPT-adaptive-humaneval/index>)
    * [Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-04-21-LLM-tuning-math/index>)


Recent posts
# Streaming input and output using WebSockets
![social preview](https://media.githubusercontent.com/media/ag2ai/ag2/refs/heads/main/website/static/img/cover.png)
Authors:
[![](https://github.com/marklysze.png)Mark SzeSoftware Engineer at AG2.ai](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/marklysze>)[![](https://github.com/sternakt.png)Tvrtko SternakMachine Learning Engineer at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/sternakt>)[![](https://github.com/davorrunje.png)Davor RunjeCTO at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/davorrunje>)
![social preview](https://media.githubusercontent.com/media/ag2ai/ag2/refs/heads/main/website/static/img/cover.png)
Authors:
[![](https://github.com/marklysze.png)Mark SzeSoftware Engineer at AG2.ai](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/marklysze>)[![](https://github.com/sternakt.png)Tvrtko SternakMachine Learning Engineer at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/sternakt>)[![](https://github.com/davorrunje.png)Davor RunjeCTO at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/davorrunje>)
![Structured messages with websockets client](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/blog/2025-01-10-WebSockets/img/structured_messages_with_websockets.png)
## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#tl-dr>)
**TL;DR**
  * Learn how to build an agent chat application using [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) and `IOStream`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/reference/io/websockets>)
  * Explore a hands-on example of connecting a web application to a responsive chat with agents over [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>).
  * **Streamlined Real-Time Interactions** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) offer a low-latency, persistent connection for sending and receiving data in real time.


## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#real-time-applications-why-websockets>)
**Real-Time Applications: Why WebSockets?**
[WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) provide a powerful framework for real-time communication between a client and server. Unlike traditional HTTP requests, which require polling for updates, [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) establish a persistent, full-duplex connection that allows for continuous data exchange.
This capability is critical for applications that use AG2, where seamless interaction is essential.
### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#key-benefits-of-websockets>)
**Key Benefits of WebSockets**
  1. **Low Latency** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) reduce latency by maintaining a direct, open connection, avoiding the overhead of repeated HTTP handshakes.
  2. **Efficient Data Streaming** : Continuous, two-way data streams enable smooth user experiences in real-time applications.
  3. **Event-Driven Communication** : With WebSocket protocols, the server can “push” updates to the client as events occur.
  4. **Simplified Architecture** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) eliminate the need for separate polling mechanisms, reducing server load and complexity.


## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#building-a-chat-system>)
**Building a chat System**
This example demonstrates how to create a WebSocket-based chat system that streams real-time input and output from AG2 Agents.
### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#how-it-works>)
**How It Works**
  1. **WebSocket Connection** : The client establishes a persistent WebSocket connection to the server.
  2. **Real-Time Data Flow** : Events in the conversation are streamed over [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) to the browser where they can be displayed.


## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#example-creating-a-weather-chat-app>)
**Example: Creating a Weather chat app**
Let’s walk through an example that integrates [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) with a weather-focused chat.
You can explore the full example code [here](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets>).
### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#1-clone-the-repository>)
**1. Clone the Repository**
Copy
```
git clone https://github.com/ag2ai/agentchat-over-websockets.git
cd agentchat-over-websockets

```

### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#2-set-up-environment-variables>)
**2. Set Up Environment Variables**
Create a `OAI_CONFIG_LIST` file based on the provided `OAI_CONFIG_LIST_sample`:
Copy
```
cp OAI_CONFIG_LIST_sample OAI_CONFIG_LIST

```

In the OAI_CONFIG_LIST file, update the `api_key` to your OpenAI API key.
### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#optional-create-and-use-a-virtual-environment>)
(Optional) Create and use a virtual environment
To reduce cluttering your global Python environment on your machine, you can create a virtual environment. On your command line, enter:
Copy
```
python3 -m venv env
source env/bin/activate

```

### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#3-install-dependencies>)
**3. Install Dependencies**
Install the required Python packages using `pip`:
Copy
```
pip install -r requirements.txt

```

### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#4-start-the-server>)
**4. Start the Server**
Run the `main.py` file:
Copy
```
python agentchat-over-websockets/main.py

```

### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#test-the-app>)
**Test the App**
With the server running, open the client application in your browser by navigating to <http://localhost:8001/>. And send a message to the chat and watch the conversation between agents roll out in your browser.
## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#code-review>)
Code review
### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#backend-code-main-py>)
**Backend Code:`main.py`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets/blob/main/agentchat-over-websockets/main.py>)**
The backend is responsible for serving the frontend, managing WebSocket connections, and hosting the AI-powered conversational agent. Below is a step-by-step breakdown.
#### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#setting-up-the-websocket-server>)
**Setting Up the WebSocket Server**
The `IOWebsockets.run_server_in_thread` utility is used to run a WebSocket server. The `on_connect` function handles new client connections and initializes the chatbot.
Copy
```
from autogen.io.websockets import IOWebsockets
from datetime import datetime
def on_connect(iostream: IOWebsockets) -> None:
  print(f"Connected to client: {iostream}")
  initial_msg = iostream.input() # Receive the first message from the client.
  print(f"Initial message: {initial_msg}")
  # Define the agent
  agent = autogen.ConversableAgent(
    name="chatbot",
    system_message="Complete tasks and reply TERMINATE when done. Use the 'weather_forecast' tool for weather-related queries.",
    llm_config={"stream": False},
  )
  # Define the user proxy
  user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    system_message="A proxy for the user.",
    is_termination_msg=lambda msg: msg.get("content", "").endswith("TERMINATE"),
    human_input_mode="NEVER",
  )
  # Register tool functions
  def weather_forecast(city: str) -> str:
    return f"The weather forecast for {city} is sunny as of {datetime.now()}."
  autogen.register_function(
    weather_forecast,
    caller=agent,
    executor=user_proxy,
    description="Provides a mock weather forecast.",
  )
  # Initiate conversation
  user_proxy.initiate_chat(agent, message=initial_msg)

```

**Explanation:**
  1. **`on_connect`**: Handles client connections and manages the interaction between the[**`ConversableAgent`**](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/reference/agentchat/conversable_agent#conversableagent>)and the client.
  2. **Tool Registration** : The `weather_forecast` function provides a mock weather report and is linked to the agent for handling weather-related queries.


#### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#serving-the-frontend>)
**Serving the Frontend**
The `SimpleHTTPRequestHandler` is used to serve HTML files. A custom handler class overrides the behavior for the root path to serve `chat.html`.
Copy
```
class MyRequestHandler(SimpleHTTPRequestHandler):
  def __init__(self, *args, **kwargs):
    super().__init__(*args, directory=Path(__file__).parent / "website_files" / "templates", **kwargs)
  def do_GET(self):
    if self.path == "/":
      self.path = "/chat.html"
    return super().do_GET()

```

**Explanation:**
  * The `MyRequestHandler` class ensures that the default page served is `chat.html`.
  * Files are served from the `website_files/templates` directory.


#### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#running-the-servers>)
**Running the Servers**
Finally, both the WebSocket and HTTP servers are started.
Copy
```
from http.server import HTTPServer
PORT = 8001
handler = MyRequestHandler
# Start WebSocket server
with IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:
  print(f"WebSocket server started at {uri}")
  # Start HTTP server
  with HTTPServer(("", PORT), handler) as httpd:
    print(f"HTTP server started at http://localhost:{PORT}")
    try:
      httpd.serve_forever()
    except KeyboardInterrupt:
      print("HTTP server stopped.")

```

**Explanation:**
  * The WebSocket server listens on port `8080`, while the HTTP server listens on port `8001`.
  * The WebSocket server handles real-time communication, while the HTTP server serves static files.


### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#frontend-code-chat-html>)
**Frontend Code:`chat.html`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets/blob/main/agentchat-over-websockets/website_files/templates/chat.html>)**
The frontend provides a simple interface for users to interact with the chatbot.
#### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#html-structure>)
**HTML Structure**
The HTML structure defines an input form for sending messages and a list for displaying them.
Copy
```
<!DOCTYPE html>
<html>
<head>
  <title>Chat Interface</title>
  <style>
    body { font-family: monospace; max-width: 800px; margin: 20px auto; }
    #messages { list-style: none; padding: 0; }
    #messages li { background: #f1f3f4; padding: 8px; border-radius: 4px; margin: 4px 0; }
  </style>
</head>
<body>
  <h1>AI Chat Interface</h1>
  <form onsubmit="sendMessage(event)">
    <input type="text" id="messageText" autocomplete="off" />
    <button>Send</button>
  </form>
  <ul id="messages"></ul>
</body>
</html>

```

#### 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#javascript-logic>)
**JavaScript Logic**
The JavaScript code establishes a WebSocket connection, handles incoming messages, and sends user input to the backend.
Copy
```
var ws = new WebSocket("ws://localhost:8080");
ws.onmessage = function(event) {
  var messages = document.getElementById('messages');
  var message = document.createElement('li');
  message.textContent = event.data; // Display the message content.
  messages.appendChild(message);
};
function sendMessage(event) {
  var input = document.getElementById("messageText");
  ws.send(input.value); // Send the input value to the backend.
  input.value = ''; // Clear the input field.
  event.preventDefault(); // Prevent form submission.
}

```

**Explanation:**
  1. **WebSocket Initialization** : Connects to the WebSocket server at `ws://localhost:8080`.
  2. **Message Display** : Appends incoming messages to the `#messages` list.
  3. **Sending Messages** : Captures user input, sends it to the server, and clears the input field.


## 
[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#conclusion>)
**Conclusion**
Building an AgentChat system with [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) unlocks the potential for real-time, interactive applications. By maintaining a persistent connection, [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) enable seamless communication, enhancing user experience with minimal latency.
The example of a weather chatbot demonstrates the ease of integrating AG2 with [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) to create dynamic conversational agents. Whether for customer support, virtual assistants, or personalized services, this architecture provides a robust foundation for building next-generation applications.
**Ready to start building?** Explore the full example code [here](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets>).
[Real-Time Voice Interactions over WebRTC](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-09-RealtimeAgent-over-WebRTC/index>)
[x](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [TL;DR](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#tl-dr>)
  * [Real-Time Applications: Why WebSockets?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#real-time-applications-why-websockets>)
  * [Key Benefits of WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#key-benefits-of-websockets>)
  * [Building a chat System](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#building-a-chat-system>)
  * [How It Works](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#how-it-works>)
  * [Example: Creating a Weather chat app](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#example-creating-a-weather-chat-app>)
  * [1. Clone the Repository](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#1-clone-the-repository>)
  * [2. Set Up Environment Variables](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#2-set-up-environment-variables>)
  * [(Optional) Create and use a virtual environment](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#optional-create-and-use-a-virtual-environment>)
  * [3. Install Dependencies](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#3-install-dependencies>)
  * [4. Start the Server](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#4-start-the-server>)
  * [Test the App](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#test-the-app>)
  * [Code review](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#code-review>)
  * [Backend Code: main.py](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#backend-code-main-py>)
  * [Setting Up the WebSocket Server](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#setting-up-the-websocket-server>)
  * [Serving the Frontend](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#serving-the-frontend>)
  * [Running the Servers](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#running-the-servers>)
  * [Frontend Code: chat.html](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#frontend-code-chat-html>)
  * [HTML Structure](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#html-structure>)
  * [JavaScript Logic](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#javascript-logic>)
  * [Conclusion](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#conclusion>)

---

# Community Talks
URL: https://docs.ag2.ai/talks/future_talks/index

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/talks/future_talks/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)


Navigation
Talks
Upcoming Talks
[Documentation](https://docs.ag2.ai/talks/future_talks/</docs/Home>)[Examples](https://docs.ag2.ai/talks/future_talks/</notebooks/Examples>)[Blog](https://docs.ag2.ai/talks/future_talks/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/talks/future_talks/</talks/future_talks/index>)
##### Talks
  * [Upcoming Talks](https://docs.ag2.ai/talks/future_talks/</talks/future_talks/index>)
  * [Globant Code Fixer Agent: #1 on SWE-Bench Lite - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19-special_talk/index>)
  * [Transforming CRM with Agents: The Journey to Ully.ai's Next-Gen ERP - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19/index>)
  * [Make AI Agents Collaborate: Drag, Drop, and Orchestrate with Waldiez - Dec 12, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-12/index>)
  * [Mosaia - The AI community’s platform for creating, sharing and deploying AI agents in a serverless cloud environment - Nov 28, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-28/index>)
  * [Investigating Group Decision-Making Mechanism in Decentralized Multi-Agent Collaboration - Nov 25, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-25/index>)
  * [Integrating Foundation Models and Symbolic Computing for Next-Generation Robot Planning - Nov 18, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-18/index>)
  * [Introducing FastAgency - the fastest way to bring AutoGen workflows to production - Nov 12, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-12/index>)
  * [Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 11, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-11/index>)
  * [Exploring Pragmatic Patterns in Agentic Systems - Nov 04, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-04/index>)
  * [Agent-Model Orchestration in Multi-Agent Applications - Oct 15, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-10-15/index>)
  * [Advanced AutoGen Interactions and Ethical Pathways for AI Sentience - Oct 14, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-10-14/index>)
  * [Trace-ing the Path to Self-adapting AI Agents - Sep 30, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-09-30/index>)
  * [Copilot Agent Architecture Designing - Sep 23, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-09-23/index>)
  * [Language Agent Tree Search in AutoGen - Aug 26, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-08-26/index>)


Talks
# Upcoming Talks
Our community is also dedicated to fostering knowledge sharing and collaboration through regular events. We frequently host talks featuring both academic experts and industry professionals, offering valuable insights into topics related to agentic AI. By joining our community, you will have access to these enriching opportunities and be able to engage with like-minded individuals.
## 
[​](https://docs.ag2.ai/talks/future_talks/<#how-to-follow-up-with-the-latest-talks>)
How to follow up with the latest talks?
  1. Stay informed about our latest events and upcoming talks by subscribing to our [lu.ma homepage](https://docs.ag2.ai/talks/future_talks/<https:/lu.ma/ag2ai>).
  2. Join our community Discord (<https://discord.gg/sUkGceyd>) to be the first to know about amazing upcoming talks!


Connect: shaokunzhang529@gmail.com
[Globant Code Fixer Agent: #1 on SWE-Bench Lite - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19-special_talk/index>)
[x](https://docs.ag2.ai/talks/future_talks/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/talks/future_talks/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/talks/future_talks/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/talks/future_talks/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/talks/future_talks/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [How to follow up with the latest talks?](https://docs.ag2.ai/talks/future_talks/<#how-to-follow-up-with-the-latest-talks>)

---

# Getting Started
URL: https://docs.ag2.ai/docs/Getting-Started

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag21,423](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,423](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Home
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


# Home
![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)
## AG2
The Open Source Agent OS
[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)
### 
[​](https://docs.ag2.ai/docs/<#key-features>)
Key Features
![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
AG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.
![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)
AG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.
![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)
AG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.
### 
[​](https://docs.ag2.ai/docs/<#explore-content>)
Explore content
## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/docs/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
### 
[​](https://docs.ag2.ai/docs/<#popular-resources>)
Popular resources
[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)
[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)
[Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
Home - AG2

---

# Overview
URL: https://docs.ag2.ai/docs/installation/Installation

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)


Navigation
Installation
Overview
[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)


Installation
# Overview
## 
[​](https://docs.ag2.ai/docs/installation/<#create-a-virtual-environment-optional>)
Create a virtual environment (optional)
When installing AG2 locally, we recommend using a virtual environment for the installation. This will ensure that the dependencies for AG2 are isolated from the rest of your system.
  * venv
  * Conda
  * Poetry


Create and activate:
Copy
```
python3 -m venv autogen
source autogen/bin/activate

```

To deactivate later, run:
Copy
```
deactivate

```

## 
[​](https://docs.ag2.ai/docs/installation/<#install-ag2>)
Install AG2
AG2 requires **Python version >= 3.9, < 3.14**. It can be installed from pip:
Copy
```
pip install autogen

```

`openai>=1` is required. 
## 
[​](https://docs.ag2.ai/docs/installation/<#install-docker-for-code-execution>)
Install Docker for Code Execution
We recommend using Docker for code execution. To install Docker, follow the instructions for your operating system on the [Docker website](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com/get-docker/>).
A simple example of how to use Docker for code execution is shown below:
Copy
```
from pathlib import Path
from autogen import UserProxyAgent
from autogen.coding import DockerCommandLineCodeExecutor
work_dir = Path("coding")
work_dir.mkdir(exist_ok=True)
with DockerCommandLineCodeExecutor(work_dir=work_dir) as code_executor:
  user_proxy = UserProxyAgent(
    name="user_proxy",
    code_execution_config={"executor": code_executor},
  )

```

To learn more about code executors, see the [code executors tutorial](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>).
You might have seen a different way of defining the executors without creating the executor object, please refer to FAQ for this [legacy code executor](https://docs.ag2.ai/docs/installation/</docs/FAQ#legacy-code-executor>).
[Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)[Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)
[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Create a virtual environment (optional)](https://docs.ag2.ai/docs/installation/<#create-a-virtual-environment-optional>)
  * [Install AG2](https://docs.ag2.ai/docs/installation/<#install-ag2>)
  * [Install Docker for Code Execution](https://docs.ag2.ai/docs/installation/<#install-docker-for-code-execution>)

---

# Docker
URL: https://docs.ag2.ai/docs/installation/Docker

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)


Navigation
[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)


Installation
# Docker
Docker, an indispensable tool in modern software development, offers a compelling solution for AG2’s setup. Docker allows you to create consistent environments that are portable and isolated from the host OS. With Docker, everything AG2 needs to run, from the operating system to specific libraries, is encapsulated in a container, ensuring uniform functionality across different systems. The Dockerfiles necessary for AG2 are conveniently located in the project’s GitHub repository at <https://github.com/ag2ai/ag2/tree/main/.devcontainer>.
**Pre-configured DockerFiles** : The AG2 Project offers pre-configured Dockerfiles for your use. These Dockerfiles will run as is, however they can be modified to suit your development needs. Please see the README.md file in autogen/.devcontainer
  * **ag2_base_img** : For a basic setup, you can use the `ag2_base_img` to run simple scripts or applications. This is ideal for general users or those new to AG2.
  * **ag2_full_img** : Advanced users or those requiring more features can use `ag2_full_img`. Be aware that this version loads ALL THE THINGS and thus is very large. Take this into consideration if you build your application off of it.


## 
[​](https://docs.ag2.ai/docs/installation/<#step-1-install-docker>)
Step 1: Install Docker
  * **General Installation** : Follow the [official Docker installation instructions](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com/get-docker/>). This is your first step towards a containerized environment, ensuring a consistent and isolated workspace for AG2.
  * **For Mac Users** : If you encounter issues with the Docker daemon, consider using [colima](https://docs.ag2.ai/docs/installation/<https:/smallsharpsoftwaretools.com/tutorials/use-colima-to-run-docker-containers-on-macos/>). Colima offers a lightweight alternative to manage Docker containers efficiently on macOS.


## 
[​](https://docs.ag2.ai/docs/installation/<#step-2-build-a-docker-image>)
Step 2: Build a Docker Image
AG2 now provides updated Dockerfiles tailored for different needs. Building a Docker image is akin to setting the foundation for your project’s environment:
  * **AG2 Basic** : Ideal for general use, this setup includes common Python libraries and essential dependencies. Perfect for those just starting with AG2.
Copy
```
docker build -f .devcontainer/Dockerfile -t ag2_base_img https://github.com/ag2ai/ag2.git#main

```

  * **AG2 Advanced** : Advanced users or those requiring all the things that AG2 has to offer `ag2_full_img`
Copy
```
docker build -f .devcontainer/full/Dockerfile -t ag2_full_img https://github.com/ag2ai/ag2.git#main

```



## 
[​](https://docs.ag2.ai/docs/installation/<#step-3-run-ag2-applications-from-docker-image>)
Step 3: Run AG2 Applications from Docker Image
Here’s how you can run an application built with AG2, using the Docker image:
  1. **Mount Your Directory** : Use the Docker `-v` flag to mount your local application directory to the Docker container. This allows you to develop on your local machine while running the code in a consistent Docker environment. For example:
Copy
```
docker run -it -v $(pwd)/myapp:/home/ag2ai/ag2/myapp ag2_base_img:latest python /home/ag2ai/ag2/myapp/main.py

```

Here, `$(pwd)/myapp` is your local directory, and `/home/ag2ai/ag2/myapp` is the path in the Docker container where your code will be located.
  2. **Mount your code:** Now suppose you have your application built with AG2 in a main script named `twoagent.py` ([example](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/test/twoagent.py>)) in a folder named `myapp`. With the command line below, you can mount your folder and run the application in Docker.
Copy
```
# Mount the local folder `myapp` into docker image and run the script named "twoagent.py" in the docker.
docker run -it -v `pwd`/myapp:/myapp ag2_base_img:latest python /myapp/main_twoagent.py

```

  3. **Port Mapping** : If your application requires a specific port, use the `-p` flag to map the container’s port to your host. For instance, if your app runs on port 3000 inside Docker and you want it accessible on port 8080 on your host machine:
Copy
```
docker run -it -p 8080:3000 -v $(pwd)/myapp:/myapp ag2_base_img:latest python /myapp

```

In this command, `-p 8080:3000` maps port 3000 from the container to port 8080 on your local machine.
  4. **Examples of Running Different Applications** : Here is the basic format of the docker run command.


Copy
```
docker run -it -p {WorkstationPortNum}:{DockerPortNum} -v {WorkStation_Dir}:{Docker_DIR} {name_of_the_image} {bash/python} {Docker_path_to_script_to_execute}

```

  * _Simple Script_ : Run a Python script located in your local `myapp` directory.
Copy
```
docker run -it -v `pwd`/myapp:/myapp ag2_base_img:latest python /myapp/my_script.py

```

  * _Web Application_ : If your application includes a web server running on port 5000.
Copy
```
docker run -it -p 8080:5000 -v $(pwd)/myapp:/myapp ag2_base_img:latest

```

  * _Data Processing_ : For tasks that involve processing data stored in a local directory.
Copy
```
docker run -it -v $(pwd)/data:/data ag2_base_img:latest python /myapp/process_data.py

```



## 
[​](https://docs.ag2.ai/docs/installation/<#additional-resources>)
Additional Resources
  * Details on all the Dockerfile options can be found in the [Dockerfile](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/.devcontainer/README.md>) README.
  * For more information on Docker usage and best practices, refer to the [official Docker documentation](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com>).
  * Details on how to use the Dockerfile dev version can be found on the [Contributor Guide](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>).


[Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)[Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)
[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Step 1: Install Docker](https://docs.ag2.ai/docs/installation/<#step-1-install-docker>)
  * [Step 2: Build a Docker Image](https://docs.ag2.ai/docs/installation/<#step-2-build-a-docker-image>)
  * [Step 3: Run AG2 Applications from Docker Image](https://docs.ag2.ai/docs/installation/<#step-3-run-ag2-applications-from-docker-image>)
  * [Additional Resources](https://docs.ag2.ai/docs/installation/<#additional-resources>)

---

# Optional Dependencies
URL: https://docs.ag2.ai/docs/installation/Optional-Dependencies

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)


Navigation
[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)


Installation
# Optional Dependencies
## 
[​](https://docs.ag2.ai/docs/installation/<#different-llms>)
Different LLMs
AG2 installs OpenAI package by default. To use LLMs by other providers, you can install the following packages:
Copy
```
pip install autogen[gemini,anthropic,mistral,together,groq,cohere]

```

Check out the [notebook](https://docs.ag2.ai/docs/installation/</notebooks/autogen_uniformed_api_calling>) and [blogpost](https://docs.ag2.ai/docs/installation/</blog/2024-06-24-AltModels-Classes/index>) for more details.
## 
[​](https://docs.ag2.ai/docs/installation/<#llm-caching>)
LLM Caching
To use LLM caching with Redis, you need to install the Python package with the option `redis`:
Copy
```
pip install "autogen[redis]"

```

See [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>) for details.
## 
[​](https://docs.ag2.ai/docs/installation/<#ipython-code-executor>)
IPython Code Executor
To use the IPython code executor, you need to install the `jupyter-client` and `ipykernel` packages:
Copy
```
pip install "autogen[ipython]"

```

To use the IPython code executor:
Copy
```
from autogen import UserProxyAgent
proxy = UserProxyAgent(name="proxy", code_execution_config={"executor": "ipython-embedded"})

```

## 
[​](https://docs.ag2.ai/docs/installation/<#blendsearch>)
blendsearch
`pyautogen<0.2` offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/docs/installation/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. Please install with the [blendsearch] option to use it.
Copy
```
pip install "autogen[blendsearch]<0.2"

```

Checkout [Optimize for Code Generation](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) and [Optimize for Math](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) for details.
## 
[​](https://docs.ag2.ai/docs/installation/<#retrievechat>)
retrievechat
`autogen` supports retrieval-augmented generation tasks such as question answering and code generation with RAG agents. Please install with the [retrievechat] option to use it with ChromaDB.
Copy
```
pip install "autogen[retrievechat]"

```

Alternatively `autogen` also supports PGVector and Qdrant which can be installed in place of ChromaDB, or alongside it.
Copy
```
pip install "autogen[retrievechat-pgvector]"

```

Copy
```
pip install "autogen[retrievechat-qdrant]"

```

RetrieveChat can handle various types of documents. By default, it can process plain text and PDF files, including formats such as ‘txt’, ‘json’, ‘csv’, ‘tsv’, ‘md’, ‘html’, ‘htm’, ‘rtf’, ‘rst’, ‘jsonl’, ‘log’, ‘xml’, ‘yaml’, ‘yml’ and ‘pdf’. If you install [unstructured](https://docs.ag2.ai/docs/installation/<https:/unstructured-io.github.io/unstructured/installation/full_installation.html>) (`pip install "unstructured[all-docs]"`), additional document types such as ‘docx’, ‘doc’, ‘odt’, ‘pptx’, ‘ppt’, ‘xlsx’, ‘eml’, ‘msg’, ‘epub’ will also be supported.
You can find a list of all supported document types by using `autogen.retrieve_utils.TEXT_FORMATS`.
Example notebooks:
[Automated Code Generation and Question Answering with Retrieval Augmented Agents](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat.ipynb>)
[Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent)](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat_RAG.ipynb>)
[Automated Code Generation and Question Answering with Qdrant based Retrieval Augmented Agents](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb>)
## 
[​](https://docs.ag2.ai/docs/installation/<#teachability>)
Teachability
To use Teachability, please install AG2 with the [teachable] option.
Copy
```
pip install "autogen[teachable]"

```

Example notebook: [Chatting with a teachable agent](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_teachability>)
## 
[​](https://docs.ag2.ai/docs/installation/<#large-multimodal-model-lmm-agents>)
Large Multimodal Model (LMM) Agents
We offered Multimodal Conversable Agent and LLaVA Agent. Please install with the [lmm] option to use it.
Copy
```
pip install "autogen[lmm]"

```

Example notebook: [LLaVA Agent](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_lmm_llava>)
## 
[​](https://docs.ag2.ai/docs/installation/<#mathchat>)
mathchat
`pyautogen<0.2` offers an experimental agent for math problem solving. Please install with the [mathchat] option to use it.
Copy
```
pip install "autogen[mathchat]<0.2"

```

Example notebook: [Using MathChat to Solve Math Problems](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_MathChat.ipynb>)
## 
[​](https://docs.ag2.ai/docs/installation/<#graph>)
Graph
To use a graph in `GroupChat`, particularly for graph visualization, please install AutoGen with the [graph] option.
Copy
```
pip install "autogen[graph]"

```

Example notebook: [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_groupchat_finite_state_machine>)
## 
[​](https://docs.ag2.ai/docs/installation/<#long-context-handling>)
Long Context Handling
AG2 includes support for handling long textual contexts by leveraging the LLMLingua library for text compression. To enable this functionality, please install AutoGen with the `[long-context]` option:
Copy
```
pip install "autogen[long-context]"

```

[Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)[Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)
[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Different LLMs](https://docs.ag2.ai/docs/installation/<#different-llms>)
  * [LLM Caching](https://docs.ag2.ai/docs/installation/<#llm-caching>)
  * [IPython Code Executor](https://docs.ag2.ai/docs/installation/<#ipython-code-executor>)
  * [blendsearch](https://docs.ag2.ai/docs/installation/<#blendsearch>)
  * [retrievechat](https://docs.ag2.ai/docs/installation/<#retrievechat>)
  * [Teachability](https://docs.ag2.ai/docs/installation/<#teachability>)
  * [Large Multimodal Model (LMM) Agents](https://docs.ag2.ai/docs/installation/<#large-multimodal-model-lmm-agents>)
  * [mathchat](https://docs.ag2.ai/docs/installation/<#mathchat>)
  * [Graph](https://docs.ag2.ai/docs/installation/<#graph>)
  * [Long Context Handling](https://docs.ag2.ai/docs/installation/<#long-context-handling>)

---

# Introduction to AutoGen
URL: https://docs.ag2.ai/docs/tutorial/introduction

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Introduction to AutoGen
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Introduction to AutoGen
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/introduction.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/introduction.ipynb>)
Welcome! AutoGen is an open-source framework that leverages multiple _agents_ to enable complex workflows. This tutorial introduces basic concepts and building blocks of AutoGen.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#why-autogen>)
Why AutoGen?
> _The whole is greater than the sum of its parts._ -**Aristotle**
While there are many definitions of agents, in AutoGen, an agent is an entity that can send messages, receive messages and generate a reply using models, tools, human inputs or a mixture of them. This abstraction not only allows agents to model real-world and abstract entities, such as people and algorithms, but it also simplifies implementation of complex workflows as collaboration among agents.
Further, AutoGen is extensible and composable: you can extend a simple agent with customizable components and create workflows that can combine these agents and power a more sophisticated agent, resulting in implementations that are modular and easy to maintain.
Most importantly, AutoGen is developed by a vibrant community of researchers and engineers. It incorporates the latest research in multi-agent systems and has been used in many real-world applications, including agent platform, advertising, AI employees, blog/article writing, blockchain, calculate burned areas by wildfires, customer support, cybersecurity, data analytics, debate, education, finance, gaming, legal consultation, research, robotics, sales/marketing, social simulation, software engineering, software security, supply chain, t-shirt design, training data generation, Youtube service…
## 
[​](https://docs.ag2.ai/docs/tutorial/<#installation>)
Installation
The simplest way to install AutoGen is from pip: `pip install autogen`. Find more options in [Installation](https://docs.ag2.ai/docs/tutorial/docs/installation/Installation>).
## 
[​](https://docs.ag2.ai/docs/tutorial/<#agents>)
Agents
In AutoGen, an agent is an entity that can send and receive messages to and from other agents in its environment. An agent can be powered by models (such as a large language model like GPT-4), code executors (such as an IPython kernel), human, or a combination of these and other pluggable and customizable components.
![ConversableAgent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/conversable-agent.jpg)
An example of such agents is the built-in `ConversableAgent` which supports the following components:
  1. A list of LLMs
  2. A code executor
  3. A function and tool executor
  4. A component for keeping human-in-the-loop


You can switch each component on or off and customize it to suit the need of your application. For advanced users, you can add additional components to the agent by using `registered_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>).
LLMs, for example, enable agents to converse in natural languages and transform between structured and unstructured text. The following example shows a `ConversableAgent` with a GPT-4 LLM switched on and other components switched off:
Copy
```
import os
from autogen import ConversableAgent
agent = ConversableAgent(
  "chatbot",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ.get("OPENAI_API_KEY")}]},
  code_execution_config=False, # Turn off code execution, by default it is off.
  function_map=None, # No registered functions, by default it is None.
  human_input_mode="NEVER", # Never ask for human input.
)

```

The `llm_config` argument contains a list of configurations for the LLMs. See [LLM Configuration](https://docs.ag2.ai/docs/tutorial/docs/topics/llm_configuration>) for more details.
You can ask this agent to generate a response to a question using the `generate_reply` method:
Copy
```
reply = agent.generate_reply(messages=[{"content": "Tell me a joke.", "role": "user"}])
print(reply)

```

Copy
```
Sure, here's a light-hearted joke for you:
Why don't scientists trust atoms?
Because they make up everything!

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#roles-and-conversations>)
Roles and Conversations
In AutoGen, you can assign roles to agents and have them participate in conversations or chat with each other. A conversation is a sequence of messages exchanged between agents. You can then use these conversations to make progress on a task. For example, in the example below, we assign different roles to two agents by setting their `system_message`.
Copy
```
cathy = ConversableAgent(
  "cathy",
  system_message="Your name is Cathy and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.9, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
)
joe = ConversableAgent(
  "joe",
  system_message="Your name is Joe and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.7, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
)

```

Now that we have two comedian agents, we can ask them to start a comedy show. This can be done using the `initiate_chat` method. We set the `max_turns` to 2 to keep the conversation short.
Copy
```
result = joe.initiate_chat(cathy, message="Cathy, tell me a joke.", max_turns=2)

```

Copy
```
joe (to cathy):
Cathy, tell me a joke.
--------------------------------------------------------------------------------
cathy (to joe):
Sure, here's one for you:
Why don't scientists trust atoms?
Because they make up everything!
--------------------------------------------------------------------------------
joe (to cathy):
Haha, that's a good one, Cathy! Okay, my turn. 
Why don't we ever tell secrets on a farm?
Because the potatoes have eyes, the corn has ears, and the beans stalk.
--------------------------------------------------------------------------------
cathy (to joe):
Haha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. 
Why couldn't the bicycle stand up by itself?
Because it was two-tired!
--------------------------------------------------------------------------------

```

The comedians are bouncing off each other!
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter, we introduced the concept of agents, roles and conversations in AutoGen. For simplicity, we only used LLMs and created fully autonomous agents (`human_input_mode` was set to `NEVER`). In the next chapter, we will show how you can control when to _terminate_ a conversation between autonomous agents.
[Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)[Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Why AutoGen?](https://docs.ag2.ai/docs/tutorial/<#why-autogen>)
  * [Installation](https://docs.ag2.ai/docs/tutorial/<#installation>)
  * [Agents](https://docs.ag2.ai/docs/tutorial/<#agents>)
  * [Roles and Conversations](https://docs.ag2.ai/docs/tutorial/<#roles-and-conversations>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# Terminating Conversations Between Agents
URL: https://docs.ag2.ai/docs/tutorial/chat-termination

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Terminating Conversations Between Agents
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Terminating Conversations Between Agents
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/chat-termination.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/chat-termination.ipynb>)
In this chapter, we will explore how to terminate a conversation between AutoGen agents.
_But why is this important?_ Its because in any complex, autonomous workflows it’s crucial to know when to stop the workflow. For example, when the task is completed, or perhaps when the process has consumed enough resources and needs to either stop or adopt different strategies, such as user intervention. So AutoGen natively supports several mechanisms to terminate conversations.
How to Control Termination with AutoGen? Currently there are two broad mechanism to control the termination of conversations between agents:
  1. **Specify parameters in`initiate_chat`** : When initiating a chat, you can define parameters that determine when the conversation should end.
  2. **Configure an agent to trigger termination** : When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions.


## 
[​](https://docs.ag2.ai/docs/tutorial/<#parameters-in-initiate-chat>)
Parameters in `initiate_chat`
In the previous chapter we actually demonstrated this when we used the `max_turns` parameter to limit the number of turns. If we increase `max_turns` to say `3` notice the conversation takes more rounds to terminate:
Copy
```
import os
from autogen import ConversableAgent

```

Copy
```
cathy = ConversableAgent(
  "cathy",
  system_message="Your name is Cathy and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.9, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
)
joe = ConversableAgent(
  "joe",
  system_message="Your name is Joe and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.7, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
)

```

Copy
```
result = joe.initiate_chat(cathy, message="Cathy, tell me a joke.", max_turns=2)

```

Copy
```
joe (to cathy):
Cathy, tell me a joke.
--------------------------------------------------------------------------------
cathy (to joe):
Sure, here's one for you:
Why don't scientists trust atoms?
Because they make up everything!
--------------------------------------------------------------------------------
joe (to cathy):
Haha, that's a good one, Cathy! Okay, my turn. 
Why don't we ever tell secrets on a farm?
Because the potatoes have eyes, the corn has ears, and the beans stalk.
--------------------------------------------------------------------------------
cathy (to joe):
Haha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. 
Why couldn't the bicycle stand up by itself?
Because it was two-tired!
--------------------------------------------------------------------------------

```

Copy
```
result = joe.initiate_chat(
  cathy, message="Cathy, tell me a joke.", max_turns=3
) # increase the number of max turns before termination

```

Copy
```
joe (to cathy):
Cathy, tell me a joke.
--------------------------------------------------------------------------------
cathy (to joe):
Sure, here's one for you:
Why don't scientists trust atoms?
Because they make up everything!
--------------------------------------------------------------------------------
joe (to cathy):
Haha, that's a good one, Cathy! Okay, my turn. 
Why don't we ever tell secrets on a farm?
Because the potatoes have eyes, the corn has ears, and the beans stalk.
--------------------------------------------------------------------------------
cathy (to joe):
Haha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. 
Why couldn't the bicycle stand up by itself?
Because it was two-tired!
--------------------------------------------------------------------------------
joe (to cathy):
Haha, that's a wheely good one, Cathy!
Why did the golfer bring two pairs of pants?
In case he got a hole in one!
--------------------------------------------------------------------------------
cathy (to joe):
Haha, that's a perfect swing of a joke!
Why did the scarecrow win an award?
Because he was outstanding in his field!
--------------------------------------------------------------------------------

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#agent-triggered-termination>)
Agent-triggered termination
You can also terminate a conversation by configuring parameters of an agent. Currently, there are two parameters you can configure:
  1. `max_consecutive_auto_reply`: This condition triggers termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the `max_consecutive_auto_reply` argument of the `ConversableAgent` class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention. We will describe this in more detail in the next chapter.
  2. `is_termination_msg`: This condition can trigger termination if the _received_ message satisfies a particular condition, e.g., it contains the word “TERMINATE”. You can customize this condition using the `is_terminate_msg` argument in the constructor of the `ConversableAgent` class.


### 
[​](https://docs.ag2.ai/docs/tutorial/<#using-max-consecutive-auto-reply>)
Using `max_consecutive_auto_reply`
In the example below lets set `max_consecutive_auto_reply` to `1` and notice how this ensures that Joe only replies once.
Copy
```
joe = ConversableAgent(
  "joe",
  system_message="Your name is Joe and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.7, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
  max_consecutive_auto_reply=1, # Limit the number of consecutive auto-replies.
)
result = joe.initiate_chat(cathy, message="Cathy, tell me a joke.")

```

Copy
```
joe (to cathy):
Cathy, tell me a joke.
--------------------------------------------------------------------------------
cathy (to joe):
Sure, here's one for you:
Why don't scientists trust atoms?
Because they make up everything!
--------------------------------------------------------------------------------
joe (to cathy):
Haha, that's a good one, Cathy! Okay, my turn. 
Why don't we ever tell secrets on a farm?
Because the potatoes have eyes, the corn has ears, and the beans stalk.
--------------------------------------------------------------------------------
cathy (to joe):
Haha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. 
Why couldn't the bicycle stand up by itself?
Because it was two-tired!
--------------------------------------------------------------------------------

```

### 
[​](https://docs.ag2.ai/docs/tutorial/<#using-is-termination-msg>)
Using `is_termination_msg`
Let’s set the termination message to “GOOD BYE” and see how the conversation terminates.
Copy
```
joe = ConversableAgent(
  "joe",
  system_message="Your name is Joe and you are a part of a duo of comedians.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0.7, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER", # Never ask for human input.
  is_termination_msg=lambda msg: "good bye" in msg["content"].lower(),
)
result = joe.initiate_chat(cathy, message="Cathy, tell me a joke and then say the words GOOD BYE.")

```

Copy
```
joe (to cathy):
Cathy, tell me a joke and then say the words GOOD BYE.
--------------------------------------------------------------------------------
cathy (to joe):
Why don't scientists trust atoms?
Because they make up everything!
GOOD BYE!
--------------------------------------------------------------------------------

```

Notice how the conversation ended based on contents of cathy’s message!
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter we introduced mechanisms to terminate a conversation between agents. You can configure both parameters in `initiate_chat` and also configuration of agents.
That said, it is important to note that when a termination condition is triggered, the conversation may not always terminate immediately. The actual termination depends on the `human_input_mode` argument of the `ConversableAgent` class. For example, when mode is `NEVER` the termination conditions above will end the conversations. But when mode is `ALWAYS` or `TERMINATE`, it will not terminate immediately. We will describe this behavior and explain why it is important in the next chapter.
[Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)[Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Parameters in initiate_chat](https://docs.ag2.ai/docs/tutorial/<#parameters-in-initiate-chat>)
  * [Agent-triggered termination](https://docs.ag2.ai/docs/tutorial/<#agent-triggered-termination>)
  * [Using max_consecutive_auto_reply](https://docs.ag2.ai/docs/tutorial/<#using-max-consecutive-auto-reply>)
  * [Using is_termination_msg](https://docs.ag2.ai/docs/tutorial/<#using-is-termination-msg>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# Allowing Human Feedback in Agents
URL: https://docs.ag2.ai/docs/tutorial/human-in-the-loop

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Allowing Human Feedback in Agents
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Allowing Human Feedback in Agents
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/human-in-the-loop.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/human-in-the-loop.ipynb>)
In the last two chapters we introduced the `ConversableAgent` class and showed how you can use it to create autonomous (`human_input_mode=NEVER`) agents that can accomplish tasks. We also showed how to properly terminate a conversation between agents.
But many applications may require putting humans in-the-loop with agents. For example, to allow human feedback to steer agents in the right direction, specify goals, etc. In this chapter, we will show how AutoGen supports human intervention.
In AutoGen’s `ConversableAgent`, the human-in-the-loop component sits in front of the auto-reply components. It can intercept the incoming messages and decide whether to pass them to the auto-reply components or to provide human feedback. The figure below illustrates the design.
![Human in the loop](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/human-in-the-loop.png)
The human-in-the-loop component can be customized through the `human_input_mode` parameter. We will show you how to use it in the following sections.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#human-input-modes>)
Human Input Modes
Currently AutoGen supports three modes for human input. The mode is specified through the `human_input_mode` argument of the `ConversableAgent`. The three modes are:
  1. `NEVER`: human input is never requested.
  2. `TERMINATE` (default): human input is only requested when a termination condition is met. Note that in this mode if the human chooses to intercept and reply, the conversation continues and the counter used by `max_consecutive_auto_reply` is reset.
  3. `ALWAYS`: human input is always requested and the human can choose to skip and trigger an auto-reply, intercept and provide feedback, or terminate the conversation. Note that in this mode termination based on `max_consecutive_auto_reply` is ignored.


The previous chapters already showed many examples of the cases when `human_input_mode` is `NEVER`. Below we show one such example again and then show the differences when this mode is set to `ALWAYS` and `TERMINATE` instead.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-never>)
Human Input Mode = `NEVER`
In this mode, human input is never requested and the termination conditions are used to terminate. This mode is useful when you want your agents to act fully autonomously.
Here is an example of using this mode to run a simple guess-a-number game between two agents, the termination message is set to check for the number that is the correct guess.
Copy
```
import os
from autogen import ConversableAgent
agent_with_number = ConversableAgent(
  "agent_with_number",
  system_message="You are playing a game of guess-my-number. You have the "
  "number 53 in your mind, and I will try to guess it. "
  "If I guess too high, say 'too high', if I guess too low, say 'too low'. ",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  is_termination_msg=lambda msg: "53" in msg["content"], # terminate if the number is guessed by the other agent
  human_input_mode="NEVER", # never ask for human input
)
agent_guess_number = ConversableAgent(
  "agent_guess_number",
  system_message="I have a number in my mind, and you will try to guess it. "
  "If I say 'too high', you should guess a lower number. If I say 'too low', "
  "you should guess a higher number. ",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
result = agent_with_number.initiate_chat(
  agent_guess_number,
  message="I have a number between 1 and 100. Guess it!",
)

```

Copy
```
agent_with_number (to agent_guess_number):
I have a number between 1 and 100. Guess it!
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 50?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too low.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 75?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too high.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 63?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too high.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 57?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too high.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 54?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too high.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 52?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Too low.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 53?
--------------------------------------------------------------------------------

```

Yay! The game is over. The guessing agent got the number correctly using binary search – very efficient! You can see that the conversation was terminated after the guessing agent said the correct number, which triggered the message-based termination condition.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-always>)
Human Input Mode = `ALWAYS`
In this mode, human input is always requested and the human can choose to skip, intercept , or terminate the conversation. Let us see this mode in action by playing the same game as before with the agent with the number, but this time participating in the game as a human. We will be the agent that is guessing the number, and play against the agent with the number from before.
Copy
```
human_proxy = ConversableAgent(
  "human_proxy",
  llm_config=False, # no LLM used for human proxy
  human_input_mode="ALWAYS", # always ask for human input
)
# Start a chat with the agent with number with an initial guess.
result = human_proxy.initiate_chat(
  agent_with_number, # this is the same agent with the number as before
  message="10",
)

```

Copy
```
human_proxy (to agent_with_number):
10
--------------------------------------------------------------------------------
agent_with_number (to human_proxy):
Too low.
--------------------------------------------------------------------------------
human_proxy (to agent_with_number):
79
--------------------------------------------------------------------------------
agent_with_number (to human_proxy):
Too high.
--------------------------------------------------------------------------------
human_proxy (to agent_with_number):
76
--------------------------------------------------------------------------------
agent_with_number (to human_proxy):
Too high.
--------------------------------------------------------------------------------
human_proxy (to agent_with_number):
I give up
--------------------------------------------------------------------------------
agent_with_number (to human_proxy):
That's okay! The number I was thinking of was 53.
--------------------------------------------------------------------------------

```

If you run the code above, you will be prompt to enter a response each time it is your turn to speak. You can see the human in the conversation was not very good at guessing the number… but hey the agent was nice enough to give out the number in the end.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-terminate>)
Human Input Mode = `TERMINATE`
In this mode, human input is only requested when a termination condition is met. **If the human chooses to intercept and reply, the counter will be reset** ; if the human chooses to skip, the automatic reply mechanism will be used; if the human chooses to terminate, the conversation will be terminated.
Let us see this mode in action by playing the same game again, but this time the guessing agent will only have two chances to guess the number, and if it fails, the human will be asked to provide feedback, and the guessing agent gets two more chances. If the correct number is guessed eventually, the conversation will be terminated.
Copy
```
agent_with_number = ConversableAgent(
  "agent_with_number",
  system_message="You are playing a game of guess-my-number. "
  "In the first game, you have the "
  "number 53 in your mind, and I will try to guess it. "
  "If I guess too high, say 'too high', if I guess too low, say 'too low'. ",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  max_consecutive_auto_reply=1, # maximum number of consecutive auto-replies before asking for human input
  is_termination_msg=lambda msg: "53" in msg["content"], # terminate if the number is guessed by the other agent
  human_input_mode="TERMINATE", # ask for human input until the game is terminated
)
agent_guess_number = ConversableAgent(
  "agent_guess_number",
  system_message="I have a number in my mind, and you will try to guess it. "
  "If I say 'too high', you should guess a lower number. If I say 'too low', "
  "you should guess a higher number. ",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
result = agent_with_number.initiate_chat(
  agent_guess_number,
  message="I have a number between 1 and 100. Guess it!",
)

```

Copy
```
agent_with_number (to agent_guess_number):
I have a number between 1 and 100. Guess it!
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 50?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
agent_with_number (to agent_guess_number):
Too low.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 75?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
It is too high my friend. 
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 60?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
agent_with_number (to agent_guess_number):
Too high.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 55?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
still too high, but you are very close.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 52?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
agent_with_number (to agent_guess_number):
Too low.
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 54?
--------------------------------------------------------------------------------
agent_with_number (to agent_guess_number):
Almost there! 
--------------------------------------------------------------------------------
agent_guess_number (to agent_with_number):
Is it 53?
--------------------------------------------------------------------------------

```

In the previous conversation,
  1. When the agent guessed “74”, the human said “It is too high my friend.”
  2. When the agent guessed “55”, the human said “still too high, but you are very close.”
  3. When the agent guessed “54”, the human said “Almost there!”


Each time after one auto-reply from the agent with the number, the human was asked to provide feedback. Once the human provided feedback, the counter was reset. The conversation was terminated after the agent correctly guessed “53”.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter, we showed you how to use the human-in-the-loop component to provide human feedback to agent and to terminate conversation. We also showed you the different human input modes and how they affect the behavior of the human-in-the-loop component.
The next chapter will be all about code executor – the most powerful component second only to LLMs.
[Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)[Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Human Input Modes](https://docs.ag2.ai/docs/tutorial/<#human-input-modes>)
  * [Human Input Mode = NEVER](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-never>)
  * [Human Input Mode = ALWAYS](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-always>)
  * [Human Input Mode = TERMINATE](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-terminate>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# Code Executors
URL: https://docs.ag2.ai/docs/tutorial/code-executors

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Code Executors
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Code Executors
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/code-executors.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/code-executors.ipynb>)
In the last chapter, we used two agents powered by a large language model (LLM) to play a game by exchanging messages. In this chapter, we introduce code executors, which enable agents to not just chat but also to interact with an environment and perform useful computations and take actions.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#overview>)
Overview
In AutoGen, a code executor is a component that takes input messages (e.g., those containing code blocks), performs execution, and outputs messages with the results. AutoGen provides two types of built-in code executors, one is command line code executor, which runs code in a command line environment such as a UNIX shell, and the other is Jupyter executor, which runs code in an interactive [Jupyter kernel](https://docs.ag2.ai/docs/tutorial/<https:/github.com/jupyter/jupyter/wiki/Jupyter-kernels>).
For each type of executor, AutoGen provides two ways to execute code: locally and in a Docker container. One way is to execute code directly in the same host platform where AutoGen is running, i.e., the local operating system. It is for development and testing, but it is not ideal for production as LLM can generate arbitrary code. The other way is to execute code in a Docker container. The table below shows the combinations of code executors and execution environments.
Code Executor (`autogen.coding`) | Environment | Platform  
---|---|---  
`LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>) | Shell | Local  
`DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) | Shell | Docker  
`jupyter.JupyterCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/jupyter/jupyter_code_executor#jupytercodeexecutor>) | Jupyter Kernel (e.g., python3) | Local/Docker  
In this chapter, we will focus on the command line code executors. For the Jupyter code executor, please refer to the topic page for [Jupyter Code Executor](https://docs.ag2.ai/docs/tutorial/docs/topics/code-execution/jupyter-code-executor>).
## 
[​](https://docs.ag2.ai/docs/tutorial/<#local-execution>)
Local Execution
The figure below shows the architecture of the local command line code executor (`autogen.coding.LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>)).
Executing LLM-generated code poses a security risk to your host environment.
![Code Executor No Docker](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-executor-no-docker.png)
Upon receiving a message with a code block, the local command line code executor first writes the code block to a code file, then starts a new subprocess to execute the code file. The executor reads the console output of the code execution and sends it back as a reply message.
Here is an example of using the code executor to run a Python code block that prints a random number. First we create an agent with the code executor that uses a temporary directory to store the code files. We specify `human_input_mode="ALWAYS"` to manually validate the safety of the the code being executed.
Copy
```
import tempfile
from autogen import ConversableAgent
from autogen.coding import LocalCommandLineCodeExecutor
# Create a temporary directory to store the code files.
temp_dir = tempfile.TemporaryDirectory()
# Create a local command line code executor.
executor = LocalCommandLineCodeExecutor(
  timeout=10, # Timeout for each code execution in seconds.
  work_dir=temp_dir.name, # Use the temporary directory to store the code files.
)
# Create an agent with code executor configuration.
code_executor_agent = ConversableAgent(
  "code_executor_agent",
  llm_config=False, # Turn off LLM for this agent.
  code_execution_config={"executor": executor}, # Use the local command line code executor.
  human_input_mode="ALWAYS", # Always take human input for this agent for safety.
)

```

Before running this example, we need to make sure the `matplotlib` and `numpy` are installed.
Copy
```
! pip install -qqq matplotlib numpy

```

Now we have the agent generate a reply given a message with a Python code block.
Copy
```
message_with_code_block = """This is a message with code block.
The code block is below:
```python
import numpy as np
import matplotlib.pyplot as plt
x = np.random.randint(0, 100, 100)
y = np.random.randint(0, 100, 100)
plt.scatter(x, y)
plt.savefig('scatter.png')
print('Scatter plot saved to scatter.png')
```
This is the end of the message.
"""
# Generate a reply for the given code.
reply = code_executor_agent.generate_reply(messages=[{"role": "user", "content": message_with_code_block}])
print(reply)

```

Copy
```

>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
exitcode: 0 (execution succeeded)
Code output: 
Scatter plot saved to scatter.png

```

During the generation of response, a human input is requested to give an opportunity to intercept the code execution. In this case, we choose to continue the execution, and the agent’s reply contains the output of the code execution.
We can take a look at the generated plot in the temporary directory.
Copy
```
import os
print(os.listdir(temp_dir.name))
# We can see the output scatter.png and the code file generated by the agent.

```

Copy
```
['scatter.png', '6507ea07b63b45aabb027ade4e213de6.py']

```

Clean up the working directory to avoid affecting future conversations.
Copy
```
temp_dir.cleanup()

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#docker-execution>)
Docker Execution
To mitigate the security risk of running LLM-generated code locally, we can use the docker command line code executor (`autogen.coding.DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>)) to execute code in a docker container. This way, the generated code can only access resources that are explicitly given to it.
The figure below illustrates how docker execution works.
![Code Executor Docker](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-executor-docker.png)
Similar to the local command line code executor, the docker executor extracts code blocks from input messages, writes them to code files. For each code file, it starts a docker container to execute the code file, and reads the console output of the code execution.
To use docker execution, you need to [install Docker](https://docs.ag2.ai/docs/tutorial/<https:/docs.docker.com/engine/install/>) on your machine. Once you have Docker installed and running, you can set up your code executor agent as follow:
Copy
```
from autogen.coding import DockerCommandLineCodeExecutor
# Create a temporary directory to store the code files.
temp_dir = tempfile.TemporaryDirectory()
# Create a Docker command line code executor.
executor = DockerCommandLineCodeExecutor(
  image="python:3.12-slim", # Execute code using the given docker image name.
  timeout=10, # Timeout for each code execution in seconds.
  work_dir=temp_dir.name, # Use the temporary directory to store the code files.
)
# Create an agent with code executor configuration that uses docker.
code_executor_agent_using_docker = ConversableAgent(
  "code_executor_agent_docker",
  llm_config=False, # Turn off LLM for this agent.
  code_execution_config={"executor": executor}, # Use the docker command line code executor.
  human_input_mode="ALWAYS", # Always take human input for this agent for safety.
)
# When the code executor is no longer used, stop it to release the resources.
# executor.stop()

```

The `work_dir` in the constructor points to a local file system directory just like in the local execution case. The docker container will mount this directory and the executor write code files and output to it.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#use-code-execution-in-conversation>)
Use Code Execution in Conversation
Writing and executing code is necessary for many tasks such as data analysis, machine learning, and mathematical modeling. In AutoGen, coding can be a conversation between a code writer agent and a code executor agent, mirroring the interaction between a programmer and a code interpreter.
![Code Writer and Code Executor](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-execution-in-conversation.png)
The code writer agent can be powered by an LLM such as GPT-4 with code-writing capability. And the code executor agent is powered by a code executor.
The following is an agent with a code writer role specified using `system_message`. The system message contains important instruction on how to use the code executor in the code executor agent.
Copy
```
# The code writer agent's system message is to instruct the LLM on how to use
# the code executor in the code executor agent.
code_writer_system_message = """You are a helpful AI assistant.
Solve tasks using your coding and language skills.
In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.
1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.
2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.
Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.
When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.
If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.
If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.
When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.
Reply 'TERMINATE' in the end when everything is done.
"""
code_writer_agent = ConversableAgent(
  "code_writer_agent",
  system_message=code_writer_system_message,
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  code_execution_config=False, # Turn off code execution for this agent.
)

```

Here is an example of solving a math problem through a conversation between the code writer agent and the code executor agent (created above).
Copy
```
chat_result = code_executor_agent.initiate_chat(
  code_writer_agent,
  message="Write Python code to calculate the 14th Fibonacci number.",
)

```

Copy
```
code_executor_agent (to code_writer_agent):
Write Python code to calculate the 14th Fibonacci number.
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
code_writer_agent (to code_executor_agent):
Sure, here is a Python code snippet to calculate the 14th Fibonacci number. The Fibonacci series is a sequence of numbers in which each number is the sum of the two preceding ones, usually starting with 0 and 1.
```python
def fibonacci(n):
  if(n <= 0):
    return "Input should be a positive integer."
  elif(n == 1):
    return 0
  elif(n == 2):
    return 1
  else:
    fib = [0, 1]
    for i in range(2, n):
      fib.append(fib[i-1] + fib[i-2])
    return fib[n-1]
print(fibonacci(14))
```
This Python code defines a function `fibonacci(n)` which computes the n-th Fibonacci number. The function uses a list `fib` to store the Fibonacci numbers as they are computed, and then returns the (n-1)-th element as the n-th Fibonacci number due to zero-indexing in Python lists.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
code_executor_agent (to code_writer_agent):
exitcode: 0 (execution succeeded)
Code output: 
233

--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
code_writer_agent (to code_executor_agent):
Great, the execution was successful and the 14th Fibonacci number is 233. The sequence goes as follows: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233... and so on, where each number is the sum of the previous two. Therefore, the 14th number in the Fibonacci series is 233. 
I hope this meets your expectations. If you have any other concerns or need further computations, feel free to ask.
TERMINATE
--------------------------------------------------------------------------------

```

During the previous chat session, human input was requested each time the code executor agent responded to ensure that the code was safe to execute.
Now we can try a more complex example that involves querying the web. Let’s say we want to get the the stock price gains year-to-date for Tesla and Meta (formerly Facebook). We can also use the two agents with several iterations of conversation.
Copy
```
import datetime
today = datetime.datetime.now().strftime("%Y-%m-%d")
chat_result = code_executor_agent.initiate_chat(
  code_writer_agent,
  message=f"Today is {today}. Write Python code to plot TSLA's and META's "
  "stock price gains YTD, and save the plot to a file named 'stock_gains.png'.",
)

```

Copy
```
code_executor_agent (to code_writer_agent):
Today is 2024-02-28. Write Python code to plot TSLA's and META's stock price gains YTD, and save the plot to a file named 'stock_gains.png'.
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
code_writer_agent (to code_executor_agent):
This task requires retrieving the historical data of the stocks from a reliable data source and calculating the Year-To-Date (YTD) gain values, and then plotting them. pandas_datareader library will be used for data retrieval, pandas will be used for data manipulation, and matplotlib for plotting. 
Below is the Python code to achieve this. To start, please install the required libraries by running to the following command:
```sh
pip install yfinance pandas matplotlib
```
Then run the python code:
```python
# filename: stock_gains.py
import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
# define the tickers
tickers = ['TSLA', 'META'] 
# define the start and end dates
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 2, 28)
# dictionary to hold dataframes
dfs = {}
for ticker in tickers:
  # get the data for the stocks
  df = yf.download(ticker, start_date, end_date)
  # get the close price and calculate the cumulative percentage gain
  df['Gain'] = df['Close'].pct_change().cumsum()
  # add to dictionary
  dfs[ticker] = df  
# plot
plt.figure(figsize=(10, 5))
for ticker, df in dfs.items():
  plt.plot(df.index, df['Gain'], label=ticker)
plt.title('YTD Stock Price Gain')
plt.xlabel('Date')
plt.ylabel('Percentage Gain')
plt.legend()
plt.grid(True)
plt.savefig('stock_gains.png')
plt.close()
print("The 'stock_gains.png' file has been successfully saved")
```
This script will download the historical data for TSLA and META from the start of the year to the specified date and calculates the YTD gains. It then generates the plot showing these gains and saves it to 'stock_gains.png'.
Please save the script to a file named 'stock_gains.py' and run it using Python. Remember to have the correct start and end dates for the YTD value when running the script. If your Python version is below 3.9, you should update it to execute this code perfectly.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...
>>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...
code_executor_agent (to code_writer_agent):
exitcode: 0 (execution succeeded)
Code output: 
Requirement already satisfied: yfinance in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (0.2.36)
Requirement already satisfied: pandas in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (2.1.4)
Requirement already satisfied: matplotlib in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (3.9.2)
Requirement already satisfied: numpy>=1.16.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.26.2)
Requirement already satisfied: requests>=2.31 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2.31.0)
Requirement already satisfied: multitasking>=0.0.7 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (0.0.11)
Requirement already satisfied: lxml>=4.9.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (5.0.1)
Requirement already satisfied: appdirs>=1.4.4 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.4.4)
Requirement already satisfied: pytz>=2022.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2023.3.post1)
Requirement already satisfied: frozendict>=2.3.4 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2.4.0)
Requirement already satisfied: peewee>=3.16.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (3.17.0)
Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (4.12.2)
Requirement already satisfied: html5lib>=1.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.1)
Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from pandas) (2.8.2)
Requirement already satisfied: tzdata>=2022.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from pandas) (2023.4)
Requirement already satisfied: contourpy>=1.0.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: cycler>=0.10 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (0.12.1)
Requirement already satisfied: fonttools>=4.22.0 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (4.47.2)
Requirement already satisfied: kiwisolver>=1.3.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (1.4.5)
Requirement already satisfied: packaging>=20.0 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (23.2)
Requirement already satisfied: pillow>=8 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (10.2.0)
Requirement already satisfied: pyparsing>=2.3.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (3.1.1)
Requirement already satisfied: soupsieve>1.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)
Requirement already satisfied: six>=1.9 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (1.16.0)
Requirement already satisfied: webencodings in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (0.5.1)
Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.1.0)
Requirement already satisfied: certifi>=2017.4.17 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2024.2.2)
The 'stock_gains.png' file has been successfully saved

--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
code_writer_agent (to code_executor_agent):
Great! The code executed successfully and the 'stock_gains.png' file has been saved successfully. This file contains the plot of TSLA's and META's stock price gains from the start of the year until February 28, 2024. You should now be able to view this image file in the same directory that you ran the script from. 
Please make sure to verify this image file. It should contain two plotted lines, each representing the percentage gain over the time for each stock (TSLA and META). The x-axis represents the date, and the y-axis represents the percentage gain. If everything looks correct, this would be the end of the task.
TERMINATE
--------------------------------------------------------------------------------

```

In the previous conversation, the code writer agent generated a code block to install necessary packages and another code block for a script to fetch the stock price and calculate gains year-to-date for Tesla and Meta. The code executor agent installed the packages, executed the script, and returned the results.
Let’s take a look at the chart that was generated.
Copy
```
from IPython.display import Image
Image(os.path.join(temp_dir, "stock_gains.png"))

```

![](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/code-executors_files/figure-markdown_strict/cell-11-output-1.png)
Because code execution leave traces like code files and output in the file system, we may want to clean up the working directory after each conversation concludes.
Copy
```
temp_dir.cleanup()

```

Stop the docker command line executor to clean up the docker container.
Copy
```
executor.stop() # Stop the docker command line code executor.

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#command-line-or-jupyter-code-executor>)
Command Line or Jupyter Code Executor?
The command line code executor does not keep any state in memory between executions of different code blocks it receives, as it writes each code block to a separate file and executes the code block in a new process.
Contrast to the command line code executor, the Jupyter code executor runs all code blocks in the same Jupyter kernel, which keeps the state in memory between executions. See the topic page for [Jupyter Code Executor](https://docs.ag2.ai/docs/tutorial/docs/topics/code-execution/jupyter-code-executor>).
The choice between command line and Jupyter code executor depends on the nature of the code blocks in agents’ conversation. If each code block is a “script” that does not use variables from previous code blocks, the command line code executor is a good choice. If some code blocks contain expensive computations (e.g., training a machine learning model and loading a large amount of data), and you want to keep the state in memory to avoid repeated computations, the Jupyter code executor is a better choice.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#note-on-user-proxy-agent-and-assistant-agent>)
Note on User Proxy Agent and Assistant Agent
### 
[​](https://docs.ag2.ai/docs/tutorial/<#user-proxy-agent>)
User Proxy Agent
In the previous examples, we create the code executor agent directly using the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. Existing AutoGen examples often create code executor agent using the `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) class, which is a subclass of `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) with `human_input_mode=ALWAYS` and `llm_config=False` – it always requests human input for every message and does not use LLM. It also comes with default `description` field for each of the `human_input_mode` setting. This class is a convenient short-cut for creating an agent that is intended to be used as a code executor.
### 
[​](https://docs.ag2.ai/docs/tutorial/<#assistant-agent>)
Assistant Agent
In the previous examples, we created the code writer agent directly using the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. Existing AutoGen examples often create the code writer agent using the `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) class, which is a subclass of `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) with `human_input_mode=NEVER` and `code_execution_config=False` – it never requests human input and does not use code executor. It also comes with default `system_message` and `description` fields. This class is a convenient short-cut for creating an agent that is intended to be used as a code writer and does not execute code.
In fact, in the previous example we use the default `system_message` field of the `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) class to instruct the code writer agent how to use code executor.
Copy
```
import pprint
from autogen import AssistantAgent
pprint.pprint(AssistantAgent.DEFAULT_SYSTEM_MESSAGE)

```

Copy
```
('You are a helpful AI assistant.\n'
 'Solve tasks using your coding and language skills.\n'
 'In the following cases, suggest python code (in a python coding block) or '
 'shell script (in a sh coding block) for the user to execute.\n'
 '  1. When you need to collect info, use the code to output the info you '
 'need, for example, browse or search the web, download/read a file, print the '
 'content of a webpage or a file, get the current date/time, check the '
 'operating system. After sufficient info is printed and the task is ready to '
 'be solved based on your language skill, you can solve the task by yourself.\n'
 '  2. When you need to perform some task with code, use the code to perform '
 'the task and output the result. Finish the task smartly.\n'
 'Solve the task step by step if you need to. If a plan is not provided, '
 'explain your plan first. Be clear which step uses code, and which step uses '
 'your language skill.\n'
 'When using code, you must indicate the script type in the code block. The '
 'user cannot provide any other feedback or perform any other action beyond '
 "executing the code you suggest. The user can't modify your code. So do not "
 "suggest incomplete code which requires users to modify. Don't use a code "
 "block if it's not intended to be executed by the user.\n"
 'If you want the user to save the code in a file before executing it, put # '
 "filename: <filename> inside the code block as the first line. Don't include "
 'multiple code blocks in one response. Do not ask users to copy and paste the '
 "result. Instead, use 'print' function for the output when relevant. Check "
 'the execution result returned by the user.\n'
 'If the result indicates there is an error, fix the error and output the code '
 'again. Suggest the full code instead of partial code or code changes. If the '
 "error can't be fixed or if the task is not solved even after the code is "
 'executed successfully, analyze the problem, revisit your assumption, collect '
 'additional info you need, and think of a different approach to try.\n'
 'When you find an answer, verify the answer carefully. Include verifiable '
 'evidence in your response if possible.\n'
 'Reply "TERMINATE" in the end when everything is done.\n'
 '  ')

```

### 
[​](https://docs.ag2.ai/docs/tutorial/<#best-practice>)
Best Practice
It is very important to note that the `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) and `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) are meant to be shortcuts to avoid writing the `system_message` instructions for the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. They are not suitable for all use cases. As we will show in the next chapter, tuning the `system_message` field is vital for agent to work properly in more complex conversation patterns beyond two-agent chat.
As a best practice, always tune your agent’s `system_message` instructions for your specific use case and avoid subclassing `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) and `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>).
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter, we introduced code executors, how to set up Docker and local execution, and how to use code execution in a conversation to solve tasks. In the next chapter, we will introduce tool use, which is similar to code executors but restricts what code an agent can execute.
[Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)[Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Overview](https://docs.ag2.ai/docs/tutorial/<#overview>)
  * [Local Execution](https://docs.ag2.ai/docs/tutorial/<#local-execution>)
  * [Docker Execution](https://docs.ag2.ai/docs/tutorial/<#docker-execution>)
  * [Use Code Execution in Conversation](https://docs.ag2.ai/docs/tutorial/<#use-code-execution-in-conversation>)
  * [Command Line or Jupyter Code Executor?](https://docs.ag2.ai/docs/tutorial/<#command-line-or-jupyter-code-executor>)
  * [Note on User Proxy Agent and Assistant Agent](https://docs.ag2.ai/docs/tutorial/<#note-on-user-proxy-agent-and-assistant-agent>)
  * [User Proxy Agent](https://docs.ag2.ai/docs/tutorial/<#user-proxy-agent>)
  * [Assistant Agent](https://docs.ag2.ai/docs/tutorial/<#assistant-agent>)
  * [Best Practice](https://docs.ag2.ai/docs/tutorial/<#best-practice>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# Tool Use
URL: https://docs.ag2.ai/docs/tutorial/tool-use

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Tool Use
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Tool Use
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/tool-use.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/tool-use.ipynb>)
In the previous chapter, we explored code executors which give agents the super power of programming. Agents writing arbitrary code is useful, however, controlling what code an agent writes can be challenging. This is where tools come in.
Tools are pre-defined functions that agents can use. Instead of writing arbitrary code, agents can call tools to perform actions, such as searching the web, performing calculations, reading files, or calling remote APIs. Because you can control what tools are available to an agent, you can control what actions an agent can perform.
Tool use is currently only available for LLMs that support OpenAI-compatible tool call API.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#creating-tools>)
Creating Tools
Tools can be created as regular Python functions. For example, let’s create a calculator tool which can only perform a single operation at a time.
Copy
```
from typing import Annotated, Literal
Operator = Literal["+", "-", "*", "/"]

def calculator(a: int, b: int, operator: Annotated[Operator, "operator"]) -> int:
  if operator == "+":
    return a + b
  elif operator == "-":
    return a - b
  elif operator == "*":
    return a * b
  elif operator == "/":
    return int(a / b)
  else:
    raise ValueError("Invalid operator")

```

The above function takes three arguments: `a` and `b` are the integer numbers to be operated on; `operator` is the operation to be performed. We used type hints to define the types of the arguments and the return value.
Always use type hints to define the types of the arguments and the return value as they provide helpful hints to the agent about the tool’s usage.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#registering-tools>)
Registering Tools
Once you have created a tool, you can register it with the agents that are involved in conversation.
Copy
```
import os
from autogen import ConversableAgent
# Let's first define the assistant agent that suggests tool calls.
assistant = ConversableAgent(
  name="Assistant",
  system_message="You are a helpful AI assistant. "
  "You can help with simple calculations. "
  "Return 'TERMINATE' when the task is done.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)
# The user proxy agent is used for interacting with the assistant agent
# and executes tool calls.
user_proxy = ConversableAgent(
  name="User",
  llm_config=False,
  is_termination_msg=lambda msg: msg.get("content") is not None and "TERMINATE" in msg["content"],
  human_input_mode="NEVER",
)
# Register the tool signature with the assistant agent.
assistant.register_for_llm(name="calculator", description="A simple calculator")(calculator)
# Register the tool function with the user proxy agent.
user_proxy.register_for_execution(name="calculator")(calculator)

```

Copy
```
<function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> int>

```

In the above code, we registered the `calculator` function as a tool with the assistant and user proxy agents. We also provide a name and a description for the tool for the assistant agent to understand its usage.
Always provide a clear and concise description for the tool as it helps the agent’s underlying LLM to understand the tool’s usage.
Similar to code executors, a tool must be registered with at least two agents for it to be useful in conversation. The agent registered with the tool’s signature through `register_for_llm`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-for-llm>) can call the tool; the agent registered with the tool’s function object through `register_for_execution`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-for-execution>) can execute the tool’s function.
Alternatively, you can use `autogen.register_function`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-function>) function to register a tool with both agents at once.
Copy
```
from autogen import register_function
# Register the calculator function to the two agents.
register_function(
  calculator,
  caller=assistant, # The assistant agent can suggest calls to the calculator.
  executor=user_proxy, # The user proxy agent can execute the calculator calls.
  name="calculator", # By default, the function name is used as the tool name.
  description="A simple calculator", # A description of the tool.
)

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#using-tool>)
Using Tool
Once the tool is registered, we can use it in conversation. In the code below, we ask the assistant to perform some arithmetic calculation using the `calculator` tool.
Copy
```
chat_result = user_proxy.initiate_chat(assistant, message="What is (44232 + 13312 / (232 - 32)) * 5?")

```

Copy
```
User (to Assistant):
What is (44232 + 13312 / (232 - 32)) * 5?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_4rElPoLggOYJmkUutbGaSTX1): calculator *****
Arguments: 
{
 "a": 232,
 "b": 32,
 "operator": "-"
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_4rElPoLggOYJmkUutbGaSTX1) *****
200
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_SGtr8tK9A4iOCJGdCqkKR2Ov): calculator *****
Arguments: 
{
 "a": 13312,
 "b": 200,
 "operator": "/"
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_SGtr8tK9A4iOCJGdCqkKR2Ov) *****
66
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_YsR95CM1Ice2GZ7ZoStYXI6M): calculator *****
Arguments: 
{
 "a": 44232,
 "b": 66,
 "operator": "+"
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_YsR95CM1Ice2GZ7ZoStYXI6M) *****
44298
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_oqZn4rTjyvXYcmjAXkvVaJm1): calculator *****
Arguments: 
{
 "a": 44298,
 "b": 5,
 "operator": "*"
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_oqZn4rTjyvXYcmjAXkvVaJm1) *****
221490
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
The result of the calculation is 221490. TERMINATE
--------------------------------------------------------------------------------

```

Let’s verify the answer:
Copy
```
(44232 + int(13312 / (232 - 32))) * 5

```

Copy
```
221490

```

The answer is correct. You can see that the assistant is able to understand the tool’s usage and perform calculation correctly.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#tool-schema>)
Tool Schema
If you are familiar with [OpenAI’s tool use API](https://docs.ag2.ai/docs/tutorial/<https:/platform.openai.com/docs/guides/function-calling>), you might be wondering why we didn’t create a tool schema. In fact, the tool schema is automatically generated from the function signature and the type hints. You can see the tool schema by inspecting the `llm_config` attribute of the agent.
Copy
```
assistant.llm_config["tools"]

```

Copy
```
[{'type': 'function',
 'function': {'description': 'A simple calculator',
  'name': 'calculator',
  'parameters': {'type': 'object',
  'properties': {'a': {'type': 'integer', 'description': 'a'},
   'b': {'type': 'integer', 'description': 'b'},
   'operator': {'enum': ['+', '-', '*', '/'],
   'type': 'string',
   'description': 'operator'}},
  'required': ['a', 'b', 'operator']}}}]

```

You can see the tool schema has been automatically generated from the function signature and the type hints, as well as the description. This is why it is important to use type hints and provide a clear description for the tool as the LLM uses them to understand the tool’s usage.
You can also use Pydantic model for the type hints to provide more complex type schema. In the example below, we use a Pydantic model to define the calculator input.
Copy
```
from pydantic import BaseModel, Field

class CalculatorInput(BaseModel):
  a: Annotated[int, Field(description="The first number.")]
  b: Annotated[int, Field(description="The second number.")]
  operator: Annotated[Operator, Field(description="The operator.")]

def calculator(input: Annotated[CalculatorInput, "Input to the calculator."]) -> int:
  if input.operator == "+":
    return input.a + input.b
  elif input.operator == "-":
    return input.a - input.b
  elif input.operator == "*":
    return input.a * input.b
  elif input.operator == "/":
    return int(input.a / input.b)
  else:
    raise ValueError("Invalid operator")

```

Same as before, we register the tool with the agents using the name `"calculator"`.
Registering tool to the same name will override the previous tool.
Copy
```
assistant.register_for_llm(name="calculator", description="A calculator tool that accepts nested expression as input")(
  calculator
)
user_proxy.register_for_execution(name="calculator")(calculator)

```

Copy
```
<function __main__.calculator(input: typing.Annotated[__main__.CalculatorInput, 'Input to the calculator.']) -> int>

```

You can see the tool schema has been updated to reflect the new type schema.
Copy
```
assistant.llm_config["tools"]

```

Copy
```
[{'type': 'function',
 'function': {'description': 'A calculator tool that accepts nested expression as input',
  'name': 'calculator',
  'parameters': {'type': 'object',
  'properties': {'input': {'properties': {'a': {'description': 'The first number.',
    'title': 'A',
    'type': 'integer'},
    'b': {'description': 'The second number.',
    'title': 'B',
    'type': 'integer'},
    'operator': {'description': 'The operator.',
    'enum': ['+', '-', '*', '/'],
    'title': 'Operator',
    'type': 'string'}},
   'required': ['a', 'b', 'operator'],
   'title': 'CalculatorInput',
   'type': 'object',
   'description': 'Input to the calculator.'}},
  'required': ['input']}}}]

```

Let’s use the tool in conversation.
Copy
```
chat_result = user_proxy.initiate_chat(assistant, message="What is (1423 - 123) / 3 + (32 + 23) * 5?")

```

Copy
```
User (to Assistant):
What is (1423 - 123) / 3 + (32 + 23) * 5?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_Uu4diKtxlTfkwXuY6MmJEb4E): calculator *****
Arguments: 
{
  "input": {
    "a": (1423 - 123) / 3,
    "b": (32 + 23) * 5,
    "operator": "+"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_Uu4diKtxlTfkwXuY6MmJEb4E) *****
Error: Expecting value: line 1 column 29 (char 28)
 You argument should follow json format.
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
I apologize for the confusion, I seem to have made a mistake. Let me recalculate the expression properly.
First, we need to do the calculations within the brackets. So, calculating (1423 - 123), (32 + 23), and then performing remaining operations.
***** Suggested tool call (call_mx3M3fNOwikFNoqSojDH1jIr): calculator *****
Arguments: 
{
  "input": {
    "a": 1423,
    "b": 123,
    "operator": "-"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_mx3M3fNOwikFNoqSojDH1jIr) *****
1300
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_hBAL2sYi6Y5ZtTHCNPCmxdN3): calculator *****
Arguments: 
{
  "input": {
    "a": 32,
    "b": 23,
    "operator": "+"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_hBAL2sYi6Y5ZtTHCNPCmxdN3) *****
55
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_wO3AP7EDeJvsVLCpvv5LohUa): calculator *****
Arguments: 
{
  "input": {
    "a": 1300,
    "b": 3,
    "operator": "/"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_wO3AP7EDeJvsVLCpvv5LohUa) *****
433
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_kQ2hDhqem8BHNlaHaE9ezvvQ): calculator *****
Arguments: 
{
  "input": {
    "a": 55,
    "b": 5,
    "operator": "*"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_kQ2hDhqem8BHNlaHaE9ezvvQ) *****
275
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
***** Suggested tool call (call_1FLDUdvAZmjlSD7g5GFFJOpO): calculator *****
Arguments: 
{
  "input": {
    "a": 433,
    "b": 275,
    "operator": "+"
  }
}
***************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION calculator...
User (to Assistant):
User (to Assistant):
***** Response from calling tool (call_1FLDUdvAZmjlSD7g5GFFJOpO) *****
708
**********************************************************************
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Assistant (to User):
The calculation result of the expression (1423 - 123) / 3 + (32 + 23) * 5 is 708. Let's proceed to the next task.
TERMINATE
--------------------------------------------------------------------------------

```

Let’s verify the answer:
Copy
```
int((1423 - 123) / 3) + (32 + 23) * 5

```

Copy
```
708

```

Again, the answer is correct. You can see that the assistant is able to understand the new tool schema and perform calculation correctly.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#how-to-hide-tool-usage-and-code-execution-within-a-single-agent>)
How to hide tool usage and code execution within a single agent?
Sometimes it is preferable to hide the tool usage inside a single agent, i.e., the tool call and tool response messages are kept invisible from outside of the agent, and the agent responds to outside messages with tool usages as “internal monologues”. For example, you might want build an agent that is similar to the [OpenAI’s Assistant](https://docs.ag2.ai/docs/tutorial/<https:/platform.openai.com/docs/assistants/overview#how-assistants-work>) which executes built-in tools internally.
To achieve this, you can use [nested chats](https://docs.ag2.ai/docs/tutorial/docs/tutorial/conversation-patterns#nested-chats>). Nested chats allow you to create “internal monologues” within an agent to call and execute tools. This works for code execution as well. See [nested chats for tool use](https://docs.ag2.ai/docs/tutorial/notebooks/agentchat_nested_chats_chess>) for an example.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter, we showed you how to create, register and use tools. Tools allows agents to perform actions without writing arbitrary code. In the next chapter, we will introduce conversation patterns, and show how to use the result of a conversation.
[Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)[Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Creating Tools](https://docs.ag2.ai/docs/tutorial/<#creating-tools>)
  * [Registering Tools](https://docs.ag2.ai/docs/tutorial/<#registering-tools>)
  * [Using Tool](https://docs.ag2.ai/docs/tutorial/<#using-tool>)
  * [Tool Schema](https://docs.ag2.ai/docs/tutorial/<#tool-schema>)
  * [How to hide tool usage and code execution within a single agent?](https://docs.ag2.ai/docs/tutorial/<#how-to-hide-tool-usage-and-code-execution-within-a-single-agent>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# Conversation Patterns
URL: https://docs.ag2.ai/docs/tutorial/conversation-patterns

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
Conversation Patterns
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# Conversation Patterns
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/conversation-patterns.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/conversation-patterns.ipynb>)
In the previous chapter we used two-agent conversation, which can be started by the `initiate_chat` method. Two-agent chat is a useful conversation pattern but AutoGen offers more. In this chapter, we will first dig a little bit more into the two-agent chat pattern and chat result, then we will show you several conversation patterns that involve more than two agents.
### 
[​](https://docs.ag2.ai/docs/tutorial/<#an-overview>)
An Overview
  1. **Two-agent chat** : the simplest form of conversation pattern where two agents chat with each other.
  2. **Sequential chat** : a sequence of chats between two agents, chained together by a carryover mechanism, which brings the summary of the previous chat to the context of the next chat.
  3. **Group Chat** : a single chat involving more than two agents. An important question in group chat is: What agent should be next to speak? To support different scenarios, we provide different ways to organize agents in a group chat: 
     * We support several strategies to select the next agent: `round_robin`, `random`, `manual` (human selection), and `auto` (Default, using an LLM to decide).
     * We provide a way to constrain the selection of the next speaker (See examples below).
     * We allow you to pass in a function to customize the selection of the next speaker. With this feature, you can build a **StateFlow** model which allows a deterministic workflow among your agents. Please refer to this [guide](https://docs.ag2.ai/docs/tutorial/docs/topics/groupchat/customized_speaker_selection>) and this [blog post](https://docs.ag2.ai/docs/tutorial/blog/2024-02-29-StateFlow>) on StateFlow for more details.
  4. **Nested Chat** : package a workflow into a single agent for reuse in a larger workflow.


## 
[​](https://docs.ag2.ai/docs/tutorial/<#two-agent-chat-and-chat-result>)
Two-Agent Chat and Chat Result
Two-agent chat is the simplest form of conversation pattern. We start a two-agent chat using the `initiate_chat` method of every `ConversableAgent` agent. We have already seen multiple examples of two-agent chats in previous chapters but we haven’t covered the details.
The following figure illustrates how two-agent chat works.
![Two-agent chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/two-agent-chat.png)
A two-agent chats takes two inputs: a message, which is a string provided by the caller; a context, which specifies various parameters of the chat. The sender agent uses its chat initializer method (i.e., `generate_init_message` method of `ConversableAgent`) to generate an initial message from the inputs, and sends it to the recipient agent to start the chat. The sender agent is the agent whose `initiate_chat` method is called, and the recipient agent is the other agent.
Once the chat terminates, the history of the chat is processed by a chat summarizer. The summarizer summarizes the chat history and calculates the token usage of the chat. You can configure the type of summary using the `summary_method` parameter of the `initiate_chat` method. By default, it is the last message of the chat (i.e., `summary_method='last_msg'`).
The example below is a two-agent chat between a student agent and a teacher agent. Its summarizer uses an LLM-based summary.
Copy
```
import os
from autogen import ConversableAgent
student_agent = ConversableAgent(
  name="Student_Agent",
  system_message="You are a student willing to learn.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)
teacher_agent = ConversableAgent(
  name="Teacher_Agent",
  system_message="You are a math teacher.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)
chat_result = student_agent.initiate_chat(
  teacher_agent,
  message="What is triangle inequality?",
  summary_method="reflection_with_llm",
  max_turns=2,
)

```

Copy
```
Student_Agent (to Teacher_Agent):
What is triangle inequality?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Teacher_Agent (to Student_Agent):
Triangle inequality theorem is a fundamental principle in geometry that states that the sum of the lengths of any two sides of a triangle must always be greater than the length of the third side. In a triangle with sides of lengths a, b, and c, the theorem can be written as:
a + b > c
a + c > b
b + c > a
Each of these represents the condition for one specific side (a, b, or c). All must be true for a triangle to exist.
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Student_Agent (to Teacher_Agent):
Thank you for the explanation. This theorem helps in understanding the basic properties of a triangle. It can also be useful when solving geometric problems or proving other mathematical theorems. Can you give me an example of how we can use the triangle inequality theorem?
--------------------------------------------------------------------------------
>>>>>>>> USING AUTO REPLY...
Teacher_Agent (to Student_Agent):
Absolutely! Here's an example:
Suppose you're given three line segments with lengths 10, 7, and 3 units. The question is: "Can these three line segments form a triangle?"
To answer this, you would use the triangle inequality theorem. Adding any two side lengths together should be greater than the third:
- For sides 10 and 7: 10 + 7 = 17, which is larger than 3.
- For sides 10 and 3: 10 + 3 = 13, which is larger than 7.
- For sides 7 and 3: 7 + 3 = 10, which is equal to the length of the third side (10), but not greater.
So, these three lines cannot form a triangle, because not all pairs of sides satisfy the triangle inequality theorem.
--------------------------------------------------------------------------------

```

Let’s see what the summary looks like. The summary is stored in the `chat_result` object of the type `ChatResult` that was returned by the `initiate_chat` method.
Copy
```
print(chat_result.summary)

```

Copy
```
The triangle inequality theorem states that in a triangle, the sum of the lengths of any two sides must always be greater than the length of the third side. This principle is significant in geometry and is used in solving problems or proving theorems. For instance, if given three line segments, you can determine if they can form a triangle using this theorem.

```

In the above example, the summary method is set to `reflection_with_llm` which takes a list of messages from the conversation and summarize them using a call to an LLM. The summary method first tries to use the recipient’s LLM, if it is not available then it uses the sender’s LLM. In this case the recipient is “Teacher_Agent” and the sender is “Student_Agent”. The input prompt for the LLM is the following default prompt:
Copy
```
print(ConversableAgent.DEFAULT_SUMMARY_PROMPT)

```

Copy
```
Summarize the takeaway from the conversation. Do not add any introductory phrases.

```

You can also use a custom prompt by setting the `summary_prompt` argument of `initiate_chat`.
There are some other useful information in the `ChatResult` object, including the conversation history, human input, and token cost.
Copy
```
# Get the chat history.
import pprint
pprint.pprint(chat_result.chat_history)

```

Copy
```
[{'content': 'What is triangle inequality?', 'role': 'assistant'},
 {'content': 'Triangle inequality theorem is a fundamental principle in '
       'geometry that states that the sum of the lengths of any two '
       'sides of a triangle must always be greater than the length of '
       'the third side. In a triangle with sides of lengths a, b, and c, '
       'the theorem can be written as:\n'
       '\n'
       'a + b > c\n'
       'a + c > b\n'
       'b + c > a\n'
       '\n'
       'Each of these represents the condition for one specific side (a, '
       'b, or c). All must be true for a triangle to exist.',
 'role': 'user'},
 {'content': 'Thank you for the explanation. This theorem helps in '
       'understanding the basic properties of a triangle. It can also be '
       'useful when solving geometric problems or proving other '
       'mathematical theorems. Can you give me an example of how we can '
       'use the triangle inequality theorem?',
 'role': 'assistant'},
 {'content': "Absolutely! Here's an example:\n"
       '\n'
       "Suppose you're given three line segments with lengths 10, 7, and "
       '3 units. The question is: "Can these three line segments form a '
       'triangle?"\n'
       '\n'
       'To answer this, you would use the triangle inequality theorem. '
       'Adding any two side lengths together should be greater than the '
       'third:\n'
       '\n'
       '- For sides 10 and 7: 10 + 7 = 17, which is larger than 3.\n'
       '- For sides 10 and 3: 10 + 3 = 13, which is larger than 7.\n'
       '- For sides 7 and 3: 7 + 3 = 10, which is equal to the length of '
       'the third side (10), but not greater.\n'
       '\n'
       'So, these three lines cannot form a triangle, because not all '
       'pairs of sides satisfy the triangle inequality theorem.',
 'role': 'user'}]

```

That chat messages in the chat result are from the recipient agent’s perspective – the sender is the “assistant” and the recipient is the “user”.
Copy
```
# Get the cost of the chat.
pprint.pprint(chat_result.cost)

```

Copy
```
({'gpt-4-0613': {'completion_tokens': 399,
         'cost': 0.04521,
         'prompt_tokens': 709,
         'total_tokens': 1108},
 'total_cost': 0.04521},
 {'total_cost': 0})

```

## 
[​](https://docs.ag2.ai/docs/tutorial/<#sequential-chats>)
Sequential Chats
The name of this pattern is self-explanatory – it is a sequence of chats between two agents, chained together by a mechanism called _carryover_ , which brings the summary of the previous chat to the context of the next chat.
This pattern is useful for complex task that can be broken down into interdependent sub-tasks. The figure below illustrate how this pattern works.
![initiate_chats](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/sequential-two-agent-chat.png)
In this pattern, the a pair of agents first start a two-agent chat, then the summary of the conversation becomes a _carryover_ for the next two-agent chat. The next chat passes the carryover to the `carryover` parameter of the context to generate its initial message.
Carryover accumulates as the conversation moves forward, so each subsequent chat starts with all the carryovers from previous chats.
The figure above shows distinct recipient agents for all the chats, however, the recipient agents in the sequence are allowed to repeat.
To illustrate this pattern, let’s consider a simple example of arithmetic operator agents. One agent (called the “Number_Agent”) is responsible for coming up with a number, and other agents are responsible for performing a specific arithmetic operation on the number, e.g., add 1, multiply by 2, etc..
Copy
```
# The Number Agent always returns the same numbers.
number_agent = ConversableAgent(
  name="Number_Agent",
  system_message="You return me the numbers I give you, one number each line.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
# The Adder Agent adds 1 to each number it receives.
adder_agent = ConversableAgent(
  name="Adder_Agent",
  system_message="You add 1 to each number I give you and return me the new numbers, one number each line.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
# The Multiplier Agent multiplies each number it receives by 2.
multiplier_agent = ConversableAgent(
  name="Multiplier_Agent",
  system_message="You multiply each number I give you by 2 and return me the new numbers, one number each line.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
# The Subtracter Agent subtracts 1 from each number it receives.
subtracter_agent = ConversableAgent(
  name="Subtracter_Agent",
  system_message="You subtract 1 from each number I give you and return me the new numbers, one number each line.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
# The Divider Agent divides each number it receives by 2.
divider_agent = ConversableAgent(
  name="Divider_Agent",
  system_message="You divide each number I give you by 2 and return me the new numbers, one number each line.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)

```

The Number Agent chats with the first operator agent, then the second operator agent, and so on. After each chat, the last message in the conversation (i.e., the result of the arithmetic operation from the operator agent) is used as the summary of the chat. This is specified by the `summary_method` parameter. In the end we will have the result of the arithmetic operations.
Copy
```
# Start a sequence of two-agent chats.
# Each element in the list is a dictionary that specifies the arguments
# for the initiate_chat method.
chat_results = number_agent.initiate_chats(
  [
    {
      "recipient": adder_agent,
      "message": "14",
      "max_turns": 2,
      "summary_method": "last_msg",
    },
    {
      "recipient": multiplier_agent,
      "message": "These are my numbers",
      "max_turns": 2,
      "summary_method": "last_msg",
    },
    {
      "recipient": subtracter_agent,
      "message": "These are my numbers",
      "max_turns": 2,
      "summary_method": "last_msg",
    },
    {
      "recipient": divider_agent,
      "message": "These are my numbers",
      "max_turns": 2,
      "summary_method": "last_msg",
    },
  ]
)

```

Copy
```

********************************************************************************
Start a new chat with the following message: 
14
With the following carryover: 

********************************************************************************
Number_Agent (to Adder_Agent):
14
--------------------------------------------------------------------------------
Adder_Agent (to Number_Agent):
15
--------------------------------------------------------------------------------
Number_Agent (to Adder_Agent):
15
--------------------------------------------------------------------------------
Adder_Agent (to Number_Agent):
16
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
These are my numbers
With the following carryover: 
16
********************************************************************************
Number_Agent (to Multiplier_Agent):
These are my numbers
Context: 
16
--------------------------------------------------------------------------------
Multiplier_Agent (to Number_Agent):
32
--------------------------------------------------------------------------------
Number_Agent (to Multiplier_Agent):
32
--------------------------------------------------------------------------------
Multiplier_Agent (to Number_Agent):
64
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
These are my numbers
With the following carryover: 
16
64
********************************************************************************
Number_Agent (to Subtracter_Agent):
These are my numbers
Context: 
16
64
--------------------------------------------------------------------------------
Subtracter_Agent (to Number_Agent):
15
63
--------------------------------------------------------------------------------
Number_Agent (to Subtracter_Agent):
15
63
--------------------------------------------------------------------------------
Subtracter_Agent (to Number_Agent):
14
62
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
These are my numbers
With the following carryover: 
16
64
14
62
********************************************************************************
Number_Agent (to Divider_Agent):
These are my numbers
Context: 
16
64
14
62
--------------------------------------------------------------------------------
Divider_Agent (to Number_Agent):
8
32
7
31
--------------------------------------------------------------------------------
Number_Agent (to Divider_Agent):
8
32
7
31
--------------------------------------------------------------------------------
Divider_Agent (to Number_Agent):
4
16
3.5
15.5
--------------------------------------------------------------------------------

```

First thing to note is that the `initiate_chats` method takes a list of dictionaries, each dictionary contains the arguments for the `initiate_chat` method.
Second, each chat in the sequence has a maximum round of 2, as specified with the setting `max_turns=2`, which means each arithmetic operation is performed twice. So you can see in the first chat the number 14 becomes 15 and then 16, in the second chat the number 16 becomes 32 and then 64, and so on.
Third, the carryover accumulates as the chats go on. In the second chat, the carryover is the summary of the first chat “16”. In the third chat, the carryover is the summary of the first and second chat, which is the list “16” and “64”, and both numbers are operated upon. In the forth and last chat, the carryover is the summary of all previous chats, which is the list “16”, “64”, “14” and “62”, and all of these numbers are operated upon.
The final note is that the `initiate_chats` method returns a list of `ChatResult` objects, one for each chat in the sequence.
Copy
```
print("First Chat Summary: ", chat_results[0].summary)
print("Second Chat Summary: ", chat_results[1].summary)
print("Third Chat Summary: ", chat_results[2].summary)
print("Fourth Chat Summary: ", chat_results[3].summary)

```

Copy
```
First Chat Summary: 16
Second Chat Summary: 64
Third Chat Summary: 14
62
Fourth Chat Summary: 4
16
3.5
15.5

```

Besides calling `initiate_chats` from the same sender agent, you can also call a high-level function `autogen.agentchat.initiate_chats` to start a sequence of two-agent chats with different sender agents. This function allows you to specify the sender agent for each chat in the sequence.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#group-chat>)
Group Chat
So far we have only seen conversation patterns that involve two agents or a sequence of two-agent chats. AutoGen provides a more general conversation pattern called group chat, which involves more than two agents. The core idea of group chat is that all agents contribute to a single conversation thread and share the same context. This is useful for tasks that require collaboration among multiple agents.
The figure below illustrates how group chat works.
![group_chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/group-chat.png)
A group chat is orchestrated by a special agent type `GroupChatManager`. In the first step of the group chat, the Group Chat Manager selects an agent to speak. Then, the selected agent speaks and the message is sent back to the Group Chat Manager, who **broadcasts** the message to all other agents in the group. This process repeats until the conversation stops.
The Group Chat Manager can use several strategies to select the next agent. Currently, the following strategies are supported:
  1. `round_robin`: The Group Chat Manager selects agents in a round-robin fashion based on the order of the agents provided.
  2. `random`: The Group Chat Manager selects agents randomly.
  3. `manual`: The Group Chat Manager selects agents by asking for human input.
  4. `auto`: The default strategy, which selects agents using the Group Chat Manager’s LLM.


To illustrate this pattern, let’s consider a simple example of a group chat among the same arithmetic operator agents as in the previous example, with the objective of turning a number into a specific target number using a sequence of arithmetic operations powered by the agents.
In this example, we use the `auto` strategy to select the next agent. To help the Group Chat Manager select the next agent, we also set the `description` of the agents. Without the `description`, the Group Chat Manager will use the agents’ `system_message`, which may be not be the best choice.
Copy
```
# The `description` attribute is a string that describes the agent.
# It can also be set in `ConversableAgent` constructor.
adder_agent.description = "Add 1 to each input number."
multiplier_agent.description = "Multiply each input number by 2."
subtracter_agent.description = "Subtract 1 from each input number."
divider_agent.description = "Divide each input number by 2."
number_agent.description = "Return the numbers given."

```

We first create a `GroupChat` object and provide the list of agents. If we were to use the `round_robin` strategy, this list would specify the order of the agents to be selected. We also initialize the group chat with an empty message list and a maximum round of 6, which means there will be at most 6 iteratiosn of selecting speaker, agent speaks and broadcasting message.
Copy
```
from autogen import GroupChat
group_chat = GroupChat(
  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],
  messages=[],
  max_round=6,
)

```

Now we create a `GroupChatManager` object and provide the `GroupChat` object as input. We also need to specify the `llm_config` of the Group Chat Manager so it can use the LLM to select the next agent (the `auto` strategy).
Copy
```
from autogen import GroupChatManager
group_chat_manager = GroupChatManager(
  groupchat=group_chat,
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)

```

Finally, we have the Number Agent from before to start a two-agent chat with the Group Chat Manager, which runs the group chat internally and terminates the two-agent chat when the internal group chat is done. Because the Number Agent is selected to speak by us, it counts as the first round of the group chat.
Copy
```
chat_result = number_agent.initiate_chat(
  group_chat_manager,
  message="My number is 3, I want to turn it into 13.",
  summary_method="reflection_with_llm",
)

```

Copy
```
Number_Agent (to chat_manager):
My number is 3, I want to turn it into 13.
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
6
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
14
--------------------------------------------------------------------------------
Subtracter_Agent (to chat_manager):
13
--------------------------------------------------------------------------------
Number_Agent (to chat_manager):
13
--------------------------------------------------------------------------------

```

You can see that the Number Agent is selected to speak first, then the Group Chat Manager selects the Multiplier Agent to speak, then the Adder Agent, and so on. The number is operated upon by each agent in the group chat, and the final result is 13.
We can take a look at the summary of the group chat, provided by the `ChatResult` object returned by the `initiate_chat` method.
Copy
```
print(chat_result.summary)

```

Copy
```
The agents cooperatively manipulated the initial number (3) through multipliying, adding, and subtracting operations to reach the target number (13).

```

### 
[​](https://docs.ag2.ai/docs/tutorial/<#send-introductions>)
Send Introductions
In the previous example, we set the `description` of the agents to help the Group Chat Manager select the next agent. This only helps the Group Chat Manager, however, does not help the participating agents to know about each other. Sometimes it is useful have each agent introduce themselves to other agents in the group chat. This can be done by setting the `send_introductions=True`.
Copy
```
group_chat_with_introductions = GroupChat(
  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],
  messages=[],
  max_round=6,
  send_introductions=True,
)

```

Under the hood, the Group Chat Manager sends a message containing the agents’ names and descriptions to all agents in the group chat before the group chat starts.
### 
[​](https://docs.ag2.ai/docs/tutorial/<#group-chat-in-a-sequential-chat>)
Group Chat in a Sequential Chat
Group chat can also be used as a part of a sequential chat. In this case, the Group Chat Manager is treated as a regular agent in the sequence of two-agent chats.
Copy
```
# Let's use the group chat with introduction messages created above.
group_chat_manager_with_intros = GroupChatManager(
  groupchat=group_chat_with_introductions,
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)
# Start a sequence of two-agent chats between the number agent and
# the group chat manager.
chat_result = number_agent.initiate_chats(
  [
    {
      "recipient": group_chat_manager_with_intros,
      "message": "My number is 3, I want to turn it into 13.",
    },
    {
      "recipient": group_chat_manager_with_intros,
      "message": "Turn this number to 32.",
    },
  ]
)

```

Copy
```

********************************************************************************
Start a new chat with the following message: 
My number is 3, I want to turn it into 13.
With the following carryover: 

********************************************************************************
Number_Agent (to chat_manager):
My number is 3, I want to turn it into 13.
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
6
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
14
--------------------------------------------------------------------------------
Subtracter_Agent (to chat_manager):
13
--------------------------------------------------------------------------------
Number_Agent (to chat_manager):
Your number is 13.
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
Turn this number to 32.
With the following carryover: 
Your number is 13.
********************************************************************************
Number_Agent (to chat_manager):
Turn this number to 32.
Context: 
Your number is 13.
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
26
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
14
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
28
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
15
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
30
--------------------------------------------------------------------------------

```

Copy
```
/Users/ekzhu/autogen/autogen/agentchat/chat.py:46: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.
 warnings.warn(

```

In the above example, the Group Chat Manager runs the group chat two times. In the first time the number 3 becomes 13, and the last message of this group chat is being used as the carryover for the next group chat, which starts from 13.
You can also see from the warning message that the Group Chat Manager’s history is being cleared after the first group chat, which is the default. To keep the history of the Group Chat Manager, you can set the `clear_history=False` for the first chat.
### 
[​](https://docs.ag2.ai/docs/tutorial/<#constrained-speaker-selection>)
Constrained Speaker Selection
Group chat is a powerful conversation pattern, but it can be hard to control if the number of participating agents is large. AutoGen provides a way to constrain the selection of the next speaker by using the `allowed_or_disallowed_speaker_transitions` argument of the `GroupChat` class.
The `allowed_or_disallowed_speaker_transitions` argument is a dictionary that maps a given agent to a list of agents that can (or cannot) be selected to speak next. The `speaker_transitions_type` argument specifies whether the transitions are allowed or disallowed.
Here is an example:
Copy
```
allowed_transitions = {
  number_agent: [adder_agent, number_agent],
  adder_agent: [multiplier_agent, number_agent],
  subtracter_agent: [divider_agent, number_agent],
  multiplier_agent: [subtracter_agent, number_agent],
  divider_agent: [adder_agent, number_agent],
}

```

In this example, the allowed transitions are specified for each agent. The Number Agent can be followed by the Adder Agent and the Number Agent, the Adder Agent can be followed by the Multiplier Agent and the Number Agent, and so on. Let’s put this into the group chat and see how it works. The `speaker_transitions_type` is set to `allowed` so the transitions are positive constraints.
Copy
```
constrained_graph_chat = GroupChat(
  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],
  allowed_or_disallowed_speaker_transitions=allowed_transitions,
  speaker_transitions_type="allowed",
  messages=[],
  max_round=12,
  send_introductions=True,
)
constrained_group_chat_manager = GroupChatManager(
  groupchat=constrained_graph_chat,
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
)
chat_result = number_agent.initiate_chat(
  constrained_group_chat_manager,
  message="My number is 3, I want to turn it into 10. Once I get to 10, keep it there.",
  summary_method="reflection_with_llm",
)

```

Copy
```
Number_Agent (to chat_manager):
My number is 3, I want to turn it into 10. Once I get to 10, keep it there.
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
4
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
8
--------------------------------------------------------------------------------
Subtracter_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
Divider_Agent (to chat_manager):
3.5
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
4.5
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
9
--------------------------------------------------------------------------------
Subtracter_Agent (to chat_manager):
8
--------------------------------------------------------------------------------
Divider_Agent (to chat_manager):
4
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
5
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
10
--------------------------------------------------------------------------------
Number_Agent (to chat_manager):
10
--------------------------------------------------------------------------------

```

This time, the agents are selected following the constraints we have specified.
### 
[​](https://docs.ag2.ai/docs/tutorial/<#changing-the-select-speaker-role-name>)
Changing the select speaker role name
As part of the Group chat process, when the select_speaker_method is set to ‘auto’ (the default value), a select speaker message is sent to the LLM to determine the next speaker.
Each message in the chat sequence has a `role` attribute that is typically `user`, `assistant`, or `system`. The select speaker message is the last in the chat sequence when used and, by default, has a role of `system`.
When using some models, such as Mistral through Mistral.AI’s API, the role on the last message in the chat sequence has to be `user`.
To change the default behaviour, Autogen provides a way to set the value of the select speaker message’s role to any string value by setting the `role_for_select_speaker_messages` parameter in the GroupChat’s constructor. The default value is `system` and by setting it to `user` you can accommodate the last message role requirement of Mistral.AI’s API.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#nested-chats>)
Nested Chats
The previous conversations patterns (two-agent chat, sequential chat, and group chat) are useful for building complex workflows, however, they do not expose a single conversational interface, which is often needed for scenarios like question-answering bots and personal assistants. In some other cases, it is also useful to package a workflow into a single agent for reuse in a larger workflow. AutoGen provides a way to achieve this by using nested chats.
Nested chats is powered by the nested chats handler, which is a pluggable component of `ConversableAgent`. The figure below illustrates how the nested chats handler triggers a sequence of nested chats when a message is received.
![nested_chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/nested-chats.png)
When a message comes in and passes the [human-in-the-loop component](https://docs.ag2.ai/docs/tutorial/<./human-in-the-loop>), the nested chats handler checks if the message should trigger a nested chat based on conditions specified by the user. If the conditions are met, the nested chats handler starts a sequence of nested chats specified using the sequential chats pattern. In each of the nested chats, the sender agent is always the same agent that triggered the nested chats. In the end, the nested chat handler uses the results of the nested chats to produce a response to the original message. By default, the nested chat handler uses the summary of the last chat as the response.
Here is an example of using nested chats to build an arithmetic agent that packages arithmetic operations, code-based validation, and poetry into a single agent. This arithmetic agent takes a number transformation request like “turn number 3 into 13” and returns a poem that describes a transformation attempt.
First we define the agents. We reuse the `group_chat_manager_with_intros` from previous example to orchestrate the arithmetic operations.
Copy
```
import tempfile
temp_dir = tempfile.gettempdir()
arithmetic_agent = ConversableAgent(
  name="Arithmetic_Agent",
  llm_config=False,
  human_input_mode="ALWAYS",
  # This agent will always require human input to make sure the code is
  # safe to execute.
  code_execution_config={"use_docker": False, "work_dir": temp_dir},
)
code_writer_agent = ConversableAgent(
  name="Code_Writer_Agent",
  system_message="You are a code writer. You write Python script in Markdown code blocks.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)
poetry_agent = ConversableAgent(
  name="Poetry_Agent",
  system_message="You are an AI poet.",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  human_input_mode="NEVER",
)

```

Now we define the nested chats using the sequential chat pattern. All the senders are always `artihmetic_agent`.
Copy
```
nested_chats = [
  {
    "recipient": group_chat_manager_with_intros,
    "summary_method": "reflection_with_llm",
    "summary_prompt": "Summarize the sequence of operations used to turn the source number into target number.",
  },
  {
    "recipient": code_writer_agent,
    "message": "Write a Python script to verify the arithmetic operations is correct.",
    "summary_method": "reflection_with_llm",
  },
  {
    "recipient": poetry_agent,
    "message": "Write a poem about it.",
    "max_turns": 1,
    "summary_method": "last_msg",
  },
]

```

Now we register the nested chats handler to the `arithmetic_agent` and set the conditions for triggering the nested chats.
Copy
```
arithmetic_agent.register_nested_chats(
  nested_chats,
  # The trigger function is used to determine if the agent should start the nested chat
  # given the sender agent.
  # In this case, the arithmetic agent will not start the nested chats if the sender is
  # from the nested chats' recipient to avoid recursive calls.
  trigger=lambda sender: sender not in [group_chat_manager_with_intros, code_writer_agent, poetry_agent],
)

```

Finally, we call `generate_reply` to get a response from the `arithmetic_agent` – this will trigger a sequence of nested chats and return the summary of the last nested chat as the response.
Copy
```
# Instead of using `initiate_chat` method to start another conversation,
# we can use the `generate_reply` method to get single reply to a message directly.
reply = arithmetic_agent.generate_reply(
  messages=[{"role": "user", "content": "I have a number 3 and I want to turn it into 7."}]
)

```

Copy
```

>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
********************************************************************************
Start a new chat with the following message: 
I have a number 3 and I want to turn it into 7.
With the following carryover: 

********************************************************************************
Arithmetic_Agent (to chat_manager):
I have a number 3 and I want to turn it into 7.
--------------------------------------------------------------------------------
Adder_Agent (to chat_manager):
To give you the result, I'll add 1 to the number you gave me. So your new number is 4.
--------------------------------------------------------------------------------
Multiplier_Agent (to chat_manager):
8
--------------------------------------------------------------------------------
Subtracter_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
Number_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
Number_Agent (to chat_manager):
7
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
Write a Python script to verify the arithmetic operations is correct.
With the following carryover: 
First, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.
********************************************************************************
Arithmetic_Agent (to Code_Writer_Agent):
Write a Python script to verify the arithmetic operations is correct.
Context: 
First, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.
--------------------------------------------------------------------------------
Code_Writer_Agent (to Arithmetic_Agent):
Here is a Python script to verify the aforementioned arithmetic operations:
```python
# defining the initial value
initial_number = 3
# Adding 1 to initial number
initial_number += 1
assert initial_number == 4, "The first operation failed!"
# Multiplying the result by 2
initial_number *= 2
assert initial_number == 8, "The second operation failed!"
# Subtracting 1 from the result
initial_number -= 1
assert initial_number == 7, "The final operation failed!"
print("All operations were carried out successfully!")
```
In the script, the entire process is broken down into steps. The `assert` function is used to verify the result at every step. If any of the operations doesn't yield the expected result, an `AssertionError` exception will be raised. If all operations pass, the message "All operations were carried out successfully!" will be printed.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
Arithmetic_Agent (to Code_Writer_Agent):
exitcode: 0 (execution succeeded)
Code output: 
All operations were carried out successfully!

--------------------------------------------------------------------------------
Code_Writer_Agent (to Arithmetic_Agent):
Certainly, that means the python script was successful and every arithmetic operation performed correctly given the initial input and the steps performed.
--------------------------------------------------------------------------------
********************************************************************************
Start a new chat with the following message: 
Write a poem about it.
With the following carryover: 
First, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.
The Python script successfully performed and verified the arithmetic operations on the initial number provided. The steps included adding 1 to the initial number, multiplying the result by 2, and finally subtracting 1. The assert function was used to check the result at each step, and confirmed that all operations were carried out correctly.
********************************************************************************
Arithmetic_Agent (to Poetry_Agent):
Write a poem about it.
Context: 
First, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.
The Python script successfully performed and verified the arithmetic operations on the initial number provided. The steps included adding 1 to the initial number, multiplying the result by 2, and finally subtracting 1. The assert function was used to check the result at each step, and confirmed that all operations were carried out correctly.
--------------------------------------------------------------------------------
Poetry_Agent (to Arithmetic_Agent):
From numbers, logic, pure mathematical creation,
Ponder this tale of numeric manipulation.
In the universe of Python where operations exist,
A story of integers and functions persist.
Three was the number from where we began,
Oblivious to the journey and its grandiosely plan.
Added with 1, the sum it adorned,
A sweet quadruple in the dawn was formed.
The saga continued with a twist of the tale,
The four was multiplied, while the winds wail.
The duo of four unfolded its wings,
An octet presence in our midst it brings.
Then enters subtraction, sly and clever,
Removing one to alter the endeavor.
From eight, subtracted one in delight,
To finally bask in the glow of seven's light.
Each operation, together they conspired,
In this tale of integers, creatively inspired.
Through life's equation, the script ran so free,
Amidst the language of Python, a symphony, you see.
Tested with assert, cross-checked the chain,
Confirming accuracy in program's domain.
Each move calculated, each step so right,
In the maze of coding, found was the light. 
Such is the tale, of numbers and operations, 
A dance among digits, logical iterations,
Just another day, in this AI poet's life,
Cutting through ambiguity, like a razor-sharp knife.
--------------------------------------------------------------------------------

```

A poem is returned as the response, which describes the transformation attempt from 3 to 7.
The implementation of the nested chats handler makes use of the `register_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>) method, which allows you to make extensive customization to `ConversableAgent`. The GroupChatManager uses the same mechanism to implement the group chat.
Nested chat is a powerful conversation pattern that allows you to package complex workflows into a single agent. You can hide [tool usages](https://docs.ag2.ai/docs/tutorial/docs/tutorial/tool-use>) within a single agent by having the tool-caller agent starts a nested chat with a tool-executor agent and then use the result of the nested chat to generate a response. See the [nested chats for tool use notebook](https://docs.ag2.ai/docs/tutorial/notebooks/agentchat_nested_chats_chess>) for an example.
## 
[​](https://docs.ag2.ai/docs/tutorial/<#summary>)
Summary
In this chapter, we covered two-agent chat, sequential chat, group chat, and nested chat patterns. You can compose these patterns like LEGO blocks to create complex workflows. You can also use `register_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>) to create new patterns.
This is the last chapter on basic AutoGen concepts. In the next chatper, we will give you some tips on what to do next.
[Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)[What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [An Overview](https://docs.ag2.ai/docs/tutorial/<#an-overview>)
  * [Two-Agent Chat and Chat Result](https://docs.ag2.ai/docs/tutorial/<#two-agent-chat-and-chat-result>)
  * [Sequential Chats](https://docs.ag2.ai/docs/tutorial/<#sequential-chats>)
  * [Group Chat](https://docs.ag2.ai/docs/tutorial/<#group-chat>)
  * [Send Introductions](https://docs.ag2.ai/docs/tutorial/<#send-introductions>)
  * [Group Chat in a Sequential Chat](https://docs.ag2.ai/docs/tutorial/<#group-chat-in-a-sequential-chat>)
  * [Constrained Speaker Selection](https://docs.ag2.ai/docs/tutorial/<#constrained-speaker-selection>)
  * [Changing the select speaker role name](https://docs.ag2.ai/docs/tutorial/<#changing-the-select-speaker-role-name>)
  * [Nested Chats](https://docs.ag2.ai/docs/tutorial/<#nested-chats>)
  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)

---

# What Next?
URL: https://docs.ag2.ai/docs/tutorial/what-next

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)


Navigation
Tutorials
What Next?
[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)


Tutorials
# What Next?
Now that you have learned the basics of AutoGen, you can start to build your own agents. Here are some ideas to get you started without going to the advanced topics:
  1. **Chat with LLMs** : In [Human in the Loop](https://docs.ag2.ai/docs/tutorial/<./human-in-the-loop>) we covered the basic human-in-the-loop usage. You can try to hook up different LLMs using local model servers like [Ollama](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ollama/ollama>) and [LM Studio](https://docs.ag2.ai/docs/tutorial/<https:/lmstudio.ai/>), and chat with them using the human-in-the-loop component of your human proxy agent.
  2. **Prompt Engineering** : In [Code Executors](https://docs.ag2.ai/docs/tutorial/<./code-executors>) we covered the simple two agent scenario using GPT-4 and Python code executor. To make this scenario work for different LLMs and programming languages, you probably need to tune the system message of the code writer agent. Same with other scenarios that we have covered in this tutorial, you can also try to tune system messages for different LLMs.
  3. **Complex Tasks** : In [ConversationPatterns](https://docs.ag2.ai/docs/tutorial/<./conversation-patterns>) we covered the basic conversation patterns. You can try to find other tasks that can be decomposed into these patterns, and leverage the code executors and tools to make the agents more powerful.


## 
[​](https://docs.ag2.ai/docs/tutorial/<#dig-deeper>)
Dig Deeper
  * Read the [user guide](https://docs.ag2.ai/docs/tutorial/</docs/topics>) to learn more
  * Read the examples and guides in the [notebooks section](https://docs.ag2.ai/docs/tutorial/</notebooks>)
  * Check [research](https://docs.ag2.ai/docs/tutorial/</docs/Research>) and [blog](https://docs.ag2.ai/docs/tutorial/</blog>)


## 
[​](https://docs.ag2.ai/docs/tutorial/<#get-help>)
Get Help
If you have any questions, you can ask in our [Discord Server](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>).
[![](https://img.shields.io/discord/1153072414184452236?logo=discord&style=flat.png)](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)
## 
[​](https://docs.ag2.ai/docs/tutorial/<#get-involved>)
Get Involved
  * Check out [Roadmap Issues](https://docs.ag2.ai/docs/tutorial/<https:/ag2ai.com/roadmap>) to see what we are working on.
  * Contribute your work to our [gallery](https://docs.ag2.ai/docs/tutorial/</docs/Gallery>)
  * Follow our [contribution guide](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>) to make a pull request to AutoGen
  * You can also share your work with the community on the Discord server.


[Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)[Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)
[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Dig Deeper](https://docs.ag2.ai/docs/tutorial/<#dig-deeper>)
  * [Get Help](https://docs.ag2.ai/docs/tutorial/<#get-help>)
  * [Get Involved](https://docs.ag2.ai/docs/tutorial/<#get-involved>)

---

# Multi-agent Conversation Framework
URL: https://docs.ag2.ai/docs/Use-Cases/agent_chat

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)


Navigation
Use Cases
Multi-agent Conversation Framework
[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)


Use Cases
# Multi-agent Conversation Framework
AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLMs, tools, and humans via automated agent chat. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.
This framework simplifies the orchestration, automation and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#agents>)
Agents
AutoGen abstracts and implements conversable agents designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following notable features:
  * Conversable: Agents in AutoGen are conversable, which means that any agent can send and receive messages from other agents to initiate or continue a conversation
  * Customizable: Agents in AutoGen can be customized to integrate LLMs, humans, tools, or a combination of them.


The figure below shows the built-in agents in AutoGen. ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/autogen_agents.png)
We have designed a generic `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) class for Agents that are capable of conversing with each other through the exchange of messages to jointly finish a task. An agent can communicate with other agents and perform actions. Different agents can differ in what actions they perform after receiving messages. Two representative subclasses are `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) and `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>)
  * The `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) is designed to act as an AI assistant, using LLMs by default but not requiring human input or code execution. It could write Python code (in a Python coding block) for a user to execute when a message (typically a description of a task that needs to be solved) is received. Under the hood, the Python code is written by LLM (e.g., GPT-4). It can also receive the execution results and suggest corrections or bug fixes. Its behavior can be altered by passing a new system message. The LLM [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration can be configured via [`llm_config`].
  * The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) is conceptually a proxy agent for humans, soliciting human input as the agent’s reply at each interaction turn by default and also having the capability to execute code and call functions or tools. The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) triggers code execution automatically when it detects an executable code block in the received message and no human user input is provided. Code execution can be disabled by setting the `code_execution_config` parameter to False. LLM-based response is disabled by default. It can be enabled by setting `llm_config` to a dict corresponding to the [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration. When `llm_config` is set as a dictionary, `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) can generate replies using an LLM when code execution is not performed.


The auto-reply capability of `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) allows for more autonomous multi-agent communication while retaining the possibility of human intervention. One can also easily extend it by registering reply functions with the `register_reply()`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#register-reply>) method.
In the following code, we create an `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) named “assistant” to serve as the assistant and a `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) named “user_proxy” to serve as a proxy for the human user. We will later employ these two agents to solve a task.
Copy
```
import os
from autogen import AssistantAgent, UserProxyAgent
from autogen.coding import DockerCommandLineCodeExecutor
config_list = [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]
# create an AssistantAgent instance named "assistant" with the LLM configuration.
assistant = AssistantAgent(name="assistant", llm_config={"config_list": config_list})
# create a UserProxyAgent instance named "user_proxy" with code execution on docker.
code_executor = DockerCommandLineCodeExecutor()
user_proxy = UserProxyAgent(name="user_proxy", code_execution_config={"executor": code_executor})

```

## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)
Multi-agent Conversations
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)
A Basic Two-Agent Conversation Example
Once the participating agents are constructed properly, one can start a multi-agent conversation session by an initialization step as shown in the following code:
Copy
```
# the assistant receives a message from the user, which contains the task description
user_proxy.initiate_chat(
  assistant,
  message="""What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?""",
)

```

After the initialization step, the conversation could proceed automatically. Find a visual illustration of how the user_proxy and assistant collaboratively solve the above task autonomously below: ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/agent_example.png)
  1. The assistant receives a message from the user_proxy, which contains the task description.
  2. The assistant then tries to write Python code to solve the task and sends the response to the user_proxy.
  3. Once the user_proxy receives a response from the assistant, it tries to reply by either soliciting human input or preparing an automatically generated reply. If no human input is provided, the user_proxy executes the code and uses the result as the auto-reply.
  4. The assistant then generates a further response for the user_proxy. The user_proxy can then decide whether to terminate the conversation. If not, steps 3 and 4 are repeated.


### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)
Supporting Diverse Conversation Patterns
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)
Conversations with different levels of autonomy, and human-involvement patterns
On the one hand, one can achieve fully autonomous conversations after an initialization step. On the other hand, AutoGen can be used to implement human-in-the-loop problem-solving by configuring human involvement levels and patterns (e.g., setting the `human_input_mode` to `ALWAYS`), as human involvement is expected and/or desired in many applications.
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)
Static and dynamic conversations
AutoGen, by integrating conversation-driven control utilizing both programming and natural language, inherently supports dynamic conversations. This dynamic nature allows the agent topology to adapt based on the actual conversation flow under varying input problem scenarios. Conversely, static conversations adhere to a predefined topology. Dynamic conversations are particularly beneficial in complex settings where interaction patterns cannot be predetermined.
  1. Registered auto-reply


With the pluggable auto-reply function, one can choose to invoke conversations with other agents depending on the content of the current message and context. For example:
  * Hierarchical chat like in [OptiGuide](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nestedchat_optiguide.ipynb>).
  * [Dynamic Group Chat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat.ipynb>) which is a special form of hierarchical chat. In the system, we register a reply function in the group chat manager, which broadcasts messages and decides who the next speaker will be in a group chat setting.
  * [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/Use-Cases/<https:/docs.ag2.ai/notebooks/agentchat_groupchat_finite_state_machine>) which is a special form of dynamic group chat. In this approach, a directed transition matrix is fed into group chat. Users can specify legal transitions or specify disallowed transitions.
  * Nested chat like in [conversational chess](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nested_chats_chess.ipynb>).


  1. LLM-Based Function Call


Another approach involves LLM-based function calls, where LLM decides if a specific function should be invoked based on the conversation’s status during each inference. This approach enables dynamic multi-agent conversations, as seen in scenarios like [multi-user math problem solving scenario](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_two_users.ipynb>), where a student assistant automatically seeks expertise via function calls.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)
Diverse Applications Implemented with AutoGen
The figure below shows six examples of applications built using AutoGen. ![Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/app.png)
Find a list of examples in this page: [Automated Agent Chat Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#automated-multi-agent-chat>)
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)
For Further Reading
_Interested in the research that leads to this package? Please check the following papers._
  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.
  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).


[What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)[Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)
[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Agents](https://docs.ag2.ai/docs/Use-Cases/<#agents>)
  * [Multi-agent Conversations](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)
  * [A Basic Two-Agent Conversation Example](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)
  * [Supporting Diverse Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)
  * [Conversations with different levels of autonomy, and human-involvement patterns](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)
  * [Static and dynamic conversations](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)
  * [Diverse Applications Implemented with AutoGen](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)
  * [For Further Reading](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)

---

# Enhanced Inference
URL: https://docs.ag2.ai/docs/Use-Cases/enhanced_inference

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)


Navigation
Use Cases
Enhanced Inference
[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)


Use Cases
# Enhanced Inference
`autogen.OpenAIWrapper` provides enhanced LLM inference for `openai>=1`. `autogen.Completion` is a drop-in replacement of `openai.Completion` and `openai.ChatCompletion` for enhanced LLM inference using `openai<1`. There are a number of benefits of using `autogen` to perform inference: performance tuning, API unification, caching, error handling, multi-config inference, result filtering, templating and so on.
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#tune-inference-parameters-for-openai1>)
Tune Inference Parameters (for openai<1)
Find a list of examples in this page: [Tune Inference Parameters Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#inference-hyperparameters-tuning>)
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#choices-to-optimize>)
Choices to optimize
The cost of using foundation models for text generation is typically measured in terms of the number of tokens in the input and output combined. From the perspective of an application builder using foundation models, the use case is to maximize the utility of the generated text under an inference budget constraint (e.g., measured by the average dollar cost needed to solve a coding problem). This can be achieved by optimizing the hyperparameters of the inference, which can significantly affect both the utility and the cost of the generated text.
The tunable hyperparameters include:
  1. model - this is a required input, specifying the model ID to use.
  2. prompt/messages - the input prompt/messages to the model, which provides the context for the text generation task.
  3. max_tokens - the maximum number of tokens (words or word pieces) to generate in the output.
  4. temperature - a value between 0 and 1 that controls the randomness of the generated text. A higher temperature will result in more random and diverse text, while a lower temperature will result in more predictable text.
  5. top_p - a value between 0 and 1 that controls the sampling probability mass for each token generation. A lower top_p value will make it more likely to generate text based on the most likely tokens, while a higher value will allow the model to explore a wider range of possible tokens.
  6. n - the number of responses to generate for a given prompt. Generating multiple responses can provide more diverse and potentially more useful output, but it also increases the cost of the request.
  7. stop - a list of strings that, when encountered in the generated text, will cause the generation to stop. This can be used to control the length or the validity of the output.
  8. presence_penalty, frequency_penalty - values that control the relative importance of the presence and frequency of certain words or phrases in the generated text.
  9. best_of - the number of responses to generate server-side when selecting the “best” (the one with the highest log probability per token) response for a given prompt.


The cost and utility of text generation are intertwined with the joint effect of these hyperparameters. There are also complex interactions among subsets of the hyperparameters. For example, the temperature and top_p are not recommended to be altered from their default values together because they both control the randomness of the generated text, and changing both at the same time can result in conflicting effects; n and best_of are rarely tuned together because if the application can process multiple outputs, filtering on the server side causes unnecessary information loss; both n and max_tokens will affect the total number of tokens generated, which in turn will affect the cost of the request. These interactions and trade-offs make it difficult to manually determine the optimal hyperparameter settings for a given text generation task.
_Do the choices matter? Check this[blogpost](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-04-21-LLM-tuning-math>) to find example tuning results about gpt-3.5-turbo and gpt-4._
With AutoGen, the tuning can be performed with the following information:
  1. Validation data.
  2. Evaluation function.
  3. Metric to optimize.
  4. Search space.
  5. Budgets: inference and optimization respectively.


### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#validation-data>)
Validation data
Collect a diverse set of instances. They can be stored in an iterable of dicts. For example, each instance dict can contain “problem” as a key and the description str of a math problem as the value; and “solution” as a key and the solution str as the value.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#evaluation-function>)
Evaluation function
The evaluation function should take a list of responses, and other keyword arguments corresponding to the keys in each validation data instance as input, and output a dict of metrics. For example,
Copy
```
def eval_math_responses(responses: List[str], solution: str, **args) -> Dict:
  # select a response from the list of responses
  answer = voted_answer(responses)
  # check whether the answer is correct
  return {"success": is_equivalent(answer, solution)}

```

`autogen.code_utils` and `autogen.math_utils` offer some example evaluation functions for code generation and math problem solving.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#metric-to-optimize>)
Metric to optimize
The metric to optimize is usually an aggregated metric over all the tuning data instances. For example, users can specify “success” as the metric and “max” as the optimization mode. By default, the aggregation function is taking the average. Users can provide a customized aggregation function if needed.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#search-space>)
Search space
Users can specify the (optional) search range for each hyperparameter.
  1. model. Either a constant str, or multiple choices specified by `flaml.tune.choice`.
  2. prompt/messages. Prompt is either a str or a list of strs, of the prompt templates. messages is a list of dicts or a list of lists, of the message templates. Each prompt/message template will be formatted with each data instance. For example, the prompt template can be: “{problem} Solve the problem carefully. Simplify your answer as much as possible. Put the final answer in \boxed{{}}.” And `{problem}` will be replaced by the “problem” field of each data instance.
  3. max_tokens, n, best_of. They can be constants, or specified by `flaml.tune.randint`, `flaml.tune.qrandint`, `flaml.tune.lograndint` or `flaml.qlograndint`. By default, max_tokens is searched in [50, 1000); n is searched in [1, 100); and best_of is fixed to 1.
  4. stop. It can be a str or a list of strs, or a list of lists of strs or None. Default is None.
  5. temperature or top_p. One of them can be specified as a constant or by `flaml.tune.uniform` or `flaml.tune.loguniform` etc. Please don’t provide both. By default, each configuration will choose either a temperature or a top_p in [0, 1] uniformly.
  6. presence_penalty, frequency_penalty. They can be constants or specified by `flaml.tune.uniform` etc. Not tuned by default.


### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#budgets>)
Budgets
One can specify an inference budget and an optimization budget. The inference budget refers to the average inference cost per data instance. The optimization budget refers to the total budget allowed in the tuning process. Both are measured by dollars and follow the price per 1000 tokens.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#perform-tuning>)
Perform tuning
Now, you can use `autogen.Completion.tune` for tuning. For example,
Copy
```
import autogen
config, analysis = autogen.Completion.tune(
  data=tune_data,
  metric="success",
  mode="max",
  eval_func=eval_func,
  inference_budget=0.05,
  optimization_budget=3,
  num_samples=-1,
)

```

`num_samples` is the number of configurations to sample. -1 means unlimited (until optimization budget is exhausted). The returned `config` contains the optimized configuration and `analysis` contains an ExperimentAnalysis object for all the tried configurations and results.
The tuned config can be used to perform inference.
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#api-unification>)
API unification
`autogen.OpenAIWrapper.create()` can be used to create completions for both chat and non-chat models, and both OpenAI API and Azure OpenAI API.
Copy
```
from autogen import OpenAIWrapper
# OpenAI endpoint
client = OpenAIWrapper()
# ChatCompletion
response = client.create(messages=[{"role": "user", "content": "2+2="}], model="gpt-3.5-turbo")
# extract the response text
print(client.extract_text_or_completion_object(response))
# get cost of this completion
print(response.cost)
# Azure OpenAI endpoint
client = OpenAIWrapper(api_key=..., base_url=..., api_version=..., api_type="azure")
# Completion
response = client.create(prompt="2+2=", model="gpt-3.5-turbo-instruct")
# extract the response text
print(client.extract_text_or_completion_object(response))

```

For local LLMs, one can spin up an endpoint using a package like [FastChat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/lm-sys/FastChat>), and then use the same API to send a request. See [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-07-14-Local-LLMs>) for examples on how to make inference with local LLMs.
For custom model clients, one can register the client with `autogen.OpenAIWrapper.register_model_client` and then use the same API to send a request. See [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2024-01-26-Custom-Models>) for examples on how to make inference with custom model clients.
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#usage-summary>)
Usage Summary
The `OpenAIWrapper` from `autogen` tracks token counts and costs of your API calls. Use the `create()` method to initiate requests and `print_usage_summary()` to retrieve a detailed usage report, including total cost and token usage for both cached and actual requests.
  * `mode=["actual", "total"]` (default): print usage summary for all completions and non-caching completions.
  * `mode='actual'`: only print non-cached usage.
  * `mode='total'`: only print all usage (including cache).


Reset your session’s usage data with `clear_usage_summary()` when needed. [View Notebook](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_cost_token_tracking.ipynb>)
Example usage:
Copy
```
from autogen import OpenAIWrapper
client = OpenAIWrapper()
client.create(messages=[{"role": "user", "content": "Python learning tips."}], model="gpt-3.5-turbo")
client.print_usage_summary() # Display usage
client.clear_usage_summary() # Reset usage data

```

Sample output:
Copy
```
Usage summary excluding cached usage:
Total cost: 0.00015
* Model 'gpt-3.5-turbo': cost: 0.00015, prompt_tokens: 25, completion_tokens: 58, total_tokens: 83
Usage summary including cached usage:
Total cost: 0.00027
* Model 'gpt-3.5-turbo': cost: 0.00027, prompt_tokens: 50, completion_tokens: 100, total_tokens: 150

```

Note: if using a custom model client (see [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2024-01-26-Custom-Models>) for details) and if usage summary is not implemented, then the usage summary will not be available.
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#caching>)
Caching
Moved to [here](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>).
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#error-handling>)
Error handling
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#runtime-error>)
Runtime error
One can pass a list of configurations of different models/endpoints to mitigate the rate limits and other runtime error. For example,
Copy
```
client = OpenAIWrapper(
  config_list=[
    {
      "model": "gpt-4",
      "api_key": os.environ.get("AZURE_OPENAI_API_KEY"),
      "api_type": "azure",
      "base_url": os.environ.get("AZURE_OPENAI_API_BASE"),
      "api_version": "2024-02-01",
    },
    {
      "model": "gpt-3.5-turbo",
      "api_key": os.environ.get("OPENAI_API_KEY"),
      "base_url": "https://api.openai.com/v1",
    },
    {
      "model": "llama2-chat-7B",
      "base_url": "http://127.0.0.1:8080",
    },
    {
      "model": "microsoft/phi-2",
      "model_client_cls": "CustomModelClient"
    }
  ],
)

```

`client.create()` will try querying Azure OpenAI gpt-4, OpenAI gpt-3.5-turbo, a locally hosted llama2-chat-7B, and phi-2 using a custom model client class named `CustomModelClient`, one by one, until a valid result is returned. This can speed up the development process where the rate limit is a bottleneck. An error will be raised if the last choice fails. So make sure the last choice in the list has the best availability.
For convenience, we provide a number of utility functions to load config lists.
  * `get_config_list`: Generates configurations for API calls, primarily from provided API keys.
  * `config_list_openai_aoai`: Constructs a list of configurations using both Azure OpenAI and OpenAI endpoints, sourcing API keys from environment variables or local files.
  * `config_list_from_json`: Loads configurations from a JSON structure, either from an environment variable or a local JSON file, with the flexibility of filtering configurations based on given criteria.
  * `config_list_from_models`: Creates configurations based on a provided list of models, useful when targeting specific models without manually specifying each configuration.
  * `config_list_from_dotenv`: Constructs a configuration list from a `.env` file, offering a consolidated way to manage multiple API configurations and keys from a single file.


We suggest that you take a look at this [notebook](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>) for full code examples of the different methods to configure your model endpoints.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#logic-error>)
Logic error
Another type of error is that the returned response does not satisfy a requirement. For example, if the response is required to be a valid json string, one would like to filter the responses that are not. This can be achieved by providing a list of configurations and a filter function. For example,
Copy
```
def valid_json_filter(response, **_):
  for text in OpenAIWrapper.extract_text_or_completion_object(response):
    try:
      json.loads(text)
      return True
    except ValueError:
      pass
  return False
client = OpenAIWrapper(
  config_list=[{"model": "text-ada-001"}, {"model": "gpt-3.5-turbo-instruct"}, {"model": "text-davinci-003"}],
)
response = client.create(
  prompt="How to construct a json request to Bing API to search for 'latest AI news'? Return the JSON request.",
  filter_func=valid_json_filter,
)

```

The example above will try to use text-ada-001, gpt-3.5-turbo-instruct, and text-davinci-003 iteratively, until a valid json string is returned or the last config is used. One can also repeat the same model in the list for multiple times (with different seeds) to try one model multiple times for increasing the robustness of the final response.
_Advanced use case: Check this[blogpost](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-05-18-GPT-adaptive-humaneval/index>) to find how to improve GPT-4’s coding performance from 68% to 90% while reducing the inference cost._
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#templating>)
Templating
If the provided prompt or message is a template, it will be automatically materialized with a given context. For example,
Copy
```
response = client.create(
  context={"problem": "How many positive integers, not exceeding 100, are multiples of 2 or 3 but not 4?"},
  prompt="{problem} Solve the problem carefully.",
  allow_format_str_template=True,
  **config
)

```

A template is either a format str, like the example above, or a function which produces a str from several input fields, like the example below.
Copy
```
def content(turn, context):
  return "\n".join(
    [
      context[f"user_message_{turn}"],
      context[f"external_info_{turn}"]
    ]
  )
messages = [
  {
    "role": "system",
    "content": "You are a teaching assistant of math.",
  },
  {
    "role": "user",
    "content": partial(content, turn=0),
  },
]
context = {
  "user_message_0": "Could you explain the solution to Problem 1?",
  "external_info_0": "Problem 1: ...",
}
response = client.create(context=context, messages=messages, **config)
messages.append(
  {
    "role": "assistant",
    "content": client.extract_text(response)[0]
  }
)
messages.append(
  {
    "role": "user",
    "content": partial(content, turn=1),
  },
)
context.append(
  {
    "user_message_1": "Why can't we apply Theorem 1 to Equation (2)?",
    "external_info_1": "Theorem 1: ...",
  }
)
response = client.create(context=context, messages=messages, **config)

```

## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#logging>)
Logging
When debugging or diagnosing an LLM-based system, it is often convenient to log the API calls and analyze them.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1>)
For openai >= 1
Logging example: [View Notebook](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_logging.ipynb>)
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#start-logging>)
Start logging:
Copy
```
import autogen.runtime_logging
autogen.runtime_logging.start(logger_type="sqlite", config={"dbname": "YOUR_DB_NAME"})

```

`logger_type` and `config` are both optional. Default logger type is SQLite logger, that’s the only one available in autogen at the moment. If you want to customize the database name, you can pass in through config, default is `logs.db`.
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#stop-logging>)
Stop logging:
Copy
```
autogen.runtime_logging.stop()

```

#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#llm-runs>)
LLM Runs
AutoGen logging supports OpenAI’s llm message schema. Each LLM run is saved in `chat_completions` table includes:
  * session_id: an unique identifier for the logging session
  * invocation_id: an unique identifier for the logging record
  * client_id: an unique identifier for the Azure OpenAI/OpenAI client
  * request: detailed llm request, see below for an example
  * response: detailed llm response, see below for an example
  * cost: total cost for the request and response
  * start_time
  * end_time


##### Sample Request
Copy
```
{
 "messages":[
  {
   "content":"system_message_1",
   "role":"system"
  },
  {
   "content":"user_message_1",
   "role":"user"
  }
 ],
 "model":"gpt-4",
 "temperature": 0.9
}

```

##### Sample Response
Copy
```
{
 "id": "id_1",
 "choices": [
  {
   "finish_reason": "stop",
   "index": 0,
   "logprobs": null,
   "message": {
    "content": "assistant_message_1",
    "role": "assistant",
    "function_call": null,
    "tool_calls": null
   }
  }
 ],
 "created": "<timestamp>",
 "model": "gpt-4",
 "object": "chat.completion",
 "system_fingerprint": null,
 "usage": {
  "completion_tokens": 155,
  "prompt_tokens": 53,
  "total_tokens": 208
 }
}

```

Learn more about [request and response format](https://docs.ag2.ai/docs/Use-Cases/<https:/platform.openai.com/docs/api-reference/introduction/chat/create>)
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1-2>)
For openai < 1
`autogen.Completion` and `autogen.ChatCompletion` offer an easy way to collect the API call histories. For example, to log the chat histories, simply run:
Copy
```
autogen.ChatCompletion.start_logging()

```

The API calls made after this will be automatically logged. They can be retrieved at any time by:
Copy
```
autogen.ChatCompletion.logged_history

```

There is a function that can be used to print usage summary (total cost, and token count usage from each model):
Copy
```
autogen.ChatCompletion.print_usage_summary()

```

To stop logging, use
Copy
```
autogen.ChatCompletion.stop_logging()

```

If one would like to append the history to an existing dict, pass the dict like:
Copy
```
autogen.ChatCompletion.start_logging(history_dict=existing_history_dict)

```

By default, the counter of API calls will be reset at `start_logging()`. If no reset is desired, set `reset_counter=False`.
There are two types of logging formats: compact logging and individual API call logging. The default format is compact. Set `compact=False` in `start_logging()` to switch.
  * Example of a history dict with compact logging.


Copy
```
{
  """
  [
    {
      'role': 'system',
      'content': system_message,
    },
    {
      'role': 'user',
      'content': user_message_1,
    },
    {
      'role': 'assistant',
      'content': assistant_message_1,
    },
    {
      'role': 'user',
      'content': user_message_2,
    },
    {
      'role': 'assistant',
      'content': assistant_message_2,
    },
  ]""": {
    "created_at": [0, 1],
    "cost": [0.1, 0.2],
  }
}

```

  * Example of a history dict with individual API call logging.


Copy
```
{
  0: {
    "request": {
      "messages": [
        {
          "role": "system",
          "content": system_message,
        },
        {
          "role": "user",
          "content": user_message_1,
        }
      ],
      ... # other parameters in the request
    },
    "response": {
      "choices": [
        "messages": {
          "role": "assistant",
          "content": assistant_message_1,
        },
      ],
      ... # other fields in the response
    }
  },
  1: {
    "request": {
      "messages": [
        {
          "role": "system",
          "content": system_message,
        },
        {
          "role": "user",
          "content": user_message_1,
        },
        {
          "role": "assistant",
          "content": assistant_message_1,
        },
        {
          "role": "user",
          "content": user_message_2,
        },
      ],
      ... # other parameters in the request
    },
    "response": {
      "choices": [
        "messages": {
          "role": "assistant",
          "content": assistant_message_2,
        },
      ],
      ... # other fields in the response
    }
  },
}

```

  * Example of printing for usage summary


Copy
```
Total cost: <cost>
Token count summary for model <model>: prompt_tokens: <count 1>, completion_tokens: <count 2>, total_tokens: <count 3>

```

It can be seen that the individual API call history contains redundant information of the conversation. For a long conversation the degree of redundancy is high. The compact history is more efficient and the individual API call history contains more details.
[Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)[Command Line Code Executor](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/code-execution/cli-code-executor>)
[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Tune Inference Parameters (for openai1)](https://docs.ag2.ai/docs/Use-Cases/<#tune-inference-parameters-for-openai1>)
  * [Choices to optimize](https://docs.ag2.ai/docs/Use-Cases/<#choices-to-optimize>)
  * [Validation data](https://docs.ag2.ai/docs/Use-Cases/<#validation-data>)
  * [Evaluation function](https://docs.ag2.ai/docs/Use-Cases/<#evaluation-function>)
  * [Metric to optimize](https://docs.ag2.ai/docs/Use-Cases/<#metric-to-optimize>)
  * [Search space](https://docs.ag2.ai/docs/Use-Cases/<#search-space>)
  * [Budgets](https://docs.ag2.ai/docs/Use-Cases/<#budgets>)
  * [Perform tuning](https://docs.ag2.ai/docs/Use-Cases/<#perform-tuning>)
  * [API unification](https://docs.ag2.ai/docs/Use-Cases/<#api-unification>)
  * [Usage Summary](https://docs.ag2.ai/docs/Use-Cases/<#usage-summary>)
  * [Caching](https://docs.ag2.ai/docs/Use-Cases/<#caching>)
  * [Error handling](https://docs.ag2.ai/docs/Use-Cases/<#error-handling>)
  * [Runtime error](https://docs.ag2.ai/docs/Use-Cases/<#runtime-error>)
  * [Logic error](https://docs.ag2.ai/docs/Use-Cases/<#logic-error>)
  * [Templating](https://docs.ag2.ai/docs/Use-Cases/<#templating>)
  * [Logging](https://docs.ag2.ai/docs/Use-Cases/<#logging>)
  * [For openai >= 1](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1>)
  * [Start logging:](https://docs.ag2.ai/docs/Use-Cases/<#start-logging>)
  * [Stop logging:](https://docs.ag2.ai/docs/Use-Cases/<#stop-logging>)
  * [LLM Runs](https://docs.ag2.ai/docs/Use-Cases/<#llm-runs>)
  * [For openai < 1](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1-2>)

---

# LLM Caching
URL: https://docs.ag2.ai/docs/topics/llm-caching

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
LLM Caching
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# LLM Caching
AutoGen supports caching API requests so that they can be reused when the same request is issued. This is useful when repeating or continuing experiments for reproducibility and cost saving.
Since version `0.2.8`, a configurable context manager allows you to easily configure LLM cache, using either `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>), `RedisCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/redis_cache#rediscache>), or Cosmos DB Cache. All agents inside the context manager will use the same cache.
Copy
```
from autogen import Cache
# Use Redis as cache
with Cache.redis(redis_url="redis://localhost:6379/0") as cache:
  user.initiate_chat(assistant, message=coding_task, cache=cache)
# Use DiskCache as cache
with Cache.disk() as cache:
  user.initiate_chat(assistant, message=coding_task, cache=cache)
# Use Azure Cosmos DB as cache
with Cache.cosmos_db(connection_string="your_connection_string", database_id="your_database_id", container_id="your_container_id") as cache:
  user.initiate_chat(assistant, message=coding_task, cache=cache)

```

The cache can also be passed directly to the model client’s create call.
Copy
```
client = OpenAIWrapper(...)
with Cache.disk() as cache:
  client.create(..., cache=cache)

```

## 
[​](https://docs.ag2.ai/docs/topics/<#controlling-the-seed>)
Controlling the seed
You can vary the `cache_seed` parameter to get different LLM output while still using cache.
Copy
```
# Setting the cache_seed to 1 will use a different cache from the default one
# and you will see different output.
with Cache.disk(cache_seed=1) as cache:
  user.initiate_chat(assistant, message=coding_task, cache=cache)

```

## 
[​](https://docs.ag2.ai/docs/topics/<#cache-path>)
Cache path
By default `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>) uses `.cache` for storage. To change the cache directory, set `cache_path_root`:
Copy
```
with Cache.disk(cache_path_root="/tmp/autogen_cache") as cache:
  user.initiate_chat(assistant, message=coding_task, cache=cache)

```

## 
[​](https://docs.ag2.ai/docs/topics/<#disabling-cache>)
Disabling cache
For backward compatibility, `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>) is on by default with `cache_seed` set to 41. To disable caching completely, set `cache_seed` to `None` in the `llm_config` of the agent.
Copy
```
assistant = AssistantAgent(
  "coding_agent",
  llm_config={
    "cache_seed": None,
    "config_list": OAI_CONFIG_LIST,
    "max_tokens": 1024,
  },
)

```

## 
[​](https://docs.ag2.ai/docs/topics/<#difference-between-cache-seed-and-openais-seed-parameter>)
Difference between `cache_seed` and OpenAI’s `seed` parameter
OpenAI v1.1 introduced a new parameter `seed`. The difference between AutoGen’s `cache_seed` and OpenAI’s `seed` is AutoGen uses an explicit request cache to guarantee the exactly same output is produced for the same input and when cache is hit, no OpenAI API call will be made. OpenAI’s `seed` is a best-effort deterministic sampling with no guarantee of determinism. When using OpenAI’s `seed` with `cache_seed` set to `None`, even for the same input, an OpenAI API call will be made and there is no guarantee for getting exactly the same output.
[Introduction to Transform Messages](https://docs.ag2.ai/docs/topics/</docs/topics/handling_long_contexts/intro_to_transform_messages>)[Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Controlling the seed](https://docs.ag2.ai/docs/topics/<#controlling-the-seed>)
  * [Cache path](https://docs.ag2.ai/docs/topics/<#cache-path>)
  * [Disabling cache](https://docs.ag2.ai/docs/topics/<#disabling-cache>)
  * [Difference between cache_seed and OpenAI’s seed parameter](https://docs.ag2.ai/docs/topics/<#difference-between-cache-seed-and-openais-seed-parameter>)

---

# Agent Observability
URL: https://docs.ag2.ai/docs/topics/llm-observability

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
Agent Observability
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# Agent Observability
AutoGen supports advanced LLM agent observability and monitoring through built-in logging and partner providers.
## 
[​](https://docs.ag2.ai/docs/topics/<#autogen-observability-integrations>)
AutoGen Observability Integrations
### 
[​](https://docs.ag2.ai/docs/topics/<#built-in-logging>)
Built-In Logging
AutoGen’s SQLite and File Logger - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_logging>)
### 
[​](https://docs.ag2.ai/docs/topics/<#full-service-partner-integrations>)
Full-Service Partner Integrations
  * AutoGen partners with [AgentOps](https://docs.ag2.ai/docs/topics/<https:/agentops.ai>) to provide multi-agent tracking, metrics, and monitoring - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_agentops>)
  * AutoGen partners with [OpenLIT](https://docs.ag2.ai/docs/topics/<https:/github.com/openlit/openlit>) to provide OpenTelemetry-native agent observability, which includes full execution traces and metrics - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_openlit.ipynb>)


## 
[​](https://docs.ag2.ai/docs/topics/<#what-is-observability>)
What is Observability?
Observability provides developers with the necessary insights to understand and improve the internal workings of their agents. Observability is necessary for maintaining reliability, tracking costs, and ensuring AI safety.
**Without observability tools, developers face significant hurdles:**
  * Tracking agent activities across sessions becomes a complex, error-prone task.
  * Manually sifting through verbose terminal outputs to understand LLM interactions is inefficient.
  * Pinpointing the exact moments of tool invocations is often like finding a needle in a haystack.


**Key Features of Observability Dashboards:**
  * Human-readable overview analytics and replays of agent activities.
  * LLM cost, prompt, completion, timestamp, and metadata tracking for performance monitoring.
  * Tool invocation, events, and agent-to-agent interactions for workflow monitoring.
  * Error flagging and notifications for faster debugging.
  * Access to a wealth of data for developers using supported agent frameworks, such as environments, SDK versions, and more.


### 
[​](https://docs.ag2.ai/docs/topics/<#compliance>)
Compliance
Observability is not just a development convenience—it’s a compliance necessity, especially in regulated industries:
  * It offers insights into AI decision-making processes, fostering trust and transparency.
  * Anomalies and unintended behaviors are detected promptly, reducing various risks.
  * Ensuring adherence to data privacy regulations, thereby safeguarding sensitive information.
  * Compliance violations are quickly identified and addressed, enhancing incident management.


[LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)[LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [AutoGen Observability Integrations](https://docs.ag2.ai/docs/topics/<#autogen-observability-integrations>)
  * [Built-In Logging](https://docs.ag2.ai/docs/topics/<#built-in-logging>)
  * [Full-Service Partner Integrations](https://docs.ag2.ai/docs/topics/<#full-service-partner-integrations>)
  * [What is Observability?](https://docs.ag2.ai/docs/topics/<#what-is-observability>)
  * [Compliance](https://docs.ag2.ai/docs/topics/<#compliance>)

---

# LLM Configuration
URL: https://docs.ag2.ai/docs/topics/llm_configuration

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
LLM Configuration
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# LLM Configuration
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/llm_configuration.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/llm_configuration.ipynb>)
In AutoGen, agents use LLMs as key components to understand and react. To configure an agent’s access to LLMs, you can specify an `llm_config` argument in its constructor. For example, the following snippet shows a configuration that uses `gpt-4`:
Copy
```
import os
llm_config = {
  "config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}],
}

```

It is important to never commit secrets into your code, therefore we read the OpenAI API key from an environment variable.
This `llm_config` can then be passed to an agent’s constructor to enable it to use the LLM.
Copy
```
import autogen
assistant = autogen.AssistantAgent(name="assistant", llm_config=llm_config)

```

## 
[​](https://docs.ag2.ai/docs/topics/<#introduction-to-config-list>)
Introduction to `config_list`
Different tasks may require different models, and the `config_list` allows specifying the different endpoints and configurations that are to be used. It is a list of dictionaries, each of which contains the following keys depending on the kind of endpoint being used:
Copy
```
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
<Tabs>
 <TabItem value="openai" label="OpenAI" default>
  - `model` (str, required): The identifier of the model to be used, such as 'gpt-4', 'gpt-3.5-turbo'.
  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.
  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.
  - `tags` (List[str], optional): Tags which can be used for filtering.
  Example:
  ```json
  [
   {
    "model": "gpt-4",
    "api_key": os.environ['OPENAI_API_KEY']
   }
  ]
  ```
 </TabItem>
 <TabItem value="azureopenai" label="Azure OpenAI">
  - `model` (str, required): The deployment to be used. The model corresponds to the deployment name on Azure OpenAI.
  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.
  - `api_type`: `azure`
  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.
  - `api_version` (str, optional): The version of the Azure API you wish to use.
  - `tags` (List[str], optional): Tags which can be used for filtering.
  Example:
  ```json
  [
   {
    "model": "my-gpt-4-deployment",
    "api_type": "azure",
    "api_key": os.environ['AZURE_OPENAI_API_KEY'],
    "base_url": "https://ENDPOINT.openai.azure.com/",
    "api_version": "2024-02-01"
   }
  ]
  ```
 </TabItem>
 <TabItem value="other" label="Other OpenAI compatible">
  - `model` (str, required): The identifier of the model to be used, such as 'llama-7B'.
  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.
  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.
  - `tags` (List[str], optional): Tags which can be used for filtering.
  Example:
  ```json
  [
   {
    "model": "llama-7B",
    "base_url": "http://localhost:1234"
   }
  ]
  ```
 </TabItem>
</Tabs>

```

By default this will create a model client which assumes an OpenAI API (or compatible) endpoint. To use custom model clients, see [here](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_custom_model.ipynb>).
### 
[​](https://docs.ag2.ai/docs/topics/<#oai-config-list-pattern>)
`OAI_CONFIG_LIST` pattern
A common, useful pattern used is to define this `config_list` via JSON (specified as a file or an environment variable set to a JSON-formatted string) and then use the `config_list_from_json`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-json>) helper function to load it:
Copy
```
config_list = autogen.config_list_from_json(
  env_or_file="OAI_CONFIG_LIST",
)
# Then, create the assistant agent with the config list
assistant = autogen.AssistantAgent(name="assistant", llm_config={"config_list": config_list})

```

This can be helpful as it keeps all the configuration in one place across different projects or notebooks.
This function interprets the `env_or_file` argument as follows:
  * If `env_or_file` is an environment variable then: 
    * It will first try to load the file from the path specified in the environment variable.
    * If there is no file, it will try to interpret the environment variable as a JSON string.
  * Otherwise, it will try to open the file at the path specified by `env_or_file`.


### 
[​](https://docs.ag2.ai/docs/topics/<#why-is-it-a-list>)
Why is it a list?
Being a list allows you to define multiple models that can be used by the agent. This is useful for a few reasons:
  * If one model times out or fails, the agent can try another model.
  * Having a single global list of models and [filtering it](https://docs.ag2.ai/docs/topics/docs/topics/llm_configuration#config-list-filtering>) based on certain keys (e.g. name, tag) in order to pass select models into a certain agent (e.g. use cheaper GPT 3.5 for agents solving easier tasks)
  * While the core agents, (e.g. conversable or assistant) do not have special logic around selecting configs, some of the specialized agents _may_ have logic to select the best model based on the task at hand.


### 
[​](https://docs.ag2.ai/docs/topics/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)
How does an agent decide which model to pick out of the list?
An agent uses the very first model available in the “config_list” and makes LLM calls against this model. If the model fails (e.g. API throttling) the agent will retry the request against the 2nd model and so on until prompt completion is received (or throws an error if none of the models successfully completes the request). In general there’s no implicit/hidden logic inside agents that is used to pick “the best model for the task”. However, some specialized agents may attempt to choose “the best model for the task”. It is developers responsibility to pick the right models and use them with agents.
### 
[​](https://docs.ag2.ai/docs/topics/<#config-list-filtering>)
Config list filtering
As described above the list can be filtered based on certain criteria. This is defined as a dictionary of key to filter on and values to filter by. For example, if you have a list of configs and you want to select the one with the model “gpt-3.5-turbo” you can use the following filter:
Copy
```
filter_dict = {"model": ["gpt-3.5-turbo"]}

```

This can then be applied to a config list loaded in Python with `filter_config`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#filter-config>):
Copy
```
config_list = autogen.filter_config(config_list, filter_dict)

```

Or, directly when loading the config list using `config_list_from_json`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-json>):
Copy
```
config_list = autogen.config_list_from_json(env_or_file="OAI_CONFIG_LIST", filter_dict=filter_dict)

```

#### 
[​](https://docs.ag2.ai/docs/topics/<#tags>)
Tags
Model names can differ between OpenAI and Azure OpenAI, so tags offer an easy way to smooth over this inconsistency. Tags are a list of strings in the `config_list`, for example for the following `config_list`:
Copy
```
config_list = [
  {"model": "my-gpt-4-deployment", "api_key": "", "tags": ["gpt4", "openai"]},
  {"model": "llama-7B", "base_url": "http://127.0.0.1:8080", "tags": ["llama", "local"]},
]

```

Then when filtering the `config_list` you can can specify the desired tags. A config is selected if it has at least one of the tags specified in the filter. For example, to just get the `llama` model, you can use the following filter:
Copy
```
filter_dict = {"tags": ["llama", "another_tag"]}
config_list = autogen.filter_config(config_list, filter_dict)
assert len(config_list) == 1

```

### 
[​](https://docs.ag2.ai/docs/topics/<#adding-http-client-in-llm-config-for-proxy>)
Adding http client in llm_config for proxy
In Autogen, a deepcopy is used on llm_config to ensure that the llm_config passed by user is not modified internally. You may get an error if the llm_config contains objects of a class that do not support deepcopy. To fix this, you need to implement a `__deepcopy__` method for the class.
The below example shows how to implement a `__deepcopy__` method for http client and add a proxy.
Copy
```
#!pip install httpx
import httpx

class MyHttpClient(httpx.Client):
  def __deepcopy__(self, memo):
    return self

config_list = [
  {
    "model": "my-gpt-4-deployment",
    "api_key": "",
    "http_client": MyHttpClient(proxy="http://localhost:8030"),
  }
]
llm_config = {
  "config_list": config_list,
}

```

### 
[​](https://docs.ag2.ai/docs/topics/<#using-azure-active-directory-aad-authentication>)
Using Azure Active Directory (AAD) Authentication
Azure Active Directory (AAD) provides secure access to resources and applications. Follow the steps below to configure AAD authentication for Autogen.
#### 
[​](https://docs.ag2.ai/docs/topics/<#prerequisites>)
Prerequisites
  * An Azure subscription - [Create one for free](https://docs.ag2.ai/docs/topics/<https:/azure.microsoft.com/en-us/pricing/purchase-options/azure-account?icid=azurefreeaccount>).
  * Access granted to the Azure OpenAI Service in the desired Azure subscription.
  * Appropriate permissions to register an application in AAD.
  * Custom subdomain names are required to enable features like Microsoft Entra ID for authentication.
  * Azure CLI - [Installation Guide](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/cli/azure/install-azure-cli>).


For more detailed and up-to-date instructions, please refer to the official [Azure OpenAI documentation](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/>).
#### 
[​](https://docs.ag2.ai/docs/topics/<#step-1-register-an-application-in-aad>)
Step 1: Register an Application in AAD
  1. Navigate to the [Azure portal](https://docs.ag2.ai/docs/topics/<https:/azure.microsoft.com/en-us/get-started/azure-portal>).
  2. Go to `Azure Active Directory` > `App registrations`.
  3. Click on `New registration`.
  4. Enter a name for your application.
  5. Set the `Redirect URI` (optional).
  6. Click `Register`.


For detailed instructions, refer to the official [Azure AD Quickstart documentation](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app?tabs=certificate>).
#### 
[​](https://docs.ag2.ai/docs/topics/<#step-2-configure-api-permissions>)
Step 2: Configure API Permissions
  1. After registration, go to `API permissions`.
  2. Click `Add a permission`.
  3. Select `Microsoft Graph` and then `Delegated permissions`.
  4. Add the necessary permissions (e.g., `User.Read`).


For more details, see [API permissions in Microsoft Graph](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/permissions-consent-overview>)
#### 
[​](https://docs.ag2.ai/docs/topics/<#step-3-obtain-client-id-and-tenant-id>)
Step 3: Obtain Client ID and Tenant ID
  1. Go to `Overview` of your registered application.
  2. Note down the `Application (client) ID` and `Directory (tenant) ID`.


For more details, visit [Register an application with the Microsoft identity platform](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app?tabs=certificate>)
#### 
[​](https://docs.ag2.ai/docs/topics/<#step-4-configure-your-application>)
Step 4: Configure Your Application
Use the obtained `Client ID` and `Tenant ID` in your application configuration. Here’s an example of how to do this in your configuration file:
Copy
```
aad_config = {
  "client_id": "YOUR_CLIENT_ID",
  "tenant_id": "YOUR_TENANT_ID",
  "authority": "https://login.microsoftonline.com/YOUR_TENANT_ID",
  "scope": ["https://graph.microsoft.com/.default"],
}

```

#### 
[​](https://docs.ag2.ai/docs/topics/<#step-5-authenticate-and-acquire-tokens>)
Step 5: Authenticate and Acquire Tokens
Use the following code to authenticate and acquire tokens:
Copy
```
from msal import ConfidentialClientApplication
app = ConfidentialClientApplication(
  client_id=aad_config["client_id"],
  client_credential="YOUR_CLIENT_SECRET",
  authority=aad_config["authority"]
)
result = app.acquire_token_for_client(scopes=aad_config["scope"])
if "access_token" in result:
  print("Token acquired")
else:
  print("Error acquiring token:", result.get("error"))

```

For more details, refer to the [Authenticate and authorize in Azure OpenAI Service](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai>) and [How to configure Azure OpenAI Service with Microsoft Entra ID authentication](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity>).
#### 
[​](https://docs.ag2.ai/docs/topics/<#step-6-configure-azure-openai-with-aad-auth-in-autogen>)
Step 6: Configure Azure OpenAI with AAD Auth in AutoGen
To use AAD authentication with Azure OpenAI in AutoGen, configure the `llm_config` with the necessary parameters.
Here is an example configuration:
Copy
```
llm_config = {
  "config_list": [
    {
      "model": "gpt-4",
      "base_url": "YOUR_BASE_URL",
      "api_type": "azure",
      "api_version": "2024-02-01",
      "max_tokens": 1000,
      "azure_ad_token_provider": "DEFAULT"
    }
  ]
}

```

For more details, refer to the [Authenticate and authorize in Azure OpenAI Service](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai>) and [How to configure Azure OpenAI Service with Microsoft Entra ID authentication](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity>).
In this configuration: - `model`: The Azure OpenAI deployment name. - `base_url`: The base URL of the Azure OpenAI endpoint. - `api_type`: Should be set to “azure”. - `api_version`: The API version to use. - `azure_ad_token_provider`: Set to “DEFAULT” to use the default token provider.
#### 
[​](https://docs.ag2.ai/docs/topics/<#example-of-initializing-an-assistant-agent-with-aad-auth>)
Example of Initializing an Assistant Agent with AAD Auth
Copy
```
import autogen
# Initialize the assistant agent with the AAD authenticated config
assistant = autogen.AssistantAgent(name="assistant", llm_config=llm_config)

```

#### 
[​](https://docs.ag2.ai/docs/topics/<#troubleshooting>)
Troubleshooting
If you encounter issues, check the following: - Ensure your `Client ID` and `Tenant ID` are correct. - Verify the permissions granted to your application. - Check network connectivity and Azure service status.
This documentation provides a complete guide to configure and use AAD authentication with Azure OpenAI in the AutoGen.
## 
[​](https://docs.ag2.ai/docs/topics/<#other-configuration-parameters>)
Other configuration parameters
Besides the `config_list`, there are other parameters that can be used to configure the LLM. These are split between parameters specifically used by Autogen and those passed into the model client.
### 
[​](https://docs.ag2.ai/docs/topics/<#autogen-specific-parameters>)
AutoGen specific parameters
  * `cache_seed` - This is a legacy parameter and not recommended to be used unless the reason for using it is to disable the default caching behavior. To disable default caching, set this to `None`. Otherwise, by default or if an int is passed the [DiskCache](https://docs.ag2.ai/docs/topics/docs/reference/cache/disk_cache>) will be used. For the new way of using caching, pass a [Cache](https://docs.ag2.ai/docs/topics/docs/reference/cache/cache>) object into `initiate_chat`[](https://docs.ag2.ai/docs/topics/docs/reference/agentchat/conversable_agent#initiate-chat>).


### 
[​](https://docs.ag2.ai/docs/topics/<#extra-model-client-parameters>)
Extra model client parameters
It is also possible to passthrough parameters through to the OpenAI client. Parameters that correspond to the `OpenAI`[ client](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/openai-python/blob/d231d1fa783967c1d3a1db3ba1b52647fff148ac/src/openai/_client.py#L67>) or the `OpenAI`[ completions create API](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/openai-python/blob/d231d1fa783967c1d3a1db3ba1b52647fff148ac/src/openai/resources/completions.py#L35>) can be supplied.
This is commonly used for things like `temperature`, or `timeout`.
## 
[​](https://docs.ag2.ai/docs/topics/<#example>)
Example
Copy
```
llm_config = {
  "config_list": [
    {
      "model": "my-gpt-4-deployment",
      "api_key": os.environ.get("AZURE_OPENAI_API_KEY"),
      "api_type": "azure",
      "base_url": os.environ.get("AZURE_OPENAI_API_BASE"),
      "api_version": "2024-02-01",
    },
    {
      "model": "llama-7B",
      "base_url": "http://127.0.0.1:8080",
      "api_type": "openai",
    },
  ],
  "temperature": 0.9,
  "timeout": 300,
}

```

## 
[​](https://docs.ag2.ai/docs/topics/<#other-helpers-for-loading-a-config-list>)
Other helpers for loading a config list
  * `get_config_list`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#get-config-list>): Generates configurations for API calls, primarily from provided API keys.
  * `config_list_openai_aoai`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-openai-aoai>): Constructs a list of configurations using both Azure OpenAI and OpenAI endpoints, sourcing API keys from environment variables or local files.
  * `config_list_from_models`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-models>): Creates configurations based on a provided list of models, useful when targeting specific models without manually specifying each configuration.
  * `config_list_from_dotenv`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-dotenv>): Constructs a configuration list from a `.env` file, offering a consolidated way to manage multiple API configurations and keys from a single file.


See [this notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/config_loader_utility_functions.ipynb>) for examples of using the above functions.
[Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)[ReAct](https://docs.ag2.ai/docs/topics/</docs/topics/prompting-and-reasoning/react>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Introduction to config_list](https://docs.ag2.ai/docs/topics/<#introduction-to-config-list>)
  * [OAI_CONFIG_LIST pattern](https://docs.ag2.ai/docs/topics/<#oai-config-list-pattern>)
  * [Why is it a list?](https://docs.ag2.ai/docs/topics/<#why-is-it-a-list>)
  * [How does an agent decide which model to pick out of the list?](https://docs.ag2.ai/docs/topics/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)
  * [Config list filtering](https://docs.ag2.ai/docs/topics/<#config-list-filtering>)
  * [Tags](https://docs.ag2.ai/docs/topics/<#tags>)
  * [Adding http client in llm_config for proxy](https://docs.ag2.ai/docs/topics/<#adding-http-client-in-llm-config-for-proxy>)
  * [Using Azure Active Directory (AAD) Authentication](https://docs.ag2.ai/docs/topics/<#using-azure-active-directory-aad-authentication>)
  * [Prerequisites](https://docs.ag2.ai/docs/topics/<#prerequisites>)
  * [Step 1: Register an Application in AAD](https://docs.ag2.ai/docs/topics/<#step-1-register-an-application-in-aad>)
  * [Step 2: Configure API Permissions](https://docs.ag2.ai/docs/topics/<#step-2-configure-api-permissions>)
  * [Step 3: Obtain Client ID and Tenant ID](https://docs.ag2.ai/docs/topics/<#step-3-obtain-client-id-and-tenant-id>)
  * [Step 4: Configure Your Application](https://docs.ag2.ai/docs/topics/<#step-4-configure-your-application>)
  * [Step 5: Authenticate and Acquire Tokens](https://docs.ag2.ai/docs/topics/<#step-5-authenticate-and-acquire-tokens>)
  * [Step 6: Configure Azure OpenAI with AAD Auth in AutoGen](https://docs.ag2.ai/docs/topics/<#step-6-configure-azure-openai-with-aad-auth-in-autogen>)
  * [Example of Initializing an Assistant Agent with AAD Auth](https://docs.ag2.ai/docs/topics/<#example-of-initializing-an-assistant-agent-with-aad-auth>)
  * [Troubleshooting](https://docs.ag2.ai/docs/topics/<#troubleshooting>)
  * [Other configuration parameters](https://docs.ag2.ai/docs/topics/<#other-configuration-parameters>)
  * [AutoGen specific parameters](https://docs.ag2.ai/docs/topics/<#autogen-specific-parameters>)
  * [Extra model client parameters](https://docs.ag2.ai/docs/topics/<#extra-model-client-parameters>)
  * [Example](https://docs.ag2.ai/docs/topics/<#example>)
  * [Other helpers for loading a config list](https://docs.ag2.ai/docs/topics/<#other-helpers-for-loading-a-config-list>)

---

# Retrieval Augmentation
URL: https://docs.ag2.ai/docs/topics/retrieval_augmentation

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
Retrieval Augmentation
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# Retrieval Augmentation
Retrieval Augmented Generation (RAG) is a powerful technique that combines language models with external knowledge retrieval to improve the quality and relevance of generated responses.
One way to realize RAG in AutoGen is to construct agent chats with `AssistantAgent` and `RetrieveUserProxyAgent` classes.
## 
[​](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents>)
Example Setup: RAG with Retrieval Augmented Agents
The following is an example setup demonstrating how to create retrieval augmented agents in AutoGen:
### 
[​](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent>)
Step 1. Create an instance of `AssistantAgent` and `RetrieveUserProxyAgent`.
Here `RetrieveUserProxyAgent` instance acts as a proxy agent that retrieves relevant information based on the user’s input.
Refer to the [doc](https://docs.ag2.ai/docs/topics/</docs/reference/agentchat/contrib/retrieve_user_proxy_agent>) for more information on the detailed configurations.
Copy
```
assistant = AssistantAgent(
  name="assistant",
  system_message="You are a helpful assistant.",
  llm_config={
    "timeout": 600,
    "cache_seed": 42,
    "config_list": config_list,
  },
)
ragproxyagent = RetrieveUserProxyAgent(
  name="ragproxyagent",
  human_input_mode="NEVER",
  max_consecutive_auto_reply=3,
  retrieve_config={
    "task": "code",
    "docs_path": [
      "https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md",
      "https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md",
      os.path.join(os.path.abspath(""), "..", "website", "docs"),
    ],
    "custom_text_types": ["mdx"],
    "chunk_token_size": 2000,
    "model": config_list[0]["model"],
    "client": chromadb.PersistentClient(path="/tmp/chromadb"),
    "embedding_model": "all-mpnet-base-v2",
    "get_or_create": True, # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually
  },
  code_execution_config=False, # set to False if you don't want to execute the code
)

```

### 
[​](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation>)
Step 2. Initiating Agent Chat with Retrieval Augmentation
Once the retrieval augmented agents are set up, you can initiate a chat with retrieval augmentation using the following code:
Copy
```
code_problem = "How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached."
ragproxyagent.initiate_chat(
  assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string="spark"
) # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain "spark".

```

## 
[​](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents-with-pgvector>)
Example Setup: RAG with Retrieval Augmented Agents with PGVector
The following is an example setup demonstrating how to create retrieval augmented agents in AutoGen:
### 
[​](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent-2>)
Step 1. Create an instance of `AssistantAgent` and `RetrieveUserProxyAgent`.
Here `RetrieveUserProxyAgent` instance acts as a proxy agent that retrieves relevant information based on the user’s input.
Specify the connection_string, or the host, port, database, username, and password in the db_config.
Copy
```
assistant = AssistantAgent(
  name="assistant",
  system_message="You are a helpful assistant.",
  llm_config={
    "timeout": 600,
    "cache_seed": 42,
    "config_list": config_list,
  },
)
ragproxyagent = RetrieveUserProxyAgent(
  name="ragproxyagent",
  human_input_mode="NEVER",
  max_consecutive_auto_reply=3,
  retrieve_config={
    "task": "code",
    "docs_path": [
      "https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md",
      "https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md",
      os.path.join(os.path.abspath(""), "..", "website", "docs"),
    ],
    "vector_db": "pgvector",
    "collection_name": "autogen_docs",
    "db_config": {
      "connection_string": "postgresql://testuser:testpwd@localhost:5432/vectordb", # Optional - connect to an external vector database
      # "host": None, # Optional vector database host
      # "port": None, # Optional vector database port
      # "database": None, # Optional vector database name
      # "username": None, # Optional vector database username
      # "password": None, # Optional vector database password
    },
    "custom_text_types": ["mdx"],
    "chunk_token_size": 2000,
    "model": config_list[0]["model"],
    "get_or_create": True,
  },
  code_execution_config=False,
)

```

### 
[​](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation-2>)
Step 2. Initiating Agent Chat with Retrieval Augmentation
Once the retrieval augmented agents are set up, you can initiate a chat with retrieval augmentation using the following code:
Copy
```
code_problem = "How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached."
ragproxyagent.initiate_chat(
  assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string="spark"
) # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain "spark".

```

## 
[​](https://docs.ag2.ai/docs/topics/<#online-demo>)
Online Demo
[Retrival-Augmented Chat Demo on Huggingface](https://docs.ag2.ai/docs/topics/<https:/huggingface.co/spaces/thinkall/autogen-demos>)
## 
[​](https://docs.ag2.ai/docs/topics/<#more-examples-and-notebooks>)
More Examples and Notebooks
For more detailed examples and notebooks showcasing the usage of retrieval augmented agents in AutoGen, refer to the following:
  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_RetrieveChat>)
  * Automated Code Generation and Question Answering with [PGVector](https://docs.ag2.ai/docs/topics/<https:/github.com/pgvector/pgvector>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_pgvector.ipynb>)
  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/docs/topics/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb>)
  * Automated Code Generation and Question Answering with [MongoDB Atlas](https://docs.ag2.ai/docs/topics/<https:/www.mongodb.com/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_mongodb.ipynb>)
  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_oai_assistant_retrieval.ipynb>)
  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_groupchat_RAG>)


## 
[​](https://docs.ag2.ai/docs/topics/<#roadmap>)
Roadmap
Explore our detailed roadmap [here](https://docs.ag2.ai/docs/topics/<https:/github.com/microsoft/autogen/issues/1657>) for further advancements plan around RAG. Your contributions, feedback, and use cases are highly appreciated! We invite you to engage with us and play a pivotal role in the development of this impactful feature.
[LLM Reflection](https://docs.ag2.ai/docs/topics/</docs/topics/prompting-and-reasoning/reflection>)[Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Example Setup: RAG with Retrieval Augmented Agents](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents>)
  * [Step 1. Create an instance of AssistantAgent and RetrieveUserProxyAgent.](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent>)
  * [Step 2. Initiating Agent Chat with Retrieval Augmentation](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation>)
  * [Example Setup: RAG with Retrieval Augmented Agents with PGVector](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents-with-pgvector>)
  * [Step 1. Create an instance of AssistantAgent and RetrieveUserProxyAgent.](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent-2>)
  * [Step 2. Initiating Agent Chat with Retrieval Augmentation](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation-2>)
  * [Online Demo](https://docs.ag2.ai/docs/topics/<#online-demo>)
  * [More Examples and Notebooks](https://docs.ag2.ai/docs/topics/<#more-examples-and-notebooks>)
  * [Roadmap](https://docs.ag2.ai/docs/topics/<#roadmap>)

---

# Swarm Orchestration
URL: https://docs.ag2.ai/docs/topics/swarm

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
Swarm Orchestration
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# Swarm Orchestration
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/swarm.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/swarm.ipynb>)
With AG2, you can initiate a Swarm Chat similar to OpenAI’s [Swarm](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/swarm>). This orchestration offers two main features:
  * **Headoffs** : Agents can transfer control to another agent via function calls, enabling smooth transitions within workflows.
  * **Context Variables** : Agents can dynamically update shared variables through function calls, maintaining context and adaptability throughout the process.


Instead of sending a task to a single LLM agent, you can assign it to a swarm of agents. Each agent in the swarm can decide whether to hand off the task to another agent. The chat terminates when the last active agent’s response is a plain string (i.e., it doesn’t suggest a tool call or handoff).
## 
[​](https://docs.ag2.ai/docs/topics/<#components>)
Components
We now introduce the main components that need to be used to create a swarm chat.
### 
[​](https://docs.ag2.ai/docs/topics/<#create-a-swarmagent>)
Create a `SwarmAgent`
All the agents passed to the swarm chat should be instances of `SwarmAgent`. `SwarmAgent` is very similar to `AssistantAgent`, but it has some additional features to support function registration and handoffs. When creating a `SwarmAgent`, you can pass in a list of functions. These functions will be converted to schemas to be passed to the LLMs, and you don’t need to worry about registering the functions for execution. You can also pass back a `SwarmResult` class, where you can return a value, the next agent to call, and update context variables at the same time.
**Notes for creating the function calls**
  * For input arguments, you must define the type of the argument, otherwise, the registration will fail (e.g. `arg_name: str`).
  * If your function requires access or modification of the context variables, you must pass in `context_variables: dict` as one argument. This argument will not be visible to the LLM (removed when registering the function schema). But when called, the global context variables will be passed in by the swarm chat.
  * The docstring of the function will be used as the prompt. So make sure to write a clear description.
  * The function name will be used as the tool name.


### 
[​](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-agents>)
Registering Handoffs to agents
While you can create a function to decide what next agent to call, we provide a quick way to register the handoff using `ON_CONDITION`. We will craft this transition function and add it to the LLM config directly.
Copy
```
agent_2 = SwarmAgent(...)
agent_3 = SwarmAgent(...)
# Register the handoff
agent_1 = SwarmAgent(...)
agent_1.handoff(hand_to=[ON_CONDITION(agent_2, "condition_1"), ON_CONDITION(agent_3, "condition_2")])
# This is equivalent to:
def transfer_to_agent_2():
  """condition_1"""
  return agent_2
def transfer_to_agent_3():
  """condition_2"""
  return agent_3
  
agent_1 = SwarmAgent(..., functions=[transfer_to_agent_2, transfer_to_agent_3])
# You can also use agent_1.add_functions to add more functions after initialization

```

### 
[​](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-a-nested-chat>)
Registering Handoffs to a nested chat
In addition to transferring to an agent, you can also trigger a nested chat by doing a handoff and using `ON_CONDITION`. This is a useful way to perform sub-tasks without that work becoming part of the broader swarm’s messages.
Configuring the nested chat is similar to [establishing a nested chat for an agent](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/tutorial/conversation-patterns#nested-chats>).
Nested chats are a set of sequential chats and these are defined like so:
Copy
```
nested_chats = [
  {
    "recipient": my_first_agent,
    "summary_method": "reflection_with_llm",
    "summary_prompt": "Summarize the conversation into bullet points.",
  },
  {
    "recipient": poetry_agent,
    "message": "Write a poem about the context.",
    "max_turns": 1,
    "summary_method": "last_msg",
  },
]

```

New to nested chats within swarms is the ability to **carryover some context from the swarm chat into the nested chat**. This is done by adding a carryover configuration. If you’re not using carryover, then no messages from the swarm chat will be brought into the nested chat.
The carryover is applicable only to the first chat in the nested chats and works together with that nested chat’s “message” value, if any.
Copy
```
my_carryover_config = {
  "summary_method": "reflection_with_llm",
  "summary_args": {"summary_prompt": "Summarise the conversation into bullet points."}
  }

```

The `summary_method` can be (with messages referring to the swarm chat’s messages):
  * `"all"` - messages will be converted to a new-line concatenated string, e.g. `[first nested chat message]\nContext: \n[swarm message 1]\n[swarm message 2]\n...`
  * `"last_msg"` - the latest message will be added, e.g. `[first nested chat message]\nContext: \n[swarm's latest message]`
  * `"reflection_with_llm"` - utilises an LLM to interpret the messages and its resulting response will be added, e.g. `[first nested chat message]\nContext: \n[llm response]`
  * `Callable` - a function that returns the full message (this will not concatenate with the first nested chat’s message, it will replace it entirely).


The signature of the `summary_method` callable is: `def my_method(agent: ConversableAgent, messages: List[Dict[str, Any]], summary_args: Dict) -> str:`
Both the “reflection_with_llm” and Callable will be able to utilise the `summary_args` if they are included.
With your configuration available, you can add it to the first chat in the nested chat:
Copy
```
nested_chats = [
  {
    "recipient": my_first_agent,
    "summary_method": "reflection_with_llm",
    "summary_prompt": "Summarize the conversation into bullet points.",
    "carryover_config": my_carryover_config,
  },
  {
    "recipient": poetry_agent,
    "message": "Write a poem about the context.",
    "max_turns": 1,
    "summary_method": "last_msg",
  },
]

```

Finally, we add the nested chat as a handoff in the same way as we do to an agent:
Copy
```
agent_1.handoff(
  hand_to=[ON_CONDITION(
    target={
      "chat_queue":[nested_chats],
      "config": Any,
      "reply_func_from_nested_chats": None,
      "use_async": False
    },
    condition="condition_1")
    ]
  )

```

See the documentation on [registering a nested chat](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/reference/agentchat/conversable_agent#register-nested-chats>) for further information on the parameters `reply_func_from_nested_chats`, `use_async`, and `config`.
Once a nested chat is complete, the resulting output from the last chat in the nested chats will be returned as the agent that triggered the nested chat’s response.
### 
[​](https://docs.ag2.ai/docs/topics/<#after-work>)
AFTER_WORK
When the active agent’s response doesn’t suggest a tool call or handoff, the chat will terminate by default. However, you can register an `AFTER_WORK` handoff to control what to do next. You can register these `AFTER_WORK` handoffs at the agent level and also the swarm level (through the `after_work` parameter on `initiate_swarm_chat`). The agent level takes precedence over the swarm level.
The AFTER_WORK takes a single parameter and this can be an agent, an agent’s name, an `AfterWorkOption`, or a callable function.
The `AfterWorkOption` options are: - `TERMINATE`: Terminate the chat
  * `STAY`: Stay at the current agent
  * `REVERT_TO_USER`: Revert to the user agent. Only if a user agent is passed in when initializing. (See below for more details)


The callable function signature is: `def my_after_work_func(last_speaker: SwarmAgent, messages: List[Dict[str, Any]], groupchat: GroupChat) -> Union[AfterWorkOption, SwarmAgent, str]:`
Note: there should only be one `AFTER_WORK`, if your requirement is more complex, use the callable function parameter.
Here are examples of registering AFTER_WORKS
Copy
```
# Register the handoff to an agent
agent_1.handoff(hand_to=[
 ON_CONDITION(...), 
 ON_CONDITION(...),
 AFTER_WORK(agent_4) # Fallback to agent_4 if no ON_CONDITION handoff is suggested
])
# Register the handoff to an AfterWorkOption
agent_2.handoff(hand_to=[AFTER_WORK(AfterWorkOption.TERMINATE)]) # Terminate the chat if no handoff is suggested
def my_after_work_func(last_speaker: SwarmAgent, messages: List[Dict[str, Any]], groupchat: GroupChat) -> Union[AfterWorkOption, SwarmAgent, str]:
  if last_speaker.get_context("agent_1_done"):
    return agent_2
  else:
    return AfterWorkOption.TERMINATE
# Register the handoff to a function that will return an agent or AfterWorkOption
agent_3.handoff(hand_to=[AFTER_WORK(my_after_work_func)])
# Register the swarm level AFTER_WORK that becomes the default for agents that don't have one specified
chat_history, context_variables, last_active_agent = initiate_swarm_chat(
  ...
  after_work=AfterWorkOption.TERMINATE # Or an agent or Callable
)

```

Copy
```

### Update Agent state before replying
It can be useful to update a swarm agent's state before they reply. For example, using an agent's context variables you could change their system message based on the state of the workflow.
When initialising a swarm agent use the `update_agent_state_before_reply` parameter to register updates that run after the agent is selected, but before they reply.
`update_agent_state_before_reply` takes a list of any combination of the following (executing them in the provided order):
- `UPDATE_SYSTEM_MESSAGE` provides a simple way to update the agent's system message via an f-string that substitutes the values of context variables, or a Callable that returns a string
- Callable with two parameters of type `ConversableAgent` for the agent and `List[Dict[str Any]]` for the messages, and does not return a value
Below is an example of setting these up when creating a Swarm agent.
```python
# Creates a system message string
def create_system_prompt_function(my_agent: ConversableAgent, messages: List[Dict[]]) -> str:
  preferred_name = my_agent.get_context("preferred_name", "(name not provided)")
  # Note that the returned string will be treated like an f-string using the context variables
  return "You are a customer service representative helping a customer named "
  + preferred_name
  + " and their passport number is '{passport_number}'."
# Function to update an Agent's state
def my_callable_state_update_function(my_agent: ConversableAgent, messages: List[Dict[]]) -> None:
  agent.set_context("context_key", 43)
  agent.update_system_message("You are a customer service representative.")
# Create the SwarmAgent and set agent updates
customer_service = SwarmAgent(
  name="CustomerServiceRep",
  system_message="You are a customer service representative.",
  update_agent_state_before_reply=[
    UPDATE_SYSTEM_MESSAGE("You are a customer service representative. Quote passport number '{passport_number}'"),
    UPDATE_SYSTEM_MESSAGE(create_system_prompt_function),
    my_callable_state_update_function]
  ...
)

```

### 
[​](https://docs.ag2.ai/docs/topics/<#initialize-swarmchat-with-initiate-swarm-chat-a-initiate-swarm-chat>)
Initialize SwarmChat with `initiate_swarm_chat` / `a_initiate_swarm_chat`
After a set of swarm agents are created, you can initiate a swarm chat by calling `initiate_swarm_chat` (or `a_initiate_swarm_chat` for an asynchronous version).
Copy
```
chat_history, context_variables, last_active_agent = initiate_swarm_chat(
  initial_agent=agent_1, # the first agent to start the chat
  agents=[agent_1, agent_2, agent_3], # a list of agents
  messages=[{"role": "user", "content": "Hello"}], # a list of messages to start the chat, you can also pass in one string
  user_agent=user_agent, # optional, if you want to revert to the user agent
  context_variables={"key": "value"} # optional, initial context variables
)

```

How we handle messages:
  * Case 1: If you pass in one single message
  * If there is a name in that message, we will assume this message is from that agent. (It will be error if that name doesn’t match any agent you passed in.)
  * If there is no name, 1. User agent passed in: we assume this message is from the user agent. 2. No user agent passed in: we will create a temporary user agent just to start the chat.
  * Case 2: We will use the [Resume GroupChat](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/topics/groupchat/resuming_groupchat>) feature to resume the chat. The `name` fields in these messages must be one of the names of the agents you passed in, otherwise, it will be an error.


## 
[​](https://docs.ag2.ai/docs/topics/<#q-and-as>)
Q&As
> How are context variables updated?
In a swarm, the context variables are shared amongst Swarm agents. As context variables are available at the agent level, you can use the context variable getters/setters on the agent to view and change the shared context variables. If you’re working with a function that returns a `SwarmResult` you should update the passed in context variables and return it in the `SwarmResult`, this will ensure the shared context is updated.
> What is the difference between ON_CONDITION and AFTER_WORK?
When registering an ON_CONDITION handoff, we are creating a function schema to be passed to the LLM. The LLM will decide whether to call this function.
When registering an AFTER_WORK handoff, we are defining the fallback mechanism when no tool calls are suggested. This is a higher level of control from the swarm chat level.
> When to pass in a user agent?
If your application requires interactions with the user, you can pass in a user agent to the groupchat, so that don’t need to write an outer loop to accept user inputs and call swarm.
## 
[​](https://docs.ag2.ai/docs/topics/<#demonstration>)
Demonstration
### 
[​](https://docs.ag2.ai/docs/topics/<#create-swarm-agents>)
Create Swarm Agents
Copy
```
import autogen
config_list = autogen.config_list_from_json(...)
llm_config = {"config_list": config_list}

```

Copy
```
import random
from autogen import (
  AFTER_WORK,
  ON_CONDITION,
  AfterWorkOption,
  SwarmAgent,
  SwarmResult,
  initiate_swarm_chat,
)

# 1. A function that returns a value of "success" and updates the context variable "1" to True
def update_context_1(context_variables: dict) -> SwarmResult:
  context_variables["1"] = True
  return SwarmResult(value="success", context_variables=context_variables)

# 2. A function that returns an SwarmAgent object
def transfer_to_agent_2() -> SwarmAgent:
  """Transfer to agent 2"""
  return agent_2

# 3. A function that returns the value of "success", updates the context variable and transfers to agent 3
def update_context_2_and_transfer_to_3(context_variables: dict) -> SwarmResult:
  context_variables["2"] = True
  return SwarmResult(value="success", context_variables=context_variables, agent=agent_3)

# 4. A function that returns a normal value
def get_random_number() -> str:
  return random.randint(1, 100)

def update_context_3_with_random_number(context_variables: dict, random_number: int) -> SwarmResult:
  context_variables["3"] = random_number
  return SwarmResult(value="success", context_variables=context_variables)

agent_1 = SwarmAgent(
  name="Agent_1",
  system_message="You are Agent 1, first, call the function to update context 1, and transfer to Agent 2",
  llm_config=llm_config,
  functions=[update_context_1, transfer_to_agent_2],
)
agent_2 = SwarmAgent(
  name="Agent_2",
  system_message="You are Agent 2, call the function that updates context 2 and transfer to Agent 3",
  llm_config=llm_config,
  functions=[update_context_2_and_transfer_to_3],
)
agent_3 = SwarmAgent(
  name="Agent_3",
  system_message="You are Agent 3, tell a joke",
  llm_config=llm_config,
)
agent_4 = SwarmAgent(
  name="Agent_4",
  system_message="You are Agent 4, call the function to get a random number",
  llm_config=llm_config,
  functions=[get_random_number],
)
agent_5 = SwarmAgent(
  name="Agent_5",
  system_message="Update context 3 with the random number.",
  llm_config=llm_config,
  functions=[update_context_3_with_random_number],
)

# This is equivalent to writing a transfer function
agent_3.register_hand_off(ON_CONDITION(agent_4, "Transfer to Agent 4"))
agent_4.register_hand_off([AFTER_WORK(agent_5)])
print("Agent 1 function schema:")
for func_schema in agent_1.llm_config["tools"]:
  print(func_schema)
print("Agent 3 function schema:")
for func_schema in agent_3.llm_config["tools"]:
  print(func_schema)

```

Copy
```
Agent 1 function schema:
{'type': 'function', 'function': {'description': '', 'name': 'update_context_1', 'parameters': {'type': 'object', 'properties': {}}}}
{'type': 'function', 'function': {'description': 'Transfer to agent 2', 'name': 'transfer_to_agent_2', 'parameters': {'type': 'object', 'properties': {}}}}
Agent 3 function schema:
{'type': 'function', 'function': {'description': 'Transfer to Agent 4', 'name': 'transfer_to_Agent_4', 'parameters': {'type': 'object', 'properties': {}}}}

```

### 
[​](https://docs.ag2.ai/docs/topics/<#start-chat>)
Start Chat
Copy
```
context_variables = {"1": False, "2": False, "3": False}
chat_result, context_variables, last_agent = initiate_swarm_chat(
  initial_agent=agent_1,
  agents=[agent_1, agent_2, agent_3, agent_4, agent_5],
  messages="start",
  context_variables=context_variables,
  after_work=AFTER_WORK(AfterWorkOption.TERMINATE), # this is the default
)

```

Copy
```
_User (to chat_manager):
start
--------------------------------------------------------------------------------
Next speaker: Agent_1
Agent_1 (to chat_manager):
***** Suggested tool call (call_kfcEAY2IeRZww06CQN7lbxOf): update_context_1 *****
Arguments: 
{}
*********************************************************************************
***** Suggested tool call (call_izl5eyV8IQ0Wg6XY2SaR1EJM): transfer_to_agent_2 *****
Arguments: 
{}
************************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION update_context_1...
>>>>>>>> EXECUTING FUNCTION transfer_to_agent_2...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_kfcEAY2IeRZww06CQN7lbxOf) *****
**********************************************************************
--------------------------------------------------------------------------------
***** Response from calling tool (call_izl5eyV8IQ0Wg6XY2SaR1EJM) *****
SwarmAgent --> Agent_2
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_2
Agent_2 (to chat_manager):
***** Suggested tool call (call_Yf5DTGaaYkA726ubnfJAvQMq): update_context_2_and_transfer_to_3 *****
Arguments: 
{}
***************************************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION update_context_2_and_transfer_to_3...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_Yf5DTGaaYkA726ubnfJAvQMq) *****
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_3
Agent_3 (to chat_manager):
***** Suggested tool call (call_jqZNHuMtQYeNh5Mq4pV2uwAj): transfer_to_Agent_4 *****
Arguments: 
{}
************************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION transfer_to_Agent_4...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_jqZNHuMtQYeNh5Mq4pV2uwAj) *****
SwarmAgent --> Agent_4
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_4
Agent_4 (to chat_manager):
***** Suggested tool call (call_KeNGv98klvDZsrAX10Ou3I71): get_random_number *****
Arguments: 
{}
**********************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION get_random_number...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_KeNGv98klvDZsrAX10Ou3I71) *****
27
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_4
Agent_4 (to chat_manager):
The random number generated is 27.
--------------------------------------------------------------------------------
Next speaker: Agent_5
Agent_5 (to chat_manager):
***** Suggested tool call (call_MlSGNNktah3m3QGssWBEzxCe): update_context_3_with_random_number *****
Arguments: 
{"random_number":27}
****************************************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION update_context_3_with_random_number...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_MlSGNNktah3m3QGssWBEzxCe) *****
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_5
Agent_5 (to chat_manager):
The random number 27 has been successfully updated in context 3.
--------------------------------------------------------------------------------

```

Copy
```
print(context_variables)

```

Copy
```
{'1': True, '2': True, '3': 27}

```

### 
[​](https://docs.ag2.ai/docs/topics/<#demo-with-user-agent>)
Demo with User Agent
We pass in a user agent to the swarm chat to accept user inputs. With `agent_6`, we register an `AFTER_WORK` handoff to revert to the user agent when no tool calls are suggested.
Copy
```
from autogen import UserProxyAgent
user_agent = UserProxyAgent(name="User", code_execution_config=False)
agent_6 = SwarmAgent(
  name="Agent_6",
  system_message="You are Agent 6. Your job is to tell jokes.",
  llm_config=llm_config,
)
agent_7 = SwarmAgent(
  name="Agent_7",
  system_message="You are Agent 7, explain the joke.",
  llm_config=llm_config,
)
agent_6.register_hand_off(
  [
    ON_CONDITION(
      agent_7, "Used to transfer to Agent 7. Don't call this function, unless the user explicitly tells you to."
    ),
    AFTER_WORK(AfterWorkOption.REVERT_TO_USER),
  ]
)
chat_result, _, _ = initiate_swarm_chat(
  initial_agent=agent_6,
  agents=[agent_6, agent_7],
  user_agent=user_agent,
  messages="start",
)

```

Copy
```
User (to chat_manager):
start
--------------------------------------------------------------------------------
Next speaker: Agent_6
Agent_6 (to chat_manager):
Why did the scarecrow win an award? 
Because he was outstanding in his field! 
Want to hear another one?
--------------------------------------------------------------------------------
Next speaker: User
User (to chat_manager):
yes
--------------------------------------------------------------------------------
Next speaker: Agent_6
Agent_6 (to chat_manager):
Why don't skeletons fight each other?
They don't have the guts! 
How about another?
--------------------------------------------------------------------------------
Next speaker: User
User (to chat_manager):
transfer
--------------------------------------------------------------------------------
Next speaker: Agent_6
Agent_6 (to chat_manager):
***** Suggested tool call (call_gQ9leFamxgzQp8ZVQB8rUH73): transfer_to_Agent_7 *****
Arguments: 
{}
************************************************************************************
--------------------------------------------------------------------------------
Next speaker: Tool_Execution

>>>>>>>> EXECUTING FUNCTION transfer_to_Agent_7...
Tool_Execution (to chat_manager):
***** Response from calling tool (call_gQ9leFamxgzQp8ZVQB8rUH73) *****
SwarmAgent --> Agent_7
**********************************************************************
--------------------------------------------------------------------------------
Next speaker: Agent_7
Agent_7 (to chat_manager):
The joke about the scarecrow winning an award is a play on words. It utilizes the term "outstanding," which can mean both exceptionally good (in the context of the scarecrow's performance) and literally being "standing out" in a field (where scarecrows are placed). So, the double meaning creates a pun that makes the joke humorous. 
The skeleton joke works similarly. When it says skeletons "don't have the guts," it plays on the literal fact that skeletons don't have internal organs (guts), and metaphorically, "having guts" means having courage. The humor comes from this clever wordplay.
--------------------------------------------------------------------------------

```

[Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)[Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Components](https://docs.ag2.ai/docs/topics/<#components>)
  * [Create a SwarmAgent](https://docs.ag2.ai/docs/topics/<#create-a-swarmagent>)
  * [Registering Handoffs to agents](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-agents>)
  * [Registering Handoffs to a nested chat](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-a-nested-chat>)
  * [AFTER_WORK](https://docs.ag2.ai/docs/topics/<#after-work>)
  * [Initialize SwarmChat with initiate_swarm_chat / a_initiate_swarm_chat](https://docs.ag2.ai/docs/topics/<#initialize-swarmchat-with-initiate-swarm-chat-a-initiate-swarm-chat>)
  * [Q&As](https://docs.ag2.ai/docs/topics/<#q-and-as>)
  * [Demonstration](https://docs.ag2.ai/docs/topics/<#demonstration>)
  * [Create Swarm Agents](https://docs.ag2.ai/docs/topics/<#create-swarm-agents>)
  * [Start Chat](https://docs.ag2.ai/docs/topics/<#start-chat>)
  * [Demo with User Agent](https://docs.ag2.ai/docs/topics/<#demo-with-user-agent>)

---

# Task Decomposition
URL: https://docs.ag2.ai/docs/topics/task_decomposition

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
Task Decomposition
[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)


User Guide
# Task Decomposition
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/task_decomposition.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/task_decomposition.ipynb>)
On this page, we demonstrate several different ways to achieve task decomposition in AutoGen.
First make sure the `pyautogen` package is installed.
Copy
```
! pip install "pyautogen>=0.2.18"

```

Import the relevant modules and configure the LLM. See [LLM Configuration](https://docs.ag2.ai/docs/topics/<./llm_configuration>) for how to configure LLMs.
Copy
```
import os
from datetime import datetime
from typing import Callable, Dict, Literal, Optional, Union
from typing_extensions import Annotated
from autogen import (
  Agent,
  AssistantAgent,
  ConversableAgent,
  GroupChat,
  GroupChatManager,
  UserProxyAgent,
  register_function,
)
from autogen.agentchat.contrib import agent_builder
from autogen.cache import Cache
from autogen.coding import LocalCommandLineCodeExecutor
config_list = [
  {"model": "gpt-4-1106-preview", "api_key": os.environ["OPENAI_API_KEY"]},
  {"model": "gpt-3.5-turbo", "api_key": os.environ["OPENAI_API_KEY"]},
]
# You can also use the following method to load the config list from a file or environment variable.
# config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")

```

The task to be solved to write a blog post about the stock price performance of Nvidia in the past month.
Copy
```
task = (
  f"Today is {datetime.now().date()}. Write a blogpost about the stock price performance of Nvidia in the past month."
)
print(task)

```

Copy
```
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.

```

## 
[​](https://docs.ag2.ai/docs/topics/<#approach-1-two-agent-chat-with-function-call-for-task-decomposition>)
Approach 1. Two-agent chat with function call for task decomposition
In this approach, we use a planner agent for coming up a plan. The planner agent is wrapped inside a function to be used as a tool.
Copy
```
# Create planner agent.
planner = AssistantAgent(
  name="planner",
  llm_config={
    "config_list": config_list,
    "cache_seed": None, # Disable legacy cache.
  },
  system_message="You are a helpful AI assistant. You suggest a feasible plan "
  "for finishing a complex task by decomposing it into 3-5 sub-tasks. "
  "If the plan is not good, suggest a better plan. "
  "If the execution is wrong, analyze the error and suggest a fix.",
)
# Create a planner user agent used to interact with the planner.
planner_user = UserProxyAgent(
  name="planner_user",
  human_input_mode="NEVER",
  code_execution_config=False,
)
# The function for asking the planner.

def task_planner(question: Annotated[str, "Question to ask the planner."]) -> str:
  with Cache.disk(cache_seed=4) as cache:
    planner_user.initiate_chat(planner, message=question, max_turns=1, cache=cache)
  # return the last message received from the planner
  return planner_user.last_message()["content"]

```

Next, we create an assistant agent to execute the plan, using the planner agent as a tool.
Copy
```
# Create assistant agent.
assistant = AssistantAgent(
  name="assistant",
  system_message="You are a helpful AI assistant. "
  "You can use the task planner to decompose a complex task into sub-tasks. "
  "Make sure your follow through the sub-tasks. "
  "When needed, write Python code in markdown blocks, and I will execute them."
  "Give the user a final solution at the end. "
  "Return TERMINATE only if the sub-tasks are completed.",
  llm_config={
    "config_list": config_list,
    "cache_seed": None, # Disable legacy cache.
  },
)
# Setting up code executor.
os.makedirs("planning", exist_ok=True)
# Use DockerCommandLineCodeExecutor to run code in a docker container.
# code_executor = DockerCommandLineCodeExecutor(work_dir="planning")
code_executor = LocalCommandLineCodeExecutor(work_dir="planning")
# Create user proxy agent used to interact with the assistant.
user_proxy = UserProxyAgent(
  name="user_proxy",
  human_input_mode="ALWAYS",
  is_termination_msg=lambda x: "content" in x
  and x["content"] is not None
  and x["content"].rstrip().endswith("TERMINATE"),
  code_execution_config={"executor": code_executor},
)
# Register the function to the agent pair.
register_function(
  task_planner,
  caller=assistant,
  executor=user_proxy,
  name="task_planner",
  description="A task planner than can help you with decomposing a complex task into sub-tasks.",
)

```

Copy
```
# Use Cache.disk to cache LLM responses. Change cache_seed for different responses.
with Cache.disk(cache_seed=1) as cache:
  # the assistant receives a message from the user, which contains the task description
  user_proxy.initiate_chat(
    assistant,
    message=task,
    cache=cache,
  )

```

Copy
```
user_proxy (to assistant):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
assistant (to user_proxy):
***** Suggested tool Call (call_rXxGJbMNXdD5PYueBc2BACez): task_planner *****
Arguments: 
{"question":"What are the steps to write a blog post about the stock price performance of Nvidia for the past month?"}
*****************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING FUNCTION task_planner...
planner_user (to planner):
What are the steps to write a blog post about the stock price performance of Nvidia for the past month?
--------------------------------------------------------------------------------
planner (to planner_user):
Writing a blog post about Nvidia's stock price performance over the past month involves several steps, which can be broken down into the following sub-tasks:
1. **Research:**
  - Gather data on Nvidia's stock price over the past month from reliable financial information sources like Bloomberg, Yahoo Finance, or the Nasdaq website.
  - Look into any recent news articles, press releases, or earnings reports that could help explain the stock price movements.
  - Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance.
2. **Analysis:**
  - Examine the data collected to identify patterns or significant changes in the stock price.
  - Investigate the correlation between stock price movements and specific events or news (e.g., product launches, earnings reports, or changes in the semiconductor industry).
  - Summarize key findings and consider creating graphs or charts to visually represent the stock performance over time.
3. **Outline and Structuring:**
  - Outline the blog post, starting with an introduction that provides context on Nvidia and its relevance in the market.
  - Create sections for your blog post: Introduction, Background (optional), Monthly Performance Analysis, Contributing Factors, and Conclusion.
  - Decide where you will include visuals like charts or infographics in your post.
4. **Writing:**
  - Write the introduction, setting the stage for your analysis and highlighting what the reader can expect to learn from the post.
  - Detail the monthly performance in the main body, integrating your analysis and the data visualizations you've prepared.
  - Discuss the identified contributing factors to Nvidia's stock performance, linking them with the analysis.
  - Conclude with a summary of the key points made in the post and any thoughts on future performance or upcoming events that investors should watch.
5. **Editing and Publishing:**
  - Review the post for clarity, grammar, and accuracy. Ensure that all data presented is correct and that sources are properly cited.
  - Optimize the post for search engines by including relevant keywords, meta descriptions, and title tags.
  - Publish the blog post on your platform and share it through social media or other marketing channels to reach your audience.
  - Engage with comments or feedback received to foster a community and show responsiveness.
Remember to comply with all financial regulations concerning stock commentary, including disclaimers where applicable, to avoid misconstruing your analysis as investment advice.
--------------------------------------------------------------------------------
user_proxy (to assistant):
user_proxy (to assistant):
***** Response from calling tool "call_rXxGJbMNXdD5PYueBc2BACez" *****
Writing a blog post about Nvidia's stock price performance over the past month involves several steps, which can be broken down into the following sub-tasks:
1. **Research:**
  - Gather data on Nvidia's stock price over the past month from reliable financial information sources like Bloomberg, Yahoo Finance, or the Nasdaq website.
  - Look into any recent news articles, press releases, or earnings reports that could help explain the stock price movements.
  - Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance.
2. **Analysis:**
  - Examine the data collected to identify patterns or significant changes in the stock price.
  - Investigate the correlation between stock price movements and specific events or news (e.g., product launches, earnings reports, or changes in the semiconductor industry).
  - Summarize key findings and consider creating graphs or charts to visually represent the stock performance over time.
3. **Outline and Structuring:**
  - Outline the blog post, starting with an introduction that provides context on Nvidia and its relevance in the market.
  - Create sections for your blog post: Introduction, Background (optional), Monthly Performance Analysis, Contributing Factors, and Conclusion.
  - Decide where you will include visuals like charts or infographics in your post.
4. **Writing:**
  - Write the introduction, setting the stage for your analysis and highlighting what the reader can expect to learn from the post.
  - Detail the monthly performance in the main body, integrating your analysis and the data visualizations you've prepared.
  - Discuss the identified contributing factors to Nvidia's stock performance, linking them with the analysis.
  - Conclude with a summary of the key points made in the post and any thoughts on future performance or upcoming events that investors should watch.
5. **Editing and Publishing:**
  - Review the post for clarity, grammar, and accuracy. Ensure that all data presented is correct and that sources are properly cited.
  - Optimize the post for search engines by including relevant keywords, meta descriptions, and title tags.
  - Publish the blog post on your platform and share it through social media or other marketing channels to reach your audience.
  - Engage with comments or feedback received to foster a community and show responsiveness.
Remember to comply with all financial regulations concerning stock commentary, including disclaimers where applicable, to avoid misconstruing your analysis as investment advice.
**********************************************************************
--------------------------------------------------------------------------------
assistant (to user_proxy):
***** Suggested tool Call (call_BAmTqvguaSkwQFq846qZxRxt): task_planner *****
Arguments: 
{"question": "How to gather data on Nvidia's stock price over the past month?"}
*****************************************************************************
***** Suggested tool Call (call_zQYeJEyx5gGzIxqirslGUgQi): task_planner *****
Arguments: 
{"question": "How to research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements?"}
*****************************************************************************
***** Suggested tool Call (call_Yb7uzCbJOFo7irlNPVzL8dem): task_planner *****
Arguments: 
{"question": "How to research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance?"}
*****************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING FUNCTION task_planner...
planner_user (to planner):
How to gather data on Nvidia's stock price over the past month?
--------------------------------------------------------------------------------
planner (to planner_user):
To gather data on Nvidia's stock price over the past month, you can decompose the task into the following sub-tasks:
1. **Define Your Source:**
  - Decide where you will obtain the data (e.g., financial websites like Yahoo Finance, Google Finance, Bloomberg, or utilizing APIs from services like Alpha Vantage, IEX Cloud, or Quandl).
2. **Data Collection:**
  - If you have chosen a financial website, you can usually download historical stock price data directly. Look for a "Download Data" or similar option on the webpage that shows Nvidia's stock history.
  - If using an API, write a script or use a tool to access the API, request the historical stock prices for the past month, and handle the response. This will typically involve some programming knowledge, for instance in Python, using libraries like `requests` or `pandas-datareader`.
3. **Data Parsing and Cleaning:**
  - After you obtain the data, you may need to parse or clean it. This means checking for any inaccuracies or missing values and formatting the data in a way that is useful for your analysis. For instance, you might want to convert the date formats or adjust for any splits or dividends if you're looking at adjusted closing prices.
4. **Analysis:**
  - Analyze the stock price data to observe trends, calculate statistics like the average closing price over the month, or perform other analyses that meet your objectives.
  
5. **Visualization (Optional):**
  - For better understanding and representation, visualize the data using charting tools or libraries (e.g., Excel, Google Sheets, or programming libraries like Matplotlib or Plotly in Python).
Here's a more detailed breakdown of the steps if you choose to use an API and write a script in Python:
**Step 1: Choosing an API**
  - Sign up for an API service like Alpha Vantage and obtain the required API key.
**Step 2: Writing the Script**
  - Install any necessary Python libraries (e.g., `requests`, `pandas`, `matplotlib`).
  - Write a Python script that uses the `requests` library to make an API call with the correct endpoint and parameters (symbol for Nvidia, your API key, and the time frame for the data).
  - Parse the JSON or CSV response and convert it into a Pandas DataFrame for ease of manipulation.
**Step 3: Data Parsing and Cleaning**
  - In your Python script, clean the data if necessary by removing any unnecessary columns, filling in missing values, or converting data types.
**Step 4: Analysis and Visualization**
  - Use Pandas to perform any desired calculations, such as moving averages.
  - Use a library like Matplotlib or Plotly to create charts from the DataFrame, such as line graphs of the closing prices over the past month.
**Note:**
  - It's important to respect the terms of service of the data provider and to be aware of any rate limits on API calls to avoid being blocked.
  - Be aware of stock market holidays and weekends when the market is closed, as these days will not have trading data.
If you encounter any difficulties in any of these sub-tasks, the error will likely fall into one of the following categories: issues with data access or download, errors in the script/code, or data quality issues. In each case, you would need to troubleshoot by checking access permissions, debugging the script, or examining the data for integrity, respectively.
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION task_planner...
planner_user (to planner):
How to research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements?
--------------------------------------------------------------------------------
planner (to planner_user):
To research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements, you'll need to systematically approach the task by breaking it down into the following sub-tasks:
1. **Identify Reliable Sources:**
  - Determine the most credible financial news websites, databases, and platforms that could have the information you’re seeking (e.g., Bloomberg, Reuters, CNBC, Nasdaq, and the official Nvidia investor relations page).
  - Consider specialized financial data platforms like Yahoo Finance, MarketWatch, or Seeking Alpha for more detailed analyses and reports.
  - Explore other reliable technology news outlets (e.g., TechCrunch, The Verge) that could have relevant information.
2. **Gather Key Data:**
  - Search for Nvidia’s latest earnings reports on their Investor Relations page, as these documents provide crucial information on the company’s financial health and outlook.
  - Look for recent press releases on Nvidia's official website or through a news aggregator service by setting up alerts for "Nvidia press release" to get real-time updates.
  - Use financial news platforms to search for Nvidia-specific news articles, filtering for the most recent ones. Include search terms like "Nvidia stock movement," "Nvidia earnings," or "Nvidia financial news." 
3. **Analyze Information:**
  - Read through the gathered documents and articles to identify any events or information that could have a direct impact on Nvidia's stock, such as product launches, partnerships, or changes in leadership.
  - Pay special attention to the numbers and forward-looking statements in earnings reports that may have influenced investor sentiment and stock prices (e.g., revenue, profit margin, sales forecasts, market share, guidance).
  - Look for any external factors that could affect the tech or semiconductor industry as a whole, such as new regulations, supply chain disruptions, or significant competitor announcements.
4. **Compare Information with Stock Price Movements:**
  - Overlay the dates of key events, announcements, or financial reporting with Nvidia's stock price chart to draw correlations between specific events and price fluctuations.
  - Cross-reference the news with trading volumes to see if significant news led to increased trading activity.
5. **Synthesize Findings:**
  - Compile your research into a timeline or a summary document that correlates specific news items with stock price changes.
  - Where possible, include expert analysis from your research to support your findings on why the stock moved in a particular way.
  - Be critical of the information sources and mindful of the potential bias that can skew the perceived impact of news on stock prices.
Remember to keep track of your sources and to cross-verify information to ensure accuracy. The stock market is influenced by numerous factors, some of which may not be immediately apparent, so it's also important to consider broader market trends and economic indicators in your analysis.
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION task_planner...
planner_user (to planner):
How to research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance?
--------------------------------------------------------------------------------
planner (to planner_user):
Researching market trends, economic factors, and industry-related developments to assess their influence on Nvidia's performance involves a systematic approach. Here's a plan that can help in fulfilling this research task:
1. **Define Objective and Scope**:
  - Identify the specific aspects of Nvidia's performance you are interested in (e.g., revenue growth, stock price fluctuation, product demand).
  - Determine the time frame for your research (e.g., last 5 years, last 10 years, or around specific events).
2. **Gather Historical Data and Performance Metrics**:
  - Collect historical performance data for Nvidia, including sales figures, earnings reports, stock price history, and market share information.
  - Obtain relevant financial documents, such as annual reports, 10-K filings, and investor presentations.
  - Look for performance benchmarks or metrics within Nvidia's sector, such as GPU market penetration, competitive analysis, etc.
3. **Analyze Market Trends and Economic Factors**:
  - Research broad market trends and economic conditions that can impact Nvidia's industry (Semiconductors and Technology Sector), including technology adoption rates, consumer spending trends, trade policies, and global economic indicators.
  - Use economic databases, government publications, financial news outlets, and market research reports for comprehensive information.
  - Explore the impact of specific events (e.g., chip shortages, tariffs, pandemic) on the technology sector and Nvidia's market.
4. **Industry-Specific Developments**:
  - Study developments within the GPU industry and technology sector that can influence Nvidia's position, such as advancements in competing technologies, regulatory changes, or patent filings.
  - Look into industry reports, whitepapers, tech journals, and conference proceedings for a deep dive into industry-specific insights.
  - Monitor tech news platforms and forums that discuss developer sentiments, product reviews, and consumer feedback on products and technologies related to Nvidia’s offerings.
5. **Synthesize Findings and Report**:
  - Integrate insights from your comprehensive research to draw conclusions about how market trends, economic factors, and industry developments have influenced Nvidia's performance.
  - Create a report or presentation with a narrative tying together Nvidia's performance data with the external factors you've identified. Use charts, graphs, and other visual aids to support your analysis.
  - Formulate recommendations or insights for investors, stakeholders, or decision-makers based on your findings.
Tools you might use for this task include financial analysis software, market research databases, economic analysis tools, and various data visualization platforms. Always ensure that the sources you use for your research are reliable and up to date.
If the research is not yielding meaningful insights or the task seems too broad, refocusing on more specific aspects of Nvidia's performance and looking into direct cause-effect relationships in market changes and Nvidia's financial outcomes can improve the plan. Additionally, consider engaging with experts in the field or leveraging advanced analytics and predictive modeling to enhance the depth of your research.
--------------------------------------------------------------------------------
user_proxy (to assistant):
user_proxy (to assistant):
***** Response from calling tool "call_BAmTqvguaSkwQFq846qZxRxt" *****
To gather data on Nvidia's stock price over the past month, you can decompose the task into the following sub-tasks:
1. **Define Your Source:**
  - Decide where you will obtain the data (e.g., financial websites like Yahoo Finance, Google Finance, Bloomberg, or utilizing APIs from services like Alpha Vantage, IEX Cloud, or Quandl).
2. **Data Collection:**
  - If you have chosen a financial website, you can usually download historical stock price data directly. Look for a "Download Data" or similar option on the webpage that shows Nvidia's stock history.
  - If using an API, write a script or use a tool to access the API, request the historical stock prices for the past month, and handle the response. This will typically involve some programming knowledge, for instance in Python, using libraries like `requests` or `pandas-datareader`.
3. **Data Parsing and Cleaning:**
  - After you obtain the data, you may need to parse or clean it. This means checking for any inaccuracies or missing values and formatting the data in a way that is useful for your analysis. For instance, you might want to convert the date formats or adjust for any splits or dividends if you're looking at adjusted closing prices.
4. **Analysis:**
  - Analyze the stock price data to observe trends, calculate statistics like the average closing price over the month, or perform other analyses that meet your objectives.
  
5. **Visualization (Optional):**
  - For better understanding and representation, visualize the data using charting tools or libraries (e.g., Excel, Google Sheets, or programming libraries like Matplotlib or Plotly in Python).
Here's a more detailed breakdown of the steps if you choose to use an API and write a script in Python:
**Step 1: Choosing an API**
  - Sign up for an API service like Alpha Vantage and obtain the required API key.
**Step 2: Writing the Script**
  - Install any necessary Python libraries (e.g., `requests`, `pandas`, `matplotlib`).
  - Write a Python script that uses the `requests` library to make an API call with the correct endpoint and parameters (symbol for Nvidia, your API key, and the time frame for the data).
  - Parse the JSON or CSV response and convert it into a Pandas DataFrame for ease of manipulation.
**Step 3: Data Parsing and Cleaning**
  - In your Python script, clean the data if necessary by removing any unnecessary columns, filling in missing values, or converting data types.
**Step 4: Analysis and Visualization**
  - Use Pandas to perform any desired calculations, such as moving averages.
  - Use a library like Matplotlib or Plotly to create charts from the DataFrame, such as line graphs of the closing prices over the past month.
**Note:**
  - It's important to respect the terms of service of the data provider and to be aware of any rate limits on API calls to avoid being blocked.
  - Be aware of stock market holidays and weekends when the market is closed, as these days will not have trading data.
If you encounter any difficulties in any of these sub-tasks, the error will likely fall into one of the following categories: issues with data access or download, errors in the script/code, or data quality issues. In each case, you would need to troubleshoot by checking access permissions, debugging the script, or examining the data for integrity, respectively.
**********************************************************************
--------------------------------------------------------------------------------
user_proxy (to assistant):
***** Response from calling tool "call_zQYeJEyx5gGzIxqirslGUgQi" *****
To research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements, you'll need to systematically approach the task by breaking it down into the following sub-tasks:
1. **Identify Reliable Sources:**
  - Determine the most credible financial news websites, databases, and platforms that could have the information you’re seeking (e.g., Bloomberg, Reuters, CNBC, Nasdaq, and the official Nvidia investor relations page).
  - Consider specialized financial data platforms like Yahoo Finance, MarketWatch, or Seeking Alpha for more detailed analyses and reports.
  - Explore other reliable technology news outlets (e.g., TechCrunch, The Verge) that could have relevant information.
2. **Gather Key Data:**
  - Search for Nvidia’s latest earnings reports on their Investor Relations page, as these documents provide crucial information on the company’s financial health and outlook.
  - Look for recent press releases on Nvidia's official website or through a news aggregator service by setting up alerts for "Nvidia press release" to get real-time updates.
  - Use financial news platforms to search for Nvidia-specific news articles, filtering for the most recent ones. Include search terms like "Nvidia stock movement," "Nvidia earnings," or "Nvidia financial news." 
3. **Analyze Information:**
  - Read through the gathered documents and articles to identify any events or information that could have a direct impact on Nvidia's stock, such as product launches, partnerships, or changes in leadership.
  - Pay special attention to the numbers and forward-looking statements in earnings reports that may have influenced investor sentiment and stock prices (e.g., revenue, profit margin, sales forecasts, market share, guidance).
  - Look for any external factors that could affect the tech or semiconductor industry as a whole, such as new regulations, supply chain disruptions, or significant competitor announcements.
4. **Compare Information with Stock Price Movements:**
  - Overlay the dates of key events, announcements, or financial reporting with Nvidia's stock price chart to draw correlations between specific events and price fluctuations.
  - Cross-reference the news with trading volumes to see if significant news led to increased trading activity.
5. **Synthesize Findings:**
  - Compile your research into a timeline or a summary document that correlates specific news items with stock price changes.
  - Where possible, include expert analysis from your research to support your findings on why the stock moved in a particular way.
  - Be critical of the information sources and mindful of the potential bias that can skew the perceived impact of news on stock prices.
Remember to keep track of your sources and to cross-verify information to ensure accuracy. The stock market is influenced by numerous factors, some of which may not be immediately apparent, so it's also important to consider broader market trends and economic indicators in your analysis.
**********************************************************************
--------------------------------------------------------------------------------
user_proxy (to assistant):
***** Response from calling tool "call_Yb7uzCbJOFo7irlNPVzL8dem" *****
Researching market trends, economic factors, and industry-related developments to assess their influence on Nvidia's performance involves a systematic approach. Here's a plan that can help in fulfilling this research task:
1. **Define Objective and Scope**:
  - Identify the specific aspects of Nvidia's performance you are interested in (e.g., revenue growth, stock price fluctuation, product demand).
  - Determine the time frame for your research (e.g., last 5 years, last 10 years, or around specific events).
2. **Gather Historical Data and Performance Metrics**:
  - Collect historical performance data for Nvidia, including sales figures, earnings reports, stock price history, and market share information.
  - Obtain relevant financial documents, such as annual reports, 10-K filings, and investor presentations.
  - Look for performance benchmarks or metrics within Nvidia's sector, such as GPU market penetration, competitive analysis, etc.
3. **Analyze Market Trends and Economic Factors**:
  - Research broad market trends and economic conditions that can impact Nvidia's industry (Semiconductors and Technology Sector), including technology adoption rates, consumer spending trends, trade policies, and global economic indicators.
  - Use economic databases, government publications, financial news outlets, and market research reports for comprehensive information.
  - Explore the impact of specific events (e.g., chip shortages, tariffs, pandemic) on the technology sector and Nvidia's market.
4. **Industry-Specific Developments**:
  - Study developments within the GPU industry and technology sector that can influence Nvidia's position, such as advancements in competing technologies, regulatory changes, or patent filings.
  - Look into industry reports, whitepapers, tech journals, and conference proceedings for a deep dive into industry-specific insights.
  - Monitor tech news platforms and forums that discuss developer sentiments, product reviews, and consumer feedback on products and technologies related to Nvidia’s offerings.
5. **Synthesize Findings and Report**:
  - Integrate insights from your comprehensive research to draw conclusions about how market trends, economic factors, and industry developments have influenced Nvidia's performance.
  - Create a report or presentation with a narrative tying together Nvidia's performance data with the external factors you've identified. Use charts, graphs, and other visual aids to support your analysis.
  - Formulate recommendations or insights for investors, stakeholders, or decision-makers based on your findings.
Tools you might use for this task include financial analysis software, market research databases, economic analysis tools, and various data visualization platforms. Always ensure that the sources you use for your research are reliable and up to date.
If the research is not yielding meaningful insights or the task seems too broad, refocusing on more specific aspects of Nvidia's performance and looking into direct cause-effect relationships in market changes and Nvidia's financial outcomes can improve the plan. Additionally, consider engaging with experts in the field or leveraging advanced analytics and predictive modeling to enhance the depth of your research.
**********************************************************************
--------------------------------------------------------------------------------
assistant (to user_proxy):
The process of writing a blog post about Nvidia's stock price performance over the past month can now progress to the data-gathering phase. Let's focus on the following three tasks:
1. **Gathering data on Nvidia's stock price over the past month:**
  - A Python script can be written to use an API service like Alpha Vantage to obtain the stock price data.
2. **Research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements:**
  - Important information will be sought from reliable financial news sites and Nvidia's official channels.
3. **Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance:**
  - Using economic databases, financial news outlets, and market research reports, a comprehensive analysis will be conducted on the factors impacting the industry and Nvidia's market position.
Let's begin by focusing on creating a Python script to get the stock price data. We'll need to perform the following steps:
1. Choose an API to retrieve the data.
2. Write a script using the chosen API and make necessary API calls.
3. Parse the JSON or CSV response and organize it into a useful format.
4. Clean the data if necessary.
5. Perform preliminary analysis and visualize the data.
Please note that accessing an API service like Alpha Vantage might require an API key, which could involve signing up for the service and may be subject to their terms of service, including request limits.
Shall I proceed with writing the Python script to retrieve Nvidia's stock price data over the past month?
--------------------------------------------------------------------------------
user_proxy (to assistant):
Write script using yfinance package instead. 
--------------------------------------------------------------------------------
assistant (to user_proxy):
To gather historical stock price information for Nvidia (NVDA) for the past month using the `yfinance` package, follow these steps:
1. **Install the Package**: If you haven't already installed `yfinance`, do so by running `pip install yfinance` in your Python environment.
2. **Import the Package**: Import `yfinance` into your script.
3. **Request Stock Data**: Use the `yfinance` package to download the closing price data for Nvidia for the past month.
4. **Plot the Data**: It can be useful to plot the data to visualize the stock's performance over the past month.
Below is the Python script that encompasses these steps:
```python
import yfinance as yf
import matplotlib.pyplot as plt
# Define the ticker symbol for Nvidia
ticker_symbol = 'NVDA'
# Set the date range for the past month: assuming today is 2024-03-18
start_date = '2024-02-18'
end_date = '2024-03-18'
# Download the data from yfinance
nvda_data = yf.download(ticker_symbol, start=start_date, end=end_date)
# Select only the 'Close' column for plotting
closing_prices = nvda_data['Close']
# Plot the closing prices
plt.figure(figsize=(14, 7))
plt.plot(closing_prices, label='NVDA Closing Prices')
plt.title('NVDA Stock Closing Prices Over the Past Month')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.show()
```
Here, `yfinance` downloads the data from Yahoo Finance for Nvidia between the desired dates (`start_date` and `end_date`). The script then uses `matplotlib` to create a simple line plot of the closing prices over this period.
Would you like me to run this script and generate the plot for you?
--------------------------------------------------------------------------------
user_proxy (to assistant):
Include code for saving the dataset. Also include code for displaying the table. 
--------------------------------------------------------------------------------
assistant (to user_proxy):
To save the dataset of Nvidia's stock prices and display the table along with plotting, you can update the script as follows:
1. **Install Necessary Packages**: You must have `yfinance`, `matplotlib`, and `pandas` installed in your Python environment.
2. **Import Packages**: Import the `yfinance`, `matplotlib.pyplot`, and `pandas` packages into your script.
3. **Request Stock Data**: Use `yfinance` to download Nvidia's stock price data for the designated period.
4. **Save the Dataset**: Save the downloaded data to a CSV file.
5. **Display the Table**: Use Pandas DataFrame's capabilities to display the table before plotting.
6. **Plot the Data**: Visualize the Nvidia's closing stock prices using `matplotlib`.
Here is the Python script updated with these steps:
```python
import yfinance as yf
import matplotlib.pyplot as plt
import pandas as pd
# Define the ticker symbol for Nvidia
ticker_symbol = 'NVDA'
# Set the date range for the past month: assuming today is 2024-03-18
start_date = '2024-02-18'
end_date = '2024-03-18'
# Download the data from yfinance
nvda_data = yf.download(ticker_symbol, start=start_date, end=end_date)
# Save the data to a CSV file
nvda_data.to_csv('NVDA_stock_data.csv')
# Display the data table
print(nvda_data)
# Select only the 'Close' column for plotting
closing_prices = nvda_data['Close']
# Plot the closing prices
plt.figure(figsize=(14, 7))
plt.plot(closing_prices, label='NVDA Closing Prices')
plt.title('NVDA Stock Closing Prices Over the Past Month')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.grid(True)
plt.show()
```
This script will download the data, save it as a CSV file named 'NVDA_stock_data.csv', print the data as a table to the console, and plot the closing prices.
Let me know if you want me to run this code or if there are any other modifications you would like to make before execution.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
user_proxy (to assistant):
exitcode: 0 (execution succeeded)
Code output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.
 df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')
[*********************100%%**********************] 1 of 1 completed
         Open    High ...  Adj Close   Volume
Date                ...            
2024-02-20 719.469971 719.559998 ... 694.487427  70483300
2024-02-21 680.059998 688.880005 ... 674.688293  69029800
2024-02-22 750.250000 785.750000 ... 785.343140  86510000
2024-02-23 807.900024 823.940002 ... 788.132996  82938800
2024-02-26 797.000000 806.460022 ... 790.882874  50397300
2024-02-27 793.809998 794.799988 ... 786.973083  39170500
2024-02-28 776.200012 789.330017 ... 776.593567  39311000
2024-02-29 790.940002 799.900024 ... 791.082886  50728900
2024-03-01 800.000000 823.000000 ... 822.751404  47677700
2024-03-04 841.299988 876.950012 ... 852.330017  61561600
2024-03-05 852.700012 860.969971 ... 859.640015  52063900
2024-03-06 880.219971 897.239990 ... 887.000000  58252000
2024-03-07 901.580017 927.669983 ... 926.690002  60811900
2024-03-08 951.380005 974.000000 ... 875.280029 113299600
2024-03-11 864.289978 887.969971 ... 857.739990  67836400
2024-03-12 880.489990 919.599976 ... 919.130005  66807500
2024-03-13 910.549988 915.039978 ... 908.880005  63571300
2024-03-14 895.770020 906.460022 ... 879.440002  60231800
2024-03-15 869.299988 895.460022 ... 878.369995  64019300
[19 rows x 6 columns]
Figure(1400x700)

--------------------------------------------------------------------------------
assistant (to user_proxy):
The script execution was successful. The historical stock price data for Nvidia (NVDA) between 2024-02-18 and 2024-03-18 has been downloaded, saved to a CSV file named 'NVDA_stock_data.csv', and the dataset has been displayed in the console output.
Here is a preview of the dataset:
| Date    | Open    | High    | Low     | Close    | Adj Close  | Volume   |
|------------|-------------|-------------|-------------|-------------|-------------|------------|
| 2024-02-20 | 719.469971 | 719.559998 | ...     | ...     | 694.487427 | 70483300  |
| 2024-02-21 | 680.059998 | 688.880005 | ...     | ...     | 674.688293 | 69029800  |
| 2024-02-22 | 750.250000 | 785.750000 | ...     | ...     | 785.343140 | 86510000  |
| 2024-02-23 | 807.900024 | 823.940002 | ...     | ...     | 788.132996 | 82938800  |
| ...    | ...     | ...     | ...     | ...     | ...     | ...    |
| 2024-03-14 | 895.770020 | 906.460022 | ...     | ...     | 879.440002 | 60231800  |
| 2024-03-15 | 869.299988 | 895.460022 | ...     | ...     | 878.369995 | 64019300  |
(Note: Some columns have been truncated for display purposes.)
Additionally, a plot showing the closing prices of Nvidia stock over the past month was generated:
![NVDA Stock Closing Prices Over the Past Month](attachment:nvda_closing_prices.png)
The plot is not displayed in the output but would be visible if the script were run in a local Python environment that supports rendering matplotlib figures. 
You can use the saved CSV file and the dataset summary as a basis for writing your blog post on the performance of the Nvidia stock. Remember to integrate your analysis and discuss any potential factors influencing the stock price that you find in news articles and market research.
--------------------------------------------------------------------------------
user_proxy (to assistant):
write the blog post
--------------------------------------------------------------------------------
assistant (to user_proxy):
# Nvidia's Stock Price Performance Review: February - March 2024
March 18, 2024
In the ever-evolving landscape of technology and finance, keeping a keen eye on industry leaders such as Nvidia Corp (NVDA) provides valuable insights into market trends and investor confidence. Over the past month, Nvidia's stock price has experienced significant movements, prompting investors and analysts to closely monitor the factors driving this volatility. In this blog post, we'll dive into the stock price performance of Nvidia from February 18 to March 18, 2024, and examine the key contributors to its fluctuations.
## A Glimpse Into Nvidia's Stock Price Movement
Analysing the stock performance over the past month reveals a dynamic and eventful period for Nvidia. Starting on February 20, 2024, the stock opened at \$719.47 and experienced a degree of instability, touching a monthly low of \$674.68 on February 21 before surging to a stellar high of \$785.34 on February 22. This upward momentum continued robustly until March 7, peaking at an admirable \$926.69. However, this ascent was followed by a substantial correction, with prices adjusting to \$878.37 by March 15, marking the end of our analysis period.
This turbulent period for Nvidia reflects a broader narrative of rapid adjustments and market reactions to a series of impactful events within the company and across the broader economic and technological ecosystems.
## Unpacking the Influences on Nvidia's Stock Performance
As we sift through the economic news, earnings reports, and industry developments, a pattern of interrelated influences on the semiconductor giant's stock price becomes evident.
### Product Launches and Technological Advancements
Nvidia's continued commitment to innovation is a significant driver of investor interest. The company's latest product releases and advancements in graphics processing units (GPU) often correlate with spikes in stock value. Given the company's historical patterns, it is plausible that Nvidia's announcements of enhanced GPU technologies for gaming and professional markets may have contributed positively to the observed stock price appreciation.
### Economic and Industry Factors
Nvidia does not operate in a vacuum; it is influenced by the health of the global economy, trade policies, and tech industry dynamics. The semiconductor industry, in particular, is sensitive to supply chain disruptions and shifts in consumer demand for technology. Any news suggesting an easing of chip shortages or an uptick in demand for Nvidia's GPUs for data centers or automotive applications could be contributing factors to the company's stock trajectory.
### Market Sentiment and Investor Confidence
Investor sentiment and confidence play crucial roles in stock performance. Nvidia's earnings reports often serve as a pulse check for shareholders, detailing the company's financial health and forecasts. A positive earnings report during this period may have reinforced confidence and catalysed further investments, propelling the stock prices to new heights.
Conversely, market corrections and profit-taking activities could also explain subsequent price adjustments, reminding us of the stock market's cyclical nature and investors' propensity to secure gains after a considerable run-up.
## Conclusion
Nvidia's stock price journey between February and March 2024 exemplifies the intricate interplay between company-specific innovations, broader economic forces, and the investing community's sentiment. As with any investment, due diligence and a comprehensive understanding of market conditions are crucial to navigating the ebbs and flows.
Looking ahead, Nvidia's future performance is likely to be swayed by its ability to maintain technological leadership, the unfolding economic climate, and its agility in adapting to industry challenges. Investors and enthusiasts alike would do well to watch the company's upcoming product revelations, quarterly reports, and industry trends for a clearer picture of what the future may hold for this semiconductor standard-bearer.
*Disclaimer: The information provided in this analysis is for educational and entertainment purposes only and does not constitute financial advice.*
---
And there you have it—a draft blog post summarizing Nvidia's stock performance over the past month and considering various factors that could have influenced its stock price. Your audience should find this overview informative and insightful. Please note that real-life data may contain fluctuations and patterns that can change the analysis considerably, so additional research and verification are always recommended before finalizing the content.
--------------------------------------------------------------------------------

```

## 
[​](https://docs.ag2.ai/docs/topics/<#approach-2-group-chat>)
Approach 2: Group chat
### 
[​](https://docs.ag2.ai/docs/topics/<#group-chat-for-task-decomposition>)
Group chat for task decomposition
Groupchat with default auto speaker selection can be used for task decomposition. With defined roles, a groupchat manager will select different agents to perform different sub-tasks.
Copy
```
user_proxy = UserProxyAgent(
  name="Admin",
  system_message="A human admin. Give the task, and send instructions to writer to refine the blog post.",
  code_execution_config=False,
)
planner = AssistantAgent(
  name="Planner",
  system_message="""Planner. Given a task, please determine what information is needed to complete the task.
Please note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code.
""",
  llm_config={"config_list": config_list, "cache_seed": None},
)
engineer = AssistantAgent(
  name="Engineer",
  llm_config={"config_list": config_list, "cache_seed": None},
  system_message="""Engineer. You write python/bash to retrieve relevant information. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.
Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.
If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.
""",
)
writer = AssistantAgent(
  name="Writer",
  llm_config={"config_list": config_list, "cache_seed": None},
  system_message="""Writer. Please write blogs in markdown format (with relevant titles) and put the content in pseudo ```md``` code block. You will write it for a task based on previous chat history. Don't write any code.""",
)
os.makedirs("paper", exist_ok=True)
code_executor = UserProxyAgent(
  name="Executor",
  system_message="Executor. Execute the code written by the engineer and report the result.",
  description="Executor should always be called after the engineer has written code to be executed.",
  human_input_mode="ALWAYS",
  code_execution_config={
    "last_n_messages": 3,
    "executor": LocalCommandLineCodeExecutor(work_dir="paper"),
  },
)
groupchat = GroupChat(
  agents=[user_proxy, engineer, code_executor, writer, planner],
  messages=[],
  max_round=20,
  speaker_selection_method="auto",
)
manager = GroupChatManager(groupchat=groupchat, llm_config={"config_list": config_list, "cache_seed": None})
# Use Cache.disk to cache LLM responses. Change cache_seed for different responses.
with Cache.disk(cache_seed=41) as cache:
  chat_history = user_proxy.initiate_chat(
    manager,
    message=task,
    cache=cache,
  )

```

Copy
```
Admin (to chat_manager):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
Planner (to chat_manager):
To write a blog post about Nvidia's stock price performance in the past month using Python code, you would need to gather and process the following information:
1. Stock Price Data:
  - Historical daily closing prices of Nvidia stock (NVDA) for the past month.
  - Volume of shares traded each day over the past month.
  - Historical high and low prices for the past month.
2. Company News and Events:
  - Any Nvidia-specific news that might have affected the stock price.
  - Relevant market news or technology sector news.
  - Details of any earnings reports, product launches, partnerships, acquisitions, or other announcements made by Nvidia in the past month.
3. Market Context:
  - Overall stock market performance over the past month, especially comparing tech sector indices such as NASDAQ or S&P 500 Information Technology Sector.
  - Performance of Nvidia's competitors' stocks.
  - Any relevant macroeconomic indicators or events that might have affected the market.
4. Technical Analysis Data (optional for a more in-depth analysis):
  - Technical indicators like moving averages, RSI (Relative Strength Index), MACD (Moving Average Convergence Divergence), etc.
  - Candlestick chart patterns for visual analysis and trend identification.
5. Statistical Analysis:
  - Percent change in Nvidia's stock price over the past month.
  - Volatility measures such as standard deviation or average true range.
To retrieve this data using Python, you could use:
- Financial and stock market APIs (such as Yahoo Finance, Alpha Vantage, or IEX Cloud) to get historical stock price data and technical indicators.
- Python libraries like `requests` for making API calls to news aggregator services for company news and market context.
- Libraries like `pandas` and `numpy` for data manipulation and statistical analysis.
- Visualization libraries such as `matplotlib` or `seaborn` for plotting stock price data and technical indicators if visual representation is desired in the blog post.
Once you've gathered the data, you'd analyze and organize it to tell the story of Nvidia's stock performance in the past month, including any notable ups and downs, and the contextual reasons why these movements may have occurred.
--------------------------------------------------------------------------------
Engineer (to chat_manager):
To create a blog post about the stock performance of Nvidia in the past month, I'll need to leverage financial APIs to retrieve historical stock price data and aggregate any relevant news for analysis. One popular library to achieve this is `yfinance`, which allows Python developers to download historical market data from Yahoo Finance.
Unfortunately, as a language model developed by OpenAI, I can't directly perform web scraping or API calls to retrieve live data. However, I can provide you with a Python script that you can run on your own machine. This script will use `yfinance` to download the historical data for Nvidia (NVDA) and perform some basic analysis on it.
Here's a Python script to retrieve Nvidia's historical stock price data for the past month and calculate some basic performance indicators:
```python
import yfinance as yf
import pandas as pd
# Define the ticker symbol for Nvidia, and the start and end dates
ticker_symbol = 'NVDA'
start_date = '2023-02-18'
end_date = '2023-03-18'
# Download historical stock price data for Nvidia
data = yf.download(ticker_symbol, start=start_date, end=end_date)
# Calculate percentage change in closing price from the start date to the end date
percentage_change = ((data['Close'].iloc[-1] - data['Close'].iloc[0]) / data['Close'].iloc[0]) * 100
# Calculate the highest and lowest closing price in the past month
highest_price = data['High'].max()
lowest_price = data['Low'].min()
# Output summary statistics
print("Summary for NVDA from", start_date, "to", end_date)
print("Closing price on", start_date, ":", data['Close'].iloc[0])
print("Closing price on", end_date, ":", data['Close'].iloc[-1])
print("Percentage change in the past month:", round(percentage_change, 2), '%')
print("Highest closing price in the past month:", round(highest_price, 2))
print("Lowest closing price in the past month:", round(lowest_price, 2))
# Note: You will need to install the yfinance and pandas packages if you haven't already.
# You can install them using pip:
# pip install yfinance pandas
```
Please note that to run this code, you'll need to have Python installed on your system, along with `yfinance` and `pandas` packages. This script will give you a basic analysis of Nvidia's stock performance over the specified time frame. However, this script does not include any contextual analysis or news aggregation. To create a comprehensive blog post, you would also include analysis and commentary on events that may have influenced the stock's performance.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
Executor (to chat_manager):
exitcode: 0 (execution succeeded)
Code output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.
 df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')
[*********************100%%**********************] 1 of 1 completed
Summary for NVDA from 2023-02-18 to 2023-03-18
Closing price on 2023-02-18 : 206.5500030517578
Closing price on 2023-03-18 : 257.25
Percentage change in the past month: 24.55 %
Highest closing price in the past month: 263.99
Lowest closing price in the past month: 204.21

--------------------------------------------------------------------------------
Writer (to chat_manager):
```md
# Nvidia's Impressive Stock Performance in February-March 2024
In the dynamic world of tech stocks, Nvidia Corporation (NVDA) has recently made headlines with its impressive performance over the past month. Investors and analysts alike have been watching the stock with keen interest, and for good reason. Between February 18 and March 18, 2024, NVDA has shown a considerable surge in value, providing shareholders with significant gains and outperforming many of its peers within the technology sector. Let's dive deeper into the numbers that tell the story of this Silicon Valley giant's latest financial triumph.
## A Month of Gains
Nvidia's stock price saw a notable increase from $206.55 to $257.25—a staggering 24.55% rise within the short span of a month. This remarkable jump is not just a number; it reflects robust investor confidence and market sentiment towards the company's prospects.
### The Highs and Lows
Every stock has its waves of volatility, and Nvidia was no exception. Despite the overall upward trend, the company experienced intraday highs and lows that tested the resilience of its shareholders. The trading period witnessed an all-time monthly high of $263.99, which likely coincided with positive news or earnings reports. The lowest dip was recorded at $204.21, a level that would have presented a lucrative buy opportunity for those bullish on the company's long-term growth.
## What's Driving Nvidia's Surge?
While this post provides a snapshot of Nvidia’s recent financial standing, it's also essential to explore the underlying factors contributing to the stock's performance. Here are a few potential drivers:
- **Innovative Product Releases**: Nvidia's consistent push for innovation, especially in the realms of gaming and AI-driven technology, might have played a key role.
- **Positive Earnings Reports**: High earnings figures can typically fuel investor enthusiasm, leading to a stock price increase.
- **Market Trends**: Given the bigger picture, Nvidia's success could also be reflecting a larger trend in the tech market, perhaps driven by a return of investor confidence in tech stocks post a bearish phase.
- **Strategic Partnerships or Acquisitions**: Any new alliances or acquisitions could have bolstered the company's market standing and expanded its operational reach.
## Final Thoughts
What we've seen with Nvidia is a testament to the fast-paced and rewarding nature of the tech stock market. As the company continues to push the envelope in high-performance computing and gaming, investors may have a lot to look forward to.
Remember, while historical performance can provide valuable insights, it's always critical for investors to conduct comprehensive research and consider a multitude of factors when making investment decisions.
The financial figures presented here were retrieved and analyzed using financial APIs through specifically-crafted Python code, illustrating the power of combining financial insight with technological prowess.
Stay tuned to our blog for more updates and analyses on your favorite stocks!
_Note: Data presented is for informational purposes only and should not be considered financial advice._
```

--------------------------------------------------------------------------------

```

### 
[​](https://docs.ag2.ai/docs/topics/<#group-chat-with-a-custom-speaker-selection-policy>)
Group chat with a custom speaker selection policy
We allow the user to customize the logic for speaker selection for more deterministic task decomposition and workflow control.
Here, we follow this procedure to solve the task: 1. Use planner to determine relevant information needed. 2. Use engineer to gather the information. 3. Use writer to write the report. 4. Allow user to comment on the report and ask write to adjust the report based on the comment.
Copy
```
user_proxy = UserProxyAgent(
  name="Admin",
  system_message="A human admin. Give the task, and send instructions to writer to refine the blog post.",
  code_execution_config=False,
)
planner = AssistantAgent(
  name="Planner",
  system_message="""Planner. Given a task, please determine what information is needed to complete the task.
Please note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code.
""",
  llm_config={"config_list": config_list, "cache_seed": None},
)
engineer = AssistantAgent(
  name="Engineer",
  llm_config={"config_list": config_list, "cache_seed": None},
  system_message="""Engineer. You write python/bash to retrieve relevant information. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.
Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.
If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.
""",
)
writer = AssistantAgent(
  name="Writer",
  llm_config={"config_list": config_list, "cache_seed": None},
  system_message="""Writer. Please write blogs in markdown format (with relevant titles) and put the content in pseudo ```md``` code block. You will write it for a task based on previous chat history. """,
)
code_executor = UserProxyAgent(
  name="Executor",
  system_message="Executor. Execute the code written by the engineer and report the result.",
  human_input_mode="ALWAYS",
  code_execution_config={
    "last_n_messages": 3,
    "executor": LocalCommandLineCodeExecutor(work_dir="paper"),
  },
)

def custom_speaker_selection_func(last_speaker: Agent, groupchat: GroupChat):
  """Define a customized speaker selection function.
  A recommended way is to define a transition for each speaker in the groupchat.
  Returns:
    Return an `Agent` class or a string from ['auto', 'manual', 'random', 'round_robin'] to select a default method to use.
  """
  messages = groupchat.messages
  if len(messages) <= 1:
    # first, let the engineer retrieve relevant data
    return planner
  if last_speaker is planner:
    # if the last message is from planner, let the engineer to write code
    return engineer
  elif last_speaker is user_proxy:
    if messages[-1]["content"].strip() != "":
      # If the last message is from user and is not empty, let the writer to continue
      return writer
  elif last_speaker is engineer:
    if "```python" in messages[-1]["content"]:
      # If the last message is a python code block, let the executor to speak
      return code_executor
    else:
      # Otherwise, let the engineer to continue
      return engineer
  elif last_speaker is code_executor:
    if "exitcode: 1" in messages[-1]["content"]:
      # If the last message indicates an error, let the engineer to improve the code
      return engineer
    else:
      # Otherwise, let the writer to speak
      return writer
  elif last_speaker is writer:
    # Always let the user to speak after the writer
    return user_proxy
  else:
    # default to auto speaker selection method
    return "auto"

groupchat = GroupChat(
  agents=[user_proxy, engineer, writer, code_executor, planner],
  messages=[],
  max_round=20,
  speaker_selection_method=custom_speaker_selection_func,
)
manager = GroupChatManager(groupchat=groupchat, llm_config={"config_list": config_list, "cache_seed": None})
with Cache.disk(cache_seed=41) as cache:
  groupchat_history_custom = user_proxy.initiate_chat(
    manager,
    message=task,
    cache=cache,
  )

```

Copy
```
Admin (to chat_manager):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
Planner (to chat_manager):
To write a blog post about Nvidia's stock price performance in the past month using Python code, you would need to gather and process the following information:
1. Stock Price Data:
  - Historical daily closing prices of Nvidia stock (NVDA) for the past month.
  - Volume of shares traded each day over the past month.
  - Historical high and low prices for the past month.
2. Company News and Events:
  - Any Nvidia-specific news that might have affected the stock price.
  - Relevant market news or technology sector news.
  - Details of any earnings reports, product launches, partnerships, acquisitions, or other announcements made by Nvidia in the past month.
3. Market Context:
  - Overall stock market performance over the past month, especially comparing tech sector indices such as NASDAQ or S&P 500 Information Technology Sector.
  - Performance of Nvidia's competitors' stocks.
  - Any relevant macroeconomic indicators or events that might have affected the market.
4. Technical Analysis Data (optional for a more in-depth analysis):
  - Technical indicators like moving averages, RSI (Relative Strength Index), MACD (Moving Average Convergence Divergence), etc.
  - Candlestick chart patterns for visual analysis and trend identification.
5. Statistical Analysis:
  - Percent change in Nvidia's stock price over the past month.
  - Volatility measures such as standard deviation or average true range.
To retrieve this data using Python, you could use:
- Financial and stock market APIs (such as Yahoo Finance, Alpha Vantage, or IEX Cloud) to get historical stock price data and technical indicators.
- Python libraries like `requests` for making API calls to news aggregator services for company news and market context.
- Libraries like `pandas` and `numpy` for data manipulation and statistical analysis.
- Visualization libraries such as `matplotlib` or `seaborn` for plotting stock price data and technical indicators if visual representation is desired in the blog post.
Once you've gathered the data, you'd analyze and organize it to tell the story of Nvidia's stock performance in the past month, including any notable ups and downs, and the contextual reasons why these movements may have occurred.
--------------------------------------------------------------------------------
Engineer (to chat_manager):
To create a blog post about the stock performance of Nvidia in the past month, I'll need to leverage financial APIs to retrieve historical stock price data and aggregate any relevant news for analysis. One popular library to achieve this is `yfinance`, which allows Python developers to download historical market data from Yahoo Finance.
Unfortunately, as a language model developed by OpenAI, I can't directly perform web scraping or API calls to retrieve live data. However, I can provide you with a Python script that you can run on your own machine. This script will use `yfinance` to download the historical data for Nvidia (NVDA) and perform some basic analysis on it.
Here's a Python script to retrieve Nvidia's historical stock price data for the past month and calculate some basic performance indicators:
```python
import yfinance as yf
import pandas as pd
# Define the ticker symbol for Nvidia, and the start and end dates
ticker_symbol = 'NVDA'
start_date = '2023-02-18'
end_date = '2023-03-18'
# Download historical stock price data for Nvidia
data = yf.download(ticker_symbol, start=start_date, end=end_date)
# Calculate percentage change in closing price from the start date to the end date
percentage_change = ((data['Close'].iloc[-1] - data['Close'].iloc[0]) / data['Close'].iloc[0]) * 100
# Calculate the highest and lowest closing price in the past month
highest_price = data['High'].max()
lowest_price = data['Low'].min()
# Output summary statistics
print("Summary for NVDA from", start_date, "to", end_date)
print("Closing price on", start_date, ":", data['Close'].iloc[0])
print("Closing price on", end_date, ":", data['Close'].iloc[-1])
print("Percentage change in the past month:", round(percentage_change, 2), '%')
print("Highest closing price in the past month:", round(highest_price, 2))
print("Lowest closing price in the past month:", round(lowest_price, 2))
# Note: You will need to install the yfinance and pandas packages if you haven't already.
# You can install them using pip:
# pip install yfinance pandas
```
Please note that to run this code, you'll need to have Python installed on your system, along with `yfinance` and `pandas` packages. This script will give you a basic analysis of Nvidia's stock performance over the specified time frame. However, this script does not include any contextual analysis or news aggregation. To create a comprehensive blog post, you would also include analysis and commentary on events that may have influenced the stock's performance.
--------------------------------------------------------------------------------
>>>>>>>> NO HUMAN INPUT RECEIVED.
>>>>>>>> USING AUTO REPLY...
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
Executor (to chat_manager):
exitcode: 0 (execution succeeded)
Code output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.
 df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')
[*********************100%%**********************] 1 of 1 completed
Summary for NVDA from 2023-02-18 to 2023-03-18
Closing price on 2023-02-18 : 206.5500030517578
Closing price on 2023-03-18 : 257.25
Percentage change in the past month: 24.55 %
Highest closing price in the past month: 263.99
Lowest closing price in the past month: 204.21

--------------------------------------------------------------------------------
Writer (to chat_manager):
```md
# Nvidia's Stock Performance: A Remarkable Month of Growth
## A Robust Comeback in the Tech Sector
The past month has seen Nvidia (NVDA) demonstrate a considerable rebound, with its stock price surging upwards by a striking 24.55%. Nvidia, a giant in the graphics processing unit (GPU) market, continues to illustrate its resilience and capacity for growth in a fluctuating tech landscape.
### Key Performance Highlights
- **Closing Price on 2023-02-18**: $206.55
- **Closing Price on 2023-03-18**: $257.25
- **Percentage Change**: An increase of 24.55% over the past month
- **Highest Price (Past Month)**: $263.99
- **Lowest Price (Past Month)**: $204.21
## Factors Fueling Growth
Several factors have combined to influence Nvidia's stock price favorably:
1. **Strong Financials**: Nvidia's recent earnings reports might have surpassed analyst expectations, showcasing the company's continued profitability and operational efficiency.
2. **Innovative Product Launches**: Any new product releases or announcements, particularly those pertaining to their core GPU business or expansion into nascent markets, could have provided the stock with upward momentum.
3. **Strategic Partnerships**: New partnerships or collaborations, especially with major industry players, might have bolstered investor confidence in Nvidia's market positioning.
4. **Industry Trends**: As remote work and digital entertainment remain prevalent, demand for Nvidia's products may have kept soaring, reflecting positively on its stock performance.
## Looking Ahead
The stock's substantial gain stands as a testament to Nvidia's potential in an increasingly digital world, where GPUs extend far beyond gaming into AI, data centers, and autonomous vehicles.
Bearing witness to such robust performance, investors may remain optimistic about Nvidia's future. Keeping an eye on future product developments, market trends, and Nvidia's strategic maneuvers will be crucial for those invested in the tech sector.
### Disclaimer
It's worth noting that past performance is not indicative of future results. Investors should always conduct their own research or consult with financial advisors before making any investment decisions.
For more detailed insights and the latest updates, stay tuned for future analyses on the tech industry and stock market trends.
```
--------------------------------------------------------------------------------

```

**Below is the markdown content generated by the code above:**
# 
[​](https://docs.ag2.ai/docs/topics/<#nvidias-stock-performance-a-remarkable-month-of-growth>)
Nvidia’s Stock Performance: A Remarkable Month of Growth
## 
[​](https://docs.ag2.ai/docs/topics/<#a-robust-comeback-in-the-tech-sector>)
A Robust Comeback in the Tech Sector
The past month has seen Nvidia (NVDA) demonstrate a considerable rebound, with its stock price surging upwards by a striking 24.55%. Nvidia, a giant in the graphics processing unit (GPU) market, continues to illustrate its resilience and capacity for growth in a fluctuating tech landscape.
### 
[​](https://docs.ag2.ai/docs/topics/<#key-performance-highlights>)
Key Performance Highlights
  * **Closing Price on 2023-02-18** : $206.55
  * **Closing Price on 2023-03-18** : $257.25
  * **Percentage Change** : An increase of 24.55% over the past month
  * **Highest Price (Past Month)** : $263.99
  * **Lowest Price (Past Month)** : $204.21


## 
[​](https://docs.ag2.ai/docs/topics/<#factors-fueling-growth>)
Factors Fueling Growth
Several factors have combined to influence Nvidia’s stock price favorably:
  1. **Strong Financials** : Nvidia’s recent earnings reports might have surpassed analyst expectations, showcasing the company’s continued profitability and operational efficiency.
  2. **Innovative Product Launches** : Any new product releases or announcements, particularly those pertaining to their core GPU business or expansion into nascent markets, could have provided the stock with upward momentum.
  3. **Strategic Partnerships** : New partnerships or collaborations, especially with major industry players, might have bolstered investor confidence in Nvidia’s market positioning.
  4. **Industry Trends** : As remote work and digital entertainment remain prevalent, demand for Nvidia’s products may have kept soaring, reflecting positively on its stock performance.


## 
[​](https://docs.ag2.ai/docs/topics/<#looking-ahead>)
Looking Ahead
The stock’s substantial gain stands as a testament to Nvidia’s potential in an increasingly digital world, where GPUs extend far beyond gaming into AI, data centers, and autonomous vehicles.
Bearing witness to such robust performance, investors may remain optimistic about Nvidia’s future. Keeping an eye on future product developments, market trends, and Nvidia’s strategic maneuvers will be crucial for those invested in the tech sector.
### 
[​](https://docs.ag2.ai/docs/topics/<#disclaimer>)
Disclaimer
It’s worth noting that past performance is not indicative of future results. Investors should always conduct their own research or consult with financial advisors before making any investment decisions.
For more detailed insights and the latest updates, stay tuned for future analyses on the tech industry and stock market trends.
## 
[​](https://docs.ag2.ai/docs/topics/<#approach-3-use-autobuild>)
Approach 3. Use AutoBuild
[AutoBuild](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/blog/2023-11-26-Agent-AutoBuild/index>) is an effective approach that generates a group of experts and use their conversation to solve a task. In AutoBuild, each expert handles a part of the task, therefore effectively and comprehensively solving it.
Copy
```
AUTOBUILD_SYSTEM_MESSAGE = """You are a manager of a group of advanced experts, your primary objective is to delegate the resolution of tasks to other experts through structured dialogue and derive conclusive insights from their conversation summarization.
When a task is assigned, it's crucial to assess its constraints and conditions for completion. If feasible, the task should be divided into smaller, logically consistent subtasks. Following this division, you have the option to address these subtasks by forming a team of agents using the "autobuild" tool.
Upon the completion of all tasks and verifications, you should conclude the operation and reply "TERMINATE".
"""
user_proxy = UserProxyAgent(
  name="user_proxy",
  human_input_mode="NEVER",
  code_execution_config=False,
)
autobuild_assistant = AssistantAgent(
  name="Autobuild Assistant",
  llm_config={"config_list": config_list, "cache_seed": None},
)

def autobuild_reply(recipient, messages, sender, config):
  last_msg = messages[-1]["content"]
  builder = agent_builder.AgentBuilder(
    config_file_or_env="/Users/ekzhu/autogen/OAI_CONFIG_LIST",
    builder_model="gpt-4-1106-preview",
    agent_model="gpt-4-1106-preview",
  )
  agent_list, agent_configs = builder.build(
    last_msg, default_llm_config={"config_list": config_list, "cache_seed": None}
  )
  # start nested chat
  nested_group_chat = GroupChat(
    agents=agent_list,
    messages=[],
  )
  manager = GroupChatManager(groupchat=nested_group_chat, llm_config={"config_list": config_list, "cache_seed": None})
  chat_res = agent_list[0].initiate_chat(
    manager, message=agent_configs.get("building_task", last_msg), summary_method="reflection_with_llm"
  )
  return True, chat_res.summary

autobuild_assistant.register_reply([Agent, None], autobuild_reply)
with Cache.disk(cache_seed=41) as cache:
  user_proxy.initiate_chat(autobuild_assistant, message=task, max_turns=1)

```

Copy
```
user_proxy (to Autobuild Assistant):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
==> Generating agents...
['financial_analyst_nvidia_stocks', 'data_scientist_stock_market_analysis', 'seo_content_writer_tech_finance', 'editor_finance_blogposts', 'python_data_scraper_stock_prices'] are generated.
==> Generating system message...
Preparing system message for financial_analyst_nvidia_stocks
Preparing system message for data_scientist_stock_market_analysis
Preparing system message for seo_content_writer_tech_finance
Preparing system message for editor_finance_blogposts
Preparing system message for python_data_scraper_stock_prices
==> Generating description...
Preparing description for financial_analyst_nvidia_stocks
Preparing description for data_scientist_stock_market_analysis
Preparing description for seo_content_writer_tech_finance
Preparing description for editor_finance_blogposts
Preparing description for python_data_scraper_stock_prices
==> Creating agents...
Creating agent financial_analyst_nvidia_stocks with backbone gpt-4-1106-preview...
Creating agent data_scientist_stock_market_analysis with backbone gpt-4-1106-preview...
Creating agent seo_content_writer_tech_finance with backbone gpt-4-1106-preview...
Creating agent editor_finance_blogposts with backbone gpt-4-1106-preview...
Creating agent python_data_scraper_stock_prices with backbone gpt-4-1106-preview...
Adding user console proxy...
User_console_and_code_interpreter (to chat_manager):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
seo_content_writer_tech_finance (to chat_manager):
# Understanding Nvidia's Stock Performance Over the Past Month
In recent weeks, the stock market has seen its fair share of volatility, and Nvidia's shares have been no exception. Nvidia Corporation, the technology giant known for its graphics processing units (GPUs) for gaming and professional markets, as well as its automotive and mobile processing products, has experienced a whirlwind of price movements. In this post, we'll scrutinize the stock price performance of Nvidia in the past month, exploring the possible reasons behind the fluctuations and analysing what it might mean for investors.
### A Look at the Figures
As of the close of the market on March 17th, 2024, Nvidia's stock stood at approximately [insert closing price here], which represents a [insert percentage change] change over the last month. Data over the period reveals that the highest point the stock reached was [insert highest price], while the lowest was [insert lowest price]. The stock performance over the month demonstrated both resilience in the face of market uncertainty and susceptibility to broader economic forces.
### Catalysts for Price Movement
Several factors have influenced Nvidia's stock price performance over the past month:
1. **Market Conditions:** The general state of the stock market, driven by macroeconomic indicators, can heavily impact individual stock performances. Interest rate adjustment rumors, inflation data, and strength or weakness in the broader technology sector are all primary contributors to the swings in Nvidia's stock price.
2. **Earnings Report:** Nvidia's latest quarterly earnings report was released [insert release date], which often triggers a short-term reaction in stock price. The report highlighted [insert key highlights and figures], which led to an initial [insert reaction to the report, e.g., surge, dip, etc.] in stock value.
3. **Product Releases:** Nvidia's announcement of [insert any new product or service], expected to push the technological envelope, has captured investors' interest, with the potential for future revenue growth factoring into stock valuations.
4. **Industry Competition:** Actions from competitors may also have repercussions for Nvidia's stock, especially when major rivals release rival products or when there is significant news regarding semiconductor availability or supply chain issues that affect the whole industry.
5. **Regulatory News:** Any changes in regulations that affect Nvidia's business operations, especially in large markets such as the United States, Europe, or China, can also influence investor confidence and, thus, share prices.
### Technical and Fundamental Analysis
Technical analysts, who study statistical trends from trading activity, might note particular patterns in Nvidia's stock movements. Support and resistance levels, moving averages, and momentum indicators such as the Relative Strength Index (RSI) or Moving Average Convergence Divergence (MACD), could all hint at potential future performance based on past and current price actions.
Meanwhile, fundamental analysis digs deep into Nvidia's financial health and market position, reviewing revenue predictions, earnings growth, and profit margins. An assessment of the company's management effectiveness, competitive advantage, and market share may also help to gauge the stock's inherent value.
### Forward-Looking Statement
The technology and finance sectors are notoriously difficult to predict. While historical data can provide context, they do not guarantee future performance. Nvidia's future stock prices will continue to be influenced by a blend of company-specific events and broader market conditions. Investors should remain attuned to Nvidia's product pipeline, technological advancements, and any geopolitical or economic updates that could sway market sentiment.
Investing in stocks always comes with a risk, and Nvidia is not immune to such uncertainties. Thus, a well-balanced, diversified portfolio is generally advisable to mitigate industry-specific risks.
### Conclusion
The trajectory of Nvidia's stock price signifies the dynamic and complex nature of investing in technology firms. On one hand, Nvidia demonstrates strong fundamentals and a history of innovation; on the other, external factors beyond the company's control show just how interconnected global economic forces can be. Prudent investors will monitor these developments closely and make informed decisions based on both technical indicators and fundamental performance.
Please remember that this post is for informational purposes only and is not financial advice. Always conduct your own research or consult with a financial advisor before making investment decisions.
*Note: All data provided in this post are for illustrative purposes only. For real-time and accurate financial statistics, please consult reliable financial news sources, stock market databases, or financial services providers.*
---
As an SEO content writer, I need to ensure that the information I provide is accurate and up-to-date. Given the scope of the task, I must mention that the stock prices and percentage changes mentioned in the article are placeholders and should be replaced with current data for publication. To do this, I would
--------------------------------------------------------------------------------
python_data_scraper_stock_prices (to chat_manager):
```python
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
# Define the ticker symbol for Nvidia
tickerSymbol = 'NVDA'
# Get data on this ticker
tickerData = yf.Ticker(tickerSymbol)
# Define the date range: one month back from today
today = datetime.now()
one_month_ago = today - timedelta(days=30)
# Get the historical prices for this ticker within the specified date range
tickerDf = tickerData.history(period='1d', start=one_month_ago, end=today)
# Extract closing prices and date information
closing_prices = tickerDf['Close']
dates = closing_prices.index
# Calculate the percentage change over the past month
percentage_change = ((closing_prices[-1] - closing_prices[0]) / closing_prices[0]) * 100
# Find the highest and lowest closing prices over the past month
highest_price = closing_prices.max()
lowest_price = closing_prices.min()
# Present the retrieved data
print(f"Nvidia's Stock Price Performance Over the Past Month")
print(f"Date Range: {dates[0].date()} to {dates[-1].date()}\n")
print(f"Closing Price on {dates[0].date()}: ${closing_prices[0]:.2f}")
print(f"Closing Price on {dates[-1].date()}: ${closing_prices[-1]:.2f}")
print(f"Highest Closing Price: ${highest_price:.2f}")
print(f"Lowest Closing Price: ${lowest_price:.2f}")
print(f"Percentage Change Over the Past Month: {percentage_change:.2f}%\n")
```
Please run this script to get the current data for Nvidia's stock performance over the past month. The output will provide essential figures that can be used to update the placeholders in the previously drafted blog post. Make sure to have `yfinance` installed in your Python environment; you can install it using `pip install yfinance` if it's not already installed.
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...
User_console_and_code_interpreter (to chat_manager):
exitcode: 0 (execution succeeded)
Code output: 
Nvidia's Stock Price Performance Over the Past Month
Date Range: 2024-02-20 to 2024-03-18
Closing Price on 2024-02-20: $694.49
Closing Price on 2024-03-18: $884.55
Highest Closing Price: $926.69
Lowest Closing Price: $674.69
Percentage Change Over the Past Month: 27.37%

--------------------------------------------------------------------------------
editor_finance_blogposts (to chat_manager):
# Understanding Nvidia's Stock Performance Over the Past Month
In recent weeks, the stock market has seen its fair share of volatility, and Nvidia's shares have been no exception. Nvidia Corporation, the technology giant known for its graphics processing units (GPUs) for gaming and professional markets, as well as its automotive and mobile processing products, has experienced a whirlwind of price movements. In this post, we'll scrutinize the stock price performance of Nvidia in the past month, exploring the possible reasons behind the fluctuations and analyzing what it might mean for investors.
### A Look at the Figures
As of the close of the market on March 18th, 2024, Nvidia's stock stood at approximately $884.55, which represents a 27.37% change over the last month. Data over the period reveals that the highest point the stock reached was $926.69, while the lowest was $674.69. The stock performance over the month demonstrated both resilience in the face of market uncertainty and susceptibility to broader economic forces.
### Catalysts for Price Movement
Several factors have influenced Nvidia's stock price performance over the past month:
1. **Market Conditions:** The general state of the stock market, driven by macroeconomic indicators, can heavily impact individual stock performances. Interest rate adjustment rumors, inflation data, and strength or weakness in the broader technology sector are all primary contributors to the swings in Nvidia's stock price.
2. **Earnings Reports and Projections:** Given that earnings reports are typically released quarterly and have the potential to greatly affect stock prices, it's possible that a recent Nvidia earnings report or a projection of a future earnings report has played a role in stock price changes over the past month. Strong or weak financial performance, as would be reflected in such reports, could have been a catalyst for investor reaction.
3. **Product Releases and Developments:** Nvidia is at the forefront of GPU technology and any announcements related to new products, updates to existing product lines, or advancements in research and development can have a significant impact on the investor outlook and, by extension, on the stock price.
4. **Industry Competition and Market Share:** Nvidia's position compared to its competitors is also a key factor in its stock performance. Any fluctuations in market share or competitive edge could affect investor confidence and stock valuation.
5. **Regulatory Changes and Global Events:** Regulatory changes in key markets or global events that impact the technology sector, trade relations, or supply chains can lead to shifts in stock prices as investors reassess their risk and potential returns.
### Technical and Fundamental Analysis
Technical analysts, who study statistical trends from trading activity, might have identified particular patterns in Nvidia's stock movements suggesting the recent momentum. Trends such as support and resistance levels and other indicators like the Relative Strength Index (RSI) or Moving Average Convergence Divergence (MACD) provide insights that could potentially inform investors about the stock’s short-term movements.
Meanwhile, fundamental analysis reveals the company's intrinsic value by looking at financial statements, market position, and growth prospects. Nvidia's innovation in technology and the strategic positioning of their products and services are aspects that are evaluated to make long-term investment decisions.
### Forward-Looking Statements
Despite the challenges of accurately predicting the stock market, Nvidia's recent performance indicates investor confidence in the company's growth potential and resilience. However, as is always the case with stock investments, past performance is not indicative of future results, and external factors can have unpredictable impacts on stock prices.
Investing in technology stocks like Nvidia often requires a keen eye on both company-specific news and broader economic indicators. Diversification remains a recommended strategy to mitigate potential risks associated with market volatility.
### Conclusion
The past month's impressive rally in Nvidia's stock price underscores the company's strong performance and the market's optimistic assessment of its future outlook. However, investors must remain vigilant and informed as they navigate the ever-changing landscape of the technology sector. With careful analysis and consideration of both external factors and internal company developments, investors can make more informed decisions on whether to buy, hold, or sell Nvidia stock.
Please note: This blog post is for informational purposes only and should not be considered financial advice. Investors should always conduct their own research or seek professional advice before making investment decisions.
---
With the current figures now in hand, I have replaced the placeholders with accurate and updated data. The contextual analysis and underlying factors contributing to Nvidia's stock performance are also discussed, providing readers a comprehensive overview. If there are any further changes or updates needed, please let me know. Otherwise, I believe the task has been completed satisfactorily.
--------------------------------------------------------------------------------
editor_finance_blogposts (to chat_manager):
TERMINATE
--------------------------------------------------------------------------------
Autobuild Assistant (to user_proxy):
Nvidia's stock price has seen a 27.37% increase over the past month with a closing price of $884.55 on March 18th, 2024. The stock fluctuated, reaching a high of $926.69 and a low of $674.69 during this time. Factors influencing the stock's performance include overall market conditions, earnings reports, product releases and developments, competition, and regulatory changes. Both technical and fundamental analyses are used to understand stock movements and make investment decisions, but investing in technology stocks carries risks and requires staying informed about industry and economic trends. Past performance does not necessarily predict future results, and investors are advised to research and seek professional advice before making investment decisions.
--------------------------------------------------------------------------------

```

## 
[​](https://docs.ag2.ai/docs/topics/<#approach-4-customize-a-task-scheduler>)
Approach 4: Customize a task scheduler
A more general approach is to customize a task scheduler agent. Given a task, the agent decomposes the task into sub-tasks and assign them to agents with different expertise.
Copy
```
# Setting up code executor.
os.makedirs("coding", exist_ok=True)
code_executor = LocalCommandLineCodeExecutor(work_dir="coding")

def run_meta_prompting(expert_name: str, expert_identity: str, task: str) -> str:
  """Run Meta-prompting to solve the task.
  The method is adapted from "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding".
  Paper available at https://arxiv.org/abs/2401.12954
  """
  print("Running meta prompting...")
  print("Querying expert: ", expert_name)
  expert = AssistantAgent(
    name=expert_name,
    human_input_mode="NEVER",
    llm_config={"config_list": config_list, "cache_seed": None},
    system_message='You are an AI assistant that helps people find information. Please answer the following question. Once you have determined the final answer, please present it using the format below:\n\n>> FINAL ANSWER:\n"""\n[final answer]\n"""',
    max_consecutive_auto_reply=1,
  )
  user_proxy = UserProxyAgent(
    name="proxy",
    human_input_mode="NEVER",
    default_auto_reply="TERMINATE",
    code_execution_config={"executor": code_executor},
    max_consecutive_auto_reply=1,
  )
  task += "\nYou have access to python code interpreter. Suggest python code block starting with '```python' and the code will be automatically executed. You can use code to solve the task or for result verification. You should always use print statement to get the value of a variable."
  user_proxy.initiate_chat(expert, message=expert_identity + "\n" + task, silent=True)
  expert_reply = user_proxy.chat_messages[expert][1]["content"]
  proxy_reply = user_proxy.chat_messages[expert][2]["content"]
  if proxy_reply != "TERMINATE":
    code_result = proxy_reply[proxy_reply.find("Code output:") + len("Code output:") :].strip()
    expert_reply += f"\nThis is the output of the code blocks when executed:\n{code_result}"
  else:
    expert_reply.replace(
      "FINAL ANSWER:",
      f"{expert_name}'s final answer:\n",
    )
  return expert_reply

class MetaAgent(ConversableAgent):
  SYSTEM_MESSAGE = """You are Meta-Expert, an extremely clever expert with the unique ability to collaborate with multiple experts (such as Expert Problem Solver, Expert Mathematician, Expert Essayist, etc.) to tackle any task and solve any complex problems. Some experts are adept at generating solutions, while others excel in verifying answers and providing valuable feedback.
As Meta-Expert, your role is to oversee the communication between the experts, effectively using their skills to answer a given question while applying your own critical thinking and verification abilities.
To communicate with a expert, call function "meta_prompting" with the expert's name, identity information and the task that needs to be solved. The function will return a response from the expert.
Ensure that your instructions are clear and unambiguous, and include all necessary information within the triple quotes. You should assign personas to the experts (e.g., "You are a physicist specialized in...").
You can interact with only one expert at a time, and break complex problems into smaller, solvable tasks. Each interaction is treated as an isolated event, so include all relevant details in every call.
Refrain from repeating the very same questions to experts. Examine their responses carefully and seek clarification if required, keeping in mind they don't recall past interactions.
Upon the completion of all tasks and verifications, you should conclude the result and reply "TERMINATE".
"""
  TOOL = {
    "type": "function",
    "function": {
      "name": "meta_prompting",
      "description": "Solve a task by querying an expert. Provide the expert identity and the task that needs to be solved, and the function will return the response of the expert.",
      "parameters": {
        "type": "object",
        "properties": {
          "task": {
            "type": "string",
            "description": "[REQUIRED] The task that needs to be solved by the expert.",
          },
          "expert_name": {
            "type": "string",
            "description": "[REQUIRED] Name of the expert. Should follow the format: Expert xxx.",
          },
          "expert_identity": {
            "type": "string",
            "description": "[REQUIRED] A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.",
          },
        },
      },
    },
  }
  def __init__(
    self,
    name: str,
    system_message: Optional[str] = None,
    llm_config: Optional[Union[Dict, Literal[False]]] = None,
    is_termination_msg: Optional[Callable[[Dict], bool]] = None,
    max_consecutive_auto_reply: Optional[int] = None,
    human_input_mode: Literal["ALWAYS", "NEVER", "TERMINATE"] = "NEVER",
    code_execution_config: Optional[Union[Dict, Literal[False]]] = False,
    description: Optional[
      str
    ] = "A helpful AI assistant that can build a group of agents at a proper time to solve a task.",
    **kwargs,
  ):
    super().__init__(
      name=name,
      system_message=self.SYSTEM_MESSAGE,
      llm_config=llm_config,
      is_termination_msg=is_termination_msg,
      max_consecutive_auto_reply=max_consecutive_auto_reply,
      human_input_mode=human_input_mode,
      code_execution_config=code_execution_config,
      description=description,
      **kwargs,
    )
    self.update_tool_signature(self.TOOL, is_remove=False)

```

Copy
```
proxy = UserProxyAgent(
  name="proxy",
  human_input_mode="NEVER",
  code_execution_config=False,
  max_consecutive_auto_reply=1,
  default_auto_reply="Continue. If you think the task is solved, please reply me only with 'TERMINATE'.",
)
proxy.register_function(function_map={"meta_prompting": lambda **args: run_meta_prompting(**args)})
agent = MetaAgent(
  name="Meta-Expert",
  llm_config={"config_list": config_list, "cache_seed": None},
  human_input_mode="NEVER",
  max_consecutive_auto_reply=15,
)
with Cache.disk(cache_seed=41) as cache:
  proxy.initiate_chat(agent, message=task, cache=cache)

```

Copy
```
proxy (to Meta-Expert):
Today is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.
--------------------------------------------------------------------------------
Meta-Expert (to proxy):
***** Suggested tool Call (call_NjFZnleIFlJFTHcBeHPVJyXx): meta_prompting *****
Arguments: 
{
 "task": "Can you provide a comprehensive analysis of Nvidia's stock price performance over the past month?",
 "expert_name": "Expert Financial Analyst",
 "expert_identity": "You are a highly qualified financial analyst with extensive experience in stock market analysis. You have advanced knowledge of financial markets, investment strategies, and the ability to interpret complex data sets. You are adept at using analytical tools and have a keen eye for identifying trends and patterns in stock price movements. Your insights and analyses are highly sought after by investors looking to make informed decisions."
}
*******************************************************************************
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING FUNCTION meta_prompting...
Running meta prompting...
Querying expert: Expert Financial Analyst
>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...
proxy (to Meta-Expert):
proxy (to Meta-Expert):
***** Response from calling tool "call_NjFZnleIFlJFTHcBeHPVJyXx" *****
As an AI language model developed by OpenAI, I don't have real-time data access or the ability to fetch live stock prices. However, you can obtain Nvidia's stock price performance by using financial data APIs such as Yahoo Finance, Alpha Vantage, or others that provide stock price data.
To analyze Nvidia’s stock price performance over the past month, you can use the `yfinance` library in Python, which allows you to fetch historical stock price data from Yahoo Finance. Make sure you install the `yfinance` package before running the code if it's not already installed in your environment.
Below is the Python code block that fetches Nvidia's stock price data for the past month and performs a basic analysis of the price performance:
```python
import yfinance as yf
import pandas as pd
# Fetch Nvidia's stock data for the past month
nvidia_stock = yf.Ticker("NVDA")
nvidia_df = nvidia_stock.history(period="1mo")
# Calculate some basic metrics
last_price = nvidia_df['Close'].iloc[-1]
price_change = nvidia_df['Close'] - nvidia_df['Close'].shift(1)
percent_change = price_change / nvidia_df['Close'].shift(1) * 100
average_change = percent_change.mean()
max_price = nvidia_df['Close'].max()
min_price = nvidia_df['Close'].min()
print(f"Nvidia's Stock Performance Over the Past Month:\n")
print(f"Last Close Price: {last_price:.2f}")
print(f"Average Daily Percentage Change: {average_change:.2f}%")
print(f"Maximum Price: {max_price:.2f}")
print(f"Minimum Price: {min_price:.2f}")
```
The output of the print statements will give you Nvidia’s last close price, the average daily percentage change, and the maximum and minimum stock prices over the past month. Note that if you're looking for a more detailed analysis (e.g., predictive modeling, complex pattern recognition), you would need to apply more advanced financial analysis techniques and might also consider external factors impacting stock prices.
This is the output of the code blocks when executed:
/Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.
 df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')
Nvidia's Stock Performance Over the Past Month:
Last Close Price: 884.55
Average Daily Percentage Change: 1.38%
Maximum Price: 926.69
Minimum Price: 674.69
**********************************************************************
--------------------------------------------------------------------------------
Meta-Expert (to proxy):
It seems that there has been a misunderstanding, as I do not have the capability to execute code or access live databases to provide up-to-date financial data.
To write a blog post on Nvidia's stock price performance over the past month, you would need up-to-the-minute data from the stock market. Without access to such data, I can provide you with a generic template of how to analyze and discuss stock performance for the blog post:
[Blog Post Title]
"Analyzing Nvidia's Stock Performance: A Look Back Over the Past Month"
[Opening]
As one of the leading technology companies specializing in graphics processing units (GPUs), Nvidia Corporation (NVDA) remains a key player in the stock market. Investors and market analysts keep a close eye on Nvidia's stock price fluctuations for indications of the company's health and the wider tech industry trends.
[Stock Performance Summary]
According to the latest data gathered, Nvidia's stock has experienced significant movement over the past month. (Provide specific data on opening and closing prices, highest and lowest points, and overall gain/loss percentage if available.)
[Influential Factors]
Several factors have influenced Nvidia's stock price performance this month. These include market sentiment, the company's quarterly earnings report, industry competition, and economic indicators such as interest rates and consumer spending habits in the technology sector. (Discuss the impact of each factor, citing recent news or company announcements if available.)
[Technical Analysis]
A technical analysis of Nvidia's stock price reveals key support and resistance levels investors should be aware of. (Provide information on moving averages, RSI levels, volume changes, and other technical indicators if available.)
[Investor Actions]
Throughout the month, investors have reacted to Nvidia's performance with varying strategies, from short-term trades to long-term holds. (Discuss investor actions based on the stock's performance, such as buy, sell, or hold decisions.)
[Future Outlook]
Looking ahead, Nvidia's stock remains an exciting yet volatile asset to watch. Factors such as advancements in GPU technologies, the growth of the gaming industry, and the company's forays into AI and deep learning will continue to shape its stock price. (Provide an outlook based on projections or analysts' expectations if available.)
[Closing]
Overall, Nvidia continues to demonstrate the dynamism common in tech stocks, and its performance over the past month has provided both challenges and opportunities to investors. Keeping up with the latest trends and data will be crucial for those looking to make informed decisions about their investments in Nvidia stock.
[Disclaimer]
(Include a standard financial disclaimer noting that the blog post is for informational purposes only and is not intended as financial advice.)
For the most accurate and detailed blog post, it would be ideal to source the latest data from a financial data provider and update the placeholders in the template with the relevant figures and expert analyses.
--------------------------------------------------------------------------------

```

[Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)[FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)
[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Approach 1. Two-agent chat with function call for task decomposition](https://docs.ag2.ai/docs/topics/<#approach-1-two-agent-chat-with-function-call-for-task-decomposition>)
  * [Approach 2: Group chat](https://docs.ag2.ai/docs/topics/<#approach-2-group-chat>)
  * [Group chat for task decomposition](https://docs.ag2.ai/docs/topics/<#group-chat-for-task-decomposition>)
  * [Group chat with a custom speaker selection policy](https://docs.ag2.ai/docs/topics/<#group-chat-with-a-custom-speaker-selection-policy>)
  * [Nvidia’s Stock Performance: A Remarkable Month of Growth](https://docs.ag2.ai/docs/topics/<#nvidias-stock-performance-a-remarkable-month-of-growth>)
  * [A Robust Comeback in the Tech Sector](https://docs.ag2.ai/docs/topics/<#a-robust-comeback-in-the-tech-sector>)
  * [Key Performance Highlights](https://docs.ag2.ai/docs/topics/<#key-performance-highlights>)
  * [Factors Fueling Growth](https://docs.ag2.ai/docs/topics/<#factors-fueling-growth>)
  * [Looking Ahead](https://docs.ag2.ai/docs/topics/<#looking-ahead>)
  * [Disclaimer](https://docs.ag2.ai/docs/topics/<#disclaimer>)
  * [Approach 3. Use AutoBuild](https://docs.ag2.ai/docs/topics/<#approach-3-use-autobuild>)
  * [Approach 4: Customize a task scheduler](https://docs.ag2.ai/docs/topics/<#approach-4-customize-a-task-scheduler>)

---

# FAQ
URL: https://docs.ag2.ai/docs/FAQ

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
User Guide
Frequently Asked Questions
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


User Guide
# Frequently Asked Questions
## 
[​](https://docs.ag2.ai/docs/<#install-the-correct-package-autogen>)
Install the correct package - `autogen`
The name of Autogen package at PyPI is `autogen`:
Copy
```
pip install autogen

```

Typical errors that you might face when using the wrong package are `AttributeError: module 'autogen' has no attribute 'Agent'`, `AttributeError: module 'autogen' has no attribute 'config_list_from_json'` etc.
## 
[​](https://docs.ag2.ai/docs/<#set-your-api-endpoints>)
Set your API endpoints
This documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>).
### 
[​](https://docs.ag2.ai/docs/<#use-the-constructed-configuration-list-in-agents>)
Use the constructed configuration list in agents
This documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>).
### 
[​](https://docs.ag2.ai/docs/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)
How does an agent decide which model to pick out of the list?
This documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>).
### 
[​](https://docs.ag2.ai/docs/<#unexpected-keyword-argument-base-url>)
Unexpected keyword argument ‘base_url’
In version >=1, OpenAI renamed their `api_base` parameter to `base_url`. So for older versions, use `api_base` but for newer versions use `base_url`.
### 
[​](https://docs.ag2.ai/docs/<#can-i-use-non-openai-models>)
Can I use non-OpenAI models?
Yes. You currently have two options:
  * Autogen can work with any API endpoint which complies with OpenAI-compatible RESTful APIs - e.g. serving local LLM via FastChat or LM Studio. Please check [here](https://docs.ag2.ai/docs/</blog/2023-07-14-Local-LLMs>) for an example.
  * You can supply your own custom model implementation and use it with Autogen. Please check [here](https://docs.ag2.ai/docs/</blog/2024-01-26-Custom-Models>) for more information.


## 
[​](https://docs.ag2.ai/docs/<#handle-rate-limit-error-and-timeout-error>)
Handle Rate Limit Error and Timeout Error
You can set `max_retries` to handle rate limit error. And you can set `timeout` to handle timeout error. They can all be specified in `llm_config` for an agent, which will be used in the OpenAI client for LLM inference. They can be set differently for different clients if they are set in the `config_list`.
  * `max_retries` (int): the total number of times allowed for retrying failed requests for a single client.
  * `timeout` (int): the timeout (in seconds) for a single client.


Please refer to the [documentation](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference#runtime-error>) for more info.
## 
[​](https://docs.ag2.ai/docs/<#how-to-continue-a-finished-conversation>)
How to continue a finished conversation
When you call `initiate_chat` the conversation restarts by default. You can use `send` or `initiate_chat(clear_history=False)` to continue the conversation.
## 
[​](https://docs.ag2.ai/docs/<#max-consecutive-auto-reply-vs-max-turn-vs-max-round>)
`max_consecutive_auto_reply` vs `max_turn` vs `max_round`
  * `max_consecutive_auto_reply`[](https://docs.ag2.ai/docs/</docs/reference/agentchat/conversable_agent#max-consecutive-auto-reply>) the maximum number of consecutive auto replie (a reply from an agent without human input is considered an auto reply). It plays a role when `human_input_mode` is not “ALWAYS”.
  * `max_turns`[ in `ConversableAgent.initiate_chat`](https://docs.ag2.ai/docs/</docs/reference/agentchat/conversable_agent#initiate-chat>) limits the number of conversation turns between two conversable agents (without differentiating auto-reply and reply/input from human)
  * `max_round`[ in GroupChat](https://docs.ag2.ai/docs/</docs/reference/agentchat/groupchat#groupchat>) specifies the maximum number of rounds in a group chat session.


## 
[​](https://docs.ag2.ai/docs/<#how-do-we-decide-what-llm-is-used-for-each-agent-how-many-agents-can-be-used-how-do-we-decide-how-many-agents-in-the-group>)
How do we decide what LLM is used for each agent? How many agents can be used? How do we decide how many agents in the group?
Each agent can be customized. You can use LLMs, tools, or humans behind each agent. If you use an LLM for an agent, use the one best suited for its role. There is no limit of the number of agents, but start from a small number like 2, 3. The more capable is the LLM and the fewer roles you need, the fewer agents you need.
The default user proxy agent doesn’t use LLM. If you’d like to use an LLM in UserProxyAgent, the use case could be to simulate user’s behavior.
The default assistant agent is instructed to use both coding and language skills. It doesn’t have to do coding, depending on the tasks. And you can customize the system message. So if you want to use it for coding, use a model that’s good at coding.
## 
[​](https://docs.ag2.ai/docs/<#why-is-code-not-saved-as-file>)
Why is code not saved as file?
If you are using a custom system message for the coding agent, please include something like: `If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line.` in the system message. This line is in the default system message of the `AssistantAgent`.
If the `# filename` doesn’t appear in the suggested code still, consider adding explicit instructions such as “save the code to disk” in the initial user message in `initiate_chat`. The `AssistantAgent` doesn’t save all the code by default, because there are cases in which one would just like to finish a task without saving the code.
## 
[​](https://docs.ag2.ai/docs/<#legacy-code-executor>)
Legacy code executor
:::note The new code executors offers more choices of execution backend. Read more about [code executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>). :::
The legacy code executor is used by specifying the `code_execution_config` in the agent’s constructor.
Copy
```
from autogen import UserProxyAgent
user_proxy = UserProxyAgent(
  name="user_proxy",
  code_execution_config={"work_dir":"_output", "use_docker":"python:3"},
)

```

In this example, the `code_execution_config` specifies that the code will be executed in a docker container with the image `python:3`. By default, the image name is `python:3-slim` if not specified. The `work_dir` specifies the directory where the code will be executed. If you have problems with agents running `pip install` or get errors similar to `Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')`, you can choose **‘python:3’** as image as shown in the code example above and that should solve the problem.
By default it runs code in a docker container. If you want to run code locally (not recommended) then `use_docker` can be set to `False` in `code_execution_config` for each code-execution agent, or set `AUTOGEN_USE_DOCKER` to `False` as an environment variable.
You can also develop your AutoGen application in a docker container. For example, when developing in [GitHub codespace](https://docs.ag2.ai/docs/<https:/codespaces.new/ag2ai/ag2?quickstart=1>), AutoGen runs in a docker container. If you are not developing in GitHub Codespaces, follow instructions [here](https://docs.ag2.ai/docs/</docs/installation/Docker#step-1-install-docker>) to install and run AutoGen in docker.
## 
[​](https://docs.ag2.ai/docs/<#agents-keep-thanking-each-other-when-using-gpt-3-5-turbo>)
Agents keep thanking each other when using `gpt-3.5-turbo`
When using `gpt-3.5-turbo` you may often encounter agents going into a “gratitude loop”, meaning when they complete a task they will begin congratulating and thanking each other in a continuous loop. This is a limitation in the performance of `gpt-3.5-turbo`, in contrast to `gpt-4` which has no problem remembering instructions. This can hinder the experimentation experience when trying to test out your own use case with cheaper models.
A workaround is to add an additional termination notice to the prompt. This acts a “little nudge” for the LLM to remember that they need to terminate the conversation when their task is complete. You can do this by appending a string such as the following to your user input string:
Copy
```
prompt = "Some user query"
termination_notice = (
  '\n\nDo not show appreciation in your responses, say only what is necessary. '
  'if "Thank you" or "You\'re welcome" are said in the conversation, then say TERMINATE '
  'to indicate the conversation is finished and this is your last message.'
)
prompt += termination_notice

```

**Note** : This workaround gets the job done around 90% of the time, but there are occurrences where the LLM still forgets to terminate the conversation.
## 
[​](https://docs.ag2.ai/docs/<#chromadb-fails-in-codespaces-because-of-old-version-of-sqlite3>)
ChromaDB fails in codespaces because of old version of sqlite3
(from [issue #251](https://docs.ag2.ai/docs/<https:/github.com/microsoft/autogen/issues/251>))
Code examples that use chromadb (like retrieval) fail in codespaces due to a sqlite3 requirement.
Copy
```
>>> import chromadb
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
 File "/home/vscode/.local/lib/python3.10/site-packages/chromadb/__init__.py", line 69, in <module>
  raise RuntimeError(
RuntimeError: Your system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.
Please visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.

```

Workaround:
  1. `pip install pysqlite3-binary`
  2. `mkdir /home/vscode/.local/lib/python3.10/site-packages/google/colab`


Explanation: Per [this gist](https://docs.ag2.ai/docs/<https:/gist.github.com/defulmere/8b9695e415a44271061cc8e272f3c300?permalink_comment_id=4711478#gistcomment-4711478>), linked from the official [chromadb docs](https://docs.ag2.ai/docs/<https:/docs.trychroma.com/troubleshooting#sqlite>), adding this folder triggers chromadb to use pysqlite3 instead of the default.
## 
[​](https://docs.ag2.ai/docs/<#how-to-register-a-reply-function>)
How to register a reply function
(from [issue #478](https://docs.ag2.ai/docs/<https:/github.com/microsoft/autogen/issues/478>))
See here /docs/reference/agentchat/conversable_agent/#register_reply
For example, you can register a reply function that gets called when `generate_reply` is called for an agent.
Copy
```
def print_messages(recipient, messages, sender, config):
  if "callback" in config and config["callback"] is not None:
    callback = config["callback"]
    callback(sender, recipient, messages[-1])
  print(f"Messages sent to: {recipient.name} | num messages: {len(messages)}")
  return False, None # required to ensure the agent communication flow continues
user_proxy.register_reply(
  [autogen.Agent, None],
  reply_func=print_messages,
  config={"callback": None},
)
assistant.register_reply(
  [autogen.Agent, None],
  reply_func=print_messages,
  config={"callback": None},
)

```

In the above, we register a `print_messages` function that is called each time the agent’s `generate_reply` is triggered after receiving a message.
## 
[​](https://docs.ag2.ai/docs/<#how-to-get-last-message>)
How to get last message ?
Refer to /docs/reference/agentchat/conversable_agent/#last_message
## 
[​](https://docs.ag2.ai/docs/<#how-to-get-each-agent-message>)
How to get each agent message ?
Please refer to /docs/reference/agentchat/conversable_agent#chat_messages
## 
[​](https://docs.ag2.ai/docs/<#when-using-autogen-docker-is-it-always-necessary-to-reinstall-modules>)
When using autogen docker, is it always necessary to reinstall modules?
The “use_docker” arg in an agent’s code_execution_config will be set to the name of the image containing the change after execution, when the conversation finishes. You can save that image name. For a new conversation, you can set “use_docker” to the saved name of the image to start execution there.
## 
[​](https://docs.ag2.ai/docs/<#database-locked-error>)
Database locked error
When using VMs such as Azure Machine Learning compute instances, you may encounter a “database locked error”. This is because the [LLM cache](https://docs.ag2.ai/docs/</docs/topics/llm-caching>) is trying to write to a location that the application does not have access to.
You can set the `cache_path_root` to a location where the application has access. For example,
Copy
```
from autogen import Cache
with Cache.disk(cache_path_root="/tmp/.cache") as cache:
  agent_a.initate_chat(agent_b, ..., cache=cache)

```

You can also use Redis cache instead of disk cache. For example,
Copy
```
from autogen import Cache
with Cache.redis(redis_url=...) as cache:
  agent_a.initate_chat(agent_b, ..., cache=cache)

```

You can also disable the cache. See [here](https://docs.ag2.ai/docs/</docs/topics/llm-caching#disabling-cache>) for details.
## 
[​](https://docs.ag2.ai/docs/<#agents-are-throwing-due-to-docker-not-running-how-can-i-resolve-this>)
Agents are throwing due to docker not running, how can I resolve this?
If running AutoGen locally the default for agents who execute code is for them to try and perform code execution within a docker container. If docker is not running, this will cause the agent to throw an error. To resolve this you have some options.
### 
[​](https://docs.ag2.ai/docs/<#if-you-want-to-disable-code-execution-entirely>)
If you want to disable code execution entirely
  * Set `code_execution_config` to `False` for each code-execution agent. E.g.:


Copy
```
user_proxy = autogen.UserProxyAgent(
  name="agent",
  llm_config=llm_config,
  code_execution_config=False)

```

### 
[​](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-in-docker>)
If you want to run code execution in docker
  * **Recommended** : Make sure docker is up and running.


### 
[​](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-locally>)
If you want to run code execution locally
  * `use_docker` can be set to `False` in `code_execution_config` for each code-execution agent.
  * To set it for all code-execution agents at once: set `AUTOGEN_USE_DOCKER` to `False` as an environment variable.


E.g.:
Copy
```
user_proxy = autogen.UserProxyAgent(
  name="agent", llm_config=llm_config,
  code_execution_config={"work_dir":"coding", "use_docker":False})

```

### 
[​](https://docs.ag2.ai/docs/<#what-should-i-do-if-i-get-the-error-typeerror-assistants-create-got-an-unexpected-keyword-argument-file-ids>)
What should I do if I get the error “TypeError: Assistants.create() got an unexpected keyword argument ‘file_ids’”?
This error typically occurs when using Autogen version earlier than 0.2.27 in combination with OpenAI library version 1.21 or later. The issue arises because the older version of Autogen does not support the file_ids parameter used by newer versions of the OpenAI API. To resolve this issue, you need to upgrade your Autogen library to version 0.2.27 or higher that ensures compatibility between Autogen and the OpenAI library.
Copy
```
pip install --upgrade autogen

```

## 
[​](https://docs.ag2.ai/docs/<#none-of-the-devcontainers-are-building-due-to-hash-sum-mismatch-what-should-i-do>)
None of the devcontainers are building due to “Hash sum mismatch”, what should I do?
This is an intermittent issue that appears to be caused by some combination of mirror and proxy issues. If it arises, try to replace the `apt-get update` step with the following:
Copy
```
RUN echo "Acquire::http::Pipeline-Depth 0;" > /etc/apt/apt.conf.d/99custom && \
  echo "Acquire::http::No-Cache true;" >> /etc/apt/apt.conf.d/99custom && \
  echo "Acquire::BrokenProxy  true;" >> /etc/apt/apt.conf.d/99custom
RUN apt-get clean && \
  rm -r /var/lib/apt/lists/* && \
  apt-get update -o Acquire::CompressionTypes::Order::=gz && \
  apt-get -y update && \
  apt-get install sudo git npm # and whatever packages need to be installed in this specific version of the devcontainer

```

This is a combination of StackOverflow suggestions [here](https://docs.ag2.ai/docs/<https:/stackoverflow.com/a/48777773/2114580>) and [here](https://docs.ag2.ai/docs/<https:/stackoverflow.com/a/76092743/2114580>).
[Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)[agent_eval](https://docs.ag2.ai/docs/</docs/reference/agentchat/contrib/agent_eval/agent_eval>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Install the correct package - autogen](https://docs.ag2.ai/docs/<#install-the-correct-package-autogen>)
  * [Set your API endpoints](https://docs.ag2.ai/docs/<#set-your-api-endpoints>)
  * [Use the constructed configuration list in agents](https://docs.ag2.ai/docs/<#use-the-constructed-configuration-list-in-agents>)
  * [How does an agent decide which model to pick out of the list?](https://docs.ag2.ai/docs/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)
  * [Unexpected keyword argument ‘base_url’](https://docs.ag2.ai/docs/<#unexpected-keyword-argument-base-url>)
  * [Can I use non-OpenAI models?](https://docs.ag2.ai/docs/<#can-i-use-non-openai-models>)
  * [Handle Rate Limit Error and Timeout Error](https://docs.ag2.ai/docs/<#handle-rate-limit-error-and-timeout-error>)
  * [How to continue a finished conversation](https://docs.ag2.ai/docs/<#how-to-continue-a-finished-conversation>)
  * [max_consecutive_auto_reply vs max_turn vs max_round](https://docs.ag2.ai/docs/<#max-consecutive-auto-reply-vs-max-turn-vs-max-round>)
  * [How do we decide what LLM is used for each agent? How many agents can be used? How do we decide how many agents in the group?](https://docs.ag2.ai/docs/<#how-do-we-decide-what-llm-is-used-for-each-agent-how-many-agents-can-be-used-how-do-we-decide-how-many-agents-in-the-group>)
  * [Why is code not saved as file?](https://docs.ag2.ai/docs/<#why-is-code-not-saved-as-file>)
  * [Legacy code executor](https://docs.ag2.ai/docs/<#legacy-code-executor>)
  * [Agents keep thanking each other when using gpt-3.5-turbo](https://docs.ag2.ai/docs/<#agents-keep-thanking-each-other-when-using-gpt-3-5-turbo>)
  * [ChromaDB fails in codespaces because of old version of sqlite3](https://docs.ag2.ai/docs/<#chromadb-fails-in-codespaces-because-of-old-version-of-sqlite3>)
  * [How to register a reply function](https://docs.ag2.ai/docs/<#how-to-register-a-reply-function>)
  * [How to get last message ?](https://docs.ag2.ai/docs/<#how-to-get-last-message>)
  * [How to get each agent message ?](https://docs.ag2.ai/docs/<#how-to-get-each-agent-message>)
  * [When using autogen docker, is it always necessary to reinstall modules?](https://docs.ag2.ai/docs/<#when-using-autogen-docker-is-it-always-necessary-to-reinstall-modules>)
  * [Database locked error](https://docs.ag2.ai/docs/<#database-locked-error>)
  * [Agents are throwing due to docker not running, how can I resolve this?](https://docs.ag2.ai/docs/<#agents-are-throwing-due-to-docker-not-running-how-can-i-resolve-this>)
  * [If you want to disable code execution entirely](https://docs.ag2.ai/docs/<#if-you-want-to-disable-code-execution-entirely>)
  * [If you want to run code execution in docker](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-in-docker>)
  * [If you want to run code execution locally](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-locally>)
  * [What should I do if I get the error “TypeError: Assistants.create() got an unexpected keyword argument ‘file_ids’”?](https://docs.ag2.ai/docs/<#what-should-i-do-if-i-get-the-error-typeerror-assistants-create-got-an-unexpected-keyword-argument-file-ids>)
  * [None of the devcontainers are building due to “Hash sum mismatch”, what should I do?](https://docs.ag2.ai/docs/<#none-of-the-devcontainers-are-building-due-to-hash-sum-mismatch-what-should-i-do>)

---

# browser_utils
URL: https://docs.ag2.ai/docs/reference/browser_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
browser_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# browser_utils
## 
[​](https://docs.ag2.ai/docs/reference/<#simpletextbrowser>)
SimpleTextBrowser
Copy
```
class SimpleTextBrowser()

```

(In preview) An extremely simple text-based web browser comparable to Lynx. Suitable for Agentic use.
### 
[​](https://docs.ag2.ai/docs/reference/<#address>)
address
Copy
```
@property
def address() -> str

```

Return the address of the current page.
### 
[​](https://docs.ag2.ai/docs/reference/<#viewport>)
viewport
Copy
```
@property
def viewport() -> str

```

Return the content of the current viewport.
### 
[​](https://docs.ag2.ai/docs/reference/<#page-content>)
page_content
Copy
```
@property
def page_content() -> str

```

Return the full contents of the current page.
### 
[​](https://docs.ag2.ai/docs/reference/<#visit-page>)
visit_page
Copy
```
def visit_page(path_or_uri: str) -> str

```

Update the address, visit the page, and return the content of the viewport.
[tool](https://docs.ag2.ai/docs/reference/</docs/reference/tools/tool>)[code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [SimpleTextBrowser](https://docs.ag2.ai/docs/reference/<#simpletextbrowser>)
  * [address](https://docs.ag2.ai/docs/reference/<#address>)
  * [viewport](https://docs.ag2.ai/docs/reference/<#viewport>)
  * [page_content](https://docs.ag2.ai/docs/reference/<#page-content>)
  * [visit_page](https://docs.ag2.ai/docs/reference/<#visit-page>)

---

# code_utils
URL: https://docs.ag2.ai/docs/reference/code_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
code_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# code_utils
### 
[​](https://docs.ag2.ai/docs/reference/<#content-str>)
content_str
Copy
```
def content_str(
  content: Union[str, list[Union[UserMessageTextContentPart,
                  UserMessageImageContentPart]], None]
) -> str

```

Converts the `content` field of an OpenAI message into a string format.
This function processes content that may be a string, a list of mixed text and image URLs, or None, and converts it into a string. Text is directly appended to the result string, while image URLs are represented by a placeholder image token. If the content is None, an empty string is returned.
**Arguments** :
  * content (Union[str, List, None]): The content to be processed. Can be a string, a list of dictionaries representing text and image URLs, or None.


**Returns** :
  * `str` - A string representation of the input content. Image URLs are replaced with an image token.


**Notes** :
  * The function expects each dictionary in the list to have a “type” key that is either “text” or “image_url”. For “text” type, the “text” key’s value is appended to the result. For “image_url”, an image token is appended.
  * This function is useful for handling content that may include both text and image references, especially in contexts where images need to be represented as placeholders.


### 
[​](https://docs.ag2.ai/docs/reference/<#infer-lang>)
infer_lang
Copy
```
def infer_lang(code: str) -> str

```

Infer the language for the code. TODO: make it robust.
### 
[​](https://docs.ag2.ai/docs/reference/<#extract-code>)
extract_code
Copy
```
def extract_code(
    text: Union[str, list],
    pattern: str = CODE_BLOCK_PATTERN,
    detect_single_line_code: bool = False) -> list[tuple[str, str]]

```

Extract code from a text.
**Arguments** :
  * `text` _str or List_ - The content to extract code from. The content can be a string or a list, as returned by standard GPT or multimodal GPT.
  * `pattern` _str, optional_ - The regular expression pattern for finding the code block. Defaults to CODE_BLOCK_PATTERN.
  * `detect_single_line_code` _bool, optional_ - Enable the new feature for extracting single line code. Defaults to False.


**Returns** :
  * `list` - A list of tuples, each containing the language and the code. If there is no code block in the input text, the language would be “unknown”. If there is code block but the language is not specified, the language would be "".


### 
[​](https://docs.ag2.ai/docs/reference/<#generate-code>)
generate_code
Copy
```
def generate_code(pattern: str = CODE_BLOCK_PATTERN,
         **config) -> tuple[str, float]

```

`(openai<1)` Generate code.
**Arguments** :
  * `pattern` _Optional, str_ - The regular expression pattern for finding the code block. The default pattern is for finding a code block in a markdown file.
  * `config` _Optional, dict_ - The configuration for the API call.


**Returns** :
  * `str` - The generated code.
  * `float` - The cost of the generation.


### 
[​](https://docs.ag2.ai/docs/reference/<#improve-function>)
improve_function
Copy
```
def improve_function(file_name, func_name, objective, **config)

```

`(openai<1)` Improve the function to achieve the objective.
### 
[​](https://docs.ag2.ai/docs/reference/<#improve-code>)
improve_code
Copy
```
def improve_code(files, objective, suggest_only=True, **config)

```

`(openai<1)` Improve the code to achieve a given objective.
**Arguments** :
  * `files` _list_ - A list of file names containing the source code.
  * `objective` _str_ - The objective to achieve.
  * `suggest_only` _bool_ - Whether to return only the suggestions or the improved code.
  * `config` _Optional, dict_ - The configuration for the API call.


**Returns** :
  * `str` - The improved code if suggest_only=False; a list of suggestions if suggest_only=True (default).
  * `float` - The cost of the generation.


### 
[​](https://docs.ag2.ai/docs/reference/<#is-docker-running>)
is_docker_running
Copy
```
def is_docker_running() -> bool

```

Check if docker is running.
**Returns** :
  * `bool` - True if docker is running; False otherwise.


### 
[​](https://docs.ag2.ai/docs/reference/<#in-docker-container>)
in_docker_container
Copy
```
def in_docker_container() -> bool

```

Check if the code is running in a docker container.
**Returns** :
  * `bool` - True if the code is running in a docker container; False otherwise.


### 
[​](https://docs.ag2.ai/docs/reference/<#execute-code>)
execute_code
Copy
```
def execute_code(
    code: Optional[str] = None,
    timeout: Optional[int] = None,
    filename: Optional[str] = None,
    work_dir: Optional[str] = None,
    use_docker: Union[list[str], str, bool] = SENTINEL,
    lang: Optional[str] = "python") -> tuple[int, str, Optional[str]]

```

Execute code in a docker container. This function is not tested on MacOS.
**Arguments** :
  * `code` _Optional, str_ - The code to execute. If None, the code from the file specified by filename will be executed. Either code or filename must be provided.
  * `timeout` _Optional, int_ - The maximum execution time in seconds. If None, a default timeout will be used. The default timeout is 600 seconds. On Windows, the timeout is not enforced when use_docker=False.
  * `filename` _Optional, str_ - The file name to save the code or where the code is stored when `code` is None. If None, a file with a randomly generated name will be created. The randomly generated file will be deleted after execution. The file name must be a relative path. Relative paths are relative to the working directory.
  * `work_dir` _Optional, str_ - The working directory for the code execution. If None, a default working directory will be used. The default working directory is the “extensions” directory under “path_to_autogen”.
  * `use_docker` _list, str or bool_ - The docker image to use for code execution. Default is True, which means the code will be executed in a docker container. A default list of images will be used. If a list or a str of image name(s) is provided, the code will be executed in a docker container with the first image successfully pulled. If False, the code will be executed in the current environment. Expected behaviour: 
    * If `use_docker` is not set (i.e. left default to True) or is explicitly set to True and the docker package is available, the code will run in a Docker container.
    * If `use_docker` is not set (i.e. left default to True) or is explicitly set to True but the Docker package is missing or docker isn’t running, an error will be raised.
    * If `use_docker` is explicitly set to False, the code will run natively. If the code is executed in the current environment, the code must be trusted.
  * `lang` _Optional, str_ - The language of the code. Default is “python”.


**Returns** :
  * `int` - 0 if the code executes successfully.
  * `str` - The error message if the code fails to execute; the stdout otherwise.
  * `image` - The docker image name after container run when docker is used.


### 
[​](https://docs.ag2.ai/docs/reference/<#generate-assertions>)
generate_assertions
Copy
```
def generate_assertions(definition: str, **config) -> tuple[str, float]

```

`(openai<1)` Generate assertions for a function.
**Arguments** :
  * `definition` _str_ - The function definition, including the signature and docstr.
  * `config` _Optional, dict_ - The configuration for the API call.


**Returns** :
  * `str` - The generated assertions.
  * `float` - The cost of the generation.


### 
[​](https://docs.ag2.ai/docs/reference/<#eval-function-completions>)
eval_function_completions
Copy
```
def eval_function_completions(responses: list[str],
               definition: str,
               test: Optional[str] = None,
               entry_point: Optional[str] = None,
               assertions: Optional[Union[str, Callable[
                 [str], tuple[str, float]]]] = None,
               timeout: Optional[float] = 3,
               use_docker: Optional[bool] = True) -> dict

```

`(openai<1)` Select a response from a list of responses for the function completion task (using generated assertions), and/or evaluate if the task is successful using a gold test.
**Arguments** :
  * `responses` _list_ - The list of responses.
  * `definition` _str_ - The input definition.
  * `test` _Optional, str_ - The test code.
  * `entry_point` _Optional, str_ - The name of the function.
  * `assertions` _Optional, str or Callable_ - The assertion code which serves as a filter of the responses, or an assertion generator. When provided, only the responses that pass the assertions will be considered for the actual test (if provided).
  * `timeout` _Optional, float_ - The timeout for executing the code.


**Returns** :
  * `dict` - The success metrics.


## 
[​](https://docs.ag2.ai/docs/reference/<#passassertionfilter>)
PassAssertionFilter
Copy
```
class PassAssertionFilter()

```

### 
[​](https://docs.ag2.ai/docs/reference/<#pass-assertions>)
pass_assertions
Copy
```
def pass_assertions(context, response, **_)

```

`(openai<1)` Check if the response passes the assertions.
### 
[​](https://docs.ag2.ai/docs/reference/<#implement>)
implement
Copy
```
def implement(
  definition: str,
  configs: Optional[list[dict]] = None,
  assertions: Optional[Union[str,
                Callable[[str],
                    tuple[str,
                       float]]]] = generate_assertions
) -> tuple[str, float]

```

`(openai<1)` Implement a function from a definition.
**Arguments** :
  * `definition` _str_ - The function definition, including the signature and docstr.
  * `configs` _list_ - The list of configurations for completion.
  * `assertions` _Optional, str or Callable_ - The assertion code which serves as a filter of the responses, or an assertion generator.


**Returns** :
  * `str` - The implementation.
  * `float` - The cost of the implementation.
  * `int` - The index of the configuration which generates the implementation.


### 
[​](https://docs.ag2.ai/docs/reference/<#create-virtual-env>)
create_virtual_env
Copy
```
def create_virtual_env(dir_path: str, **env_args) -> SimpleNamespace

```

Creates a python virtual environment and returns the context.
**Arguments** :
  * `dir_path` _str_ - Directory path where the env will be created.
  * `**env_args` - Any extra args to pass to the `EnvBuilder`


**Returns** :
  * `SimpleNamespace` - the virtual env context object.


[browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)[exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [content_str](https://docs.ag2.ai/docs/reference/<#content-str>)
  * [infer_lang](https://docs.ag2.ai/docs/reference/<#infer-lang>)
  * [extract_code](https://docs.ag2.ai/docs/reference/<#extract-code>)
  * [generate_code](https://docs.ag2.ai/docs/reference/<#generate-code>)
  * [improve_function](https://docs.ag2.ai/docs/reference/<#improve-function>)
  * [improve_code](https://docs.ag2.ai/docs/reference/<#improve-code>)
  * [is_docker_running](https://docs.ag2.ai/docs/reference/<#is-docker-running>)
  * [in_docker_container](https://docs.ag2.ai/docs/reference/<#in-docker-container>)
  * [execute_code](https://docs.ag2.ai/docs/reference/<#execute-code>)
  * [generate_assertions](https://docs.ag2.ai/docs/reference/<#generate-assertions>)
  * [eval_function_completions](https://docs.ag2.ai/docs/reference/<#eval-function-completions>)
  * [PassAssertionFilter](https://docs.ag2.ai/docs/reference/<#passassertionfilter>)
  * [pass_assertions](https://docs.ag2.ai/docs/reference/<#pass-assertions>)
  * [implement](https://docs.ag2.ai/docs/reference/<#implement>)
  * [create_virtual_env](https://docs.ag2.ai/docs/reference/<#create-virtual-env>)

---

# exception_utils
URL: https://docs.ag2.ai/docs/reference/exception_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
exception_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# exception_utils
## 
[​](https://docs.ag2.ai/docs/reference/<#noeligiblespeaker>)
NoEligibleSpeaker
Copy
```
class NoEligibleSpeaker(Exception)

```

Exception raised for early termination of a GroupChat.
## 
[​](https://docs.ag2.ai/docs/reference/<#senderrequired>)
SenderRequired
Copy
```
class SenderRequired(Exception)

```

Exception raised when the sender is required but not provided.
## 
[​](https://docs.ag2.ai/docs/reference/<#invalidcarryovertype>)
InvalidCarryOverType
Copy
```
class InvalidCarryOverType(Exception)

```

Exception raised when the carryover type is invalid.
## 
[​](https://docs.ag2.ai/docs/reference/<#undefinednextagent>)
UndefinedNextAgent
Copy
```
class UndefinedNextAgent(Exception)

```

Exception raised when the provided next agents list does not overlap with agents in the group.
## 
[​](https://docs.ag2.ai/docs/reference/<#modeltoolnotsupportederror>)
ModelToolNotSupportedError
Copy
```
class ModelToolNotSupportedError(Exception)

```

Exception raised when attempting to use tools with models that do not support them.
[code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)[graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [NoEligibleSpeaker](https://docs.ag2.ai/docs/reference/<#noeligiblespeaker>)
  * [SenderRequired](https://docs.ag2.ai/docs/reference/<#senderrequired>)
  * [InvalidCarryOverType](https://docs.ag2.ai/docs/reference/<#invalidcarryovertype>)
  * [UndefinedNextAgent](https://docs.ag2.ai/docs/reference/<#undefinednextagent>)
  * [ModelToolNotSupportedError](https://docs.ag2.ai/docs/reference/<#modeltoolnotsupportederror>)

---

# graph_utils
URL: https://docs.ag2.ai/docs/reference/graph_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
graph_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# graph_utils
### 
[​](https://docs.ag2.ai/docs/reference/<#has-self-loops>)
has_self_loops
Copy
```
def has_self_loops(allowed_speaker_transitions: dict) -> bool

```

Returns True if there are self loops in the allowed_speaker_transitions_Dict.
### 
[​](https://docs.ag2.ai/docs/reference/<#check-graph-validity>)
check_graph_validity
Copy
```
def check_graph_validity(allowed_speaker_transitions_dict: dict,
             agents: list[Agent])

```

allowed_speaker_transitions_dict: A dictionary of keys and list as values. The keys are the names of the agents, and the values are the names of the agents that the key agent can transition to. agents: A list of Agents
Checks for the following: Errors
  1. The dictionary must have a structure of keys and list as values
  2. Every key exists in agents.
  3. Every value is a list of Agents (not string).


**Warnings** :
  1. Warning if there are isolated agent nodes
  2. Warning if the set of agents in allowed_speaker_transitions do not match agents
  3. Warning if there are duplicated agents in any values of `allowed_speaker_transitions_dict`


### 
[​](https://docs.ag2.ai/docs/reference/<#invert-disallowed-to-allowed>)
invert_disallowed_to_allowed
Copy
```
def invert_disallowed_to_allowed(disallowed_speaker_transitions_dict: dict,
                 agents: list[Agent]) -> dict

```

Start with a fully connected allowed_speaker_transitions_dict of all agents. Remove edges from the fully connected allowed_speaker_transitions_dict according to the disallowed_speaker_transitions_dict to form the allowed_speaker_transitions_dict.
### 
[​](https://docs.ag2.ai/docs/reference/<#visualize-speaker-transitions-dict>)
visualize_speaker_transitions_dict
Copy
```
def visualize_speaker_transitions_dict(speaker_transitions_dict: dict,
                    agents: list[Agent],
                    export_path: Optional[str] = None)

```

Visualize the speaker_transitions_dict using networkx.
[exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)[math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [has_self_loops](https://docs.ag2.ai/docs/reference/<#has-self-loops>)
  * [check_graph_validity](https://docs.ag2.ai/docs/reference/<#check-graph-validity>)
  * [invert_disallowed_to_allowed](https://docs.ag2.ai/docs/reference/<#invert-disallowed-to-allowed>)
  * [visualize_speaker_transitions_dict](https://docs.ag2.ai/docs/reference/<#visualize-speaker-transitions-dict>)

---

# math_utils
URL: https://docs.ag2.ai/docs/reference/math_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
math_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# math_utils
### 
[​](https://docs.ag2.ai/docs/reference/<#solve-problem>)
solve_problem
Copy
```
def solve_problem(problem: str, **config) -> str

```

`(openai<1)` Solve the math problem.
**Arguments** :
  * `problem` _str_ - The problem statement.
  * `config` _Optional, dict_ - The configuration for the API call.


**Returns** :
  * `str` - The solution to the problem.


### 
[​](https://docs.ag2.ai/docs/reference/<#remove-boxed>)
remove_boxed
Copy
```
def remove_boxed(string: str) -> Optional[str]

```

Source: <https://github.com/hendrycks/math> Extract the text within a \boxed`{...}` environment.
**Example** :
Copy
```
> remove_boxed("\boxed{\frac{2}{3}}")
\frac{2}{3}

```

### 
[​](https://docs.ag2.ai/docs/reference/<#last-boxed-only-string>)
last_boxed_only_string
Copy
```
def last_boxed_only_string(string: str) -> Optional[str]

```

Source: <https://github.com/hendrycks/math> Extract the last \boxed`{...}` or \fbox`{...}` element from a string.
### 
[​](https://docs.ag2.ai/docs/reference/<#is-equiv>)
is_equiv
Copy
```
def is_equiv(str1: Optional[str], str2: Optional[str]) -> float

```

Returns (as a float) whether two strings containing math are equivalent up to differences of formatting in
  * units
  * fractions
  * square roots
  * superfluous LaTeX. Source: <https://github.com/hendrycks/math>


### 
[​](https://docs.ag2.ai/docs/reference/<#is-equiv-chain-of-thought>)
is_equiv_chain_of_thought
Copy
```
def is_equiv_chain_of_thought(str1: str, str2: str) -> float

```

Strips the solution first before calling `is_equiv`.
### 
[​](https://docs.ag2.ai/docs/reference/<#eval-math-responses>)
eval_math_responses
Copy
```
def eval_math_responses(responses, solution=None, **args)

```

Select a response for a math problem using voting, and check if the response is correct if the solution is provided.
**Arguments** :
  * `responses` _list_ - The list of responses.
  * `solution` _str_ - The canonical solution.


**Returns** :
  * `dict` - The success metrics.


[graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)[retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [solve_problem](https://docs.ag2.ai/docs/reference/<#solve-problem>)
  * [remove_boxed](https://docs.ag2.ai/docs/reference/<#remove-boxed>)
  * [last_boxed_only_string](https://docs.ag2.ai/docs/reference/<#last-boxed-only-string>)
  * [is_equiv](https://docs.ag2.ai/docs/reference/<#is-equiv>)
  * [is_equiv_chain_of_thought](https://docs.ag2.ai/docs/reference/<#is-equiv-chain-of-thought>)
  * [eval_math_responses](https://docs.ag2.ai/docs/reference/<#eval-math-responses>)

---

# retrieve_utils
URL: https://docs.ag2.ai/docs/reference/retrieve_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
retrieve_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# retrieve_utils
#### 
[​](https://docs.ag2.ai/docs/reference/<#unstructured-formats>)
UNSTRUCTURED_FORMATS
These formats will be parsed by the ‘unstructured’ library, if installed.
### 
[​](https://docs.ag2.ai/docs/reference/<#split-text-to-chunks>)
split_text_to_chunks
Copy
```
def split_text_to_chunks(text: str,
             max_tokens: int = 4000,
             chunk_mode: str = "multi_lines",
             must_break_at_empty_line: bool = True,
             overlap: int = 0)

```

Split a long text into chunks of max_tokens.
### 
[​](https://docs.ag2.ai/docs/reference/<#extract-text-from-pdf>)
extract_text_from_pdf
Copy
```
def extract_text_from_pdf(file: str) -> str

```

Extract text from PDF files
### 
[​](https://docs.ag2.ai/docs/reference/<#split-files-to-chunks>)
split_files_to_chunks
Copy
```
def split_files_to_chunks(
  files: list,
  max_tokens: int = 4000,
  chunk_mode: str = "multi_lines",
  must_break_at_empty_line: bool = True,
  custom_text_split_function: Callable = None
) -> tuple[list[str], list[dict]]

```

Split a list of files into chunks of max_tokens.
### 
[​](https://docs.ag2.ai/docs/reference/<#get-files-from-dir>)
get_files_from_dir
Copy
```
def get_files_from_dir(dir_path: Union[str, list[str]],
            types: list = TEXT_FORMATS,
            recursive: bool = True)

```

Return a list of all the files in a given directory, a url, a file path or a list of them.
### 
[​](https://docs.ag2.ai/docs/reference/<#parse-html-to-markdown>)
parse_html_to_markdown
Copy
```
def parse_html_to_markdown(html: str, url: str = None) -> str

```

Parse HTML to markdown.
### 
[​](https://docs.ag2.ai/docs/reference/<#get-file-from-url>)
get_file_from_url
Copy
```
def get_file_from_url(url: str, save_path: str = None) -> tuple[str, str]

```

Download a file from a URL.
### 
[​](https://docs.ag2.ai/docs/reference/<#is-url>)
is_url
Copy
```
def is_url(string: str)

```

Return True if the string is a valid URL.
### 
[​](https://docs.ag2.ai/docs/reference/<#create-vector-db-from-dir>)
create_vector_db_from_dir
Copy
```
def create_vector_db_from_dir(dir_path: Union[str, list[str]],
               max_tokens: int = 4000,
               client: API = None,
               db_path: str = "tmp/chromadb.db",
               collection_name: str = "all-my-documents",
               get_or_create: bool = False,
               chunk_mode: str = "multi_lines",
               must_break_at_empty_line: bool = True,
               embedding_model: str = "all-MiniLM-L6-v2",
               embedding_function: Callable = None,
               custom_text_split_function: Callable = None,
               custom_text_types: list[str] = TEXT_FORMATS,
               recursive: bool = True,
               extra_docs: bool = False) -> API

```

Create a vector db from all the files in a given directory, the directory can also be a single file or a url to a single file. We support chromadb compatible APIs to create the vector db, this function is not required if you prepared your own vector db.
**Arguments** :
  * `dir_path` _Union[str, List[str]]_ - the path to the directory, file, url or a list of them.
  * `max_tokens` _Optional, int_ - the maximum number of tokens per chunk. Default is 4000.
  * `client` _Optional, API_ - the chromadb client. Default is None.
  * `db_path` _Optional, str_ - the path to the chromadb. Default is “tmp/chromadb.db”. The default was `/tmp/chromadb.db` for version `<=0.2.24`.
  * `collection_name` _Optional, str_ - the name of the collection. Default is “all-my-documents”.
  * `get_or_create` _Optional, bool_ - Whether to get or create the collection. Default is False. If True, the collection will be returned if it already exists. Will raise ValueError if the collection already exists and get_or_create is False.
  * `chunk_mode` _Optional, str_ - the chunk mode. Default is “multi_lines”.
  * `must_break_at_empty_line` _Optional, bool_ - Whether to break at empty line. Default is True.
  * `embedding_model` _Optional, str_ - the embedding model to use. Default is “all-MiniLM-L6-v2”. Will be ignored if embedding_function is not None.
  * `embedding_function` _Optional, Callable_ - the embedding function to use. Default is None, SentenceTransformer with the given `embedding_model` will be used. If you want to use OpenAI, Cohere, HuggingFace or other embedding functions, you can pass it here, follow the examples in `https://docs.trychroma.com/embeddings`.
  * `custom_text_split_function` _Optional, Callable_ - a custom function to split a string into a list of strings. Default is None, will use the default function in `autogen.retrieve_utils.split_text_to_chunks`.
  * `custom_text_types` _Optional, List[str]_ - a list of file types to be processed. Default is TEXT_FORMATS.
  * `recursive` _Optional, bool_ - whether to search documents recursively in the dir_path. Default is True.
  * `extra_docs` _Optional, bool_ - whether to add more documents in the collection. Default is False


**Returns** :
The chromadb client.
### 
[​](https://docs.ag2.ai/docs/reference/<#query-vector-db>)
query_vector_db
Copy
```
def query_vector_db(query_texts: list[str],
          n_results: int = 10,
          client: API = None,
          db_path: str = "tmp/chromadb.db",
          collection_name: str = "all-my-documents",
          search_string: str = "",
          embedding_model: str = "all-MiniLM-L6-v2",
          embedding_function: Callable = None) -> QueryResult

```

Query a vector db. We support chromadb compatible APIs, it’s not required if you prepared your own vector db and query function.
**Arguments** :
  * `query_texts` _List[str]_ - the list of strings which will be used to query the vector db.
  * `n_results` _Optional, int_ - the number of results to return. Default is 10.
  * `client` _Optional, API_ - the chromadb compatible client. Default is None, a chromadb client will be used.
  * `db_path` _Optional, str_ - the path to the vector db. Default is “tmp/chromadb.db”. The default was `/tmp/chromadb.db` for version `<=0.2.24`.
  * `collection_name` _Optional, str_ - the name of the collection. Default is “all-my-documents”.
  * `search_string` _Optional, str_ - the search string. Only docs that contain an exact match of this string will be retrieved. Default is "".
  * `embedding_model` _Optional, str_ - the embedding model to use. Default is “all-MiniLM-L6-v2”. Will be ignored if embedding_function is not None.
  * `embedding_function` _Optional, Callable_ - the embedding function to use. Default is None, SentenceTransformer with the given `embedding_model` will be used. If you want to use OpenAI, Cohere, HuggingFace or other embedding functions, you can pass it here, follow the examples in `https://docs.trychroma.com/embeddings`.


**Returns** :
The query result. The format is:
Copy
```
class QueryResult(TypedDict):
  ids: List[IDs]
  embeddings: Optional[List[List[Embedding]]]
  documents: Optional[List[List[Document]]]
  metadatas: Optional[List[List[Metadata]]]
  distances: Optional[List[List[float]]]

```

[math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)[runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [UNSTRUCTURED_FORMATS](https://docs.ag2.ai/docs/reference/<#unstructured-formats>)
  * [split_text_to_chunks](https://docs.ag2.ai/docs/reference/<#split-text-to-chunks>)
  * [extract_text_from_pdf](https://docs.ag2.ai/docs/reference/<#extract-text-from-pdf>)
  * [split_files_to_chunks](https://docs.ag2.ai/docs/reference/<#split-files-to-chunks>)
  * [get_files_from_dir](https://docs.ag2.ai/docs/reference/<#get-files-from-dir>)
  * [parse_html_to_markdown](https://docs.ag2.ai/docs/reference/<#parse-html-to-markdown>)
  * [get_file_from_url](https://docs.ag2.ai/docs/reference/<#get-file-from-url>)
  * [is_url](https://docs.ag2.ai/docs/reference/<#is-url>)
  * [create_vector_db_from_dir](https://docs.ag2.ai/docs/reference/<#create-vector-db-from-dir>)
  * [query_vector_db](https://docs.ag2.ai/docs/reference/<#query-vector-db>)

---

# runtime_logging
URL: https://docs.ag2.ai/docs/reference/runtime_logging

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
runtime_logging
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# runtime_logging
### 
[​](https://docs.ag2.ai/docs/reference/<#start>)
start
Copy
```
def start(logger: BaseLogger | None = None,
     logger_type: Literal["sqlite", "file"] = "sqlite",
     config: dict[str, Any] | None = None) -> str

```

Start logging for the runtime.
**Arguments** :
  * `logger` _BaseLogger_ - A logger instance
  * `logger_type` _str_ - The type of logger to use (default: sqlite)
  * `config` _dict_ - Configuration for the logger


**Returns** :
session_id (str(uuid.uuid4)): a unique id for the logging session
[retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)[token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [start](https://docs.ag2.ai/docs/reference/<#start>)

---

# token_count_utils
URL: https://docs.ag2.ai/docs/reference/token_count_utils

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
token_count_utils
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# token_count_utils
### 
[​](https://docs.ag2.ai/docs/reference/<#token-left>)
token_left
Copy
```
def token_left(input: Union[str, list, dict],
        model="gpt-3.5-turbo-0613") -> int

```

Count number of tokens left for an OpenAI model.
**Arguments** :
  * `input` - (str, list, dict): Input to the model.
  * `model` - (str): Model name.


**Returns** :
  * `int` - Number of tokens left that the model can use for completion.


### 
[​](https://docs.ag2.ai/docs/reference/<#count-token>)
count_token
Copy
```
def count_token(input: Union[str, list, dict],
        model: str = "gpt-3.5-turbo-0613") -> int

```

Count number of tokens used by an OpenAI model.
**Arguments** :
  * `input` - (str, list, dict): Input to the model.
  * `model` - (str): Model name.


**Returns** :
  * `int` - Number of tokens from the input.


### 
[​](https://docs.ag2.ai/docs/reference/<#num-tokens-from-functions>)
num_tokens_from_functions
Copy
```
def num_tokens_from_functions(functions, model="gpt-3.5-turbo-0613") -> int

```

Return the number of tokens used by a list of functions.
**Arguments** :
  * `functions` - (list): List of function descriptions that will be passed in model.
  * `model` - (str): Model name.


**Returns** :
  * `int` - Number of tokens from the function descriptions.


[runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)[types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [token_left](https://docs.ag2.ai/docs/reference/<#token-left>)
  * [count_token](https://docs.ag2.ai/docs/reference/<#count-token>)
  * [num_tokens_from_functions](https://docs.ag2.ai/docs/reference/<#num-tokens-from-functions>)

---

# types
URL: https://docs.ag2.ai/docs/reference/types

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)


Navigation
API Reference
types
[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)


API Reference
# types
## 
[​](https://docs.ag2.ai/docs/reference/<#usermessagetextcontentpart>)
UserMessageTextContentPart
Copy
```
class UserMessageTextContentPart(TypedDict)

```

Represents a text content part of a user message
#### 
[​](https://docs.ag2.ai/docs/reference/<#type>)
type
The type of the content part. Always “text” for text content parts.
#### 
[​](https://docs.ag2.ai/docs/reference/<#text>)
text
The text content of the part.
## 
[​](https://docs.ag2.ai/docs/reference/<#usermessageimagecontentpart>)
UserMessageImageContentPart
Copy
```
class UserMessageImageContentPart(TypedDict)

```

Represents an image content part of a user message
#### 
[​](https://docs.ag2.ai/docs/reference/<#type-2>)
type
The type of the content part. Always “image_url” for image content parts.
#### 
[​](https://docs.ag2.ai/docs/reference/<#image-url>)
image_url
The URL of the image.
[token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)[Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)
[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [UserMessageTextContentPart](https://docs.ag2.ai/docs/reference/<#usermessagetextcontentpart>)
  * [type](https://docs.ag2.ai/docs/reference/<#type>)
  * [text](https://docs.ag2.ai/docs/reference/<#text>)
  * [UserMessageImageContentPart](https://docs.ag2.ai/docs/reference/<#usermessageimagecontentpart>)
  * [type](https://docs.ag2.ai/docs/reference/<#type-2>)
  * [image_url](https://docs.ag2.ai/docs/reference/<#image-url>)

---

# Getting Started
URL: https://docs.ag2.ai/docs/autogen-studio/getting-started

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)


Navigation
AutoGen Studio
Getting Started
[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)


AutoGen Studio
# Getting Started
[![Open in Colab](https://badge.fury.io/py/autogenstudio.svg)](https://docs.ag2.ai/docs/autogen-studio/<https:/badge.fury.io/py/autogenstudio>)
[![Open in GitHub](https://static.pepy.tech/badge/autogenstudio/week)](https://docs.ag2.ai/docs/autogen-studio/<https:/pepy.tech/project/autogenstudio>)
![ARA](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/ara_stockprices.png)
AutoGen Studio is an low-code interface built to help you rapidly prototype AI agents, enhance them with skills, compose them into workflows and interact with them to accomplish tasks. It is built on top of the [AutoGen](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.ag2.ai>) framework, which is a toolkit for building AI agents.
Code for AutoGen Studio is on GitHub at [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/autogen-studio>)
> **Note** : AutoGen Studio is meant to help you rapidly prototype multi-agent workflows and demonstrate an example of end user interfaces built with AutoGen. It is not meant to be a production-ready app. Developers are encouraged to use the AutoGen framework to build their own applications, implementing authentication, security and other features required for deployed applications.
**Updates**
  * April 17: AutoGen Studio database layer is now rewritten to use [SQLModel](https://docs.ag2.ai/docs/autogen-studio/<https:/sqlmodel.tiangolo.com/>) (Pydantic + SQLAlchemy). This provides entity linking (skills, models, agents and workflows are linked via association tables) and supports multiple [database backend dialects](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.sqlalchemy.org/en/20/dialects/>) supported in SQLAlchemy (SQLite, PostgreSQL, MySQL, Oracle, Microsoft SQL Server). The backend database can be specified with a `--database-uri` argument when running the application. For example, `autogenstudio ui --database-uri sqlite:///database.sqlite` for SQLite and `autogenstudio ui --database-uri postgresql+psycopg://user:password@localhost/dbname` for PostgreSQL.
  * March 12: Default directory for AutoGen Studio is now /home/<user>/.autogenstudio. You can also specify this directory using the `--appdir` argument when running the application. For example, `autogenstudio ui --appdir /path/to/folder`. This will store the database and other files in the specified directory e.g. `/path/to/folder/database.sqlite`. `.env` files in that directory will be used to set environment variables for the app.


### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#installation>)
Installation
There are two ways to install AutoGen Studio - from PyPi or from source. We **recommend installing from PyPi** unless you plan to modify the source code.
  1. **Install from PyPi**
We recommend using a virtual environment (e.g., conda) to avoid conflicts with existing Python packages. With Python 3.10 or newer active in your virtual environment, use pip to install AutoGen Studio:
Copy
```
pip install autogenstudio

```

  2. **Install from Source**
> Note: This approach requires some familiarity with building interfaces in React.
If you prefer to install from source, ensure you have Python 3.10+ and Node.js (version above 14.15.0) installed. Here’s how you get started:
     * Clone the AutoGen Studio repository from the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository and install its Python dependencies:
Copy
```
pip install -e .

```

     * Navigate to the `samples/apps/autogen-studio/frontend` directory, install dependencies, and build the UI:
Copy
```
npm install -g gatsby-cli
npm install --global yarn
cd frontend
yarn install
yarn build

```



For Windows users, to build the frontend, you may need alternative commands to build the frontend.
Copy
```

 gatsby clean && rmdir /s /q ..\\autogenstudio\\web\\ui 2>nul & (set \"PREFIX_PATH_VALUE=\" || ver>nul) && gatsby build --prefix-paths && xcopy /E /I /Y public ..\\autogenstudio\\web\\ui

```

### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#running-the-application>)
Running the Application
Once installed, run the web UI by entering the following in your terminal:
Copy
```
autogenstudio ui --port 8081

```

This will start the application on the specified port. Open your web browser and go to `http://localhost:8081/` to begin using AutoGen Studio.
AutoGen Studio also takes several parameters to customize the application:
  * `--host <host>` argument to specify the host address. By default, it is set to `localhost`. Y
  * `--appdir <appdir>` argument to specify the directory where the app files (e.g., database and generated user files) are stored. By default, it is set to the a `.autogenstudio` directory in the user’s home directory.
  * `--port <port>` argument to specify the port number. By default, it is set to `8080`.
  * `--reload` argument to enable auto-reloading of the server when changes are made to the code. By default, it is set to `False`.
  * `--database-uri` argument to specify the database URI. Example values include `sqlite:///database.sqlite` for SQLite and `postgresql+psycopg://user:password@localhost/dbname` for PostgreSQL. If this is not specified, the database URI defaults to a `database.sqlite` file in the `--appdir` directory.


Now that you have AutoGen Studio installed and running, you are ready to explore its capabilities, including defining and modifying agent workflows, interacting with agents and sessions, and expanding agent skills.
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#capabilities-roadmap>)
Capabilities / Roadmap
Some of the capabilities supported by the app frontend include the following:
  * Build / Configure agents (currently supports two agent workflows based on `UserProxyAgent` and `AssistantAgent`), modify their configuration (e.g. skills, temperature, model, agent system message, model etc) and compose them into workflows.
  * Chat with agent workflows and specify tasks.
  * View agent messages and output files in the UI from agent runs.
  * Support for more complex agent workflows (e.g. `GroupChat` and `Sequential` workflows).
  * Improved user experience (e.g., streaming intermediate model output, better summarization of agent responses, etc).


Project Structure:
  * _autogenstudio/_ code for the backend classes and web api (FastAPI)
  * _frontend/_ code for the webui, built with Gatsby and TailwindCSS


## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#contribution-guide>)
Contribution Guide
We welcome contributions to AutoGen Studio. We recommend the following general steps to contribute to the project:
  * AutoGen Studio is in the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository.
  * Please initiate a discussion on the roadmap issue or a new issue in that repository to discuss your proposed contribution.
  * Submit a pull request in the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository with your contribution!
  * Please use the tag `studio` for any issues, questions, and PRs related to Studio


## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#a-note-on-security>)
A Note on Security
AutoGen Studio is a research prototype and is not meant to be used in a production environment. Some baseline practices are encouraged e.g., using Docker code execution environment for your agents.
However, other considerations such as rigorous tests related to jailbreaking, ensuring LLMs only have access to the right keys of data given the end user’s permissions, and other security features are not implemented in AutoGen Studio.
If you are building a production application, please use the AutoGen framework and implement the necessary security features.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#acknowledgements>)
Acknowledgements
AutoGen Studio is Based on the [AutoGen](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.ag2.ai>) project. It was adapted from a research prototype built in October 2023 (original credits: Gagan Bansal, Adam Fourney, Victor Dibia, Piali Choudhury, Saleema Amershi, Ahmed Awadallah, Chi Wang).
[types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)[Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)
[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Installation](https://docs.ag2.ai/docs/autogen-studio/<#installation>)
  * [Running the Application](https://docs.ag2.ai/docs/autogen-studio/<#running-the-application>)
  * [Capabilities / Roadmap](https://docs.ag2.ai/docs/autogen-studio/<#capabilities-roadmap>)
  * [Contribution Guide](https://docs.ag2.ai/docs/autogen-studio/<#contribution-guide>)
  * [A Note on Security](https://docs.ag2.ai/docs/autogen-studio/<#a-note-on-security>)
  * [Acknowledgements](https://docs.ag2.ai/docs/autogen-studio/<#acknowledgements>)

---

# Using AutoGen Studio
URL: https://docs.ag2.ai/docs/autogen-studio/usage

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)


Navigation
AutoGen Studio
Using AutoGen Studio
[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)


AutoGen Studio
# Using AutoGen Studio
AutoGen Studio supports the declarative creation of an agent workflow and tasks can be specified and run in a chat interface for the agents to complete. The expected usage behavior is that developers can create skills and models, _attach_ them to agents, and compose agents into workflows that can be tested interactively in the chat interface.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#building-an-agent-workflow>)
Building an Agent Workflow
AutoGen Studio implements several entities that are ultimately composed into a workflow.
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#skills>)
Skills
A skill is a python function that implements the solution to a task. In general, a good skill has a descriptive name (e.g. generate _images), extensive docstrings and good defaults (e.g., writing out files to disk for persistence and reuse). Skills can be _associated with_ or _attached to_ agent specifications.
![AutoGen Studio Skill Interface](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/skill.png)
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#models>)
Models
A model refers to the configuration of an LLM. Similar to skills, a model can be attached to an agent specification. The AutoGen Studio interface supports multiple model types including OpenAI models (and any other model endpoint provider that supports the OpenAI endpoint specification), Azure OpenAI models and Gemini Models.
![AutoGen Studio Create new model](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/model_new.png) ![AutoGen Studio Create new model](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/model_openai.png)
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#agents>)
Agents
An agent entity declaratively specifies properties for an AutoGen agent (mirrors most but not all of the members of a base AutoGen Conversable agent class). Currently `UserProxyAgent` and `AssistantAgent` and `GroupChat` agent abstractions are supported.
![AutoGen Studio Create new agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_new.png) ![AutoGen Studio Createan assistant agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_groupchat.png)
Once agents have been created, existing models or skills can be _added_ to the agent.
![AutoGen Studio Add skills and models to agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_skillsmodel.png)
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#workflows>)
Workflows
An agent workflow is a specification of a set of agents (team of agents) that can work together to accomplish a task. AutoGen Studio supports two types of high level workflow patterns:
#### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#autonomous-chat>)
Autonomous Chat :
This workflow implements a paradigm where agents are defined and a chat is initiated between the agents to accomplish a task. AutoGen simplifies this into defining an `initiator` agent and a `receiver` agent where the receiver agent is selected from a list of previously created agents. Note that when the receiver is a `GroupChat` agent (i.e., contains multiple agents), the communication pattern between those agents is determined by the `speaker_selection_method` parameter in the `GroupChat` agent configuration.
![AutoGen Studio Autonomous Chat Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_chat.png)
#### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#sequential-chat>)
Sequential Chat
This workflow allows users to specify a list of `AssistantAgent` agents that are executed in sequence to accomplish a task. The runtime behavior here follows the following pattern: at each step, each `AssistantAgent` is _paired_ with a `UserProxyAgent` and chat initiated between this pair to process the input task. The result of this exchange is summarized and provided to the next `AssistantAgent` which is also paired with a `UserProxyAgent` and their summarized result is passed to the next `AssistantAgent` in the sequence. This continues until the last `AssistantAgent` in the sequence is reached.
![AutoGen Studio Sequential Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_sequential.png)
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#testing-an-agent-workflow>)
Testing an Agent Workflow
AutoGen Studio allows users to interactively test workflows on tasks and review resulting artifacts (such as images, code, and documents).
![AutoGen Studio Test Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_test.png)
Users can also review the “inner monologue” of agent workflows as they address tasks, and view profiling information such as costs associated with the run (such as number of turns, number of tokens etc.), and agent actions (such as whether tools were called and the outcomes of code execution).
![AutoGen Studio Profile Workflow Results](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_profile.png)
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#exporting-agent-workflows>)
Exporting Agent Workflows
Users can download the skills, agents, and workflow configurations they create as well as share and reuse these artifacts. AutoGen Studio also offers a seamless process to export workflows and deploy them as application programming interfaces (APIs) that can be consumed in other applications deploying workflows as APIs.
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#export-workflow>)
Export Workflow
AutoGen Studio allows you to export a selected workflow as a JSON configuration file.
Build -> Workflows -> (On workflow card) -> Export
![AutoGen Studio Export Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_export.png)
### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#using-autogen-studio-workflows-in-a-python-application>)
Using AutoGen Studio Workflows in a Python Application
An exported workflow can be easily integrated into any Python application using the `WorkflowManager` class with just two lines of code. Underneath, the WorkflowManager rehydrates the workflow specification into AutoGen agents that are subsequently used to address tasks.
Copy
```

from autogenstudio import WorkflowManager
# load workflow from exported json workflow file.
workflow_manager = WorkflowManager(workflow="path/to/your/workflow_.json")
# run the workflow on a task
task_query = "What is the height of the Eiffel Tower?. Dont write code, just respond to the question."
workflow_manager.run(message=task_query)

```

### 
[​](https://docs.ag2.ai/docs/autogen-studio/<#deploying-autogen-studio-workflows-as-apis>)
Deploying AutoGen Studio Workflows as APIs
The workflow can be launched as an API endpoint from the command line using the autogenstudio commandline tool.
Copy
```
autogenstudio serve --workflow=workflow.json --port=5000

```

Similarly, the workflow launch command above can be wrapped into a Dockerfile that can be deployed on cloud services like Azure Container Apps or Azure Web Apps.
[Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)[FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)
[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Building an Agent Workflow](https://docs.ag2.ai/docs/autogen-studio/<#building-an-agent-workflow>)
  * [Skills](https://docs.ag2.ai/docs/autogen-studio/<#skills>)
  * [Models](https://docs.ag2.ai/docs/autogen-studio/<#models>)
  * [Agents](https://docs.ag2.ai/docs/autogen-studio/<#agents>)
  * [Workflows](https://docs.ag2.ai/docs/autogen-studio/<#workflows>)
  * [Autonomous Chat :](https://docs.ag2.ai/docs/autogen-studio/<#autonomous-chat>)
  * [Sequential Chat](https://docs.ag2.ai/docs/autogen-studio/<#sequential-chat>)
  * [Testing an Agent Workflow](https://docs.ag2.ai/docs/autogen-studio/<#testing-an-agent-workflow>)
  * [Exporting Agent Workflows](https://docs.ag2.ai/docs/autogen-studio/<#exporting-agent-workflows>)
  * [Export Workflow](https://docs.ag2.ai/docs/autogen-studio/<#export-workflow>)
  * [Using AutoGen Studio Workflows in a Python Application](https://docs.ag2.ai/docs/autogen-studio/<#using-autogen-studio-workflows-in-a-python-application>)
  * [Deploying AutoGen Studio Workflows as APIs](https://docs.ag2.ai/docs/autogen-studio/<#deploying-autogen-studio-workflows-as-apis>)

---

# FAQs
URL: https://docs.ag2.ai/docs/autogen-studio/faqs

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)


Navigation
AutoGen Studio
FAQs
[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)


AutoGen Studio
# FAQs
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-how-do-i-specify-the-directory-where-files-e-g-database-are-stored>)
Q: How do I specify the directory where files(e.g. database) are stored?
A: You can specify the directory where files are stored by setting the `--appdir` argument when running the application. For example, `autogenstudio ui --appdir /path/to/folder`. This will store the database (default) and other files in the specified directory e.g. `/path/to/folder/database.sqlite`.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-where-can-i-adjust-the-default-skills-agent-and-workflow-configurations>)
Q: Where can I adjust the default skills, agent and workflow configurations?
A: You can modify agent configurations directly from the UI or by editing the `init_db_samples` function in the `autogenstudio/database/utils.py` file which is used to initialize the database.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-if-i-want-to-reset-the-entire-conversation-with-an-agent-how-do-i-go-about-it>)
Q: If I want to reset the entire conversation with an agent, how do I go about it?
A: To reset your conversation history, you can delete the `database.sqlite` file in the `--appdir` directory. This will reset the entire conversation history. To delete user files, you can delete the `files` directory in the `--appdir` directory.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-is-it-possible-to-view-the-output-and-messages-generated-by-the-agents-during-interactions>)
Q: Is it possible to view the output and messages generated by the agents during interactions?
A: Yes, you can view the generated messages in the debug console of the web UI, providing insights into the agent interactions. Alternatively, you can inspect the `database.sqlite` file for a comprehensive record of messages.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-use-other-models-with-autogen-studio>)
Q: Can I use other models with AutoGen Studio?
Yes. AutoGen standardizes on the openai model api format, and you can use any api server that offers an openai compliant endpoint. In the AutoGen Studio UI, each agent has an `llm_config` field where you can input your model endpoint details including `model`, `api key`, `base url`, `model type` and `api version`. For Azure OpenAI models, you can find these details in the Azure portal. Note that for Azure OpenAI, the `model name` is the deployment id or engine, and the `model type` is “azure”. For other OSS models, we recommend using a server such as vllm, LMStudio, Ollama, to instantiate an openai compliant endpoint.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-the-server-starts-but-i-cant-access-the-ui>)
Q: The server starts but I can’t access the UI
A: If you are running the server on a remote machine (or a local machine that fails to resolve localhost correctly), you may need to specify the host address. By default, the host address is set to `localhost`. You can specify the host address using the `--host <host>` argument. For example, to start the server on port 8081 and local address such that it is accessible from other machines on the network, you can run the following command:
Copy
```
autogenstudio ui --port 8081 --host 0.0.0.0

```

## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-export-my-agent-workflows-for-use-in-a-python-app>)
Q: Can I export my agent workflows for use in a python app?
Yes. In the Build view, you can click the export button to save your agent workflow as a JSON file. This file can be imported in a python application using the `WorkflowManager` class. For example:
Copy
```

from autogenstudio import WorkflowManager
# load workflow from exported json workflow file.
workflow_manager = WorkflowManager(workflow="path/to/your/workflow_.json")
# run the workflow on a task
task_query = "What is the height of the Eiffel Tower?. Dont write code, just respond to the question."
workflow_manager.run(message=task_query)

```

## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-deploy-my-agent-workflows-as-apis>)
Q: Can I deploy my agent workflows as APIs?
Yes. You can launch the workflow as an API endpoint from the command line using the `autogenstudio` commandline tool. For example:
Copy
```
autogenstudio serve --workflow=workflow.json --port=5000

```

Similarly, the workflow launch command above can be wrapped into a Dockerfile that can be deployed on cloud services like Azure Container Apps or Azure Web Apps.
## 
[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-run-autogen-studio-in-a-docker-container>)
Q: Can I run AutoGen Studio in a Docker container?
A: Yes, you can run AutoGen Studio in a Docker container. You can build the Docker image using the provided [Dockerfile](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/apps/autogen-studio/Dockerfile>) and run the container using the following commands:
Copy
```
FROM python:3.10
WORKDIR /code
RUN pip install -U gunicorn autogenstudio
RUN useradd -m -u 1000 user
USER user
ENV HOME=/home/user \
  PATH=/home/user/.local/bin:$PATH \
  AUTOGENSTUDIO_APPDIR=/home/user/app
WORKDIR $HOME/app
COPY --chown=user . $HOME/app
CMD gunicorn -w $((2 * $(getconf _NPROCESSORS_ONLN) + 1)) --timeout 12600 -k uvicorn.workers.UvicornWorker autogenstudio.web.app:app --bind "0.0.0.0:8081"

```

Using Gunicorn as the application server for improved performance is recommended. To run AutoGen Studio with Gunicorn, you can use the following command:
Copy
```
gunicorn -w $((2 * $(getconf _NPROCESSORS_ONLN) + 1)) --timeout 12600 -k uvicorn.workers.UvicornWorker autogenstudio.web.app:app --bind

```

[Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)[Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)
[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Q: How do I specify the directory where files(e.g. database) are stored?](https://docs.ag2.ai/docs/autogen-studio/<#q-how-do-i-specify-the-directory-where-files-e-g-database-are-stored>)
  * [Q: Where can I adjust the default skills, agent and workflow configurations?](https://docs.ag2.ai/docs/autogen-studio/<#q-where-can-i-adjust-the-default-skills-agent-and-workflow-configurations>)
  * [Q: If I want to reset the entire conversation with an agent, how do I go about it?](https://docs.ag2.ai/docs/autogen-studio/<#q-if-i-want-to-reset-the-entire-conversation-with-an-agent-how-do-i-go-about-it>)
  * [Q: Is it possible to view the output and messages generated by the agents during interactions?](https://docs.ag2.ai/docs/autogen-studio/<#q-is-it-possible-to-view-the-output-and-messages-generated-by-the-agents-during-interactions>)
  * [Q: Can I use other models with AutoGen Studio?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-use-other-models-with-autogen-studio>)
  * [Q: The server starts but I can’t access the UI](https://docs.ag2.ai/docs/autogen-studio/<#q-the-server-starts-but-i-cant-access-the-ui>)
  * [Q: Can I export my agent workflows for use in a python app?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-export-my-agent-workflows-for-use-in-a-python-app>)
  * [Q: Can I deploy my agent workflows as APIs?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-deploy-my-agent-workflows-as-apis>)
  * [Q: Can I run AutoGen Studio in a Docker container?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-run-autogen-studio-in-a-docker-container>)

---

# Agent Monitoring and Debugging with AgentOps
URL: https://docs.ag2.ai/docs/ecosystem/agentops

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Agent Monitoring and Debugging with AgentOps
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Agent Monitoring and Debugging with AgentOps
![AgentOps logo](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/logo/banner-badge.png?raw=true)
[AgentOps](https://docs.ag2.ai/docs/ecosystem/<https:/agentops.ai/?=autogen>) provides session replays, metrics, and monitoring for AI agents.
At a high level, AgentOps gives you the ability to monitor LLM calls, costs, latency, agent failures, multi-agent interactions, tool usage, session-wide statistics, and more. For more info, check out the [AgentOps Repo](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/AgentOps-AI/agentops>).
📊 **Replay Analytics and Debugging**|  Step-by-step agent execution graphs  
---|---  
💸 **LLM Cost Management**|  Track spend with LLM foundation model providers  
🧪 **Agent Benchmarking**|  Test your agents against 1,000+ evals  
🔐 **Compliance and Security**|  Detect common prompt injection and data exfiltration exploits  
🤝 **Framework Integrations**|  Native Integrations with CrewAI, AutoGen, & LangChain  
Agent Dashboard
[![Agent Dashboard](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/overview.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)
Session Analytics
[![Session
Analytics](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/session-overview.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)
Session Replays
[![Session Replays](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/session-replay.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#installation>)
Installation
AgentOps works seamlessly with applications built using Autogen.
  1. **Install AgentOps**


Copy
```
pip install agentops

```

  1. **Create an API Key:** Create a user API key here: [Create API Key](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/settings/projects>)
  2. **Configure Your Environment:** Add your API key to your environment variables


Copy
```
AGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>

```

  1. **Initialize AgentOps**


To start tracking all available data on Autogen runs, simply add two lines of code before implementing Autogen.
Copy
```
import agentops
agentops.init() # Or: agentops.init(api_key="your-api-key-here")

```

After initializing AgentOps, Autogen will now start automatically tracking your agent runs.
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#features>)
Features
  * **LLM Costs** : Track spend with foundation model providers
  * **Replay Analytics** : Watch step-by-step agent execution graphs
  * **Recursive Thought Detection** : Identify when agents fall into infinite loops
  * **Custom Reporting:** Create custom analytics on agent performance
  * **Analytics Dashboard:** Monitor high level statistics about agents in development and production
  * **Public Model Testing** : Test your agents against benchmarks and leaderboards
  * **Custom Tests:** Run your agents against domain specific tests
  * **Time Travel Debugging** : Save snapshots of session states to rewind and replay agent runs from chosen checkpoints.
  * **Compliance and Security** : Create audit logs and detect potential threats such as profanity and PII leaks
  * **Prompt Injection Detection** : Identify potential code injection and secret leaks


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#autogen-agentops-examples>)
Autogen + AgentOps examples
  * [AgentChat with AgentOps Notebook](https://docs.ag2.ai/docs/ecosystem/</notebooks/agentchat_agentops>)
  * [More AgentOps Examples](https://docs.ag2.ai/docs/ecosystem/<https:/docs.agentops.ai/v1/quickstart>)


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#extra-links>)
Extra links
  * [🐦 Twitter](https://docs.ag2.ai/docs/ecosystem/<https:/twitter.com/agentopsai/>)
  * [📢 Discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/JHPt4C7r>)
  * [🖇️ AgentOps Dashboard](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/ref?=autogen>)
  * [📙 Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.agentops.ai/introduction>)


[FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)[Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Installation](https://docs.ag2.ai/docs/ecosystem/<#installation>)
  * [Features](https://docs.ag2.ai/docs/ecosystem/<#features>)
  * [Autogen + AgentOps examples](https://docs.ag2.ai/docs/ecosystem/<#autogen-agentops-examples>)
  * [Extra links](https://docs.ag2.ai/docs/ecosystem/<#extra-links>)

---

# Azure Cosmos DB
URL: https://docs.ag2.ai/docs/ecosystem/azure_cosmos_db

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Azure Cosmos DB
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Azure Cosmos DB
> “OpenAI relies on Cosmos DB to dynamically scale their ChatGPT service – one of the fastest-growing consumer apps ever – enabling high reliability and low maintenance.” – Satya Nadella, Microsoft chairman and chief executive officer
Azure Cosmos DB is a fully managed [NoSQL](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/distributed-nosql>), [relational](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/distributed-relational>), and [vector database](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/azure/cosmos-db/vector-database>). It offers single-digit millisecond response times, automatic and instant scalability, along with guaranteed speed at any scale. Your business continuity is assured with up to 99.999% availability backed by SLA.
Your can simplify your application development by using this single database service for all your AI agent memory system needs, from [geo-replicated distributed cache](https://docs.ag2.ai/docs/ecosystem/<https:/medium.com/@marcodesanctis2/using-azure-cosmos-db-as-your-persistent-geo-replicated-distributed-cache-b381ad80f8a0>) to tracing/logging to [vector database](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/vector-database>).
Learn more about how Azure Cosmos DB enhances the performance of your [AI agent](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/ai-agents>).
  * [Try Azure Cosmos DB free](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/try-free>)
  * [Use Azure Cosmos DB lifetime free tier](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/free-tier>)


[Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)[Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Composio
URL: https://docs.ag2.ai/docs/ecosystem/composio

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Composio
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Composio
![Composio Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-composio.png)
Composio empowers AI agents to seamlessly connect with external tools, Apps, and APIs to perform actions and receive triggers. With built-in support for AutoGen, Composio enables the creation of highly capable and adaptable AI agents that can autonomously execute complex tasks and deliver personalized experiences.
  * [Composio + AutoGen Documentation with Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/docs.composio.dev/framework/autogen>)


[Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)[Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Databricks
URL: https://docs.ag2.ai/docs/ecosystem/databricks

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Databricks
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Databricks
![Databricks Data Intelligence Platform](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-databricks.png)
The [Databricks Data Intelligence Platform ](https://docs.ag2.ai/docs/ecosystem/<https:/www.databricks.com/product/data-intelligence-platform>) allows your entire organization to use data and AI. It’s built on a lakehouse to provide an open, unified foundation for all data and governance, and is powered by a Data Intelligence Engine that understands the uniqueness of your data.
This example demonstrates how to use AutoGen alongside Databricks Foundation Model APIs and open-source LLM DBRX.
  * [Databricks + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/agentchat_databricks_dbrx>)


[Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)[Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Llamaindex
URL: https://docs.ag2.ai/docs/ecosystem/llamaindex

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Llamaindex
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Llamaindex
![Llamaindex Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-llamaindex.png)
[Llamaindex](https://docs.ag2.ai/docs/ecosystem/<https:/www.llamaindex.ai/>) allows the users to create Llamaindex agents and integrate them in autogen conversation patterns.
  * [Llamaindex + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_group_chat_with_llamaindex_agents.ipynb>)


[Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)[Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Mem0:Long-Term Memory and Personalization for Agents
URL: https://docs.ag2.ai/docs/ecosystem/mem0

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Mem0:Long-Term Memory and Personalization for Agents
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Mem0:Long-Term Memory and Personalization for Agents
![Mem0 logo](https://github.com/mem0ai/mem0/blob/main/docs/images/mem0-bg.png?raw=true)
[Mem0 Platform](https://docs.ag2.ai/docs/ecosystem/<https:/www.mem0.ai/>) provides a smart, self-improving memory layer for Large Language Models (LLMs), enabling developers to create personalized AI experiences that evolve with each user interaction.
At a high level, Mem0 Platform offers comprehensive memory management, self-improving memory capabilities, cross-platform consistency, and centralized memory control for AI applications. For more info, check out the [Mem0 Platform Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.mem0.ai>).
🧠 **Comprehensive Memory Management**|  Manage long-term, short-term, semantic, and episodic memories  
---|---  
🔄 **Self-Improving Memory**|  Adaptive system that learns from user interactions  
🌐 **Cross-Platform Consistency**|  Unified user experience across various AI platforms  
🎛️ **Centralized Memory Control**|  Effortless storage, updating, and deletion of memories  
🚀 **Simplified Development**|  API-first approach for streamlined integration  
Activity Dashboard
[![Activity
Dashboard](https://github.com/mem0ai/mem0/blob/main/docs/images/platform/activity.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.mem0.ai/>)
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#installation>)
Installation
Mem0 Platform works seamlessly with various AI applications.
  1. **Sign Up:** Create an account at [Mem0 Platform](https://docs.ag2.ai/docs/ecosystem/<https:/app.mem0.ai/>)
  2. **Generate API Key:** Create an API key in your Mem0 dashboard
  3. **Install Mem0 SDK:**


Copy
```
pip install mem0ai

```

  1. **Configure Your Environment:** Add your API key to your environment variables


Copy
```
MEM0_API_KEY=<YOUR_MEM0_API_KEY>

```

  1. **Initialize Mem0:**


Copy
```
from mem0ai import MemoryClient
memory = MemoryClient(api_key=os.getenv("MEM0_API_KEY"))

```

After initializing Mem0, you can start using its memory management features in your AI application.
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#features>)
Features
  * **Long-term Memory** : Store and retrieve information persistently across sessions
  * **Short-term Memory** : Manage temporary information within a single interaction
  * **Semantic Memory** : Organize and retrieve conceptual knowledge
  * **Episodic Memory** : Store and recall specific events or experiences
  * **Self-Improving System** : Continuously refine understanding based on user interactions


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#common-use-cases>)
Common Use Cases
  * Personalized Learning Assistants
  * Customer Support AI Agents
  * Healthcare Assistants
  * Virtual Companions


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#mem0-platform-examples>)
Mem0 Platform Examples
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#autogen-with-mem0-example>)
AutoGen with Mem0 Example
This example demonstrates how to use Mem0 with AutoGen to create a conversational AI system with memory capabilities.
Copy
```
import os
from autogen import ConversableAgent
from mem0 import MemoryClient
# Set up environment variables
os.environ["OPENAI_API_KEY"] = "your_openai_api_key"
os.environ["MEM0_API_KEY"] = "your_mem0_api_key"
# Initialize Agent and Memory
agent = ConversableAgent(
  "chatbot",
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ.get("OPENAI_API_KEY")}]},
  code_execution_config=False,
  function_map=None,
  human_input_mode="NEVER",
)
memory = MemoryClient(api_key=os.environ.get("MEM0_API_KEY"))
# Insert a conversation into memory
conversation = [
  {
    "role": "assistant",
    "content": "Hi, I'm Best Buy's chatbot!\n\nThanks for being a My Best Buy TotalTM member.\n\nWhat can I help you with?"
  },
  {
    "role": "user",
    "content": "Seeing horizontal lines on our tv. TV model: Sony - 77\" Class BRAVIA XR A80K OLED 4K UHD Smart Google TV"
  },
]
memory.add(messages=conversation, user_id="customer_service_bot")
# Agent Inference
data = "Which TV am I using?"
relevant_memories = memory.search(data, user_id="customer_service_bot")
flatten_relevant_memories = "\n".join([m["memory"] for m in relevant_memories])
prompt = f"""Answer the user question considering the memories.
Memories:
{flatten_relevant_memories}
\n\n
Question: {data}
"""
reply = agent.generate_reply(messages=[{"content": prompt, "role": "user"}])
print("Reply :", reply)
# Multi Agent Conversation
manager = ConversableAgent(
  "manager",
  system_message="You are a manager who helps in resolving customer issues.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER"
)
customer_bot = ConversableAgent(
  "customer_bot",
  system_message="You are a customer service bot who gathers information on issues customers are facing.",
  llm_config={"config_list": [{"model": "gpt-4", "temperature": 0, "api_key": os.environ.get("OPENAI_API_KEY")}]},
  human_input_mode="NEVER"
)
data = "What appointment is booked?"
relevant_memories = memory.search(data, user_id="customer_service_bot")
flatten_relevant_memories = "\n".join([m["memory"] for m in relevant_memories])
prompt = f"""
Context:
{flatten_relevant_memories}
\n\n
Question: {data}
"""
result = manager.send(prompt, customer_bot, request_reply=True)

```

Access the complete code from this notebook: [Mem0 with AutoGen](https://docs.ag2.ai/docs/ecosystem/<https:/colab.research.google.com/drive/1NZEwC9w6V2S6hYmK7l2SQ9jhQrG1uKk8?usp=sharing>)
This example showcases:
  1. Setting up AutoGen agents and Mem0 memory
  2. Adding a conversation to Mem0 memory
  3. Using Mem0 to retrieve relevant memories for agent inference
  4. Implementing a multi-agent conversation with memory-augmented context


For more Mem0 examples, visit our [documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.mem0.ai/examples>).
[Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)[MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Installation](https://docs.ag2.ai/docs/ecosystem/<#installation>)
  * [Features](https://docs.ag2.ai/docs/ecosystem/<#features>)
  * [Common Use Cases](https://docs.ag2.ai/docs/ecosystem/<#common-use-cases>)
  * [Mem0 Platform Examples](https://docs.ag2.ai/docs/ecosystem/<#mem0-platform-examples>)
  * [AutoGen with Mem0 Example](https://docs.ag2.ai/docs/ecosystem/<#autogen-with-mem0-example>)

---

# MemGPT
URL: https://docs.ag2.ai/docs/ecosystem/memgpt

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
MemGPT
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# MemGPT
![MemGPT Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-memgpt.png)
MemGPT enables LLMs to manage their own memory and overcome limited context windows. You can use MemGPT to create perpetual chatbots that learn about you and modify their own personalities over time. You can connect MemGPT to your own local filesystems and databases, as well as connect MemGPT to your own tools and APIs. The MemGPT + AutoGen integration allows you to equip any AutoGen agent with MemGPT capabilities.
  * [MemGPT + AutoGen Documentation with Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/memgpt.readme.io/docs/autogen>)


[Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Microsoft Fabric
URL: https://docs.ag2.ai/docs/ecosystem/microsoft-fabric

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Microsoft Fabric
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Microsoft Fabric
![Fabric Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-fabric.png)
[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview>) is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place. In this notenook, we give a simple example for using AutoGen in Microsoft Fabric.
  * [Microsoft Fabric + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_microsoft_fabric.ipynb>)


[MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)[Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Ollama
URL: https://docs.ag2.ai/docs/ecosystem/ollama

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Ollama
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Ollama
![Ollama Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-ollama.png)
[Ollama](https://docs.ag2.ai/docs/ecosystem/<https:/ollama.com/>) allows the users to run open-source large language models, such as Llama 2, locally. Ollama bundles model weights, configuration, and data into a single package, defined by a Modelfile. It optimizes setup and configuration details, including GPU usage.
  * [Ollama + AutoGen instruction](https://docs.ag2.ai/docs/ecosystem/<https:/ollama.ai/blog/openai-compatibility>)


[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)[PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# PGVector
URL: https://docs.ag2.ai/docs/ecosystem/pgvector

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
PGVector
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# PGVector
[PGVector](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/pgvector/pgvector>) is an open-source vector similarity search for Postgres.
  * [PGVector + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_pgvector.ipynb>)


[Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)[Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Portkey Integration with AutoGen
URL: https://docs.ag2.ai/docs/ecosystem/portkey

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Portkey Integration with AutoGen
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Portkey Integration with AutoGen
![Portkey Metrics Visualization](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Autogen.png?raw=true)
[Portkey](https://docs.ag2.ai/docs/ecosystem/<https:/portkey.ai>) is a 2-line upgrade to make your AutoGen agents reliable, cost-efficient, and fast.
Portkey adds 4 core production capabilities to any AutoGen agent:
  1. Routing to 200+ LLMs
  2. Making each LLM call more robust
  3. Full-stack tracing & cost, performance analytics
  4. Real-time guardrails to enforce behavior


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#getting-started>)
Getting Started
  1. **Install Required Packages:**
  2. Copy
```
pip install -qU pyautogen portkey-ai

```

**Configure AutoGen with Portkey:**
Copy
```
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders
config = [
  {
    "api_key": "OPENAI_API_KEY",
    "model": "gpt-3.5-turbo",
    "base_url": PORTKEY_GATEWAY_URL,
    "api_type": "openai",
    "default_headers": createHeaders(
      api_key="YOUR_PORTKEY_API_KEY",
      provider="openai",
    )
  }
]

```

Generate your API key in the [Portkey Dashboard](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>).


And, that’s it! With just this, you can start logging all of your AutoGen requests and make them reliable.
  1. **Let’s Run your Agent**


Copy
```
import autogen
# Create user proxy agent, coder, product manager

user_proxy = autogen.UserProxyAgent(
  name="User_proxy",
  system_message="A human admin who will give the idea and run the code provided by Coder.",
  code_execution_config={"last_n_messages": 2, "work_dir": "groupchat"},
  human_input_mode="ALWAYS",
)

coder = autogen.AssistantAgent(
  name="Coder",
  system_message = "You are a Python developer who is good at developing games. You work with Product Manager.",
  llm_config={"config_list": config},
)
# Create groupchat
groupchat = autogen.GroupChat(
  agents=[user_proxy, coder], messages=[])
manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={"config_list": config})

# Start the conversation
user_proxy.initiate_chat(
  manager, message="Build a classic & basic pong game with 2 players in python")

```

Here’s the output from your Agent’s run on Portkey’s dashboard
![Portkey Dashboard](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Dashboard.png?raw=true)
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#key-features>)
Key Features
Portkey offers a range of advanced features to enhance your AutoGen agents. Here’s an overview
Feature| Description  
---|---  
🌐 [Multi-LLM Integration](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#interoperability>)| Access 200+ LLMs with simple configuration changes  
🛡️ [Enhanced Reliability](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#reliability>)| Implement fallbacks, load balancing, retries, and much more  
📊 [Advanced Metrics](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#metrics>)| Track costs, tokens, latency, and 40+ custom metrics effortlessly  
🔍 [Detailed Traces and Logs](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#comprehensive-logging>)| Gain insights into every agent action and decision  
🚧 [Guardrails](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#guardrails>)| Enforce agent behavior with real-time checks on inputs and outputs  
🔄 [Continuous Optimization](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#continuous-improvement>)| Capture user feedback for ongoing agent improvements  
💾 [Smart Caching](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#caching>)| Reduce costs and latency with built-in caching mechanisms  
🔐 [Enterprise-Grade Security](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#security-and-compliance>)| Set budget limits and implement fine-grained access controls  
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#colab-notebook>)
Colab Notebook
For a hands-on example of integrating Portkey with Autogen, check out our notebook [![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/ecosystem/<https:/git.new/Portkey-Autogen>) .
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#advanced-features>)
Advanced Features
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#interoperability>)
Interoperability
Easily switch between **200+ LLMs** by changing the `provider` and API key in your configuration.
#### 
[​](https://docs.ag2.ai/docs/ecosystem/<#example-switching-from-openai-to-azure-openai>)
Example: Switching from OpenAI to Azure OpenAI
Copy
```
config = [
  {
    "api_key": "api-key",
    "model": "gpt-3.5-turbo",
    "base_url": PORTKEY_GATEWAY_URL,
    "api_type": "openai",
    "default_headers": createHeaders(
      api_key="YOUR_PORTKEY_API_KEY",
      provider="azure-openai",
      virtual_key="AZURE_VIRTUAL_KEY"
    )
  }
]

```

Note: AutoGen messages will go through Portkey’s AI Gateway following OpenAI’s API signature. Some language models may not work properly because messages need to be in a specific role order.
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#reliability>)
Reliability
Implement fallbacks, load balancing, and automatic retries to make your agents more resilient.
Copy
```
{
 "strategy": {
  "mode": "fallback" # Options: "loadbalance" or "fallback"
 },
 "targets": [
  {
   "provider": "openai",
   "api_key": "openai-api-key",
   "override_params": {
    "top_k": "0.4",
    "max_tokens": "100"
   }
  },
  {
   "provider": "anthropic",
   "api_key": "anthropic-api-key",
   "override_params": {
    "top_p": "0.6",
    "model": "claude-3-5-sonnet-20240620"
   }
  }
 ]
}

```

Learn more about [Portkey Config object here](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai/docs/product/ai-gateway-streamline-llm-integrations/configs>). Be Careful to Load-Balance/Fallback to providers that don’t support tool calling when the request contains a function call.
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#metrics>)
Metrics
Agent runs are complex. Portkey automatically logs **40+ comprehensive metrics** for your AI agents, including cost, tokens used, latency, etc. Whether you need a broad overview or granular insights into your agent runs, Portkey’s customizable filters provide the metrics you need.
Portkey's Observability Dashboard
[![Portkey's Observability
Dashboard](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Dashboard.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>)
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#comprehensive-logging>)
Comprehensive Logging
Access detailed logs and traces of agent activities, function calls, and errors. Filter logs based on multiple parameters for in-depth analysis.
Traces
![Portkey Traces](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-Traces.png)
Logs
[![Portkey
Logs](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-Logs.png)](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>)
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#guardrails>)
Guardrails
AutoGen agents, while powerful, can sometimes produce unexpected or undesired outputs. Portkey’s Guardrails feature helps enforce agent behavior in real-time, ensuring your AutoGen agents operate within specified parameters. Verify both the **inputs** to and _outputs_ from your agents to ensure they adhere to specified formats and content guidelines. Learn more about Portkey’s Guardrails [here](https://docs.ag2.ai/docs/ecosystem/<https:/portkey.ai/docs/product/guardrails>)
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#continuous-improvement>)
Continuous Improvement
Capture qualitative and quantitative user feedback on your requests to continuously enhance your agent performance.
### 
[​](https://docs.ag2.ai/docs/ecosystem/<#caching>)
Caching
Reduce costs and latency with Portkey’s built-in caching system.
Copy
```
portkey_config = {
 "cache": {
  "mode": "semantic" # Options: "simple" or "semantic"
 }
}

```

### 
[​](https://docs.ag2.ai/docs/ecosystem/<#security-and-compliance>)
Security and Compliance
Set budget limits on provider API keys and implement fine-grained user roles and permissions for both your application and the Portkey APIs.
## 
[​](https://docs.ag2.ai/docs/ecosystem/<#additional-resources>)
Additional Resources
  * [📘 Portkey Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai>)
  * [🐦 Twitter](https://docs.ag2.ai/docs/ecosystem/<https:/twitter.com/portkeyai>)
  * [💬 Discord Community](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/JHPt4C7r>)
  * [📊 Portkey App](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai>)


For more information on using these features and setting up your Config, please refer to the [Portkey documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai>).
[PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)[Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/<#getting-started>)
  * [Key Features](https://docs.ag2.ai/docs/ecosystem/<#key-features>)
  * [Colab Notebook](https://docs.ag2.ai/docs/ecosystem/<#colab-notebook>)
  * [Advanced Features](https://docs.ag2.ai/docs/ecosystem/<#advanced-features>)
  * [Interoperability](https://docs.ag2.ai/docs/ecosystem/<#interoperability>)
  * [Example: Switching from OpenAI to Azure OpenAI](https://docs.ag2.ai/docs/ecosystem/<#example-switching-from-openai-to-azure-openai>)
  * [Reliability](https://docs.ag2.ai/docs/ecosystem/<#reliability>)
  * [Metrics](https://docs.ag2.ai/docs/ecosystem/<#metrics>)
  * [Comprehensive Logging](https://docs.ag2.ai/docs/ecosystem/<#comprehensive-logging>)
  * [Guardrails](https://docs.ag2.ai/docs/ecosystem/<#guardrails>)
  * [Continuous Improvement](https://docs.ag2.ai/docs/ecosystem/<#continuous-improvement>)
  * [Caching](https://docs.ag2.ai/docs/ecosystem/<#caching>)
  * [Security and Compliance](https://docs.ag2.ai/docs/ecosystem/<#security-and-compliance>)
  * [Additional Resources](https://docs.ag2.ai/docs/ecosystem/<#additional-resources>)

---

# Promptflow
URL: https://docs.ag2.ai/docs/ecosystem/promptflow

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)


Navigation
Ecosystem
Promptflow
[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)


Ecosystem
# Promptflow
Promptflow is a comprehensive suite of tools that simplifies the development, testing, evaluation, and deployment of LLM based AI applications. It also supports integration with Azure AI for cloud-based operations and is designed to streamline end-to-end development.
Refer to [Promptflow docs](https://docs.ag2.ai/docs/ecosystem/<https:/microsoft.github.io/promptflow/>) for more information.
Quick links:
  * Why use Promptflow - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow>)
  * Quick start guide - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/microsoft.github.io/promptflow/how-to-guides/quick-start.html>)
  * Sample application for Promptflow + AutoGen integration - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/promptflow-autogen>)


## 
[​](https://docs.ag2.ai/docs/ecosystem/<#sample-flow>)
Sample Flow
![Sample Promptflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-promptflow.png)
[Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)[Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)
[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Sample Flow](https://docs.ag2.ai/docs/ecosystem/<#sample-flow>)

---

# Contributing to AG2
URL: https://docs.ag2.ai/docs/contributor-guide/contributing

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Contributing to AG2
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Contributing to AG2
The project welcomes contributions from developers and organizations worldwide. Our goal is to foster a collaborative and inclusive community where diverse perspectives and expertise can drive innovation and enhance the project’s capabilities. Whether you are an individual contributor or represent an organization, we invite you to join us in shaping the future of this project. Together, we can build something truly remarkable. Possible contributions include but not limited to:
  * Pushing patches.
  * Code review of pull requests.
  * Documentation, examples and test cases.
  * Readability improvement, e.g., improvement on docstr and comments.
  * Community participation in [issues](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues>), [discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>), and [twitter](https://docs.ag2.ai/docs/contributor-guide/<https:/twitter.com/Chi_Wang_>).
  * Tutorials, blog posts, talks that promote the project.
  * Sharing application scenarios and/or related research.


If you are new to GitHub [here](https://docs.ag2.ai/docs/contributor-guide/<https:/docs.github.com/en/pull-requests/collaborating-with-pull-requests>) is a detailed help source on getting involved with development on GitHub.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#roadmaps>)
Roadmaps
To see what we are working on and what we plan to work on, please check our [Roadmap](https://docs.ag2.ai/docs/contributor-guide/<https:/ag2.ai/#roadmap>) and [Roadmap Issues](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues?q=is%3Aopen+is%3Aissue+label%3Aroadmap>).
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#becoming-a-reviewer>)
Becoming a Reviewer
There is currently no formal reviewer solicitation process. Current reviewers identify reviewers from active contributors. If you are willing to become a reviewer, you are welcome to let us know on discord.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#contact-maintainers>)
Contact Maintainers
The project is currently maintained by a [dynamic group of volunteers](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/MAINTAINERS.md>) from several organizations. Contact project administrators Chi Wang and Qingyun Wu via support@ag2.ai if you are interested in becoming a maintainer.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#license-headers>)
License Headers
To maintain proper licensing and copyright notices, please include the following header at the top of each new source code file you create, regardless of the programming language:
Copy
```
# Copyright (c) 2023 - 2024, Owners of https://github.com/ag2ai
#
# SPDX-License-Identifier: Apache-2.0

```

For files that contain or are derived from the original MIT-licensed code from <https://github.com/microsoft/autogen>, please use this extended header:
Copy
```
# Copyright (c) 2023 - 2024, Owners of https://github.com/ag2ai
#
# SPDX-License-Identifier: Apache-2.0
#
# Portions derived from https://github.com/microsoft/autogen are under the MIT License.
# SPDX-License-Identifier: MIT

```

Please ensure you update the year range as appropriate. If you’re unsure which header to use or have any questions about licensing, please don’t hesitate to ask in your pull request or reach out to the maintainers.
[Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)[Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Roadmaps](https://docs.ag2.ai/docs/contributor-guide/<#roadmaps>)
  * [Becoming a Reviewer](https://docs.ag2.ai/docs/contributor-guide/<#becoming-a-reviewer>)
  * [Contact Maintainers](https://docs.ag2.ai/docs/contributor-guide/<#contact-maintainers>)
  * [License Headers](https://docs.ag2.ai/docs/contributor-guide/<#license-headers>)

---

# Docker for Development
URL: https://docs.ag2.ai/docs/contributor-guide/docker

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Docker for Development
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Docker for Development
For developers contributing to the AG2 project, we offer a specialized devcontainer environment. This setup is designed to streamline the development process, ensuring that all contributors work within a consistent and well-equipped environment.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#ag2-devcontainer>)
AG2 Devcontainer
  * **Purpose** : The devcontainer is tailored for contributors to the AG2 project. It includes a suite of tools and configurations that aid in the development and testing of new features or fixes.
  * **Usage** : This image is recommended for developers who intend to contribute code or documentation to AG2.
  * **Forking the Project** : It’s advisable to fork the AG2 GitHub project to your own repository. This allows you to make changes in a separate environment without affecting the main project.
  * **Submitting Pull Requests** : Once your changes are ready, submit a pull request from your branch to the upstream AG2 GitHub project for review and integration. For more details on contributing, see the [AG2 Contributing](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>) page.


## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-devcontainers>)
Developing AutoGen with Devcontainers
  1. Open the project in Visual Studio Code.
  2. Press `Ctrl+Shift+P` and select `Dev Containers: Reopen in Container`.
  3. Select the desired python environment and wait for the container to build.
  4. Once the container is built, you can start developing AutoGen.


## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-codespaces>)
Developing Autogen with Codespaces
Provided devcontainer files can be used with GitHub Codespaces. To use the devcontainer with GitHub Codespaces, follow the steps below:
  1. Open the AG2 repository in GitHub.
  2. Click on the `Code` button and select `Open with Codespaces`.
  3. Select the desired python environment and wait for the container to build.
  4. Once the container is built, you can start developing AutoGen.


[Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [AG2 Devcontainer](https://docs.ag2.ai/docs/contributor-guide/<#ag2-devcontainer>)
  * [Developing AutoGen with Devcontainers](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-devcontainers>)
  * [Developing Autogen with Codespaces](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-codespaces>)

---

# Documentation
URL: https://docs.ag2.ai/docs/contributor-guide/documentation

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Documentation
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Documentation
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#how-to-get-a-notebook-rendered-on-the-website>)
How to get a notebook rendered on the website
See [here](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/notebook/contributing.md#how-to-get-a-notebook-displayed-on-the-website>) for instructions on how to get a notebook in the `notebook` directory rendered on the website.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#build-documentation-locally>)
Build documentation locally
  1. To build and test documentation locally, first install [Node.js](https://docs.ag2.ai/docs/contributor-guide/<https:/nodejs.org/en/download/>). For example,


Copy
```
nvm install --lts

```

Then, install the required packages by running the following commands:
Copy
```
pip install pydoc-markdown pyyaml termcolor nbclient

```

  1. You also need to install quarto. Please click on the `Pre-release` tab from [this website](https://docs.ag2.ai/docs/contributor-guide/<https:/quarto.org/docs/download/>) to download the latest version of `quarto` and install it. Ensure that the `quarto` version is `1.5.23` or higher.
  2. Finally, run the following commands to build and serve the documentation:


Copy
```
cd website
python ./process_api_reference.py
python ./process_notebooks.py render
npm install
npm run mintlify:dev

```

The last command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#build-with-devcontainer>)
Build with devcontainer
To build and test documentation using devcontainer, open the project using [VSCode](https://docs.ag2.ai/docs/contributor-guide/<https:/code.visualstudio.com/>), press `Ctrl+Shift+P` and select `Dev Containers: Reopen in Container`.
This will open the project in a devcontainer with all the required dependencies installed.
Open a terminal and run the following command to build and serve the documentation:
Copy
```
cd website
python ./process_api_reference.py
python ./process_notebooks.py render
npm install
npm run mintlify:dev

```

Once done you should be able to access the documentation at `http://localhost:3000/`.
[Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)[File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [How to get a notebook rendered on the website](https://docs.ag2.ai/docs/contributor-guide/<#how-to-get-a-notebook-rendered-on-the-website>)
  * [Build documentation locally](https://docs.ag2.ai/docs/contributor-guide/<#build-documentation-locally>)
  * [Build with devcontainer](https://docs.ag2.ai/docs/contributor-guide/<#build-with-devcontainer>)

---

# File A Bug Report
URL: https://docs.ag2.ai/docs/contributor-guide/file-bug-report

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
File A Bug Report
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# File A Bug Report
When you submit an issue to [GitHub](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues>), please do your best to follow these guidelines! This will make it a lot easier to provide you with good feedback:
  * The ideal bug report contains a short reproducible code snippet. This way anyone can try to reproduce the bug easily (see [this](https://docs.ag2.ai/docs/contributor-guide/<https:/stackoverflow.com/help/mcve>) for more details). If your snippet is longer than around 50 lines, please link to a [gist](https://docs.ag2.ai/docs/contributor-guide/<https:/gist.github.com>) or a GitHub repo.
  * If an exception is raised, please **provide the full traceback**.
  * Please include your **operating system type and version number** , as well as your **Python, autogen, scikit-learn versions**. The version of autogen can be found by running the following code snippet:


Copy
```
import autogen
print(autogen.__version__)

```

  * Please ensure all **code snippets and error messages are formatted in appropriate code blocks**. See [Creating and highlighting code blocks](https://docs.ag2.ai/docs/contributor-guide/<https:/help.github.com/articles/creating-and-highlighting-code-blocks>) for more details.


[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)[Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Guidance for Maintainers
URL: https://docs.ag2.ai/docs/contributor-guide/maintainer

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Guidance for Maintainers
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Guidance for Maintainers
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#general>)
General
  * Be a member of the community and treat everyone as a member. Be inclusive.
  * Help each other and encourage mutual help.
  * Actively post and respond.
  * Keep open communication.
  * Identify good maintainer candidates from active contributors.


## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#pull-requests>)
Pull Requests
  * For new PR, decide whether to close without review. If not, find the right reviewers. One source to refer to is the roles on Discord. Another consideration is to ask users who can benefit from the PR to review it.
  * For old PR, check the blocker: reviewer or PR creator. Try to unblock. Get additional help when needed.
  * When requesting changes, make sure you can check back in time because it blocks merging.
  * Make sure all the checks are passed.
  * For changes that require running OpenAI tests, make sure the OpenAI tests pass too. Running these tests requires approval.
  * In general, suggest small PRs instead of a giant PR.
  * For documentation change, request snapshot of the compiled website, or compile by yourself to verify the format.
  * For new contributors who have not signed the contributing agreement, remind them to sign before reviewing.
  * For multiple PRs which may have conflict, coordinate them to figure out the right order.
  * Pay special attention to:
    * Breaking changes. Don’t make breaking changes unless necessary. Don’t merge to main until enough headsup is provided and a new release is ready.
    * Test coverage decrease.
    * Changes that may cause performance degradation. Do regression test when test suites are available.
    * Discourage **change to the core library** when there is an alternative.


## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#issues-and-discussions>)
Issues and Discussions
  * For new issues, write a reply, apply a label if relevant. Ask on discord when necessary. For roadmap issues, apply the roadmap label and encourage community discussion. Mention relevant experts when necessary.
  * For old issues, provide an update or close. Ask on discord when necessary. Encourage PR creation when relevant.
  * Use “good first issue” for easy fix suitable for first-time contributors.
  * Use “task list” for issues that require multiple PRs.
  * For discussions, create an issue when relevant. Discuss on discord when appropriate.


[File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)[Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [General](https://docs.ag2.ai/docs/contributor-guide/<#general>)
  * [Pull Requests](https://docs.ag2.ai/docs/contributor-guide/<#pull-requests>)
  * [Issues and Discussions](https://docs.ag2.ai/docs/contributor-guide/<#issues-and-discussions>)

---

# Pre-commit
URL: https://docs.ag2.ai/docs/contributor-guide/pre-commit

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Pre-commit
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Pre-commit
Run `pre-commit install` to install pre-commit into your git hooks. Before you commit, run `pre-commit run` to check if you meet the pre-commit requirements. If you use Windows (without WSL) and can’t commit after installing pre-commit, you can run `pre-commit uninstall` to uninstall the hook. In WSL or Linux this is supposed to work.
[Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)[Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Tests
URL: https://docs.ag2.ai/docs/contributor-guide/tests

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Tests
[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)


Contributor Guide
# Tests
Tests are automatically run via GitHub actions. There are two workflows:
  1. [build.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/build.yml>)
  2. [openai.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/openai.yml>)


The first workflow is required to pass for all PRs (and it doesn’t do any OpenAI calls). The second workflow is required for changes that affect the OpenAI tests (and does actually call LLM). The second workflow requires approval to run. When writing tests that require OpenAI calls, please use `pytest.mark.skipif`[](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/b1adac515931bf236ac59224269eeec683a162ba/test/oai/test_client.py#L19>) to make them run in only when `openai` package is installed. If additional dependency for this test is required, install the dependency in the corresponding python version in [openai.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/openai.yml>).
Make sure all tests pass, this is required for [build.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/build.yml>) checks to pass
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#running-tests-locally>)
Running tests locally
To run tests, install the [test] option:
Copy
```
pip install -e."[test]"

```

Then you can run the tests from the `test` folder using the following command:
Copy
```
bash scripts/test.sh test

```

Tests for the `autogen.agentchat.contrib` module may be skipped automatically if the required dependencies are not installed. Please consult the documentation for each contrib module to see what dependencies are required.
See [here](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/notebook/contributing.md#testing>) for how to run notebook tests.
## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#skip-flags-for-tests>)
Skip flags for tests
  * `-m "not openai"` for skipping tests that require access to OpenAI services.
  * `--skip-docker` for skipping tests that explicitly use docker
  * `--skip-redis` for skipping tests that require a Redis server


For example, the following command will skip tests that require access to OpenAI and docker services:
Copy
```
bash scripts/test.sh test -m "not openai" --skip-docker

```

## 
[​](https://docs.ag2.ai/docs/contributor-guide/<#coverage>)
Coverage
Any code you commit should not decrease coverage. To ensure your code maintains or increases coverage, use the following commands after installing the required test dependencies:
Copy
```
pip install -e ."[test]"
bash scripts/test.sh test --cov-report=html

```

Pytest generated a code coverage report and created a htmlcov directory containing an index.html file and other related files. Open index.html in any web browser to visualize and navigate through the coverage data interactively. This interactive visualization allows you to identify uncovered lines and review coverage statistics for individual files.
[Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)[Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)
[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Running tests locally](https://docs.ag2.ai/docs/contributor-guide/<#running-tests-locally>)
  * [Skip flags for tests](https://docs.ag2.ai/docs/contributor-guide/<#skip-flags-for-tests>)
  * [Coverage](https://docs.ag2.ai/docs/contributor-guide/<#coverage>)

---

# Research
URL: https://docs.ag2.ai/docs/Research

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Research
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


Contributor Guide
# Research
For technical details, please check our technical report and research publications.
  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.


Copy
```
@inproceedings{wu2023autogen,
   title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},
   author={Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Shaokun Zhang and Erkang Zhu and Beibin Li and Li Jiang and Xiaoyun Zhang and Chi Wang},
   year={2023},
   eprint={2308.08155},
   archivePrefix={arXiv},
   primaryClass={cs.AI}
}

```

  * [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2303.04673>). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. AutoML’23.


Copy
```
@inproceedings{wang2023EcoOptiGen,
  title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},
  author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},
  year={2023},
  booktitle={AutoML'23},
}

```

  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).


Copy
```
@inproceedings{wu2023empirical,
  title={An Empirical Study on Challenging Math Problem Solving with GPT-4},
  author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},
  year={2023},
  booktitle={ArXiv preprint arXiv:2306.01337},
}

```

  * [EcoAssistant: Using LLM Assistant More Affordably and Accurately](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2310.03046>). Jieyu Zhang, Ranjay Krishna, Ahmed H. Awadallah, Chi Wang. ArXiv preprint arXiv:2310.03046 (2023).


Copy
```
@inproceedings{zhang2023ecoassistant,
  title={EcoAssistant: Using LLM Assistant More Affordably and Accurately},
  author={Zhang, Jieyu and Krishna, Ranjay and Awadallah, Ahmed H and Wang, Chi},
  year={2023},
  booktitle={ArXiv preprint arXiv:2310.03046},
}

```

  * [Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2402.09015>). Negar Arabzadeh, Julia Kiseleva, Qingyun Wu, Chi Wang, Ahmed Awadallah, Victor Dibia, Adam Fourney, Charles Clarke. ArXiv preprint arXiv:2402.09015 (2024).


Copy
```
@misc{Kiseleva2024agenteval,
   title={Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications},
   author={Negar Arabzadeh and Julia Kiseleva and Qingyun Wu and Chi Wang and Ahmed Awadallah and Victor Dibia and Adam Fourney and Charles Clarke},
   year={2024},
   eprint={2402.09015},
   archivePrefix={arXiv},
   primaryClass={cs.CL}
}

```

  * [Training Language Model Agents without Modifying Language Models](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2402.11359>). Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, Qingyun Wu. ICML’24.


Copy
```
@misc{zhang2024agentoptimizer,
   title={Training Language Model Agents without Modifying Language Models},
   author={Shaokun Zhang and Jieyu Zhang and Jiale Liu and Linxin Song and Chi Wang and Ranjay Krishna and Qingyun Wu},
   year={2024},
   booktitle={ICML'24},
}

```

  * [AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2403.04783>). Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu. ArXiv preprint arXiv:2403.04783 (2024).


Copy
```
@misc{zeng2024autodefense,
   title={AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks},
   author={Yifan Zeng and Yiran Wu and Xiao Zhang and Huazheng Wang and Qingyun Wu},
   year={2024},
   eprint={2403.04783},
   archivePrefix={arXiv},
   primaryClass={cs.LG}
}

```

  * [StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2403.11322>). Yiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang, Qingyun Wu. ArXiv preprint arXiv:2403.11322 (2024).


Copy
```
@misc{wu2024stateflow,
    title={StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows},
    author={Yiran Wu and Tianwei Yue and Shaokun Zhang and Chi Wang and Qingyun Wu},
    year={2024},
    eprint={2403.11322},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

```

[Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)[Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# Migration Guide
URL: https://docs.ag2.ai/docs/Migration-Guide

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Contributor Guide
Migration Guide
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


Contributor Guide
# Migration Guide
## 
[​](https://docs.ag2.ai/docs/<#migrating-to-0-2>)
Migrating to 0.2
openai v1 is a total rewrite of the library with many breaking changes. For example, the inference requires instantiating a client, instead of using a global class method. Therefore, some changes are required for users of `pyautogen<0.2`.
  * `api_base` -> `base_url`, `request_timeout` -> `timeout` in `llm_config` and `config_list`. `max_retry_period` and `retry_wait_time` are deprecated. `max_retries` can be set for each client.
  * MathChat is unsupported until it is tested in future release.
  * `autogen.Completion` and `autogen.ChatCompletion` are deprecated. The essential functionalities are moved to `autogen.OpenAIWrapper`:


Copy
```
from autogen import OpenAIWrapper
client = OpenAIWrapper(config_list=config_list)
response = client.create(messages=[{"role": "user", "content": "2+2="}])
print(client.extract_text_or_completion_object(response))

```

  * Inference parameter tuning and inference logging features are updated:


Copy
```
import autogen.runtime_logging
# Start logging
autogen.runtime_logging.start()
# Stop logging
autogen.runtime_logging.stop()

```

Checkout [Logging documentation](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference#logging>) and [Logging example notebook](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_logging.ipynb>) to learn more.
Inference parameter tuning can be done via `flaml.tune`[](https://docs.ag2.ai/docs/<https:/microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function>).
  * `seed` in autogen is renamed into `cache_seed` to accommodate the newly added `seed` param in openai chat completion api. `use_cache` is removed as a kwarg in `OpenAIWrapper.create()` for being automatically decided by `cache_seed`: int | None. The difference between autogen’s `cache_seed` and openai’s `seed` is that: 
    * autogen uses local disk cache to guarantee the exactly same output is produced for the same input and when cache is hit, no openai api call will be made.
    * openai’s `seed` is a best-effort deterministic sampling with no guarantee of determinism. When using openai’s `seed` with `cache_seed` set to None, even for the same input, an openai api call will be made and there is no guarantee for getting exactly the same output.


[Research](https://docs.ag2.ai/docs/</docs/Research>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Migrating to 0.2](https://docs.ag2.ai/docs/<#migrating-to-0-2>)

---

# ​
URL: https://docs.ag2.ai/docs/Home#key-features

* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)

  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)

The Open Source Agent OS

[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)

AG2 provides multi-agent conversation framework as a high-level abstraction.
With this framework, one can conveniently build LLM workflows.

AG2 offers a collection of working systems spanning a wide range of applications
from various domains and complexities.

[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-
Cases/enhanced_inference>)

AG2 supports enhanced LLM inference APIs, which can be used to improve inference
performance and reduce cost.

[Learn how to get started with AG2. Follow the instruction to quickly build-up
your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-
Started>)[This tutorial introduces basic concepts and building blocks of
AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to
different functionalities of AG2, including CodeExecution, GroupChat, and
more.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples
demonstrating the usage of AG2 in various
scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different
applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn
about how you can contribute to AG2 and this documentation, including pushing
patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-
guide/contributing>)

[Foundation Capital Interview with Dr. Chi
Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)

---

# Easily Build Diverse Applications
URL: https://docs.ag2.ai/docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)
Search or ask...
  * [ag2ai/ag2](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag2](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)


Navigation
Use Cases
Multi-agent Conversation Framework
[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)


Use Cases
# Multi-agent Conversation Framework
AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLMs, tools, and humans via automated agent chat. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.
This framework simplifies the orchestration, automation and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#agents>)
Agents
AutoGen abstracts and implements conversable agents designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following notable features:
  * Conversable: Agents in AutoGen are conversable, which means that any agent can send and receive messages from other agents to initiate or continue a conversation
  * Customizable: Agents in AutoGen can be customized to integrate LLMs, humans, tools, or a combination of them.


The figure below shows the built-in agents in AutoGen. ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/autogen_agents.png)
We have designed a generic `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) class for Agents that are capable of conversing with each other through the exchange of messages to jointly finish a task. An agent can communicate with other agents and perform actions. Different agents can differ in what actions they perform after receiving messages. Two representative subclasses are `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) and `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>)
  * The `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) is designed to act as an AI assistant, using LLMs by default but not requiring human input or code execution. It could write Python code (in a Python coding block) for a user to execute when a message (typically a description of a task that needs to be solved) is received. Under the hood, the Python code is written by LLM (e.g., GPT-4). It can also receive the execution results and suggest corrections or bug fixes. Its behavior can be altered by passing a new system message. The LLM [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration can be configured via [`llm_config`].
  * The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) is conceptually a proxy agent for humans, soliciting human input as the agent’s reply at each interaction turn by default and also having the capability to execute code and call functions or tools. The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) triggers code execution automatically when it detects an executable code block in the received message and no human user input is provided. Code execution can be disabled by setting the `code_execution_config` parameter to False. LLM-based response is disabled by default. It can be enabled by setting `llm_config` to a dict corresponding to the [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration. When `llm_config` is set as a dictionary, `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) can generate replies using an LLM when code execution is not performed.


The auto-reply capability of `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) allows for more autonomous multi-agent communication while retaining the possibility of human intervention. One can also easily extend it by registering reply functions with the `register_reply()`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#register-reply>) method.
In the following code, we create an `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) named “assistant” to serve as the assistant and a `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) named “user_proxy” to serve as a proxy for the human user. We will later employ these two agents to solve a task.
Copy
```
import os
from autogen import AssistantAgent, UserProxyAgent
from autogen.coding import DockerCommandLineCodeExecutor
config_list = [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]
# create an AssistantAgent instance named "assistant" with the LLM configuration.
assistant = AssistantAgent(name="assistant", llm_config={"config_list": config_list})
# create a UserProxyAgent instance named "user_proxy" with code execution on docker.
code_executor = DockerCommandLineCodeExecutor()
user_proxy = UserProxyAgent(name="user_proxy", code_execution_config={"executor": code_executor})

```

## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)
Multi-agent Conversations
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)
A Basic Two-Agent Conversation Example
Once the participating agents are constructed properly, one can start a multi-agent conversation session by an initialization step as shown in the following code:
Copy
```
# the assistant receives a message from the user, which contains the task description
user_proxy.initiate_chat(
  assistant,
  message="""What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?""",
)

```

After the initialization step, the conversation could proceed automatically. Find a visual illustration of how the user_proxy and assistant collaboratively solve the above task autonomously below: ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/agent_example.png)
  1. The assistant receives a message from the user_proxy, which contains the task description.
  2. The assistant then tries to write Python code to solve the task and sends the response to the user_proxy.
  3. Once the user_proxy receives a response from the assistant, it tries to reply by either soliciting human input or preparing an automatically generated reply. If no human input is provided, the user_proxy executes the code and uses the result as the auto-reply.
  4. The assistant then generates a further response for the user_proxy. The user_proxy can then decide whether to terminate the conversation. If not, steps 3 and 4 are repeated.


### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)
Supporting Diverse Conversation Patterns
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)
Conversations with different levels of autonomy, and human-involvement patterns
On the one hand, one can achieve fully autonomous conversations after an initialization step. On the other hand, AutoGen can be used to implement human-in-the-loop problem-solving by configuring human involvement levels and patterns (e.g., setting the `human_input_mode` to `ALWAYS`), as human involvement is expected and/or desired in many applications.
#### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)
Static and dynamic conversations
AutoGen, by integrating conversation-driven control utilizing both programming and natural language, inherently supports dynamic conversations. This dynamic nature allows the agent topology to adapt based on the actual conversation flow under varying input problem scenarios. Conversely, static conversations adhere to a predefined topology. Dynamic conversations are particularly beneficial in complex settings where interaction patterns cannot be predetermined.
  1. Registered auto-reply


With the pluggable auto-reply function, one can choose to invoke conversations with other agents depending on the content of the current message and context. For example:
  * Hierarchical chat like in [OptiGuide](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nestedchat_optiguide.ipynb>).
  * [Dynamic Group Chat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat.ipynb>) which is a special form of hierarchical chat. In the system, we register a reply function in the group chat manager, which broadcasts messages and decides who the next speaker will be in a group chat setting.
  * [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/Use-Cases/<https:/docs.ag2.ai/notebooks/agentchat_groupchat_finite_state_machine>) which is a special form of dynamic group chat. In this approach, a directed transition matrix is fed into group chat. Users can specify legal transitions or specify disallowed transitions.
  * Nested chat like in [conversational chess](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nested_chats_chess.ipynb>).


  1. LLM-Based Function Call


Another approach involves LLM-based function calls, where LLM decides if a specific function should be invoked based on the conversation’s status during each inference. This approach enables dynamic multi-agent conversations, as seen in scenarios like [multi-user math problem solving scenario](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_two_users.ipynb>), where a student assistant automatically seeks expertise via function calls.
### 
[​](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)
Diverse Applications Implemented with AutoGen
The figure below shows six examples of applications built using AutoGen. ![Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/app.png)
Find a list of examples in this page: [Automated Agent Chat Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#automated-multi-agent-chat>)
## 
[​](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)
For Further Reading
_Interested in the research that leads to this package? Please check the following papers._
  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.
  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).


[What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)[Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)
[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Agents](https://docs.ag2.ai/docs/Use-Cases/<#agents>)
  * [Multi-agent Conversations](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)
  * [A Basic Two-Agent Conversation Example](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)
  * [Supporting Diverse Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)
  * [Conversations with different levels of autonomy, and human-involvement patterns](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)
  * [Static and dynamic conversations](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)
  * [Diverse Applications Implemented with AutoGen](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)
  * [For Further Reading](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)

---

# ​
URL: https://docs.ag2.ai/docs/Home#explore-content

* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)

  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)

The Open Source Agent OS

[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)

AG2 provides multi-agent conversation framework as a high-level abstraction.
With this framework, one can conveniently build LLM workflows.

AG2 offers a collection of working systems spanning a wide range of applications
from various domains and complexities.

[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-
Cases/enhanced_inference>)

AG2 supports enhanced LLM inference APIs, which can be used to improve inference
performance and reduce cost.

[Learn how to get started with AG2. Follow the instruction to quickly build-up
your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-
Started>)[This tutorial introduces basic concepts and building blocks of
AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to
different functionalities of AG2, including CodeExecution, GroupChat, and
more.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples
demonstrating the usage of AG2 in various
scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different
applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn
about how you can contribute to AG2 and this documentation, including pushing
patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-
guide/contributing>)

[Foundation Capital Interview with Dr. Chi
Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)

---

# User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.
URL: https://docs.ag2.ai/docs/topics

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Code Execution
Command Line Code Executor
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
    * [Command Line Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/cli-code-executor>)
    * [Custom Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/custom-executor>)
    * [Jupyter Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/jupyter-code-executor>)
    * [User Defined Functions](https://docs.ag2.ai/docs/</docs/topics/code-execution/user-defined-functions>)
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


Code Execution
# Command Line Code Executor
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/code-execution/cli-code-executor.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/code-execution/cli-code-executor.ipynb>)
Command line code execution is the simplest form of code execution. Generally speaking, it will save each code block to a file and the execute that file. This means that each code block is executed in a new process. There are two forms of this executor:
  * Docker (`DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>)) - this is where all commands are executed in a Docker container
  * Local (`LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>)) - this is where all commands are executed on the host machine


This executor type is similar to the legacy code execution in AutoGen.
## 
[​](https://docs.ag2.ai/docs/<#docker>)
Docker
The `DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) will create a Docker container and run all commands within that container. The default image that is used is `python:3-slim`, this can be customized by passing the `image` parameter to the constructor. If the image is not found locally then the class will try to pull it. Therefore, having built the image locally is enough. The only thing required for this image to be compatible with the executor is to have `sh` and `python` installed. Therefore, creating a custom image is a simple and effective way to ensure required system dependencies are available.
You can use the executor as a context manager to ensure the container is cleaned up after use. Otherwise, the `atexit` module will be used to stop the container when the program exits.
### 
[​](https://docs.ag2.ai/docs/<#inspecting-the-container>)
Inspecting the container
If you wish to keep the container around after AutoGen is finished using it for whatever reason (e.g. to inspect the container), then you can set the `auto_remove` parameter to `False` when creating the executor. `stop_container` can also be set to `False` to prevent the container from being stopped at the end of the execution.
### 
[​](https://docs.ag2.ai/docs/<#example>)
Example
Copy
```
from pathlib import Path
from autogen.coding import CodeBlock, DockerCommandLineCodeExecutor
work_dir = Path("coding")
work_dir.mkdir(exist_ok=True)
with DockerCommandLineCodeExecutor(work_dir=work_dir) as executor:
  print(
    executor.execute_code_blocks(
      code_blocks=[
        CodeBlock(language="python", code="print('Hello, World!')"),
      ]
    )
  )

```

Copy
```
exit_code=0 output='Hello, World!\n' code_file='coding/tmp_code_07da107bb575cc4e02b0e1d6d99cc204.py'

```

### 
[​](https://docs.ag2.ai/docs/<#combining-autogen-in-docker-with-a-docker-based-executor>)
Combining AutoGen in Docker with a Docker based executor
It is desirable to bundle your AutoGen application into a Docker image. But then, how do you allow your containerised application to execute code in a different container?
The recommended approach to this is called “Docker out of Docker”, where the Docker socket is mounted to the main AutoGen container, so that it can spawn and control “sibling” containers on the host. This is better than what is called “Docker in Docker”, where the main container runs a Docker daemon and spawns containers within itself. You can read more about this [here](https://docs.ag2.ai/docs/<https:/jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/>).
To do this you would need to mount the Docker socket into the AutoGen container. This can be done by adding the following to the `docker run` command:
Copy
```
-v /var/run/docker.sock:/var/run/docker.sock

```

This will allow the AutoGen container to spawn and control sibling containers on the host.
If you need to bind a working directory to the AutoGen container but the directory belongs to your host machine, use the `bind_dir` parameter. This will allow the main AutoGen container to bind the _host_ directory to the new spawned containers and allow it to access the files within the said directory. If the `bind_dir` is not specified, it will fallback to `work_dir`.
## 
[​](https://docs.ag2.ai/docs/<#local>)
Local
The local version will run code on your local system. Use it with caution.
To execute code on the host machine, as in the machine running AutoGen, the `LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>) can be used.
### 
[​](https://docs.ag2.ai/docs/<#example-2>)
Example
Copy
```
from pathlib import Path
from autogen.coding import CodeBlock, LocalCommandLineCodeExecutor
work_dir = Path("coding")
work_dir.mkdir(exist_ok=True)
executor = LocalCommandLineCodeExecutor(work_dir=work_dir)
print(
  executor.execute_code_blocks(
    code_blocks=[
      CodeBlock(language="python", code="print('Hello, World!')"),
    ]
  )
)

```

Copy
```
exit_code=0 output='\nHello, World!\n' code_file='coding/065b51a16ee54f3298847518f9e999d7.py'

```

## 
[​](https://docs.ag2.ai/docs/<#using-a-python-virtual-environment>)
Using a Python virtual environment
By default, the LocalCommandLineCodeExecutor executes code and installs dependencies within the same Python environment as the AutoGen code. You have the option to specify a Python virtual environment to prevent polluting the base Python environment.
### 
[​](https://docs.ag2.ai/docs/<#example-3>)
Example
Copy
```
from autogen.code_utils import create_virtual_env
from autogen.coding import CodeBlock, LocalCommandLineCodeExecutor
venv_dir = ".venv"
venv_context = create_virtual_env(venv_dir)
executor = LocalCommandLineCodeExecutor(virtual_env_context=venv_context)
print(
  executor.execute_code_blocks(code_blocks=[CodeBlock(language="python", code="import sys; print(sys.executable)")])
)

```

## 
[​](https://docs.ag2.ai/docs/<#assigning-to-an-agent>)
Assigning to an agent
These executors can be used to facilitate the execution of agent written code.
Copy
```
from pathlib import Path
from autogen import ConversableAgent
from autogen.coding import DockerCommandLineCodeExecutor
work_dir = Path("coding")
work_dir.mkdir(exist_ok=True)
executor = DockerCommandLineCodeExecutor(work_dir=work_dir)
code_executor_agent = ConversableAgent(
  name="code_executor_agent",
  llm_config=False,
  code_execution_config={
    "executor": executor,
  },
  human_input_mode="NEVER",
)

```

When using code execution it is critical that you update the system prompt of agents you expect to write code to be able to make use of the executor. For example, for the `DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) you might setup a code writing agent like so:
Copy
```
# The code writer agent's system message is to instruct the LLM on how to
# use the Jupyter code executor with IPython kernel.
code_writer_system_message = """
You have been given coding capability to solve tasks using Python code.
In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.
  1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.
  2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.
Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.
When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.
If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.
"""
import os
code_writer_agent = ConversableAgent(
  "code_writer",
  system_message=code_writer_system_message,
  llm_config={"config_list": [{"model": "gpt-4", "api_key": os.environ["OPENAI_API_KEY"]}]},
  code_execution_config=False, # Turn off code execution for this agent.
  max_consecutive_auto_reply=2,
  human_input_mode="NEVER",
)

```

Then we can use these two agents to solve a problem:
Copy
```
import pprint
chat_result = code_executor_agent.initiate_chat(
  code_writer_agent, message="Write Python code to calculate the 14th Fibonacci number."
)
pprint.pprint(chat_result)

```

Copy
```
code_executor_agent (to code_writer):
Write Python code to calculate the 14th Fibonacci number.
--------------------------------------------------------------------------------
code_writer (to code_executor_agent):
Sure, we can calculate the Fibonacci series using a few different methods such as recursion, iterative, by using Binet's formula, or by using matrix exponentiation.
But, since we only need to calculate the 14th number, we will simply use the iterative method as it's the most efficient for this case.
Here is the Python code that solves the task:
```python
def fibonacci(n):
  a, b = 0, 1
  for _ in range(n):
    a, b = b, a + b
  return a
print(fibonacci(14))
```
In this script, `fibonacci(n)` is a function that calculates the nth Fibonacci number. Inside the function, two variables `a` and `b` are initialised to `0` and `1` which are the first two numbers in the Fibonacci series. Then, a loop runs `n` times (14 times in your case), and in each iteration `a` is replaced with `b` and `b` is replaced with `a + b`, which generates the next number in the series. 
The function returns `a`, which is the nth Fibonacci number. The result is then printed to the console.
--------------------------------------------------------------------------------
>>>>>>>> EXECUTING 1 CODE BLOCKS (inferred languages are [python])...
code_executor_agent (to code_writer):
exitcode: 0 (execution succeeded)
Code output: 377

--------------------------------------------------------------------------------
code_writer (to code_executor_agent):
Great! The script has successfully computed the 14th Fibonacci number as 377. If you need to compute other Fibonacci numbers, you can simply change the argument in the `fibonacci()` function call. Please let me know if you need help with anything else.
--------------------------------------------------------------------------------
code_executor_agent (to code_writer):

--------------------------------------------------------------------------------
ChatResult(chat_id=None,
      chat_history=[{'content': 'Write Python code to calculate the 14th '
                   'Fibonacci number.',
             'role': 'assistant'},
             {'content': 'Sure, we can calculate the Fibonacci '
                   'series using a few different methods '
                   'such as recursion, iterative, by using '
                   "Binet's formula, or by using matrix "
                   'exponentiation.\n'
                   '\n'
                   'But, since we only need to calculate the '
                   '14th number, we will simply use the '
                   "iterative method as it's the most "
                   'efficient for this case.\n'
                   '\n'
                   'Here is the Python code that solves the '
                   'task:\n'
                   '\n'
                   '```python\n'
                   'def fibonacci(n):\n'
                   '  a, b = 0, 1\n'
                   '  for _ in range(n):\n'
                   '    a, b = b, a + b\n'
                   '  return a\n'
                   '\n'
                   'print(fibonacci(14))\n'
                   '```\n'
                   '\n'
                   'In this script, `fibonacci(n)` is a '
                   'function that calculates the nth '
                   'Fibonacci number. Inside the function, '
                   'two variables `a` and `b` are '
                   'initialised to `0` and `1` which are the '
                   'first two numbers in the Fibonacci '
                   'series. Then, a loop runs `n` times (14 '
                   'times in your case), and in each '
                   'iteration `a` is replaced with `b` and '
                   '`b` is replaced with `a + b`, which '
                   'generates the next number in the '
                   'series. \n'
                   '\n'
                   'The function returns `a`, which is the '
                   'nth Fibonacci number. The result is then '
                   'printed to the console.',
             'role': 'user'},
             {'content': 'exitcode: 0 (execution succeeded)\n'
                   'Code output: 377\n',
             'role': 'assistant'},
             {'content': 'Great! The script has successfully '
                   'computed the 14th Fibonacci number as '
                   '377. If you need to compute other '
                   'Fibonacci numbers, you can simply change '
                   'the argument in the `fibonacci()` '
                   'function call. Please let me know if you '
                   'need help with anything else.',
             'role': 'user'},
             {'content': '', 'role': 'assistant'}],
      summary='',
      cost=({'gpt-4-0613': {'completion_tokens': 302,
                 'cost': 0.04842,
                 'prompt_tokens': 1010,
                 'total_tokens': 1312},
         'total_cost': 0.04842},
         {'gpt-4-0613': {'completion_tokens': 302,
                 'cost': 0.04842,
                 'prompt_tokens': 1010,
                 'total_tokens': 1312},
         'total_cost': 0.04842}),
      human_input=[])

```

Finally, stop the container. Or better yet use a context manager for it to be stopped automatically.
Copy
```
executor.stop()

```

[Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)[Custom Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/custom-executor>)
[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Docker](https://docs.ag2.ai/docs/<#docker>)
  * [Inspecting the container](https://docs.ag2.ai/docs/<#inspecting-the-container>)
  * [Example](https://docs.ag2.ai/docs/<#example>)
  * [Combining AutoGen in Docker with a Docker based executor](https://docs.ag2.ai/docs/<#combining-autogen-in-docker-with-a-docker-based-executor>)
  * [Local](https://docs.ag2.ai/docs/<#local>)
  * [Example](https://docs.ag2.ai/docs/<#example-2>)
  * [Using a Python virtual environment](https://docs.ag2.ai/docs/<#using-a-python-virtual-environment>)
  * [Example](https://docs.ag2.ai/docs/<#example-3>)
  * [Assigning to an agent](https://docs.ag2.ai/docs/<#assigning-to-an-agent>)

---

# ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.
URL: https://docs.ag2.ai/docs/Examples

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Examples by Category
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


# Examples by Category
## 
[​](https://docs.ag2.ai/docs/<#automated-multi-agent-chat>)
Automated Multi Agent Chat
AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation. Please find documentation about this feature [here](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>).
Links to notebook examples:
### 
[​](https://docs.ag2.ai/docs/<#code-generation-execution-and-debugging>)
Code Generation, Execution, and Debugging
  * Automated Task Solving with Code Generation, Execution & Debugging - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_auto_feedback_from_code_execution>)
  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_RetrieveChat>)
  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/docs/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_RetrieveChat_qdrant>)


### 
[​](https://docs.ag2.ai/docs/<#multi-agent-collaboration-3-agents>)
Multi-Agent Collaboration (>3 Agents)
  * Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat>)
  * Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_vis>)
  * Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_research>)
  * Automated Task Solving with Coding & Planning Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_planning>)
  * Automated Task Solving with transition paths specified in a graph - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_finite_state_machine>)
  * Running a group chat as an inner-monolgue via the SocietyOfMindAgent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_society_of_mind>)
  * Running a group chat with custom speaker selection function - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_customized>)


### 
[​](https://docs.ag2.ai/docs/<#sequential-multi-agent-chats>)
Sequential Multi-Agent Chats
  * Solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_multi_task_chats>)
  * Async-solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_multi_task_async_chats>)
  * Solving Multiple Tasks in a Sequence of Chats Initiated by Different Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchats_sequential_chats>)


### 
[​](https://docs.ag2.ai/docs/<#nested-chats>)
Nested Chats
  * Solving Complex Tasks with Nested Chats - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nestedchat>)
  * Solving Complex Tasks with A Sequence of Nested Chats - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_sequential_chats>)
  * OptiGuide for Solving a Supply Chain Optimization Problem with Nested Chats with a Coding Agent and a Safeguard Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nestedchat_optiguide>)
  * Conversational Chess with Nested Chats and Tool Use - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_chats_chess>)


### 
[​](https://docs.ag2.ai/docs/<#swarms>)
Swarms
  * Orchestrating agents in a Swarm - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm>)
  * Orchestrating agents in a Swarm (Enhanced) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm_enhanced>)


### 
[​](https://docs.ag2.ai/docs/<#applications>)
Applications
  * Automated Continual Learning from New Data - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_stream>)


  * [AutoAnny](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/auto-anny>) - A Discord bot built using AutoGen


### 
[​](https://docs.ag2.ai/docs/<#rag>)
RAG
  * GraphRAG agent using FalkorDB (feat. swarms and Google Maps API) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm_graphrag_trip_planner>)


### 
[​](https://docs.ag2.ai/docs/<#tool-use>)
Tool Use
  * **Web Search** : Solve Tasks Requiring Web Info - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_web_info>)
  * Use Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_currency_calculator>)
  * Use Tools via Sync and Async Function Calling - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_async>)
  * Task Solving with Langchain Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_langchain>)
  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_RAG>)
  * Function Inception: Enable AutoGen agents to update/remove functions during conversations. - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_inception_function>)
  * Agent Chat with Whisper - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_video_transcript_translate_with_whisper>)
  * Constrained Responses via Guidance - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_guidance>)
  * Browse the Web with Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_surfer>)
  * **SQL** : Natural Language Text to SQL Query using the [Spider](https://docs.ag2.ai/docs/<https:/yale-lily.github.io/spider>) Text-to-SQL Benchmark - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_sql_spider>)
  * **Web Scraping** : Web Scraping with Apify - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_webscraping_with_apify>)
  * **Write a software app, task by task, with specially designed functions.** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_code_writing>).


### 
[​](https://docs.ag2.ai/docs/<#human-involvement>)
Human Involvement
  * Simple example in ChatGPT style [View example](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/simple_chat.py>)
  * Auto Code Generation, Execution, Debugging and **Human Feedback** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_human_feedback>)
  * Automated Task Solving with GPT-4 + **Multiple Human Users** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_two_users>)
  * Agent Chat with **Async Human Inputs** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/async_human_input>)


### 
[​](https://docs.ag2.ai/docs/<#agent-teaching-and-learning>)
Agent Teaching and Learning
  * Teach Agents New Skills & Reuse via Automated Chat - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teaching>)
  * Teach Agents New Facts, User Preferences and Skills Beyond Coding - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teachability>)
  * Teach OpenAI Assistants Through GPTAssistantAgent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teachable_oai_assistants>)
  * Agent Optimizer: Train Agents in an Agentic Way - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_agentoptimizer>)


### 
[​](https://docs.ag2.ai/docs/<#multi-agent-chat-with-openai-assistants-in-the-loop>)
Multi-Agent Chat with OpenAI Assistants in the loop
  * Hello-World Chat with OpenAi Assistant in AutoGen - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_twoagents_basic>)
  * Chat with OpenAI Assistant using Function Call - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_function_call>)
  * Chat with OpenAI Assistant with Code Interpreter - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_code_interpreter>)
  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_retrieval>)
  * OpenAI Assistant in a Group Chat - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_groupchat>)
  * GPTAssistantAgent based Multi-Agent Tool Use - [View Notebook](https://docs.ag2.ai/docs/</notebooks/gpt_assistant_agent_function_call>)


### 
[​](https://docs.ag2.ai/docs/<#non-openai-models>)
Non-OpenAI Models
  * Conversational Chess using non-OpenAI Models - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_chats_chess_altmodels>)


### 
[​](https://docs.ag2.ai/docs/<#multimodal-agent>)
Multimodal Agent
  * Multimodal Agent Chat with DALLE and GPT-4V - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_dalle_and_gpt4v>)
  * Multimodal Agent Chat with Llava - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_lmm_llava>)
  * Multimodal Agent Chat with GPT-4V - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_lmm_gpt-4v>)


### 
[​](https://docs.ag2.ai/docs/<#long-context-handling>)
Long Context Handling
  * Long Context Handling as A Capability - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_transform_messages>)


### 
[​](https://docs.ag2.ai/docs/<#evaluation-and-assessment>)
Evaluation and Assessment
  * AgentEval: A Multi-Agent System for Assess Utility of LLM-powered Applications - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agenteval_cq_math>)


### 
[​](https://docs.ag2.ai/docs/<#automatic-agent-building>)
Automatic Agent Building
  * Automatically Build Multi-agent System with AgentBuilder - [View Notebook](https://docs.ag2.ai/docs/</notebooks/autobuild_basic>)
  * Automatically Build Multi-agent System from Agent Library - [View Notebook](https://docs.ag2.ai/docs/</notebooks/autobuild_agent_library>)


### 
[​](https://docs.ag2.ai/docs/<#observability>)
Observability
  * Track LLM calls, tool usage, actions and errors using AgentOps - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_agentops>)
  * Cost Calculation - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_cost_token_tracking>)


## 
[​](https://docs.ag2.ai/docs/<#enhanced-inferences>)
Enhanced Inferences
### 
[​](https://docs.ag2.ai/docs/<#utilities>)
Utilities
  * API Unification - [View Documentation with Code Example](https://docs.ag2.ai/docs/<https:/docs.ag2.ai/docs/Use-Cases/enhanced_inference#api-unification>)
  * Utility Functions to Help Managing API configurations effectively - [View Notebook](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)


### 
[​](https://docs.ag2.ai/docs/<#inference-hyperparameters-tuning>)
Inference Hyperparameters Tuning
AutoGen offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them. Please find documentation about this feature [here](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>).
Links to notebook examples:
  * [Optimize for Code Generation](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) | [Open in colab](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>)
  * [Optimize for Math](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) | [Open in colab](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>)


[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)
On this page
  * [Automated Multi Agent Chat](https://docs.ag2.ai/docs/<#automated-multi-agent-chat>)
  * [Code Generation, Execution, and Debugging](https://docs.ag2.ai/docs/<#code-generation-execution-and-debugging>)
  * [Multi-Agent Collaboration (>3 Agents)](https://docs.ag2.ai/docs/<#multi-agent-collaboration-3-agents>)
  * [Sequential Multi-Agent Chats](https://docs.ag2.ai/docs/<#sequential-multi-agent-chats>)
  * [Nested Chats](https://docs.ag2.ai/docs/<#nested-chats>)
  * [Swarms](https://docs.ag2.ai/docs/<#swarms>)
  * [Applications](https://docs.ag2.ai/docs/<#applications>)
  * [RAG](https://docs.ag2.ai/docs/<#rag>)
  * [Tool Use](https://docs.ag2.ai/docs/<#tool-use>)
  * [Human Involvement](https://docs.ag2.ai/docs/<#human-involvement>)
  * [Agent Teaching and Learning](https://docs.ag2.ai/docs/<#agent-teaching-and-learning>)
  * [Multi-Agent Chat with OpenAI Assistants in the loop](https://docs.ag2.ai/docs/<#multi-agent-chat-with-openai-assistants-in-the-loop>)
  * [Non-OpenAI Models](https://docs.ag2.ai/docs/<#non-openai-models>)
  * [Multimodal Agent](https://docs.ag2.ai/docs/<#multimodal-agent>)
  * [Long Context Handling](https://docs.ag2.ai/docs/<#long-context-handling>)
  * [Evaluation and Assessment](https://docs.ag2.ai/docs/<#evaluation-and-assessment>)
  * [Automatic Agent Building](https://docs.ag2.ai/docs/<#automatic-agent-building>)
  * [Observability](https://docs.ag2.ai/docs/<#observability>)
  * [Enhanced Inferences](https://docs.ag2.ai/docs/<#enhanced-inferences>)
  * [Utilities](https://docs.ag2.ai/docs/<#utilities>)
  * [Inference Hyperparameters Tuning](https://docs.ag2.ai/docs/<#inference-hyperparameters-tuning>)

---

# ApplicationsA collection of different applications built using AG2.
URL: https://docs.ag2.ai/docs/Gallery

[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)
Search or ask...
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)
  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)


Navigation
Application Gallery
[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)
  * [Home](https://docs.ag2.ai/docs/</docs/Home>)
  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)


##### Installation
  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)
  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)
  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)


##### Tutorials
  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)
  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)
  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)
  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)
  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)
  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)
  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)


##### Use Cases
  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)
  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)


##### User Guide
  * Code Execution
  * OpenAI Assistant
  * GroupChat
  * Using Non-OpenAI Models
  * CaptainAgent
  * Handling Long Contexts
  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)
  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)
  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)
  * Prompting and Reasoning
  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)
  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)
  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)
  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)


##### API Reference
  * agentchat
  * cache
  * coding
  * interop
  * io
  * logger
  * messages
  * oai
  * tools
  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)
  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)
  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)
  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)
  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)
  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)
  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)
  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)
  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)


##### AutoGen Studio
  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)
  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)
  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)


##### Ecosystem
  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)
  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)
  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)
  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)
  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)
  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)
  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)
  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)
  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)
  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)


##### Contributor Guide
  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)
  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)
  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)
  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)
  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)
  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)
  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)
  * [Research](https://docs.ag2.ai/docs/</docs/Research>)
  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)


# Application Gallery
This page contains a list of demos that use AutoGen in various applications from the community.
**Contribution guide:** Built something interesting with AutoGen? Submit a PR to add it to the list! See the [Contribution Guide below](https://docs.ag2.ai/docs/</docs/Gallery#contributing>) for more details.
toolsgroupchatappblockchainuiroboticsextension
![AutoTx - Crypto Transactions Agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/autotx.png)
##### AutoTx - Crypto Transactions Agent
Generates on-chain transactions, which are submitted to a smart account so users can easily approve & execute them.
toolsgroupchatappblockchain
![AutoGen Virtual Focus Group](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Virtual Focus Group
A virtual consumer focus group with multiple custom personas, product details, and final analysis created with AutoGen, Ollama/Llama3, and Streamlit.
uigroupchat
![Function Generator & Validator](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/TensionCode.png)
##### Function Generator & Validator
A platform where user-required code is generated and simultaneously validated against sample data by AutoGen.
appui
![Autogen Robot](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/robot.jpg)
##### Autogen Robot
This project showcases how agent's can act as a brain to control a physical robot.
robotics
![AutoGen Group Chat Playground](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Group Chat Playground
A huggingface space to explore AutoGen group chat, build agents with zero-code, and access source code for reuse.
ui
![A Stateful Dev Environment Powered by Jupyter Notebook](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### A Stateful Dev Environment Powered by Jupyter Notebook
An AutoGen Teams Powered by Jupyter notebook.
extensiontools
![Solving Security Vulnerabilities with AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Solving Security Vulnerabilities with AutoGen
An article discussing the use of AutoGen to tackle security vulnerabilities.
app
![Research Agents via AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Research Agents via AutoGen
A guide to building a team of AI research agents using AutoGen.
groupchattools
![AutoGen with Ollama and LiteLLM](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen with Ollama and LiteLLM
A demonstration of integrating Ollama, LiteLLM, and AutoGen.
extension
![AutoGen Engineer](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Engineer
Join the AutoGen Engineer group chat to collaborate and build with others.
groupchatapp
![AutoGen with Obsidian](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen with Obsidian
Learn how to integrate AutoGen with Obsidian for note-taking and management.
toolsapp
![AutoGen Builder GPT](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Builder GPT
A platform for building conversational AI agents with AutoGen Builder GPT.
groupchatui
![AutoGen Multi-Round Human Interaction Chatbot with Gradio 4.0](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Multi-Round Human Interaction Chatbot with Gradio 4.0
Experience a multi-round human interaction chatbot built with AutoGen and Gradio 4.0.
uiapp
![Agentcloud.dev \(UI for AutoGen\)](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Agentcloud.dev (UI for AutoGen)
Agentcloud.dev provides a user interface for managing and collaborating with AutoGen agents.
ui
![Next.js + FASTAPI Based UI for AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Next.js + FASTAPI Based UI for AutoGen
A project featuring a UI for AutoGen built with Next.js and FastAPI.
ui
![Full Function UI for AutoGen Powered by Panel](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Full Function UI for AutoGen Powered by Panel
A UI allows users to directly interact with AI agents in real-time during a group chat scenario
ui
![AutoGen Monitoring and Observability](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Monitoring and Observability
Documentation on monitoring and observability features for AutoGen.
extension
![Postgres Data Analytics AI Agent with AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Postgres Data Analytics AI Agent with AutoGen
Utilizing AutoGen to speak directly to Postgres Database.
toolsapp
![AutoGen with Local LLMs](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen with Local LLMs
An article on deploying multiple AI agents using local LLMs with AutoGen.
extension
![AutoGen with FastApi backend and React Frontend](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen with FastApi backend and React Frontend
A demonstration of using AutoGen with a FastAPI backend and React frontend.
ui
![Talk to AutoGen Agents Using Whisper and Gradio](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Talk to AutoGen Agents Using Whisper and Gradio
Interact with AutoGen agents using Whisper and Gradio interfaces.
ui
![AutoGen + LangChain + ChromaDB = You Super AI Assistant](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen + LangChain + ChromaDB = You Super AI Assistant
Create a super AI assistant combining AutoGen, LangChain, and ChromaDB.
app
![AutoGen + Flowise = Super AI Agents on No-Code Platform](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen + Flowise = Super AI Agents on No-Code Platform
Build super AI agents on a no-code platform using AutoGen and Flowise.
app
![AutoGen with RunPod and TextGen WebUI](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen with RunPod and TextGen WebUI
Learn how to use AutoGen with RunPod and TextGen WebUI for enhanced AI agent integration.
uiextension
![Jarvis Collaborates with AutoGen for Tweet Analysis](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Jarvis Collaborates with AutoGen for Tweet Analysis
Explore how Jarvis collaborates with AutoGen for tweet analysis.
toolsapp
![AutoGen + LangChain + PlayHT = Super AI Agent that Speaks](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen + LangChain + PlayHT = Super AI Agent that Speaks
Combine AutoGen, LangChain, and PlayHT to create a speaking super AI agent.
toolsapp
![AutoGen Flow with FastAPI and Nextjs](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen Flow with FastAPI and Nextjs
A development flow using AutoGen with FastAPI and Next.js.
ui
![Build Vision-Enabled AI Agents with AutoGen + Llava](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Build Vision-Enabled AI Agents with AutoGen + Llava
Tutorial on building vision-enabled AI agents using AutoGen and llava.
toolsapp
![AutoGen + Chainlit chat interface with multi-agent conversation](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### AutoGen + Chainlit chat interface with multi-agent conversation
Chainlit chat interface with multi-agent conversation between agents to complete a tasks
ui
![XForce IDE: Build AutoGen based workforces from a drag and drop UI](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/x-force-ide-ui.png)
##### XForce IDE: Build AutoGen based workforces from a drag and drop UI
X-Force IDE is a low-code, agent-as-a-service UI framework that lets you create AutoGen-based workforces from a drag-and-drop-like user interface.
ui
![Multimodal Webagent created with AutoGen and OpenAI's Assistants API](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/webagent.jpg)
##### Multimodal Webagent created with AutoGen and OpenAI's Assistants API
A multimodal webbrowsing agent that autonomously browses the web.
toolsapp
![Create Issues from Code Commits - using Autogen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/composio-autogen.png)
##### Create Issues from Code Commits - using Autogen
Automatically creating linear tasks and assigning them to the right person, project, and team from GitHub commits using AutoGen Agents.
tools
![Agentok - Autogen Visualized](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Agentok - Autogen Visualized
Offering intuitive visual tools that streamline the creation and management of complex AutoGen workflows.
toolsuiapp
![Expense Tracker - using Autogen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)
##### Expense Tracker - using Autogen
Tracks personal finance income and expenses then helps the user to analyse it using AutoGen agents.
toolsapp
## 
[​](https://docs.ag2.ai/docs/<#contributing>)
Contributing
Thank you for your interest in contributing! To add your demo to the gallery, please create a Pull Request (PR) with the following details.
  * Updated `website/snippets/data/GalleryItems.mdx` file with your application entry.
  * The application image added to the `static/img/gallery` directory if the image is local. If the image is hosted online, just update the `image` property with the URL of the image.
  * Below is an example of an entry in the `website/snippets/data/GalleryItems.mdx` file:
Copy
```
 {
 "title": "AutoGen Playground", // The title of your demo
 "link": "https://huggingface.co/spaces/thinkall/AutoGen_Playground", // URL to your demo
 "description": "A space to explore the capabilities of AutoGen.", // A brief description
 "image": "default.png", // Filename of the image present in the `static/img/gallery` directory or URL of the hosted image
 "tags": ["ui"] // Tags to categorize your demo
 }

```

  * Refer to the below table for description of each property:
Property| Description  
---|---  
`title`| Provide a clear and concise title for your demo.  
`link`| Include a valid URL linking to your demo.  
`description`| Write a short description (1-2 sentences) to summarize your demo.  
`image`| Use the filename of an image stored in the `static/img/gallery` directory if the image is local.  
If the image is hosted online, ensure the URL is correctly added to the entry.  
`tags`| Add up to two tags that best describe your demo for clarity.  
Choose from the existing tags:  
- `app`: Using Autogen for specific applications.  
- `extension`: Enhancing AutoGen beyond the features in the current version.  
- `ui`: Building a user interface for AutoGen.  
- `tool`: Strengthening AutoGen Agents with external tools.  
- `groupchat`: Solving complex tasks with a group of Agents.  
Or propose new tags if the existing ones do not describe your demo. Ensure they are descriptive and concise.  


[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)
[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)

---

# ​
URL: https://docs.ag2.ai/docs/Home#popular-resources

* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)

  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)
  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)

The Open Source Agent OS

[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)

AG2 provides multi-agent conversation framework as a high-level abstraction.
With this framework, one can conveniently build LLM workflows.

AG2 offers a collection of working systems spanning a wide range of applications
from various domains and complexities.

[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-
Cases/enhanced_inference>)

AG2 supports enhanced LLM inference APIs, which can be used to improve inference
performance and reduce cost.

[Learn how to get started with AG2. Follow the instruction to quickly build-up
your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-
Started>)[This tutorial introduces basic concepts and building blocks of
AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to
different functionalities of AG2, including CodeExecution, GroupChat, and
more.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples
demonstrating the usage of AG2 in various
scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different
applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn
about how you can contribute to AG2 and this documentation, including pushing
patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-
guide/contributing>)

[Foundation Capital Interview with Dr. Chi
Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)

---

