{
  "url": "https://docs.ag2.ai/docs/Home",
  "content": "# AG2 home page\nURL: https://docs.ag2.ai/\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nHome\n[Documentation](https://docs.ag2.ai/</docs/Home>)[Examples](https://docs.ag2.ai/</notebooks/Examples>)[Blog](https://docs.ag2.ai/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/</docs/Migration-Guide>)\n\n\n# Home\n![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)\n## AG2\nThe Open Source Agent OS\n[Getting Started - 3 Minute](https://docs.ag2.ai/</docs/Getting-Started>)\n### \n[​](https://docs.ag2.ai/<#key-features>)\nKey Features\n![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/</docs/Use-Cases/agent_chat>)\nAG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.\n![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)\nAG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.\n![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/</docs/Use-Cases/enhanced_inference>)\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.\n### \n[​](https://docs.ag2.ai/<#explore-content>)\nExplore content\n## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/</docs/contributor-guide/contributing>)\n### \n[​](https://docs.ag2.ai/<#popular-resources>)\nPopular resources\n[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)\n[Getting Started](https://docs.ag2.ai/</docs/Getting-Started>)\n[x](https://docs.ag2.ai/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Documentation\nURL: https://docs.ag2.ai/docs/Home\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nHome\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\n# Home\n![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)\n## AG2\nThe Open Source Agent OS\n[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n### \n[​](https://docs.ag2.ai/docs/<#key-features>)\nKey Features\n![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\nAG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.\n![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)\nAG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.\n![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.\n### \n[​](https://docs.ag2.ai/docs/<#explore-content>)\nExplore content\n## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/docs/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n### \n[​](https://docs.ag2.ai/docs/<#popular-resources>)\nPopular resources\n[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)\n[Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Examples\nURL: https://docs.ag2.ai/notebooks/Examples\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/notebooks/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nExamples\nExamples by Category\n[Documentation](https://docs.ag2.ai/notebooks/</docs/Home>)[Examples](https://docs.ag2.ai/notebooks/</notebooks/Examples>)[Blog](https://docs.ag2.ai/notebooks/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/notebooks/</talks/future_talks/index>)\n##### Examples\n  * [Examples by Category](https://docs.ag2.ai/notebooks/</notebooks/Examples>)\n  * Examples by Notebook\n  * [Application Gallery](https://docs.ag2.ai/notebooks/</notebooks/Gallery>)\n\n\nExamples\n# Examples by Category\n## \n[​](https://docs.ag2.ai/notebooks/<#automated-multi-agent-chat>)\nAutomated Multi Agent Chat\nAutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation. Please find documentation about this feature [here](https://docs.ag2.ai/notebooks/</docs/Use-Cases/agent_chat>).\nLinks to notebook examples:\n### \n[​](https://docs.ag2.ai/notebooks/<#code-generation-execution-and-debugging>)\nCode Generation, Execution, and Debugging\n  * Automated Task Solving with Code Generation, Execution & Debugging - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_auto_feedback_from_code_execution>)\n  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_RetrieveChat>)\n  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/notebooks/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_RetrieveChat_qdrant>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#multi-agent-collaboration-3-agents>)\nMulti-Agent Collaboration (>3 Agents)\n  * Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat>)\n  * Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_vis>)\n  * Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_research>)\n  * Automated Task Solving with Coding & Planning Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_planning>)\n  * Automated Task Solving with transition paths specified in a graph - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_finite_state_machine>)\n  * Running a group chat as an inner-monolgue via the SocietyOfMindAgent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_society_of_mind>)\n  * Running a group chat with custom speaker selection function - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_customized>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#sequential-multi-agent-chats>)\nSequential Multi-Agent Chats\n  * Solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_multi_task_chats>)\n  * Async-solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_multi_task_async_chats>)\n  * Solving Multiple Tasks in a Sequence of Chats Initiated by Different Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchats_sequential_chats>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#nested-chats>)\nNested Chats\n  * Solving Complex Tasks with Nested Chats - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nestedchat>)\n  * Solving Complex Tasks with A Sequence of Nested Chats - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_sequential_chats>)\n  * OptiGuide for Solving a Supply Chain Optimization Problem with Nested Chats with a Coding Agent and a Safeguard Agent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nestedchat_optiguide>)\n  * Conversational Chess with Nested Chats and Tool Use - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_chats_chess>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#swarms>)\nSwarms\n  * Orchestrating agents in a Swarm - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm>)\n  * Orchestrating agents in a Swarm (Enhanced) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm_enhanced>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#applications>)\nApplications\n  * Automated Continual Learning from New Data - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_stream>)\n\n\n  * [AutoAnny](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/auto-anny>) - A Discord bot built using AutoGen\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#rag>)\nRAG\n  * GraphRAG agent using FalkorDB (feat. swarms and Google Maps API) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_swarm_graphrag_trip_planner>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#tool-use>)\nTool Use\n  * **Web Search** : Solve Tasks Requiring Web Info - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_web_info>)\n  * Use Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_currency_calculator>)\n  * Use Tools via Sync and Async Function Calling - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_async>)\n  * Task Solving with Langchain Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_langchain>)\n  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_groupchat_RAG>)\n  * Function Inception: Enable AutoGen agents to update/remove functions during conversations. - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_inception_function>)\n  * Agent Chat with Whisper - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_video_transcript_translate_with_whisper>)\n  * Constrained Responses via Guidance - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_guidance>)\n  * Browse the Web with Agents - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_surfer>)\n  * **SQL** : Natural Language Text to SQL Query using the [Spider](https://docs.ag2.ai/notebooks/<https:/yale-lily.github.io/spider>) Text-to-SQL Benchmark - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_sql_spider>)\n  * **Web Scraping** : Web Scraping with Apify - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_webscraping_with_apify>)\n  * **Write a software app, task by task, with specially designed functions.** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_function_call_code_writing>).\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#human-involvement>)\nHuman Involvement\n  * Simple example in ChatGPT style [View example](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/simple_chat.py>)\n  * Auto Code Generation, Execution, Debugging and **Human Feedback** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_human_feedback>)\n  * Automated Task Solving with GPT-4 + **Multiple Human Users** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_two_users>)\n  * Agent Chat with **Async Human Inputs** - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/async_human_input>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#agent-teaching-and-learning>)\nAgent Teaching and Learning\n  * Teach Agents New Skills & Reuse via Automated Chat - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teaching>)\n  * Teach Agents New Facts, User Preferences and Skills Beyond Coding - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teachability>)\n  * Teach OpenAI Assistants Through GPTAssistantAgent - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_teachable_oai_assistants>)\n  * Agent Optimizer: Train Agents in an Agentic Way - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_agentoptimizer>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#multi-agent-chat-with-openai-assistants-in-the-loop>)\nMulti-Agent Chat with OpenAI Assistants in the loop\n  * Hello-World Chat with OpenAi Assistant in AutoGen - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_twoagents_basic>)\n  * Chat with OpenAI Assistant using Function Call - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_function_call>)\n  * Chat with OpenAI Assistant with Code Interpreter - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_code_interpreter>)\n  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_retrieval>)\n  * OpenAI Assistant in a Group Chat - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_oai_assistant_groupchat>)\n  * GPTAssistantAgent based Multi-Agent Tool Use - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/gpt_assistant_agent_function_call>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#non-openai-models>)\nNon-OpenAI Models\n  * Conversational Chess using non-OpenAI Models - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_nested_chats_chess_altmodels>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#multimodal-agent>)\nMultimodal Agent\n  * Multimodal Agent Chat with DALLE and GPT-4V - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_dalle_and_gpt4v>)\n  * Multimodal Agent Chat with Llava - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_lmm_llava>)\n  * Multimodal Agent Chat with GPT-4V - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_lmm_gpt-4v>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#long-context-handling>)\nLong Context Handling\n  * Long Context Handling as A Capability - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_transform_messages>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#evaluation-and-assessment>)\nEvaluation and Assessment\n  * AgentEval: A Multi-Agent System for Assess Utility of LLM-powered Applications - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agenteval_cq_math>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#automatic-agent-building>)\nAutomatic Agent Building\n  * Automatically Build Multi-agent System with AgentBuilder - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/autobuild_basic>)\n  * Automatically Build Multi-agent System from Agent Library - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/autobuild_agent_library>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#observability>)\nObservability\n  * Track LLM calls, tool usage, actions and errors using AgentOps - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_agentops>)\n  * Cost Calculation - [View Notebook](https://docs.ag2.ai/notebooks/</notebooks/agentchat_cost_token_tracking>)\n\n\n## \n[​](https://docs.ag2.ai/notebooks/<#enhanced-inferences>)\nEnhanced Inferences\n### \n[​](https://docs.ag2.ai/notebooks/<#utilities>)\nUtilities\n  * API Unification - [View Documentation with Code Example](https://docs.ag2.ai/notebooks/<https:/docs.ag2.ai/docs/Use-Cases/enhanced_inference#api-unification>)\n  * Utility Functions to Help Managing API configurations effectively - [View Notebook](https://docs.ag2.ai/notebooks/</docs/topics/llm_configuration>)\n\n\n### \n[​](https://docs.ag2.ai/notebooks/<#inference-hyperparameters-tuning>)\nInference Hyperparameters Tuning\nAutoGen offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/notebooks/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them. Please find documentation about this feature [here](https://docs.ag2.ai/notebooks/</docs/Use-Cases/enhanced_inference>).\nLinks to notebook examples:\n  * [Optimize for Code Generation](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) | [Open in colab](https://docs.ag2.ai/notebooks/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>)\n  * [Optimize for Math](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) | [Open in colab](https://docs.ag2.ai/notebooks/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>)\n\n\n[Notebooks](https://docs.ag2.ai/notebooks/</notebooks/Notebooks>)\n[x](https://docs.ag2.ai/notebooks/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/notebooks/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/notebooks/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/notebooks/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/notebooks/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/notebooks/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Automated Multi Agent Chat](https://docs.ag2.ai/notebooks/<#automated-multi-agent-chat>)\n  * [Code Generation, Execution, and Debugging](https://docs.ag2.ai/notebooks/<#code-generation-execution-and-debugging>)\n  * [Multi-Agent Collaboration (>3 Agents)](https://docs.ag2.ai/notebooks/<#multi-agent-collaboration-3-agents>)\n  * [Sequential Multi-Agent Chats](https://docs.ag2.ai/notebooks/<#sequential-multi-agent-chats>)\n  * [Nested Chats](https://docs.ag2.ai/notebooks/<#nested-chats>)\n  * [Swarms](https://docs.ag2.ai/notebooks/<#swarms>)\n  * [Applications](https://docs.ag2.ai/notebooks/<#applications>)\n  * [RAG](https://docs.ag2.ai/notebooks/<#rag>)\n  * [Tool Use](https://docs.ag2.ai/notebooks/<#tool-use>)\n  * [Human Involvement](https://docs.ag2.ai/notebooks/<#human-involvement>)\n  * [Agent Teaching and Learning](https://docs.ag2.ai/notebooks/<#agent-teaching-and-learning>)\n  * [Multi-Agent Chat with OpenAI Assistants in the loop](https://docs.ag2.ai/notebooks/<#multi-agent-chat-with-openai-assistants-in-the-loop>)\n  * [Non-OpenAI Models](https://docs.ag2.ai/notebooks/<#non-openai-models>)\n  * [Multimodal Agent](https://docs.ag2.ai/notebooks/<#multimodal-agent>)\n  * [Long Context Handling](https://docs.ag2.ai/notebooks/<#long-context-handling>)\n  * [Evaluation and Assessment](https://docs.ag2.ai/notebooks/<#evaluation-and-assessment>)\n  * [Automatic Agent Building](https://docs.ag2.ai/notebooks/<#automatic-agent-building>)\n  * [Observability](https://docs.ag2.ai/notebooks/<#observability>)\n  * [Enhanced Inferences](https://docs.ag2.ai/notebooks/<#enhanced-inferences>)\n  * [Utilities](https://docs.ag2.ai/notebooks/<#utilities>)\n  * [Inference Hyperparameters Tuning](https://docs.ag2.ai/notebooks/<#inference-hyperparameters-tuning>)\n\n---\n\n# Blog\nURL: https://docs.ag2.ai/blog/2025-01-10-WebSockets/index\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nRecent posts\nStreaming input and output using WebSockets\n[Documentation](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/Home>)[Examples](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</notebooks/Examples>)[Blog](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</talks/future_talks/index>)\n##### Blog\n  * Recent posts\n    * [Streaming input and output using WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-10-WebSockets/index>)\n    * [Real-Time Voice Interactions over WebRTC](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-09-RealtimeAgent-over-WebRTC/index>)\n    * [Real-Time Voice Interactions with the WebSocket Audio Adapter](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-08-RealtimeAgent-over-websocket/index>)\n    * [Tools Dependency Injection](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-07-Tools-Dependency-Injection/index>)\n    * [Cross-Framework LLM Tool Integration with AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-Tools-interoperability/index>)\n    * [ReasoningAgent Update - Beam Search, MCTS, and LATS for LLM Reasoning](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-Reasoning-Update/index>)\n    * [Introducing RealtimeAgent Capabilities in AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-20-RealtimeAgent/index>)\n    * [Knowledgeable Agents with FalkorDB Graph RAG](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-06-FalkorDB-Structured/index>)\n    * [ReasoningAgent - Tree of Thoughts with Beam Search in AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-12-02-ReasoningAgent2/index>)\n    * [Agentic testing for prompt leakage security](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-27-Prompt-Leakage-Probing/index>)\n    * [Building Swarm-based agents with AG2](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-17-Swarm/index>)\n    * [Introducing CaptainAgent for Adaptive Team Building](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-11-15-CaptainAgent/index>)\n    * [Unlocking the Power of Agentic Workflows at Nexla with Autogen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-10-23-NOVA/index>)\n    * [AgentOps, the Best Tool for AutoGen Agent Observability](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-07-25-AgentOps/index>)\n    * [Enhanced Support for Non-OpenAI Models](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-06-24-AltModels-Classes/index>)\n    * [AgentEval: A Developer Tool to Assess Utility of LLM-powered Applications](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-06-21-AgentEval/index>)\n    * [Agents in AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-05-24-Agent/index>)\n    * [AutoDefense - Defend against jailbreak attacks with AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-03-11-AutoDefense/index>)\n    * [What's New in AutoGen?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-03-03-AutoGen-Update/index>)\n    * [StateFlow - Build State-Driven Workflows with Customized Speaker Selection in GroupChat](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-29-StateFlow/index>)\n    * [FSM Group Chat -- User-specified agent transitions](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-11-FSM-GroupChat/index>)\n    * [Anny: Assisting AutoGen Devs Via AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-02-02-AutoAnny/index>)\n    * [AutoGen with Custom Models: Empowering Users to Use Their Own Inference Mechanism](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-26-Custom-Models/index>)\n    * [AutoGenBench -- A Tool for Measuring and Evaluating AutoGen Agents](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-25-AutoGenBench/index>)\n    * [Code execution is now by default inside docker container](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2024-01-23-Code-execution-in-docker/index>)\n    * [All About Agent Descriptions](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-29-AgentDescriptions/index>)\n    * [AgentOptimizer - An Agentic Way to Train Your LLM Agent](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-23-AgentOptimizer/index>)\n    * [AutoGen Studio: Interactively Explore Multi-Agent Workflows](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-12-01-AutoGenStudio/index>)\n    * [Agent AutoBuild - Automatically Building Multi-agent Systems](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-26-Agent-AutoBuild/index>)\n    * [How to Assess Utility of LLM-powered Applications?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-20-AgentEval/index>)\n    * [AutoGen Meets GPTs](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-13-OAI-assistants/index>)\n    * [EcoAssistant - Using LLM Assistants More Accurately and Affordably](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-09-EcoAssistant/index>)\n    * [Multimodal with GPT-4V and LLaVA](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-11-06-LMM-Agent/index>)\n    * [AutoGen's Teachable Agents](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-10-26-TeachableAgent/index>)\n    * [Retrieval-Augmented Generation (RAG) Applications with AutoGen](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-10-18-RetrieveChat/index>)\n    * [Use AutoGen for Local LLMs](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-07-14-Local-LLMs/index>)\n    * [MathChat - An Conversational Framework to Solve Math Problems](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-06-28-MathChat/index>)\n    * [Achieve More, Pay Less - Use GPT-4 Smartly](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-05-18-GPT-adaptive-humaneval/index>)\n    * [Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2023-04-21-LLM-tuning-math/index>)\n\n\nRecent posts\n# Streaming input and output using WebSockets\n![social preview](https://media.githubusercontent.com/media/ag2ai/ag2/refs/heads/main/website/static/img/cover.png)\nAuthors:\n[![](https://github.com/marklysze.png)Mark SzeSoftware Engineer at AG2.ai](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/marklysze>)[![](https://github.com/sternakt.png)Tvrtko SternakMachine Learning Engineer at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/sternakt>)[![](https://github.com/davorrunje.png)Davor RunjeCTO at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/davorrunje>)\n![social preview](https://media.githubusercontent.com/media/ag2ai/ag2/refs/heads/main/website/static/img/cover.png)\nAuthors:\n[![](https://github.com/marklysze.png)Mark SzeSoftware Engineer at AG2.ai](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/marklysze>)[![](https://github.com/sternakt.png)Tvrtko SternakMachine Learning Engineer at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/sternakt>)[![](https://github.com/davorrunje.png)Davor RunjeCTO at Airt](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/davorrunje>)\n![Structured messages with websockets client](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/blog/2025-01-10-WebSockets/img/structured_messages_with_websockets.png)\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#tl-dr>)\n**TL;DR**\n  * Learn how to build an agent chat application using [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) and `IOStream`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/reference/io/websockets>)\n  * Explore a hands-on example of connecting a web application to a responsive chat with agents over [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>).\n  * **Streamlined Real-Time Interactions** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) offer a low-latency, persistent connection for sending and receiving data in real time.\n\n\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#real-time-applications-why-websockets>)\n**Real-Time Applications: Why WebSockets?**\n[WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) provide a powerful framework for real-time communication between a client and server. Unlike traditional HTTP requests, which require polling for updates, [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) establish a persistent, full-duplex connection that allows for continuous data exchange.\nThis capability is critical for applications that use AG2, where seamless interaction is essential.\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#key-benefits-of-websockets>)\n**Key Benefits of WebSockets**\n  1. **Low Latency** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) reduce latency by maintaining a direct, open connection, avoiding the overhead of repeated HTTP handshakes.\n  2. **Efficient Data Streaming** : Continuous, two-way data streams enable smooth user experiences in real-time applications.\n  3. **Event-Driven Communication** : With WebSocket protocols, the server can “push” updates to the client as events occur.\n  4. **Simplified Architecture** : [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) eliminate the need for separate polling mechanisms, reducing server load and complexity.\n\n\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#building-a-chat-system>)\n**Building a chat System**\nThis example demonstrates how to create a WebSocket-based chat system that streams real-time input and output from AG2 Agents.\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#how-it-works>)\n**How It Works**\n  1. **WebSocket Connection** : The client establishes a persistent WebSocket connection to the server.\n  2. **Real-Time Data Flow** : Events in the conversation are streamed over [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) to the browser where they can be displayed.\n\n\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#example-creating-a-weather-chat-app>)\n**Example: Creating a Weather chat app**\nLet’s walk through an example that integrates [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) with a weather-focused chat.\nYou can explore the full example code [here](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets>).\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#1-clone-the-repository>)\n**1. Clone the Repository**\nCopy\n```\ngit clone https://github.com/ag2ai/agentchat-over-websockets.git\ncd agentchat-over-websockets\n\n```\n\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#2-set-up-environment-variables>)\n**2. Set Up Environment Variables**\nCreate a `OAI_CONFIG_LIST` file based on the provided `OAI_CONFIG_LIST_sample`:\nCopy\n```\ncp OAI_CONFIG_LIST_sample OAI_CONFIG_LIST\n\n```\n\nIn the OAI_CONFIG_LIST file, update the `api_key` to your OpenAI API key.\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#optional-create-and-use-a-virtual-environment>)\n(Optional) Create and use a virtual environment\nTo reduce cluttering your global Python environment on your machine, you can create a virtual environment. On your command line, enter:\nCopy\n```\npython3 -m venv env\nsource env/bin/activate\n\n```\n\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#3-install-dependencies>)\n**3. Install Dependencies**\nInstall the required Python packages using `pip`:\nCopy\n```\npip install -r requirements.txt\n\n```\n\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#4-start-the-server>)\n**4. Start the Server**\nRun the `main.py` file:\nCopy\n```\npython agentchat-over-websockets/main.py\n\n```\n\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#test-the-app>)\n**Test the App**\nWith the server running, open the client application in your browser by navigating to <http://localhost:8001/>. And send a message to the chat and watch the conversation between agents roll out in your browser.\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#code-review>)\nCode review\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#backend-code-main-py>)\n**Backend Code:`main.py`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets/blob/main/agentchat-over-websockets/main.py>)**\nThe backend is responsible for serving the frontend, managing WebSocket connections, and hosting the AI-powered conversational agent. Below is a step-by-step breakdown.\n#### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#setting-up-the-websocket-server>)\n**Setting Up the WebSocket Server**\nThe `IOWebsockets.run_server_in_thread` utility is used to run a WebSocket server. The `on_connect` function handles new client connections and initializes the chatbot.\nCopy\n```\nfrom autogen.io.websockets import IOWebsockets\nfrom datetime import datetime\ndef on_connect(iostream: IOWebsockets) -> None:\n  print(f\"Connected to client: {iostream}\")\n  initial_msg = iostream.input() # Receive the first message from the client.\n  print(f\"Initial message: {initial_msg}\")\n  # Define the agent\n  agent = autogen.ConversableAgent(\n    name=\"chatbot\",\n    system_message=\"Complete tasks and reply TERMINATE when done. Use the 'weather_forecast' tool for weather-related queries.\",\n    llm_config={\"stream\": False},\n  )\n  # Define the user proxy\n  user_proxy = autogen.UserProxyAgent(\n    name=\"user_proxy\",\n    system_message=\"A proxy for the user.\",\n    is_termination_msg=lambda msg: msg.get(\"content\", \"\").endswith(\"TERMINATE\"),\n    human_input_mode=\"NEVER\",\n  )\n  # Register tool functions\n  def weather_forecast(city: str) -> str:\n    return f\"The weather forecast for {city} is sunny as of {datetime.now()}.\"\n  autogen.register_function(\n    weather_forecast,\n    caller=agent,\n    executor=user_proxy,\n    description=\"Provides a mock weather forecast.\",\n  )\n  # Initiate conversation\n  user_proxy.initiate_chat(agent, message=initial_msg)\n\n```\n\n**Explanation:**\n  1. **`on_connect`**: Handles client connections and manages the interaction between the[**`ConversableAgent`**](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</docs/reference/agentchat/conversable_agent#conversableagent>)and the client.\n  2. **Tool Registration** : The `weather_forecast` function provides a mock weather report and is linked to the agent for handling weather-related queries.\n\n\n#### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#serving-the-frontend>)\n**Serving the Frontend**\nThe `SimpleHTTPRequestHandler` is used to serve HTML files. A custom handler class overrides the behavior for the root path to serve `chat.html`.\nCopy\n```\nclass MyRequestHandler(SimpleHTTPRequestHandler):\n  def __init__(self, *args, **kwargs):\n    super().__init__(*args, directory=Path(__file__).parent / \"website_files\" / \"templates\", **kwargs)\n  def do_GET(self):\n    if self.path == \"/\":\n      self.path = \"/chat.html\"\n    return super().do_GET()\n\n```\n\n**Explanation:**\n  * The `MyRequestHandler` class ensures that the default page served is `chat.html`.\n  * Files are served from the `website_files/templates` directory.\n\n\n#### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#running-the-servers>)\n**Running the Servers**\nFinally, both the WebSocket and HTTP servers are started.\nCopy\n```\nfrom http.server import HTTPServer\nPORT = 8001\nhandler = MyRequestHandler\n# Start WebSocket server\nwith IOWebsockets.run_server_in_thread(on_connect=on_connect, port=8080) as uri:\n  print(f\"WebSocket server started at {uri}\")\n  # Start HTTP server\n  with HTTPServer((\"\", PORT), handler) as httpd:\n    print(f\"HTTP server started at http://localhost:{PORT}\")\n    try:\n      httpd.serve_forever()\n    except KeyboardInterrupt:\n      print(\"HTTP server stopped.\")\n\n```\n\n**Explanation:**\n  * The WebSocket server listens on port `8080`, while the HTTP server listens on port `8001`.\n  * The WebSocket server handles real-time communication, while the HTTP server serves static files.\n\n\n### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#frontend-code-chat-html>)\n**Frontend Code:`chat.html`[](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets/blob/main/agentchat-over-websockets/website_files/templates/chat.html>)**\nThe frontend provides a simple interface for users to interact with the chatbot.\n#### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#html-structure>)\n**HTML Structure**\nThe HTML structure defines an input form for sending messages and a list for displaying them.\nCopy\n```\n<!DOCTYPE html>\n<html>\n<head>\n  <title>Chat Interface</title>\n  <style>\n    body { font-family: monospace; max-width: 800px; margin: 20px auto; }\n    #messages { list-style: none; padding: 0; }\n    #messages li { background: #f1f3f4; padding: 8px; border-radius: 4px; margin: 4px 0; }\n  </style>\n</head>\n<body>\n  <h1>AI Chat Interface</h1>\n  <form onsubmit=\"sendMessage(event)\">\n    <input type=\"text\" id=\"messageText\" autocomplete=\"off\" />\n    <button>Send</button>\n  </form>\n  <ul id=\"messages\"></ul>\n</body>\n</html>\n\n```\n\n#### \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#javascript-logic>)\n**JavaScript Logic**\nThe JavaScript code establishes a WebSocket connection, handles incoming messages, and sends user input to the backend.\nCopy\n```\nvar ws = new WebSocket(\"ws://localhost:8080\");\nws.onmessage = function(event) {\n  var messages = document.getElementById('messages');\n  var message = document.createElement('li');\n  message.textContent = event.data; // Display the message content.\n  messages.appendChild(message);\n};\nfunction sendMessage(event) {\n  var input = document.getElementById(\"messageText\");\n  ws.send(input.value); // Send the input value to the backend.\n  input.value = ''; // Clear the input field.\n  event.preventDefault(); // Prevent form submission.\n}\n\n```\n\n**Explanation:**\n  1. **WebSocket Initialization** : Connects to the WebSocket server at `ws://localhost:8080`.\n  2. **Message Display** : Appends incoming messages to the `#messages` list.\n  3. **Sending Messages** : Captures user input, sends it to the server, and clears the input field.\n\n\n## \n[​](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#conclusion>)\n**Conclusion**\nBuilding an AgentChat system with [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) unlocks the potential for real-time, interactive applications. By maintaining a persistent connection, [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) enable seamless communication, enhancing user experience with minimal latency.\nThe example of a weather chatbot demonstrates the ease of integrating AG2 with [WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/fastapi.tiangolo.com/advanced/websockets/>) to create dynamic conversational agents. Whether for customer support, virtual assistants, or personalized services, this architecture provides a robust foundation for building next-generation applications.\n**Ready to start building?** Explore the full example code [here](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/agentchat-over-websockets>).\n[Real-Time Voice Interactions over WebRTC](https://docs.ag2.ai/blog/2025-01-10-WebSockets/</blog/2025-01-09-RealtimeAgent-over-WebRTC/index>)\n[x](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [TL;DR](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#tl-dr>)\n  * [Real-Time Applications: Why WebSockets?](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#real-time-applications-why-websockets>)\n  * [Key Benefits of WebSockets](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#key-benefits-of-websockets>)\n  * [Building a chat System](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#building-a-chat-system>)\n  * [How It Works](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#how-it-works>)\n  * [Example: Creating a Weather chat app](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#example-creating-a-weather-chat-app>)\n  * [1. Clone the Repository](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#1-clone-the-repository>)\n  * [2. Set Up Environment Variables](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#2-set-up-environment-variables>)\n  * [(Optional) Create and use a virtual environment](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#optional-create-and-use-a-virtual-environment>)\n  * [3. Install Dependencies](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#3-install-dependencies>)\n  * [4. Start the Server](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#4-start-the-server>)\n  * [Test the App](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#test-the-app>)\n  * [Code review](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#code-review>)\n  * [Backend Code: main.py](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#backend-code-main-py>)\n  * [Setting Up the WebSocket Server](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#setting-up-the-websocket-server>)\n  * [Serving the Frontend](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#serving-the-frontend>)\n  * [Running the Servers](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#running-the-servers>)\n  * [Frontend Code: chat.html](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#frontend-code-chat-html>)\n  * [HTML Structure](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#html-structure>)\n  * [JavaScript Logic](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#javascript-logic>)\n  * [Conclusion](https://docs.ag2.ai/blog/2025-01-10-WebSockets/<#conclusion>)\n\n---\n\n# Community Talks\nURL: https://docs.ag2.ai/talks/future_talks/index\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/talks/future_talks/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTalks\nUpcoming Talks\n[Documentation](https://docs.ag2.ai/talks/future_talks/</docs/Home>)[Examples](https://docs.ag2.ai/talks/future_talks/</notebooks/Examples>)[Blog](https://docs.ag2.ai/talks/future_talks/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/talks/future_talks/</talks/future_talks/index>)\n##### Talks\n  * [Upcoming Talks](https://docs.ag2.ai/talks/future_talks/</talks/future_talks/index>)\n  * [Globant Code Fixer Agent: #1 on SWE-Bench Lite - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19-special_talk/index>)\n  * [Transforming CRM with Agents: The Journey to Ully.ai's Next-Gen ERP - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19/index>)\n  * [Make AI Agents Collaborate: Drag, Drop, and Orchestrate with Waldiez - Dec 12, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-12/index>)\n  * [Mosaia - The AI community’s platform for creating, sharing and deploying AI agents in a serverless cloud environment - Nov 28, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-28/index>)\n  * [Investigating Group Decision-Making Mechanism in Decentralized Multi-Agent Collaboration - Nov 25, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-25/index>)\n  * [Integrating Foundation Models and Symbolic Computing for Next-Generation Robot Planning - Nov 18, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-18/index>)\n  * [Introducing FastAgency - the fastest way to bring AutoGen workflows to production - Nov 12, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-12/index>)\n  * [Multi-AI Agents for Chip Design with Distilled Knowledge Debugging Graph, Task Graph Solving, and Multi-Modal Capabilities - Nov 11, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-11/index>)\n  * [Exploring Pragmatic Patterns in Agentic Systems - Nov 04, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-11-04/index>)\n  * [Agent-Model Orchestration in Multi-Agent Applications - Oct 15, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-10-15/index>)\n  * [Advanced AutoGen Interactions and Ethical Pathways for AI Sentience - Oct 14, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-10-14/index>)\n  * [Trace-ing the Path to Self-adapting AI Agents - Sep 30, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-09-30/index>)\n  * [Copilot Agent Architecture Designing - Sep 23, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-09-23/index>)\n  * [Language Agent Tree Search in AutoGen - Aug 26, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-08-26/index>)\n\n\nTalks\n# Upcoming Talks\nOur community is also dedicated to fostering knowledge sharing and collaboration through regular events. We frequently host talks featuring both academic experts and industry professionals, offering valuable insights into topics related to agentic AI. By joining our community, you will have access to these enriching opportunities and be able to engage with like-minded individuals.\n## \n[​](https://docs.ag2.ai/talks/future_talks/<#how-to-follow-up-with-the-latest-talks>)\nHow to follow up with the latest talks?\n  1. Stay informed about our latest events and upcoming talks by subscribing to our [lu.ma homepage](https://docs.ag2.ai/talks/future_talks/<https:/lu.ma/ag2ai>).\n  2. Join our community Discord (<https://discord.gg/sUkGceyd>) to be the first to know about amazing upcoming talks!\n\n\nConnect: shaokunzhang529@gmail.com\n[Globant Code Fixer Agent: #1 on SWE-Bench Lite - Dec 19, 2024](https://docs.ag2.ai/talks/future_talks/</talks/2024-12-19-special_talk/index>)\n[x](https://docs.ag2.ai/talks/future_talks/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/talks/future_talks/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/talks/future_talks/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/talks/future_talks/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/talks/future_talks/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/talks/future_talks/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [How to follow up with the latest talks?](https://docs.ag2.ai/talks/future_talks/<#how-to-follow-up-with-the-latest-talks>)\n\n---\n\n# Getting Started\nURL: https://docs.ag2.ai/docs/Getting-Started\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag21,423](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,423](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nHome\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\n# Home\n![AG2 Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/ag2.svg)\n## AG2\nThe Open Source Agent OS\n[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n### \n[​](https://docs.ag2.ai/docs/<#key-features>)\nKey Features\n![Multi-Agent Conversation Framework](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/conv_2.svg)[Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\nAG2 provides multi-agent conversation framework as a high-level abstraction. With this framework, one can conveniently build LLM workflows.\n![Easily Build Diverse Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/autogen_app.svg)[Easily Build Diverse Applications](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen>)\nAG2 offers a collection of working systems spanning a wide range of applications from various domains and complexities.\n![Enhanced LLM Inference & Optimization](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/extend.svg)[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference performance and reduce cost.\n### \n[​](https://docs.ag2.ai/docs/<#explore-content>)\nExplore content\n## [Get StartedLearn how to get started with AG2. Follow the instruction to quickly build-up your first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-Started>)## [TutorialThis tutorial introduces basic concepts and building blocks of AG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)## [User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.](https://docs.ag2.ai/docs/</docs/topics>)## [ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.](https://docs.ag2.ai/docs/</docs/Examples>)## [ApplicationsA collection of different applications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)## [ContributionsLearn about how you can contribute to AG2 and this documentation, including pushing patches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n### \n[​](https://docs.ag2.ai/docs/<#popular-resources>)\nPopular resources\n[Foundation Capital Interview with Dr. Chi Wang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n[Learn AG2 on DeepLearningAI](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=TBNTH-fwGPE>)\n[Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nHome - AG2\n\n---\n\n# Overview\nURL: https://docs.ag2.ai/docs/installation/Installation\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nInstallation\nOverview\n[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)\n\n\nInstallation\n# Overview\n## \n[​](https://docs.ag2.ai/docs/installation/<#create-a-virtual-environment-optional>)\nCreate a virtual environment (optional)\nWhen installing AG2 locally, we recommend using a virtual environment for the installation. This will ensure that the dependencies for AG2 are isolated from the rest of your system.\n  * venv\n  * Conda\n  * Poetry\n\n\nCreate and activate:\nCopy\n```\npython3 -m venv autogen\nsource autogen/bin/activate\n\n```\n\nTo deactivate later, run:\nCopy\n```\ndeactivate\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#install-ag2>)\nInstall AG2\nAG2 requires **Python version >= 3.9, < 3.14**. It can be installed from pip:\nCopy\n```\npip install autogen\n\n```\n\n`openai>=1` is required. \n## \n[​](https://docs.ag2.ai/docs/installation/<#install-docker-for-code-execution>)\nInstall Docker for Code Execution\nWe recommend using Docker for code execution. To install Docker, follow the instructions for your operating system on the [Docker website](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com/get-docker/>).\nA simple example of how to use Docker for code execution is shown below:\nCopy\n```\nfrom pathlib import Path\nfrom autogen import UserProxyAgent\nfrom autogen.coding import DockerCommandLineCodeExecutor\nwork_dir = Path(\"coding\")\nwork_dir.mkdir(exist_ok=True)\nwith DockerCommandLineCodeExecutor(work_dir=work_dir) as code_executor:\n  user_proxy = UserProxyAgent(\n    name=\"user_proxy\",\n    code_execution_config={\"executor\": code_executor},\n  )\n\n```\n\nTo learn more about code executors, see the [code executors tutorial](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>).\nYou might have seen a different way of defining the executors without creating the executor object, please refer to FAQ for this [legacy code executor](https://docs.ag2.ai/docs/installation/</docs/FAQ#legacy-code-executor>).\n[Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)[Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)\n[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Create a virtual environment (optional)](https://docs.ag2.ai/docs/installation/<#create-a-virtual-environment-optional>)\n  * [Install AG2](https://docs.ag2.ai/docs/installation/<#install-ag2>)\n  * [Install Docker for Code Execution](https://docs.ag2.ai/docs/installation/<#install-docker-for-code-execution>)\n\n---\n\n# Docker\nURL: https://docs.ag2.ai/docs/installation/Docker\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\n[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)\n\n\nInstallation\n# Docker\nDocker, an indispensable tool in modern software development, offers a compelling solution for AG2’s setup. Docker allows you to create consistent environments that are portable and isolated from the host OS. With Docker, everything AG2 needs to run, from the operating system to specific libraries, is encapsulated in a container, ensuring uniform functionality across different systems. The Dockerfiles necessary for AG2 are conveniently located in the project’s GitHub repository at <https://github.com/ag2ai/ag2/tree/main/.devcontainer>.\n**Pre-configured DockerFiles** : The AG2 Project offers pre-configured Dockerfiles for your use. These Dockerfiles will run as is, however they can be modified to suit your development needs. Please see the README.md file in autogen/.devcontainer\n  * **ag2_base_img** : For a basic setup, you can use the `ag2_base_img` to run simple scripts or applications. This is ideal for general users or those new to AG2.\n  * **ag2_full_img** : Advanced users or those requiring more features can use `ag2_full_img`. Be aware that this version loads ALL THE THINGS and thus is very large. Take this into consideration if you build your application off of it.\n\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#step-1-install-docker>)\nStep 1: Install Docker\n  * **General Installation** : Follow the [official Docker installation instructions](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com/get-docker/>). This is your first step towards a containerized environment, ensuring a consistent and isolated workspace for AG2.\n  * **For Mac Users** : If you encounter issues with the Docker daemon, consider using [colima](https://docs.ag2.ai/docs/installation/<https:/smallsharpsoftwaretools.com/tutorials/use-colima-to-run-docker-containers-on-macos/>). Colima offers a lightweight alternative to manage Docker containers efficiently on macOS.\n\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#step-2-build-a-docker-image>)\nStep 2: Build a Docker Image\nAG2 now provides updated Dockerfiles tailored for different needs. Building a Docker image is akin to setting the foundation for your project’s environment:\n  * **AG2 Basic** : Ideal for general use, this setup includes common Python libraries and essential dependencies. Perfect for those just starting with AG2.\nCopy\n```\ndocker build -f .devcontainer/Dockerfile -t ag2_base_img https://github.com/ag2ai/ag2.git#main\n\n```\n\n  * **AG2 Advanced** : Advanced users or those requiring all the things that AG2 has to offer `ag2_full_img`\nCopy\n```\ndocker build -f .devcontainer/full/Dockerfile -t ag2_full_img https://github.com/ag2ai/ag2.git#main\n\n```\n\n\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#step-3-run-ag2-applications-from-docker-image>)\nStep 3: Run AG2 Applications from Docker Image\nHere’s how you can run an application built with AG2, using the Docker image:\n  1. **Mount Your Directory** : Use the Docker `-v` flag to mount your local application directory to the Docker container. This allows you to develop on your local machine while running the code in a consistent Docker environment. For example:\nCopy\n```\ndocker run -it -v $(pwd)/myapp:/home/ag2ai/ag2/myapp ag2_base_img:latest python /home/ag2ai/ag2/myapp/main.py\n\n```\n\nHere, `$(pwd)/myapp` is your local directory, and `/home/ag2ai/ag2/myapp` is the path in the Docker container where your code will be located.\n  2. **Mount your code:** Now suppose you have your application built with AG2 in a main script named `twoagent.py` ([example](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/test/twoagent.py>)) in a folder named `myapp`. With the command line below, you can mount your folder and run the application in Docker.\nCopy\n```\n# Mount the local folder `myapp` into docker image and run the script named \"twoagent.py\" in the docker.\ndocker run -it -v `pwd`/myapp:/myapp ag2_base_img:latest python /myapp/main_twoagent.py\n\n```\n\n  3. **Port Mapping** : If your application requires a specific port, use the `-p` flag to map the container’s port to your host. For instance, if your app runs on port 3000 inside Docker and you want it accessible on port 8080 on your host machine:\nCopy\n```\ndocker run -it -p 8080:3000 -v $(pwd)/myapp:/myapp ag2_base_img:latest python /myapp\n\n```\n\nIn this command, `-p 8080:3000` maps port 3000 from the container to port 8080 on your local machine.\n  4. **Examples of Running Different Applications** : Here is the basic format of the docker run command.\n\n\nCopy\n```\ndocker run -it -p {WorkstationPortNum}:{DockerPortNum} -v {WorkStation_Dir}:{Docker_DIR} {name_of_the_image} {bash/python} {Docker_path_to_script_to_execute}\n\n```\n\n  * _Simple Script_ : Run a Python script located in your local `myapp` directory.\nCopy\n```\ndocker run -it -v `pwd`/myapp:/myapp ag2_base_img:latest python /myapp/my_script.py\n\n```\n\n  * _Web Application_ : If your application includes a web server running on port 5000.\nCopy\n```\ndocker run -it -p 8080:5000 -v $(pwd)/myapp:/myapp ag2_base_img:latest\n\n```\n\n  * _Data Processing_ : For tasks that involve processing data stored in a local directory.\nCopy\n```\ndocker run -it -v $(pwd)/data:/data ag2_base_img:latest python /myapp/process_data.py\n\n```\n\n\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#additional-resources>)\nAdditional Resources\n  * Details on all the Dockerfile options can be found in the [Dockerfile](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/.devcontainer/README.md>) README.\n  * For more information on Docker usage and best practices, refer to the [official Docker documentation](https://docs.ag2.ai/docs/installation/<https:/docs.docker.com>).\n  * Details on how to use the Dockerfile dev version can be found on the [Contributor Guide](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>).\n\n\n[Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)[Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)\n[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Step 1: Install Docker](https://docs.ag2.ai/docs/installation/<#step-1-install-docker>)\n  * [Step 2: Build a Docker Image](https://docs.ag2.ai/docs/installation/<#step-2-build-a-docker-image>)\n  * [Step 3: Run AG2 Applications from Docker Image](https://docs.ag2.ai/docs/installation/<#step-3-run-ag2-applications-from-docker-image>)\n  * [Additional Resources](https://docs.ag2.ai/docs/installation/<#additional-resources>)\n\n---\n\n# Optional Dependencies\nURL: https://docs.ag2.ai/docs/installation/Optional-Dependencies\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/installation/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\n[Documentation](https://docs.ag2.ai/docs/installation/</docs/Home>)[Examples](https://docs.ag2.ai/docs/installation/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/installation/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/installation/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/installation/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/installation/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/installation/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/installation/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/installation/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/installation/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/installation/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/installation/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/installation/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/installation/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/installation/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/installation/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/installation/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/installation/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/installation/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/installation/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/installation/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/installation/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/installation/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/installation/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/installation/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/installation/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/installation/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/installation/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/installation/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/installation/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/installation/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/installation/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/installation/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/installation/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/installation/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/installation/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/installation/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/installation/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/installation/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/installation/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/installation/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/installation/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/installation/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/installation/</docs/Migration-Guide>)\n\n\nInstallation\n# Optional Dependencies\n## \n[​](https://docs.ag2.ai/docs/installation/<#different-llms>)\nDifferent LLMs\nAG2 installs OpenAI package by default. To use LLMs by other providers, you can install the following packages:\nCopy\n```\npip install autogen[gemini,anthropic,mistral,together,groq,cohere]\n\n```\n\nCheck out the [notebook](https://docs.ag2.ai/docs/installation/</notebooks/autogen_uniformed_api_calling>) and [blogpost](https://docs.ag2.ai/docs/installation/</blog/2024-06-24-AltModels-Classes/index>) for more details.\n## \n[​](https://docs.ag2.ai/docs/installation/<#llm-caching>)\nLLM Caching\nTo use LLM caching with Redis, you need to install the Python package with the option `redis`:\nCopy\n```\npip install \"autogen[redis]\"\n\n```\n\nSee [LLM Caching](https://docs.ag2.ai/docs/installation/</docs/topics/llm-caching>) for details.\n## \n[​](https://docs.ag2.ai/docs/installation/<#ipython-code-executor>)\nIPython Code Executor\nTo use the IPython code executor, you need to install the `jupyter-client` and `ipykernel` packages:\nCopy\n```\npip install \"autogen[ipython]\"\n\n```\n\nTo use the IPython code executor:\nCopy\n```\nfrom autogen import UserProxyAgent\nproxy = UserProxyAgent(name=\"proxy\", code_execution_config={\"executor\": \"ipython-embedded\"})\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/installation/<#blendsearch>)\nblendsearch\n`pyautogen<0.2` offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/docs/installation/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. Please install with the [blendsearch] option to use it.\nCopy\n```\npip install \"autogen[blendsearch]<0.2\"\n\n```\n\nCheckout [Optimize for Code Generation](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) and [Optimize for Math](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) for details.\n## \n[​](https://docs.ag2.ai/docs/installation/<#retrievechat>)\nretrievechat\n`autogen` supports retrieval-augmented generation tasks such as question answering and code generation with RAG agents. Please install with the [retrievechat] option to use it with ChromaDB.\nCopy\n```\npip install \"autogen[retrievechat]\"\n\n```\n\nAlternatively `autogen` also supports PGVector and Qdrant which can be installed in place of ChromaDB, or alongside it.\nCopy\n```\npip install \"autogen[retrievechat-pgvector]\"\n\n```\n\nCopy\n```\npip install \"autogen[retrievechat-qdrant]\"\n\n```\n\nRetrieveChat can handle various types of documents. By default, it can process plain text and PDF files, including formats such as ‘txt’, ‘json’, ‘csv’, ‘tsv’, ‘md’, ‘html’, ‘htm’, ‘rtf’, ‘rst’, ‘jsonl’, ‘log’, ‘xml’, ‘yaml’, ‘yml’ and ‘pdf’. If you install [unstructured](https://docs.ag2.ai/docs/installation/<https:/unstructured-io.github.io/unstructured/installation/full_installation.html>) (`pip install \"unstructured[all-docs]\"`), additional document types such as ‘docx’, ‘doc’, ‘odt’, ‘pptx’, ‘ppt’, ‘xlsx’, ‘eml’, ‘msg’, ‘epub’ will also be supported.\nYou can find a list of all supported document types by using `autogen.retrieve_utils.TEXT_FORMATS`.\nExample notebooks:\n[Automated Code Generation and Question Answering with Retrieval Augmented Agents](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat.ipynb>)\n[Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent)](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat_RAG.ipynb>)\n[Automated Code Generation and Question Answering with Qdrant based Retrieval Augmented Agents](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb>)\n## \n[​](https://docs.ag2.ai/docs/installation/<#teachability>)\nTeachability\nTo use Teachability, please install AG2 with the [teachable] option.\nCopy\n```\npip install \"autogen[teachable]\"\n\n```\n\nExample notebook: [Chatting with a teachable agent](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_teachability>)\n## \n[​](https://docs.ag2.ai/docs/installation/<#large-multimodal-model-lmm-agents>)\nLarge Multimodal Model (LMM) Agents\nWe offered Multimodal Conversable Agent and LLaVA Agent. Please install with the [lmm] option to use it.\nCopy\n```\npip install \"autogen[lmm]\"\n\n```\n\nExample notebook: [LLaVA Agent](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_lmm_llava>)\n## \n[​](https://docs.ag2.ai/docs/installation/<#mathchat>)\nmathchat\n`pyautogen<0.2` offers an experimental agent for math problem solving. Please install with the [mathchat] option to use it.\nCopy\n```\npip install \"autogen[mathchat]<0.2\"\n\n```\n\nExample notebook: [Using MathChat to Solve Math Problems](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_MathChat.ipynb>)\n## \n[​](https://docs.ag2.ai/docs/installation/<#graph>)\nGraph\nTo use a graph in `GroupChat`, particularly for graph visualization, please install AutoGen with the [graph] option.\nCopy\n```\npip install \"autogen[graph]\"\n\n```\n\nExample notebook: [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/installation/</notebooks/agentchat_groupchat_finite_state_machine>)\n## \n[​](https://docs.ag2.ai/docs/installation/<#long-context-handling>)\nLong Context Handling\nAG2 includes support for handling long textual contexts by leveraging the LLMLingua library for text compression. To enable this functionality, please install AutoGen with the `[long-context]` option:\nCopy\n```\npip install \"autogen[long-context]\"\n\n```\n\n[Docker](https://docs.ag2.ai/docs/installation/</docs/installation/Docker>)[Introduction to AutoGen](https://docs.ag2.ai/docs/installation/</docs/tutorial/introduction>)\n[x](https://docs.ag2.ai/docs/installation/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/installation/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/installation/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/installation/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/installation/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/installation/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Different LLMs](https://docs.ag2.ai/docs/installation/<#different-llms>)\n  * [LLM Caching](https://docs.ag2.ai/docs/installation/<#llm-caching>)\n  * [IPython Code Executor](https://docs.ag2.ai/docs/installation/<#ipython-code-executor>)\n  * [blendsearch](https://docs.ag2.ai/docs/installation/<#blendsearch>)\n  * [retrievechat](https://docs.ag2.ai/docs/installation/<#retrievechat>)\n  * [Teachability](https://docs.ag2.ai/docs/installation/<#teachability>)\n  * [Large Multimodal Model (LMM) Agents](https://docs.ag2.ai/docs/installation/<#large-multimodal-model-lmm-agents>)\n  * [mathchat](https://docs.ag2.ai/docs/installation/<#mathchat>)\n  * [Graph](https://docs.ag2.ai/docs/installation/<#graph>)\n  * [Long Context Handling](https://docs.ag2.ai/docs/installation/<#long-context-handling>)\n\n---\n\n# Introduction to AutoGen\nURL: https://docs.ag2.ai/docs/tutorial/introduction\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nIntroduction to AutoGen\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Introduction to AutoGen\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/introduction.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/introduction.ipynb>)\nWelcome! AutoGen is an open-source framework that leverages multiple _agents_ to enable complex workflows. This tutorial introduces basic concepts and building blocks of AutoGen.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#why-autogen>)\nWhy AutoGen?\n> _The whole is greater than the sum of its parts._ -**Aristotle**\nWhile there are many definitions of agents, in AutoGen, an agent is an entity that can send messages, receive messages and generate a reply using models, tools, human inputs or a mixture of them. This abstraction not only allows agents to model real-world and abstract entities, such as people and algorithms, but it also simplifies implementation of complex workflows as collaboration among agents.\nFurther, AutoGen is extensible and composable: you can extend a simple agent with customizable components and create workflows that can combine these agents and power a more sophisticated agent, resulting in implementations that are modular and easy to maintain.\nMost importantly, AutoGen is developed by a vibrant community of researchers and engineers. It incorporates the latest research in multi-agent systems and has been used in many real-world applications, including agent platform, advertising, AI employees, blog/article writing, blockchain, calculate burned areas by wildfires, customer support, cybersecurity, data analytics, debate, education, finance, gaming, legal consultation, research, robotics, sales/marketing, social simulation, software engineering, software security, supply chain, t-shirt design, training data generation, Youtube service…\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#installation>)\nInstallation\nThe simplest way to install AutoGen is from pip: `pip install autogen`. Find more options in [Installation](https://docs.ag2.ai/docs/tutorial/docs/installation/Installation>).\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#agents>)\nAgents\nIn AutoGen, an agent is an entity that can send and receive messages to and from other agents in its environment. An agent can be powered by models (such as a large language model like GPT-4), code executors (such as an IPython kernel), human, or a combination of these and other pluggable and customizable components.\n![ConversableAgent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/conversable-agent.jpg)\nAn example of such agents is the built-in `ConversableAgent` which supports the following components:\n  1. A list of LLMs\n  2. A code executor\n  3. A function and tool executor\n  4. A component for keeping human-in-the-loop\n\n\nYou can switch each component on or off and customize it to suit the need of your application. For advanced users, you can add additional components to the agent by using `registered_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>).\nLLMs, for example, enable agents to converse in natural languages and transform between structured and unstructured text. The following example shows a `ConversableAgent` with a GPT-4 LLM switched on and other components switched off:\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\nagent = ConversableAgent(\n  \"chatbot\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  code_execution_config=False, # Turn off code execution, by default it is off.\n  function_map=None, # No registered functions, by default it is None.\n  human_input_mode=\"NEVER\", # Never ask for human input.\n)\n\n```\n\nThe `llm_config` argument contains a list of configurations for the LLMs. See [LLM Configuration](https://docs.ag2.ai/docs/tutorial/docs/topics/llm_configuration>) for more details.\nYou can ask this agent to generate a response to a question using the `generate_reply` method:\nCopy\n```\nreply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\nprint(reply)\n\n```\n\nCopy\n```\nSure, here's a light-hearted joke for you:\nWhy don't scientists trust atoms?\nBecause they make up everything!\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#roles-and-conversations>)\nRoles and Conversations\nIn AutoGen, you can assign roles to agents and have them participate in conversations or chat with each other. A conversation is a sequence of messages exchanged between agents. You can then use these conversations to make progress on a task. For example, in the example below, we assign different roles to two agents by setting their `system_message`.\nCopy\n```\ncathy = ConversableAgent(\n  \"cathy\",\n  system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n)\njoe = ConversableAgent(\n  \"joe\",\n  system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n)\n\n```\n\nNow that we have two comedian agents, we can ask them to start a comedy show. This can be done using the `initiate_chat` method. We set the `max_turns` to 2 to keep the conversation short.\nCopy\n```\nresult = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)\n\n```\n\nCopy\n```\njoe (to cathy):\nCathy, tell me a joke.\n--------------------------------------------------------------------------------\ncathy (to joe):\nSure, here's one for you:\nWhy don't scientists trust atoms?\nBecause they make up everything!\n--------------------------------------------------------------------------------\njoe (to cathy):\nHaha, that's a good one, Cathy! Okay, my turn. \nWhy don't we ever tell secrets on a farm?\nBecause the potatoes have eyes, the corn has ears, and the beans stalk.\n--------------------------------------------------------------------------------\ncathy (to joe):\nHaha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. \nWhy couldn't the bicycle stand up by itself?\nBecause it was two-tired!\n--------------------------------------------------------------------------------\n\n```\n\nThe comedians are bouncing off each other!\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter, we introduced the concept of agents, roles and conversations in AutoGen. For simplicity, we only used LLMs and created fully autonomous agents (`human_input_mode` was set to `NEVER`). In the next chapter, we will show how you can control when to _terminate_ a conversation between autonomous agents.\n[Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)[Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Why AutoGen?](https://docs.ag2.ai/docs/tutorial/<#why-autogen>)\n  * [Installation](https://docs.ag2.ai/docs/tutorial/<#installation>)\n  * [Agents](https://docs.ag2.ai/docs/tutorial/<#agents>)\n  * [Roles and Conversations](https://docs.ag2.ai/docs/tutorial/<#roles-and-conversations>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# Terminating Conversations Between Agents\nURL: https://docs.ag2.ai/docs/tutorial/chat-termination\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nTerminating Conversations Between Agents\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Terminating Conversations Between Agents\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/chat-termination.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/chat-termination.ipynb>)\nIn this chapter, we will explore how to terminate a conversation between AutoGen agents.\n_But why is this important?_ Its because in any complex, autonomous workflows it’s crucial to know when to stop the workflow. For example, when the task is completed, or perhaps when the process has consumed enough resources and needs to either stop or adopt different strategies, such as user intervention. So AutoGen natively supports several mechanisms to terminate conversations.\nHow to Control Termination with AutoGen? Currently there are two broad mechanism to control the termination of conversations between agents:\n  1. **Specify parameters in`initiate_chat`** : When initiating a chat, you can define parameters that determine when the conversation should end.\n  2. **Configure an agent to trigger termination** : When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions.\n\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#parameters-in-initiate-chat>)\nParameters in `initiate_chat`\nIn the previous chapter we actually demonstrated this when we used the `max_turns` parameter to limit the number of turns. If we increase `max_turns` to say `3` notice the conversation takes more rounds to terminate:\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\n\n```\n\nCopy\n```\ncathy = ConversableAgent(\n  \"cathy\",\n  system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n)\njoe = ConversableAgent(\n  \"joe\",\n  system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n)\n\n```\n\nCopy\n```\nresult = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)\n\n```\n\nCopy\n```\njoe (to cathy):\nCathy, tell me a joke.\n--------------------------------------------------------------------------------\ncathy (to joe):\nSure, here's one for you:\nWhy don't scientists trust atoms?\nBecause they make up everything!\n--------------------------------------------------------------------------------\njoe (to cathy):\nHaha, that's a good one, Cathy! Okay, my turn. \nWhy don't we ever tell secrets on a farm?\nBecause the potatoes have eyes, the corn has ears, and the beans stalk.\n--------------------------------------------------------------------------------\ncathy (to joe):\nHaha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. \nWhy couldn't the bicycle stand up by itself?\nBecause it was two-tired!\n--------------------------------------------------------------------------------\n\n```\n\nCopy\n```\nresult = joe.initiate_chat(\n  cathy, message=\"Cathy, tell me a joke.\", max_turns=3\n) # increase the number of max turns before termination\n\n```\n\nCopy\n```\njoe (to cathy):\nCathy, tell me a joke.\n--------------------------------------------------------------------------------\ncathy (to joe):\nSure, here's one for you:\nWhy don't scientists trust atoms?\nBecause they make up everything!\n--------------------------------------------------------------------------------\njoe (to cathy):\nHaha, that's a good one, Cathy! Okay, my turn. \nWhy don't we ever tell secrets on a farm?\nBecause the potatoes have eyes, the corn has ears, and the beans stalk.\n--------------------------------------------------------------------------------\ncathy (to joe):\nHaha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. \nWhy couldn't the bicycle stand up by itself?\nBecause it was two-tired!\n--------------------------------------------------------------------------------\njoe (to cathy):\nHaha, that's a wheely good one, Cathy!\nWhy did the golfer bring two pairs of pants?\nIn case he got a hole in one!\n--------------------------------------------------------------------------------\ncathy (to joe):\nHaha, that's a perfect swing of a joke!\nWhy did the scarecrow win an award?\nBecause he was outstanding in his field!\n--------------------------------------------------------------------------------\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#agent-triggered-termination>)\nAgent-triggered termination\nYou can also terminate a conversation by configuring parameters of an agent. Currently, there are two parameters you can configure:\n  1. `max_consecutive_auto_reply`: This condition triggers termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the `max_consecutive_auto_reply` argument of the `ConversableAgent` class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention. We will describe this in more detail in the next chapter.\n  2. `is_termination_msg`: This condition can trigger termination if the _received_ message satisfies a particular condition, e.g., it contains the word “TERMINATE”. You can customize this condition using the `is_terminate_msg` argument in the constructor of the `ConversableAgent` class.\n\n\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#using-max-consecutive-auto-reply>)\nUsing `max_consecutive_auto_reply`\nIn the example below lets set `max_consecutive_auto_reply` to `1` and notice how this ensures that Joe only replies once.\nCopy\n```\njoe = ConversableAgent(\n  \"joe\",\n  system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n  max_consecutive_auto_reply=1, # Limit the number of consecutive auto-replies.\n)\nresult = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\")\n\n```\n\nCopy\n```\njoe (to cathy):\nCathy, tell me a joke.\n--------------------------------------------------------------------------------\ncathy (to joe):\nSure, here's one for you:\nWhy don't scientists trust atoms?\nBecause they make up everything!\n--------------------------------------------------------------------------------\njoe (to cathy):\nHaha, that's a good one, Cathy! Okay, my turn. \nWhy don't we ever tell secrets on a farm?\nBecause the potatoes have eyes, the corn has ears, and the beans stalk.\n--------------------------------------------------------------------------------\ncathy (to joe):\nHaha, that's a great one! A farm is definitely not the place for secrets. Okay, my turn again. \nWhy couldn't the bicycle stand up by itself?\nBecause it was two-tired!\n--------------------------------------------------------------------------------\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#using-is-termination-msg>)\nUsing `is_termination_msg`\nLet’s set the termination message to “GOOD BYE” and see how the conversation terminates.\nCopy\n```\njoe = ConversableAgent(\n  \"joe\",\n  system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\", # Never ask for human input.\n  is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n)\nresult = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")\n\n```\n\nCopy\n```\njoe (to cathy):\nCathy, tell me a joke and then say the words GOOD BYE.\n--------------------------------------------------------------------------------\ncathy (to joe):\nWhy don't scientists trust atoms?\nBecause they make up everything!\nGOOD BYE!\n--------------------------------------------------------------------------------\n\n```\n\nNotice how the conversation ended based on contents of cathy’s message!\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter we introduced mechanisms to terminate a conversation between agents. You can configure both parameters in `initiate_chat` and also configuration of agents.\nThat said, it is important to note that when a termination condition is triggered, the conversation may not always terminate immediately. The actual termination depends on the `human_input_mode` argument of the `ConversableAgent` class. For example, when mode is `NEVER` the termination conditions above will end the conversations. But when mode is `ALWAYS` or `TERMINATE`, it will not terminate immediately. We will describe this behavior and explain why it is important in the next chapter.\n[Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)[Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Parameters in initiate_chat](https://docs.ag2.ai/docs/tutorial/<#parameters-in-initiate-chat>)\n  * [Agent-triggered termination](https://docs.ag2.ai/docs/tutorial/<#agent-triggered-termination>)\n  * [Using max_consecutive_auto_reply](https://docs.ag2.ai/docs/tutorial/<#using-max-consecutive-auto-reply>)\n  * [Using is_termination_msg](https://docs.ag2.ai/docs/tutorial/<#using-is-termination-msg>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# Allowing Human Feedback in Agents\nURL: https://docs.ag2.ai/docs/tutorial/human-in-the-loop\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nAllowing Human Feedback in Agents\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Allowing Human Feedback in Agents\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/human-in-the-loop.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/human-in-the-loop.ipynb>)\nIn the last two chapters we introduced the `ConversableAgent` class and showed how you can use it to create autonomous (`human_input_mode=NEVER`) agents that can accomplish tasks. We also showed how to properly terminate a conversation between agents.\nBut many applications may require putting humans in-the-loop with agents. For example, to allow human feedback to steer agents in the right direction, specify goals, etc. In this chapter, we will show how AutoGen supports human intervention.\nIn AutoGen’s `ConversableAgent`, the human-in-the-loop component sits in front of the auto-reply components. It can intercept the incoming messages and decide whether to pass them to the auto-reply components or to provide human feedback. The figure below illustrates the design.\n![Human in the loop](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/human-in-the-loop.png)\nThe human-in-the-loop component can be customized through the `human_input_mode` parameter. We will show you how to use it in the following sections.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#human-input-modes>)\nHuman Input Modes\nCurrently AutoGen supports three modes for human input. The mode is specified through the `human_input_mode` argument of the `ConversableAgent`. The three modes are:\n  1. `NEVER`: human input is never requested.\n  2. `TERMINATE` (default): human input is only requested when a termination condition is met. Note that in this mode if the human chooses to intercept and reply, the conversation continues and the counter used by `max_consecutive_auto_reply` is reset.\n  3. `ALWAYS`: human input is always requested and the human can choose to skip and trigger an auto-reply, intercept and provide feedback, or terminate the conversation. Note that in this mode termination based on `max_consecutive_auto_reply` is ignored.\n\n\nThe previous chapters already showed many examples of the cases when `human_input_mode` is `NEVER`. Below we show one such example again and then show the differences when this mode is set to `ALWAYS` and `TERMINATE` instead.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-never>)\nHuman Input Mode = `NEVER`\nIn this mode, human input is never requested and the termination conditions are used to terminate. This mode is useful when you want your agents to act fully autonomously.\nHere is an example of using this mode to run a simple guess-a-number game between two agents, the termination message is set to check for the number that is the correct guess.\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\nagent_with_number = ConversableAgent(\n  \"agent_with_number\",\n  system_message=\"You are playing a game of guess-my-number. You have the \"\n  \"number 53 in your mind, and I will try to guess it. \"\n  \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  is_termination_msg=lambda msg: \"53\" in msg[\"content\"], # terminate if the number is guessed by the other agent\n  human_input_mode=\"NEVER\", # never ask for human input\n)\nagent_guess_number = ConversableAgent(\n  \"agent_guess_number\",\n  system_message=\"I have a number in my mind, and you will try to guess it. \"\n  \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n  \"you should guess a higher number. \",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\nresult = agent_with_number.initiate_chat(\n  agent_guess_number,\n  message=\"I have a number between 1 and 100. Guess it!\",\n)\n\n```\n\nCopy\n```\nagent_with_number (to agent_guess_number):\nI have a number between 1 and 100. Guess it!\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 50?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo low.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 75?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo high.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 63?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo high.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 57?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo high.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 54?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo high.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 52?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nToo low.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 53?\n--------------------------------------------------------------------------------\n\n```\n\nYay! The game is over. The guessing agent got the number correctly using binary search – very efficient! You can see that the conversation was terminated after the guessing agent said the correct number, which triggered the message-based termination condition.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-always>)\nHuman Input Mode = `ALWAYS`\nIn this mode, human input is always requested and the human can choose to skip, intercept , or terminate the conversation. Let us see this mode in action by playing the same game as before with the agent with the number, but this time participating in the game as a human. We will be the agent that is guessing the number, and play against the agent with the number from before.\nCopy\n```\nhuman_proxy = ConversableAgent(\n  \"human_proxy\",\n  llm_config=False, # no LLM used for human proxy\n  human_input_mode=\"ALWAYS\", # always ask for human input\n)\n# Start a chat with the agent with number with an initial guess.\nresult = human_proxy.initiate_chat(\n  agent_with_number, # this is the same agent with the number as before\n  message=\"10\",\n)\n\n```\n\nCopy\n```\nhuman_proxy (to agent_with_number):\n10\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\nToo low.\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\n79\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\nToo high.\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\n76\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\nToo high.\n--------------------------------------------------------------------------------\nhuman_proxy (to agent_with_number):\nI give up\n--------------------------------------------------------------------------------\nagent_with_number (to human_proxy):\nThat's okay! The number I was thinking of was 53.\n--------------------------------------------------------------------------------\n\n```\n\nIf you run the code above, you will be prompt to enter a response each time it is your turn to speak. You can see the human in the conversation was not very good at guessing the number… but hey the agent was nice enough to give out the number in the end.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-terminate>)\nHuman Input Mode = `TERMINATE`\nIn this mode, human input is only requested when a termination condition is met. **If the human chooses to intercept and reply, the counter will be reset** ; if the human chooses to skip, the automatic reply mechanism will be used; if the human chooses to terminate, the conversation will be terminated.\nLet us see this mode in action by playing the same game again, but this time the guessing agent will only have two chances to guess the number, and if it fails, the human will be asked to provide feedback, and the guessing agent gets two more chances. If the correct number is guessed eventually, the conversation will be terminated.\nCopy\n```\nagent_with_number = ConversableAgent(\n  \"agent_with_number\",\n  system_message=\"You are playing a game of guess-my-number. \"\n  \"In the first game, you have the \"\n  \"number 53 in your mind, and I will try to guess it. \"\n  \"If I guess too high, say 'too high', if I guess too low, say 'too low'. \",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  max_consecutive_auto_reply=1, # maximum number of consecutive auto-replies before asking for human input\n  is_termination_msg=lambda msg: \"53\" in msg[\"content\"], # terminate if the number is guessed by the other agent\n  human_input_mode=\"TERMINATE\", # ask for human input until the game is terminated\n)\nagent_guess_number = ConversableAgent(\n  \"agent_guess_number\",\n  system_message=\"I have a number in my mind, and you will try to guess it. \"\n  \"If I say 'too high', you should guess a lower number. If I say 'too low', \"\n  \"you should guess a higher number. \",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\nresult = agent_with_number.initiate_chat(\n  agent_guess_number,\n  message=\"I have a number between 1 and 100. Guess it!\",\n)\n\n```\n\nCopy\n```\nagent_with_number (to agent_guess_number):\nI have a number between 1 and 100. Guess it!\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 50?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\nToo low.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 75?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nIt is too high my friend. \n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 60?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\nToo high.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 55?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nstill too high, but you are very close.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 52?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nagent_with_number (to agent_guess_number):\nToo low.\n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 54?\n--------------------------------------------------------------------------------\nagent_with_number (to agent_guess_number):\nAlmost there! \n--------------------------------------------------------------------------------\nagent_guess_number (to agent_with_number):\nIs it 53?\n--------------------------------------------------------------------------------\n\n```\n\nIn the previous conversation,\n  1. When the agent guessed “74”, the human said “It is too high my friend.”\n  2. When the agent guessed “55”, the human said “still too high, but you are very close.”\n  3. When the agent guessed “54”, the human said “Almost there!”\n\n\nEach time after one auto-reply from the agent with the number, the human was asked to provide feedback. Once the human provided feedback, the counter was reset. The conversation was terminated after the agent correctly guessed “53”.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter, we showed you how to use the human-in-the-loop component to provide human feedback to agent and to terminate conversation. We also showed you the different human input modes and how they affect the behavior of the human-in-the-loop component.\nThe next chapter will be all about code executor – the most powerful component second only to LLMs.\n[Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)[Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Human Input Modes](https://docs.ag2.ai/docs/tutorial/<#human-input-modes>)\n  * [Human Input Mode = NEVER](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-never>)\n  * [Human Input Mode = ALWAYS](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-always>)\n  * [Human Input Mode = TERMINATE](https://docs.ag2.ai/docs/tutorial/<#human-input-mode-terminate>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# Code Executors\nURL: https://docs.ag2.ai/docs/tutorial/code-executors\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nCode Executors\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Code Executors\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/code-executors.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/code-executors.ipynb>)\nIn the last chapter, we used two agents powered by a large language model (LLM) to play a game by exchanging messages. In this chapter, we introduce code executors, which enable agents to not just chat but also to interact with an environment and perform useful computations and take actions.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#overview>)\nOverview\nIn AutoGen, a code executor is a component that takes input messages (e.g., those containing code blocks), performs execution, and outputs messages with the results. AutoGen provides two types of built-in code executors, one is command line code executor, which runs code in a command line environment such as a UNIX shell, and the other is Jupyter executor, which runs code in an interactive [Jupyter kernel](https://docs.ag2.ai/docs/tutorial/<https:/github.com/jupyter/jupyter/wiki/Jupyter-kernels>).\nFor each type of executor, AutoGen provides two ways to execute code: locally and in a Docker container. One way is to execute code directly in the same host platform where AutoGen is running, i.e., the local operating system. It is for development and testing, but it is not ideal for production as LLM can generate arbitrary code. The other way is to execute code in a Docker container. The table below shows the combinations of code executors and execution environments.\nCode Executor (`autogen.coding`) | Environment | Platform  \n---|---|---  \n`LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>) | Shell | Local  \n`DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) | Shell | Docker  \n`jupyter.JupyterCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/jupyter/jupyter_code_executor#jupytercodeexecutor>) | Jupyter Kernel (e.g., python3) | Local/Docker  \nIn this chapter, we will focus on the command line code executors. For the Jupyter code executor, please refer to the topic page for [Jupyter Code Executor](https://docs.ag2.ai/docs/tutorial/docs/topics/code-execution/jupyter-code-executor>).\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#local-execution>)\nLocal Execution\nThe figure below shows the architecture of the local command line code executor (`autogen.coding.LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>)).\nExecuting LLM-generated code poses a security risk to your host environment.\n![Code Executor No Docker](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-executor-no-docker.png)\nUpon receiving a message with a code block, the local command line code executor first writes the code block to a code file, then starts a new subprocess to execute the code file. The executor reads the console output of the code execution and sends it back as a reply message.\nHere is an example of using the code executor to run a Python code block that prints a random number. First we create an agent with the code executor that uses a temporary directory to store the code files. We specify `human_input_mode=\"ALWAYS\"` to manually validate the safety of the the code being executed.\nCopy\n```\nimport tempfile\nfrom autogen import ConversableAgent\nfrom autogen.coding import LocalCommandLineCodeExecutor\n# Create a temporary directory to store the code files.\ntemp_dir = tempfile.TemporaryDirectory()\n# Create a local command line code executor.\nexecutor = LocalCommandLineCodeExecutor(\n  timeout=10, # Timeout for each code execution in seconds.\n  work_dir=temp_dir.name, # Use the temporary directory to store the code files.\n)\n# Create an agent with code executor configuration.\ncode_executor_agent = ConversableAgent(\n  \"code_executor_agent\",\n  llm_config=False, # Turn off LLM for this agent.\n  code_execution_config={\"executor\": executor}, # Use the local command line code executor.\n  human_input_mode=\"ALWAYS\", # Always take human input for this agent for safety.\n)\n\n```\n\nBefore running this example, we need to make sure the `matplotlib` and `numpy` are installed.\nCopy\n```\n! pip install -qqq matplotlib numpy\n\n```\n\nNow we have the agent generate a reply given a message with a Python code block.\nCopy\n```\nmessage_with_code_block = \"\"\"This is a message with code block.\nThe code block is below:\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nx = np.random.randint(0, 100, 100)\ny = np.random.randint(0, 100, 100)\nplt.scatter(x, y)\nplt.savefig('scatter.png')\nprint('Scatter plot saved to scatter.png')\n```\nThis is the end of the message.\n\"\"\"\n# Generate a reply for the given code.\nreply = code_executor_agent.generate_reply(messages=[{\"role\": \"user\", \"content\": message_with_code_block}])\nprint(reply)\n\n```\n\nCopy\n```\n\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nexitcode: 0 (execution succeeded)\nCode output: \nScatter plot saved to scatter.png\n\n```\n\nDuring the generation of response, a human input is requested to give an opportunity to intercept the code execution. In this case, we choose to continue the execution, and the agent’s reply contains the output of the code execution.\nWe can take a look at the generated plot in the temporary directory.\nCopy\n```\nimport os\nprint(os.listdir(temp_dir.name))\n# We can see the output scatter.png and the code file generated by the agent.\n\n```\n\nCopy\n```\n['scatter.png', '6507ea07b63b45aabb027ade4e213de6.py']\n\n```\n\nClean up the working directory to avoid affecting future conversations.\nCopy\n```\ntemp_dir.cleanup()\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#docker-execution>)\nDocker Execution\nTo mitigate the security risk of running LLM-generated code locally, we can use the docker command line code executor (`autogen.coding.DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/tutorial/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>)) to execute code in a docker container. This way, the generated code can only access resources that are explicitly given to it.\nThe figure below illustrates how docker execution works.\n![Code Executor Docker](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-executor-docker.png)\nSimilar to the local command line code executor, the docker executor extracts code blocks from input messages, writes them to code files. For each code file, it starts a docker container to execute the code file, and reads the console output of the code execution.\nTo use docker execution, you need to [install Docker](https://docs.ag2.ai/docs/tutorial/<https:/docs.docker.com/engine/install/>) on your machine. Once you have Docker installed and running, you can set up your code executor agent as follow:\nCopy\n```\nfrom autogen.coding import DockerCommandLineCodeExecutor\n# Create a temporary directory to store the code files.\ntemp_dir = tempfile.TemporaryDirectory()\n# Create a Docker command line code executor.\nexecutor = DockerCommandLineCodeExecutor(\n  image=\"python:3.12-slim\", # Execute code using the given docker image name.\n  timeout=10, # Timeout for each code execution in seconds.\n  work_dir=temp_dir.name, # Use the temporary directory to store the code files.\n)\n# Create an agent with code executor configuration that uses docker.\ncode_executor_agent_using_docker = ConversableAgent(\n  \"code_executor_agent_docker\",\n  llm_config=False, # Turn off LLM for this agent.\n  code_execution_config={\"executor\": executor}, # Use the docker command line code executor.\n  human_input_mode=\"ALWAYS\", # Always take human input for this agent for safety.\n)\n# When the code executor is no longer used, stop it to release the resources.\n# executor.stop()\n\n```\n\nThe `work_dir` in the constructor points to a local file system directory just like in the local execution case. The docker container will mount this directory and the executor write code files and output to it.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#use-code-execution-in-conversation>)\nUse Code Execution in Conversation\nWriting and executing code is necessary for many tasks such as data analysis, machine learning, and mathematical modeling. In AutoGen, coding can be a conversation between a code writer agent and a code executor agent, mirroring the interaction between a programmer and a code interpreter.\n![Code Writer and Code Executor](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/code-execution-in-conversation.png)\nThe code writer agent can be powered by an LLM such as GPT-4 with code-writing capability. And the code executor agent is powered by a code executor.\nThe following is an agent with a code writer role specified using `system_message`. The system message contains important instruction on how to use the code executor in the code executor agent.\nCopy\n```\n# The code writer agent's system message is to instruct the LLM on how to use\n# the code executor in the code executor agent.\ncode_writer_system_message = \"\"\"You are a helpful AI assistant.\nSolve tasks using your coding and language skills.\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\nSolve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\nWhen using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\nIf you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\nWhen you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\nReply 'TERMINATE' in the end when everything is done.\n\"\"\"\ncode_writer_agent = ConversableAgent(\n  \"code_writer_agent\",\n  system_message=code_writer_system_message,\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  code_execution_config=False, # Turn off code execution for this agent.\n)\n\n```\n\nHere is an example of solving a math problem through a conversation between the code writer agent and the code executor agent (created above).\nCopy\n```\nchat_result = code_executor_agent.initiate_chat(\n  code_writer_agent,\n  message=\"Write Python code to calculate the 14th Fibonacci number.\",\n)\n\n```\n\nCopy\n```\ncode_executor_agent (to code_writer_agent):\nWrite Python code to calculate the 14th Fibonacci number.\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\ncode_writer_agent (to code_executor_agent):\nSure, here is a Python code snippet to calculate the 14th Fibonacci number. The Fibonacci series is a sequence of numbers in which each number is the sum of the two preceding ones, usually starting with 0 and 1.\n```python\ndef fibonacci(n):\n  if(n <= 0):\n    return \"Input should be a positive integer.\"\n  elif(n == 1):\n    return 0\n  elif(n == 2):\n    return 1\n  else:\n    fib = [0, 1]\n    for i in range(2, n):\n      fib.append(fib[i-1] + fib[i-2])\n    return fib[n-1]\nprint(fibonacci(14))\n```\nThis Python code defines a function `fibonacci(n)` which computes the n-th Fibonacci number. The function uses a list `fib` to store the Fibonacci numbers as they are computed, and then returns the (n-1)-th element as the n-th Fibonacci number due to zero-indexing in Python lists.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\ncode_executor_agent (to code_writer_agent):\nexitcode: 0 (execution succeeded)\nCode output: \n233\n\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\ncode_writer_agent (to code_executor_agent):\nGreat, the execution was successful and the 14th Fibonacci number is 233. The sequence goes as follows: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233... and so on, where each number is the sum of the previous two. Therefore, the 14th number in the Fibonacci series is 233. \nI hope this meets your expectations. If you have any other concerns or need further computations, feel free to ask.\nTERMINATE\n--------------------------------------------------------------------------------\n\n```\n\nDuring the previous chat session, human input was requested each time the code executor agent responded to ensure that the code was safe to execute.\nNow we can try a more complex example that involves querying the web. Let’s say we want to get the the stock price gains year-to-date for Tesla and Meta (formerly Facebook). We can also use the two agents with several iterations of conversation.\nCopy\n```\nimport datetime\ntoday = datetime.datetime.now().strftime(\"%Y-%m-%d\")\nchat_result = code_executor_agent.initiate_chat(\n  code_writer_agent,\n  message=f\"Today is {today}. Write Python code to plot TSLA's and META's \"\n  \"stock price gains YTD, and save the plot to a file named 'stock_gains.png'.\",\n)\n\n```\n\nCopy\n```\ncode_executor_agent (to code_writer_agent):\nToday is 2024-02-28. Write Python code to plot TSLA's and META's stock price gains YTD, and save the plot to a file named 'stock_gains.png'.\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\ncode_writer_agent (to code_executor_agent):\nThis task requires retrieving the historical data of the stocks from a reliable data source and calculating the Year-To-Date (YTD) gain values, and then plotting them. pandas_datareader library will be used for data retrieval, pandas will be used for data manipulation, and matplotlib for plotting. \nBelow is the Python code to achieve this. To start, please install the required libraries by running to the following command:\n```sh\npip install yfinance pandas matplotlib\n```\nThen run the python code:\n```python\n# filename: stock_gains.py\nimport yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n# define the tickers\ntickers = ['TSLA', 'META'] \n# define the start and end dates\nstart_date = datetime(2024, 1, 1)\nend_date = datetime(2024, 2, 28)\n# dictionary to hold dataframes\ndfs = {}\nfor ticker in tickers:\n  # get the data for the stocks\n  df = yf.download(ticker, start_date, end_date)\n  # get the close price and calculate the cumulative percentage gain\n  df['Gain'] = df['Close'].pct_change().cumsum()\n  # add to dictionary\n  dfs[ticker] = df  \n# plot\nplt.figure(figsize=(10, 5))\nfor ticker, df in dfs.items():\n  plt.plot(df.index, df['Gain'], label=ticker)\nplt.title('YTD Stock Price Gain')\nplt.xlabel('Date')\nplt.ylabel('Percentage Gain')\nplt.legend()\nplt.grid(True)\nplt.savefig('stock_gains.png')\nplt.close()\nprint(\"The 'stock_gains.png' file has been successfully saved\")\n```\nThis script will download the historical data for TSLA and META from the start of the year to the specified date and calculates the YTD gains. It then generates the plot showing these gains and saves it to 'stock_gains.png'.\nPlease save the script to a file named 'stock_gains.py' and run it using Python. Remember to have the correct start and end dates for the YTD value when running the script. If your Python version is below 3.9, you should update it to execute this code perfectly.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\n>>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\ncode_executor_agent (to code_writer_agent):\nexitcode: 0 (execution succeeded)\nCode output: \nRequirement already satisfied: yfinance in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (0.2.36)\nRequirement already satisfied: pandas in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (2.1.4)\nRequirement already satisfied: matplotlib in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (3.9.2)\nRequirement already satisfied: numpy>=1.16.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.26.2)\nRequirement already satisfied: requests>=2.31 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2.31.0)\nRequirement already satisfied: multitasking>=0.0.7 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: lxml>=4.9.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (5.0.1)\nRequirement already satisfied: appdirs>=1.4.4 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.4.4)\nRequirement already satisfied: pytz>=2022.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2023.3.post1)\nRequirement already satisfied: frozendict>=2.3.4 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (2.4.0)\nRequirement already satisfied: peewee>=3.16.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (3.17.0)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (4.12.2)\nRequirement already satisfied: html5lib>=1.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from yfinance) (1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: tzdata>=2022.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from pandas) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (4.47.2)\nRequirement already satisfied: kiwisolver>=1.3.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (23.2)\nRequirement already satisfied: pillow>=8 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (10.2.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: soupsieve>1.2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: six>=1.9 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages (from requests>=2.31->yfinance) (2024.2.2)\nThe 'stock_gains.png' file has been successfully saved\n\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\ncode_writer_agent (to code_executor_agent):\nGreat! The code executed successfully and the 'stock_gains.png' file has been saved successfully. This file contains the plot of TSLA's and META's stock price gains from the start of the year until February 28, 2024. You should now be able to view this image file in the same directory that you ran the script from. \nPlease make sure to verify this image file. It should contain two plotted lines, each representing the percentage gain over the time for each stock (TSLA and META). The x-axis represents the date, and the y-axis represents the percentage gain. If everything looks correct, this would be the end of the task.\nTERMINATE\n--------------------------------------------------------------------------------\n\n```\n\nIn the previous conversation, the code writer agent generated a code block to install necessary packages and another code block for a script to fetch the stock price and calculate gains year-to-date for Tesla and Meta. The code executor agent installed the packages, executed the script, and returned the results.\nLet’s take a look at the chart that was generated.\nCopy\n```\nfrom IPython.display import Image\nImage(os.path.join(temp_dir, \"stock_gains.png\"))\n\n```\n\n![](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/code-executors_files/figure-markdown_strict/cell-11-output-1.png)\nBecause code execution leave traces like code files and output in the file system, we may want to clean up the working directory after each conversation concludes.\nCopy\n```\ntemp_dir.cleanup()\n\n```\n\nStop the docker command line executor to clean up the docker container.\nCopy\n```\nexecutor.stop() # Stop the docker command line code executor.\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#command-line-or-jupyter-code-executor>)\nCommand Line or Jupyter Code Executor?\nThe command line code executor does not keep any state in memory between executions of different code blocks it receives, as it writes each code block to a separate file and executes the code block in a new process.\nContrast to the command line code executor, the Jupyter code executor runs all code blocks in the same Jupyter kernel, which keeps the state in memory between executions. See the topic page for [Jupyter Code Executor](https://docs.ag2.ai/docs/tutorial/docs/topics/code-execution/jupyter-code-executor>).\nThe choice between command line and Jupyter code executor depends on the nature of the code blocks in agents’ conversation. If each code block is a “script” that does not use variables from previous code blocks, the command line code executor is a good choice. If some code blocks contain expensive computations (e.g., training a machine learning model and loading a large amount of data), and you want to keep the state in memory to avoid repeated computations, the Jupyter code executor is a better choice.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#note-on-user-proxy-agent-and-assistant-agent>)\nNote on User Proxy Agent and Assistant Agent\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#user-proxy-agent>)\nUser Proxy Agent\nIn the previous examples, we create the code executor agent directly using the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. Existing AutoGen examples often create code executor agent using the `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) class, which is a subclass of `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) with `human_input_mode=ALWAYS` and `llm_config=False` – it always requests human input for every message and does not use LLM. It also comes with default `description` field for each of the `human_input_mode` setting. This class is a convenient short-cut for creating an agent that is intended to be used as a code executor.\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#assistant-agent>)\nAssistant Agent\nIn the previous examples, we created the code writer agent directly using the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. Existing AutoGen examples often create the code writer agent using the `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) class, which is a subclass of `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) with `human_input_mode=NEVER` and `code_execution_config=False` – it never requests human input and does not use code executor. It also comes with default `system_message` and `description` fields. This class is a convenient short-cut for creating an agent that is intended to be used as a code writer and does not execute code.\nIn fact, in the previous example we use the default `system_message` field of the `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) class to instruct the code writer agent how to use code executor.\nCopy\n```\nimport pprint\nfrom autogen import AssistantAgent\npprint.pprint(AssistantAgent.DEFAULT_SYSTEM_MESSAGE)\n\n```\n\nCopy\n```\n('You are a helpful AI assistant.\\n'\n 'Solve tasks using your coding and language skills.\\n'\n 'In the following cases, suggest python code (in a python coding block) or '\n 'shell script (in a sh coding block) for the user to execute.\\n'\n '  1. When you need to collect info, use the code to output the info you '\n 'need, for example, browse or search the web, download/read a file, print the '\n 'content of a webpage or a file, get the current date/time, check the '\n 'operating system. After sufficient info is printed and the task is ready to '\n 'be solved based on your language skill, you can solve the task by yourself.\\n'\n '  2. When you need to perform some task with code, use the code to perform '\n 'the task and output the result. Finish the task smartly.\\n'\n 'Solve the task step by step if you need to. If a plan is not provided, '\n 'explain your plan first. Be clear which step uses code, and which step uses '\n 'your language skill.\\n'\n 'When using code, you must indicate the script type in the code block. The '\n 'user cannot provide any other feedback or perform any other action beyond '\n \"executing the code you suggest. The user can't modify your code. So do not \"\n \"suggest incomplete code which requires users to modify. Don't use a code \"\n \"block if it's not intended to be executed by the user.\\n\"\n 'If you want the user to save the code in a file before executing it, put # '\n \"filename: <filename> inside the code block as the first line. Don't include \"\n 'multiple code blocks in one response. Do not ask users to copy and paste the '\n \"result. Instead, use 'print' function for the output when relevant. Check \"\n 'the execution result returned by the user.\\n'\n 'If the result indicates there is an error, fix the error and output the code '\n 'again. Suggest the full code instead of partial code or code changes. If the '\n \"error can't be fixed or if the task is not solved even after the code is \"\n 'executed successfully, analyze the problem, revisit your assumption, collect '\n 'additional info you need, and think of a different approach to try.\\n'\n 'When you find an answer, verify the answer carefully. Include verifiable '\n 'evidence in your response if possible.\\n'\n 'Reply \"TERMINATE\" in the end when everything is done.\\n'\n '  ')\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#best-practice>)\nBest Practice\nIt is very important to note that the `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) and `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>) are meant to be shortcuts to avoid writing the `system_message` instructions for the `ConversableAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#conversableagent>) class. They are not suitable for all use cases. As we will show in the next chapter, tuning the `system_message` field is vital for agent to work properly in more complex conversation patterns beyond two-agent chat.\nAs a best practice, always tune your agent’s `system_message` instructions for your specific use case and avoid subclassing `UserProxyAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/user_proxy_agent#userproxyagent>) and `AssistantAgent`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/assistant_agent#assistantagent>).\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter, we introduced code executors, how to set up Docker and local execution, and how to use code execution in a conversation to solve tasks. In the next chapter, we will introduce tool use, which is similar to code executors but restricts what code an agent can execute.\n[Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)[Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Overview](https://docs.ag2.ai/docs/tutorial/<#overview>)\n  * [Local Execution](https://docs.ag2.ai/docs/tutorial/<#local-execution>)\n  * [Docker Execution](https://docs.ag2.ai/docs/tutorial/<#docker-execution>)\n  * [Use Code Execution in Conversation](https://docs.ag2.ai/docs/tutorial/<#use-code-execution-in-conversation>)\n  * [Command Line or Jupyter Code Executor?](https://docs.ag2.ai/docs/tutorial/<#command-line-or-jupyter-code-executor>)\n  * [Note on User Proxy Agent and Assistant Agent](https://docs.ag2.ai/docs/tutorial/<#note-on-user-proxy-agent-and-assistant-agent>)\n  * [User Proxy Agent](https://docs.ag2.ai/docs/tutorial/<#user-proxy-agent>)\n  * [Assistant Agent](https://docs.ag2.ai/docs/tutorial/<#assistant-agent>)\n  * [Best Practice](https://docs.ag2.ai/docs/tutorial/<#best-practice>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# Tool Use\nURL: https://docs.ag2.ai/docs/tutorial/tool-use\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nTool Use\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Tool Use\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/tool-use.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/tool-use.ipynb>)\nIn the previous chapter, we explored code executors which give agents the super power of programming. Agents writing arbitrary code is useful, however, controlling what code an agent writes can be challenging. This is where tools come in.\nTools are pre-defined functions that agents can use. Instead of writing arbitrary code, agents can call tools to perform actions, such as searching the web, performing calculations, reading files, or calling remote APIs. Because you can control what tools are available to an agent, you can control what actions an agent can perform.\nTool use is currently only available for LLMs that support OpenAI-compatible tool call API.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#creating-tools>)\nCreating Tools\nTools can be created as regular Python functions. For example, let’s create a calculator tool which can only perform a single operation at a time.\nCopy\n```\nfrom typing import Annotated, Literal\nOperator = Literal[\"+\", \"-\", \"*\", \"/\"]\n\ndef calculator(a: int, b: int, operator: Annotated[Operator, \"operator\"]) -> int:\n  if operator == \"+\":\n    return a + b\n  elif operator == \"-\":\n    return a - b\n  elif operator == \"*\":\n    return a * b\n  elif operator == \"/\":\n    return int(a / b)\n  else:\n    raise ValueError(\"Invalid operator\")\n\n```\n\nThe above function takes three arguments: `a` and `b` are the integer numbers to be operated on; `operator` is the operation to be performed. We used type hints to define the types of the arguments and the return value.\nAlways use type hints to define the types of the arguments and the return value as they provide helpful hints to the agent about the tool’s usage.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#registering-tools>)\nRegistering Tools\nOnce you have created a tool, you can register it with the agents that are involved in conversation.\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\n# Let's first define the assistant agent that suggests tool calls.\nassistant = ConversableAgent(\n  name=\"Assistant\",\n  system_message=\"You are a helpful AI assistant. \"\n  \"You can help with simple calculations. \"\n  \"Return 'TERMINATE' when the task is done.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\n# The user proxy agent is used for interacting with the assistant agent\n# and executes tool calls.\nuser_proxy = ConversableAgent(\n  name=\"User\",\n  llm_config=False,\n  is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n  human_input_mode=\"NEVER\",\n)\n# Register the tool signature with the assistant agent.\nassistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(calculator)\n# Register the tool function with the user proxy agent.\nuser_proxy.register_for_execution(name=\"calculator\")(calculator)\n\n```\n\nCopy\n```\n<function __main__.calculator(a: int, b: int, operator: Annotated[Literal['+', '-', '*', '/'], 'operator']) -> int>\n\n```\n\nIn the above code, we registered the `calculator` function as a tool with the assistant and user proxy agents. We also provide a name and a description for the tool for the assistant agent to understand its usage.\nAlways provide a clear and concise description for the tool as it helps the agent’s underlying LLM to understand the tool’s usage.\nSimilar to code executors, a tool must be registered with at least two agents for it to be useful in conversation. The agent registered with the tool’s signature through `register_for_llm`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-for-llm>) can call the tool; the agent registered with the tool’s function object through `register_for_execution`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-for-execution>) can execute the tool’s function.\nAlternatively, you can use `autogen.register_function`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-function>) function to register a tool with both agents at once.\nCopy\n```\nfrom autogen import register_function\n# Register the calculator function to the two agents.\nregister_function(\n  calculator,\n  caller=assistant, # The assistant agent can suggest calls to the calculator.\n  executor=user_proxy, # The user proxy agent can execute the calculator calls.\n  name=\"calculator\", # By default, the function name is used as the tool name.\n  description=\"A simple calculator\", # A description of the tool.\n)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#using-tool>)\nUsing Tool\nOnce the tool is registered, we can use it in conversation. In the code below, we ask the assistant to perform some arithmetic calculation using the `calculator` tool.\nCopy\n```\nchat_result = user_proxy.initiate_chat(assistant, message=\"What is (44232 + 13312 / (232 - 32)) * 5?\")\n\n```\n\nCopy\n```\nUser (to Assistant):\nWhat is (44232 + 13312 / (232 - 32)) * 5?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_4rElPoLggOYJmkUutbGaSTX1): calculator *****\nArguments: \n{\n \"a\": 232,\n \"b\": 32,\n \"operator\": \"-\"\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_4rElPoLggOYJmkUutbGaSTX1) *****\n200\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_SGtr8tK9A4iOCJGdCqkKR2Ov): calculator *****\nArguments: \n{\n \"a\": 13312,\n \"b\": 200,\n \"operator\": \"/\"\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_SGtr8tK9A4iOCJGdCqkKR2Ov) *****\n66\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_YsR95CM1Ice2GZ7ZoStYXI6M): calculator *****\nArguments: \n{\n \"a\": 44232,\n \"b\": 66,\n \"operator\": \"+\"\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_YsR95CM1Ice2GZ7ZoStYXI6M) *****\n44298\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_oqZn4rTjyvXYcmjAXkvVaJm1): calculator *****\nArguments: \n{\n \"a\": 44298,\n \"b\": 5,\n \"operator\": \"*\"\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_oqZn4rTjyvXYcmjAXkvVaJm1) *****\n221490\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\nThe result of the calculation is 221490. TERMINATE\n--------------------------------------------------------------------------------\n\n```\n\nLet’s verify the answer:\nCopy\n```\n(44232 + int(13312 / (232 - 32))) * 5\n\n```\n\nCopy\n```\n221490\n\n```\n\nThe answer is correct. You can see that the assistant is able to understand the tool’s usage and perform calculation correctly.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#tool-schema>)\nTool Schema\nIf you are familiar with [OpenAI’s tool use API](https://docs.ag2.ai/docs/tutorial/<https:/platform.openai.com/docs/guides/function-calling>), you might be wondering why we didn’t create a tool schema. In fact, the tool schema is automatically generated from the function signature and the type hints. You can see the tool schema by inspecting the `llm_config` attribute of the agent.\nCopy\n```\nassistant.llm_config[\"tools\"]\n\n```\n\nCopy\n```\n[{'type': 'function',\n 'function': {'description': 'A simple calculator',\n  'name': 'calculator',\n  'parameters': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'a'},\n   'b': {'type': 'integer', 'description': 'b'},\n   'operator': {'enum': ['+', '-', '*', '/'],\n   'type': 'string',\n   'description': 'operator'}},\n  'required': ['a', 'b', 'operator']}}}]\n\n```\n\nYou can see the tool schema has been automatically generated from the function signature and the type hints, as well as the description. This is why it is important to use type hints and provide a clear description for the tool as the LLM uses them to understand the tool’s usage.\nYou can also use Pydantic model for the type hints to provide more complex type schema. In the example below, we use a Pydantic model to define the calculator input.\nCopy\n```\nfrom pydantic import BaseModel, Field\n\nclass CalculatorInput(BaseModel):\n  a: Annotated[int, Field(description=\"The first number.\")]\n  b: Annotated[int, Field(description=\"The second number.\")]\n  operator: Annotated[Operator, Field(description=\"The operator.\")]\n\ndef calculator(input: Annotated[CalculatorInput, \"Input to the calculator.\"]) -> int:\n  if input.operator == \"+\":\n    return input.a + input.b\n  elif input.operator == \"-\":\n    return input.a - input.b\n  elif input.operator == \"*\":\n    return input.a * input.b\n  elif input.operator == \"/\":\n    return int(input.a / input.b)\n  else:\n    raise ValueError(\"Invalid operator\")\n\n```\n\nSame as before, we register the tool with the agents using the name `\"calculator\"`.\nRegistering tool to the same name will override the previous tool.\nCopy\n```\nassistant.register_for_llm(name=\"calculator\", description=\"A calculator tool that accepts nested expression as input\")(\n  calculator\n)\nuser_proxy.register_for_execution(name=\"calculator\")(calculator)\n\n```\n\nCopy\n```\n<function __main__.calculator(input: typing.Annotated[__main__.CalculatorInput, 'Input to the calculator.']) -> int>\n\n```\n\nYou can see the tool schema has been updated to reflect the new type schema.\nCopy\n```\nassistant.llm_config[\"tools\"]\n\n```\n\nCopy\n```\n[{'type': 'function',\n 'function': {'description': 'A calculator tool that accepts nested expression as input',\n  'name': 'calculator',\n  'parameters': {'type': 'object',\n  'properties': {'input': {'properties': {'a': {'description': 'The first number.',\n    'title': 'A',\n    'type': 'integer'},\n    'b': {'description': 'The second number.',\n    'title': 'B',\n    'type': 'integer'},\n    'operator': {'description': 'The operator.',\n    'enum': ['+', '-', '*', '/'],\n    'title': 'Operator',\n    'type': 'string'}},\n   'required': ['a', 'b', 'operator'],\n   'title': 'CalculatorInput',\n   'type': 'object',\n   'description': 'Input to the calculator.'}},\n  'required': ['input']}}}]\n\n```\n\nLet’s use the tool in conversation.\nCopy\n```\nchat_result = user_proxy.initiate_chat(assistant, message=\"What is (1423 - 123) / 3 + (32 + 23) * 5?\")\n\n```\n\nCopy\n```\nUser (to Assistant):\nWhat is (1423 - 123) / 3 + (32 + 23) * 5?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_Uu4diKtxlTfkwXuY6MmJEb4E): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": (1423 - 123) / 3,\n    \"b\": (32 + 23) * 5,\n    \"operator\": \"+\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_Uu4diKtxlTfkwXuY6MmJEb4E) *****\nError: Expecting value: line 1 column 29 (char 28)\n You argument should follow json format.\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\nI apologize for the confusion, I seem to have made a mistake. Let me recalculate the expression properly.\nFirst, we need to do the calculations within the brackets. So, calculating (1423 - 123), (32 + 23), and then performing remaining operations.\n***** Suggested tool call (call_mx3M3fNOwikFNoqSojDH1jIr): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": 1423,\n    \"b\": 123,\n    \"operator\": \"-\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_mx3M3fNOwikFNoqSojDH1jIr) *****\n1300\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_hBAL2sYi6Y5ZtTHCNPCmxdN3): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": 32,\n    \"b\": 23,\n    \"operator\": \"+\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_hBAL2sYi6Y5ZtTHCNPCmxdN3) *****\n55\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_wO3AP7EDeJvsVLCpvv5LohUa): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": 1300,\n    \"b\": 3,\n    \"operator\": \"/\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_wO3AP7EDeJvsVLCpvv5LohUa) *****\n433\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_kQ2hDhqem8BHNlaHaE9ezvvQ): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": 55,\n    \"b\": 5,\n    \"operator\": \"*\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_kQ2hDhqem8BHNlaHaE9ezvvQ) *****\n275\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\n***** Suggested tool call (call_1FLDUdvAZmjlSD7g5GFFJOpO): calculator *****\nArguments: \n{\n  \"input\": {\n    \"a\": 433,\n    \"b\": 275,\n    \"operator\": \"+\"\n  }\n}\n***************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION calculator...\nUser (to Assistant):\nUser (to Assistant):\n***** Response from calling tool (call_1FLDUdvAZmjlSD7g5GFFJOpO) *****\n708\n**********************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nAssistant (to User):\nThe calculation result of the expression (1423 - 123) / 3 + (32 + 23) * 5 is 708. Let's proceed to the next task.\nTERMINATE\n--------------------------------------------------------------------------------\n\n```\n\nLet’s verify the answer:\nCopy\n```\nint((1423 - 123) / 3) + (32 + 23) * 5\n\n```\n\nCopy\n```\n708\n\n```\n\nAgain, the answer is correct. You can see that the assistant is able to understand the new tool schema and perform calculation correctly.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#how-to-hide-tool-usage-and-code-execution-within-a-single-agent>)\nHow to hide tool usage and code execution within a single agent?\nSometimes it is preferable to hide the tool usage inside a single agent, i.e., the tool call and tool response messages are kept invisible from outside of the agent, and the agent responds to outside messages with tool usages as “internal monologues”. For example, you might want build an agent that is similar to the [OpenAI’s Assistant](https://docs.ag2.ai/docs/tutorial/<https:/platform.openai.com/docs/assistants/overview#how-assistants-work>) which executes built-in tools internally.\nTo achieve this, you can use [nested chats](https://docs.ag2.ai/docs/tutorial/docs/tutorial/conversation-patterns#nested-chats>). Nested chats allow you to create “internal monologues” within an agent to call and execute tools. This works for code execution as well. See [nested chats for tool use](https://docs.ag2.ai/docs/tutorial/notebooks/agentchat_nested_chats_chess>) for an example.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter, we showed you how to create, register and use tools. Tools allows agents to perform actions without writing arbitrary code. In the next chapter, we will introduce conversation patterns, and show how to use the result of a conversation.\n[Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)[Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Creating Tools](https://docs.ag2.ai/docs/tutorial/<#creating-tools>)\n  * [Registering Tools](https://docs.ag2.ai/docs/tutorial/<#registering-tools>)\n  * [Using Tool](https://docs.ag2.ai/docs/tutorial/<#using-tool>)\n  * [Tool Schema](https://docs.ag2.ai/docs/tutorial/<#tool-schema>)\n  * [How to hide tool usage and code execution within a single agent?](https://docs.ag2.ai/docs/tutorial/<#how-to-hide-tool-usage-and-code-execution-within-a-single-agent>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# Conversation Patterns\nURL: https://docs.ag2.ai/docs/tutorial/conversation-patterns\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nConversation Patterns\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# Conversation Patterns\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/tutorial/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/tutorial/conversation-patterns.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2/blob/main/website/docs/tutorial/conversation-patterns.ipynb>)\nIn the previous chapter we used two-agent conversation, which can be started by the `initiate_chat` method. Two-agent chat is a useful conversation pattern but AutoGen offers more. In this chapter, we will first dig a little bit more into the two-agent chat pattern and chat result, then we will show you several conversation patterns that involve more than two agents.\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#an-overview>)\nAn Overview\n  1. **Two-agent chat** : the simplest form of conversation pattern where two agents chat with each other.\n  2. **Sequential chat** : a sequence of chats between two agents, chained together by a carryover mechanism, which brings the summary of the previous chat to the context of the next chat.\n  3. **Group Chat** : a single chat involving more than two agents. An important question in group chat is: What agent should be next to speak? To support different scenarios, we provide different ways to organize agents in a group chat: \n     * We support several strategies to select the next agent: `round_robin`, `random`, `manual` (human selection), and `auto` (Default, using an LLM to decide).\n     * We provide a way to constrain the selection of the next speaker (See examples below).\n     * We allow you to pass in a function to customize the selection of the next speaker. With this feature, you can build a **StateFlow** model which allows a deterministic workflow among your agents. Please refer to this [guide](https://docs.ag2.ai/docs/tutorial/docs/topics/groupchat/customized_speaker_selection>) and this [blog post](https://docs.ag2.ai/docs/tutorial/blog/2024-02-29-StateFlow>) on StateFlow for more details.\n  4. **Nested Chat** : package a workflow into a single agent for reuse in a larger workflow.\n\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#two-agent-chat-and-chat-result>)\nTwo-Agent Chat and Chat Result\nTwo-agent chat is the simplest form of conversation pattern. We start a two-agent chat using the `initiate_chat` method of every `ConversableAgent` agent. We have already seen multiple examples of two-agent chats in previous chapters but we haven’t covered the details.\nThe following figure illustrates how two-agent chat works.\n![Two-agent chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/two-agent-chat.png)\nA two-agent chats takes two inputs: a message, which is a string provided by the caller; a context, which specifies various parameters of the chat. The sender agent uses its chat initializer method (i.e., `generate_init_message` method of `ConversableAgent`) to generate an initial message from the inputs, and sends it to the recipient agent to start the chat. The sender agent is the agent whose `initiate_chat` method is called, and the recipient agent is the other agent.\nOnce the chat terminates, the history of the chat is processed by a chat summarizer. The summarizer summarizes the chat history and calculates the token usage of the chat. You can configure the type of summary using the `summary_method` parameter of the `initiate_chat` method. By default, it is the last message of the chat (i.e., `summary_method='last_msg'`).\nThe example below is a two-agent chat between a student agent and a teacher agent. Its summarizer uses an LLM-based summary.\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\nstudent_agent = ConversableAgent(\n  name=\"Student_Agent\",\n  system_message=\"You are a student willing to learn.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\nteacher_agent = ConversableAgent(\n  name=\"Teacher_Agent\",\n  system_message=\"You are a math teacher.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\nchat_result = student_agent.initiate_chat(\n  teacher_agent,\n  message=\"What is triangle inequality?\",\n  summary_method=\"reflection_with_llm\",\n  max_turns=2,\n)\n\n```\n\nCopy\n```\nStudent_Agent (to Teacher_Agent):\nWhat is triangle inequality?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nTeacher_Agent (to Student_Agent):\nTriangle inequality theorem is a fundamental principle in geometry that states that the sum of the lengths of any two sides of a triangle must always be greater than the length of the third side. In a triangle with sides of lengths a, b, and c, the theorem can be written as:\na + b > c\na + c > b\nb + c > a\nEach of these represents the condition for one specific side (a, b, or c). All must be true for a triangle to exist.\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nStudent_Agent (to Teacher_Agent):\nThank you for the explanation. This theorem helps in understanding the basic properties of a triangle. It can also be useful when solving geometric problems or proving other mathematical theorems. Can you give me an example of how we can use the triangle inequality theorem?\n--------------------------------------------------------------------------------\n>>>>>>>> USING AUTO REPLY...\nTeacher_Agent (to Student_Agent):\nAbsolutely! Here's an example:\nSuppose you're given three line segments with lengths 10, 7, and 3 units. The question is: \"Can these three line segments form a triangle?\"\nTo answer this, you would use the triangle inequality theorem. Adding any two side lengths together should be greater than the third:\n- For sides 10 and 7: 10 + 7 = 17, which is larger than 3.\n- For sides 10 and 3: 10 + 3 = 13, which is larger than 7.\n- For sides 7 and 3: 7 + 3 = 10, which is equal to the length of the third side (10), but not greater.\nSo, these three lines cannot form a triangle, because not all pairs of sides satisfy the triangle inequality theorem.\n--------------------------------------------------------------------------------\n\n```\n\nLet’s see what the summary looks like. The summary is stored in the `chat_result` object of the type `ChatResult` that was returned by the `initiate_chat` method.\nCopy\n```\nprint(chat_result.summary)\n\n```\n\nCopy\n```\nThe triangle inequality theorem states that in a triangle, the sum of the lengths of any two sides must always be greater than the length of the third side. This principle is significant in geometry and is used in solving problems or proving theorems. For instance, if given three line segments, you can determine if they can form a triangle using this theorem.\n\n```\n\nIn the above example, the summary method is set to `reflection_with_llm` which takes a list of messages from the conversation and summarize them using a call to an LLM. The summary method first tries to use the recipient’s LLM, if it is not available then it uses the sender’s LLM. In this case the recipient is “Teacher_Agent” and the sender is “Student_Agent”. The input prompt for the LLM is the following default prompt:\nCopy\n```\nprint(ConversableAgent.DEFAULT_SUMMARY_PROMPT)\n\n```\n\nCopy\n```\nSummarize the takeaway from the conversation. Do not add any introductory phrases.\n\n```\n\nYou can also use a custom prompt by setting the `summary_prompt` argument of `initiate_chat`.\nThere are some other useful information in the `ChatResult` object, including the conversation history, human input, and token cost.\nCopy\n```\n# Get the chat history.\nimport pprint\npprint.pprint(chat_result.chat_history)\n\n```\n\nCopy\n```\n[{'content': 'What is triangle inequality?', 'role': 'assistant'},\n {'content': 'Triangle inequality theorem is a fundamental principle in '\n       'geometry that states that the sum of the lengths of any two '\n       'sides of a triangle must always be greater than the length of '\n       'the third side. In a triangle with sides of lengths a, b, and c, '\n       'the theorem can be written as:\\n'\n       '\\n'\n       'a + b > c\\n'\n       'a + c > b\\n'\n       'b + c > a\\n'\n       '\\n'\n       'Each of these represents the condition for one specific side (a, '\n       'b, or c). All must be true for a triangle to exist.',\n 'role': 'user'},\n {'content': 'Thank you for the explanation. This theorem helps in '\n       'understanding the basic properties of a triangle. It can also be '\n       'useful when solving geometric problems or proving other '\n       'mathematical theorems. Can you give me an example of how we can '\n       'use the triangle inequality theorem?',\n 'role': 'assistant'},\n {'content': \"Absolutely! Here's an example:\\n\"\n       '\\n'\n       \"Suppose you're given three line segments with lengths 10, 7, and \"\n       '3 units. The question is: \"Can these three line segments form a '\n       'triangle?\"\\n'\n       '\\n'\n       'To answer this, you would use the triangle inequality theorem. '\n       'Adding any two side lengths together should be greater than the '\n       'third:\\n'\n       '\\n'\n       '- For sides 10 and 7: 10 + 7 = 17, which is larger than 3.\\n'\n       '- For sides 10 and 3: 10 + 3 = 13, which is larger than 7.\\n'\n       '- For sides 7 and 3: 7 + 3 = 10, which is equal to the length of '\n       'the third side (10), but not greater.\\n'\n       '\\n'\n       'So, these three lines cannot form a triangle, because not all '\n       'pairs of sides satisfy the triangle inequality theorem.',\n 'role': 'user'}]\n\n```\n\nThat chat messages in the chat result are from the recipient agent’s perspective – the sender is the “assistant” and the recipient is the “user”.\nCopy\n```\n# Get the cost of the chat.\npprint.pprint(chat_result.cost)\n\n```\n\nCopy\n```\n({'gpt-4-0613': {'completion_tokens': 399,\n         'cost': 0.04521,\n         'prompt_tokens': 709,\n         'total_tokens': 1108},\n 'total_cost': 0.04521},\n {'total_cost': 0})\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#sequential-chats>)\nSequential Chats\nThe name of this pattern is self-explanatory – it is a sequence of chats between two agents, chained together by a mechanism called _carryover_ , which brings the summary of the previous chat to the context of the next chat.\nThis pattern is useful for complex task that can be broken down into interdependent sub-tasks. The figure below illustrate how this pattern works.\n![initiate_chats](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/sequential-two-agent-chat.png)\nIn this pattern, the a pair of agents first start a two-agent chat, then the summary of the conversation becomes a _carryover_ for the next two-agent chat. The next chat passes the carryover to the `carryover` parameter of the context to generate its initial message.\nCarryover accumulates as the conversation moves forward, so each subsequent chat starts with all the carryovers from previous chats.\nThe figure above shows distinct recipient agents for all the chats, however, the recipient agents in the sequence are allowed to repeat.\nTo illustrate this pattern, let’s consider a simple example of arithmetic operator agents. One agent (called the “Number_Agent”) is responsible for coming up with a number, and other agents are responsible for performing a specific arithmetic operation on the number, e.g., add 1, multiply by 2, etc..\nCopy\n```\n# The Number Agent always returns the same numbers.\nnumber_agent = ConversableAgent(\n  name=\"Number_Agent\",\n  system_message=\"You return me the numbers I give you, one number each line.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n# The Adder Agent adds 1 to each number it receives.\nadder_agent = ConversableAgent(\n  name=\"Adder_Agent\",\n  system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n# The Multiplier Agent multiplies each number it receives by 2.\nmultiplier_agent = ConversableAgent(\n  name=\"Multiplier_Agent\",\n  system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n# The Subtracter Agent subtracts 1 from each number it receives.\nsubtracter_agent = ConversableAgent(\n  name=\"Subtracter_Agent\",\n  system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n# The Divider Agent divides each number it receives by 2.\ndivider_agent = ConversableAgent(\n  name=\"Divider_Agent\",\n  system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n\n```\n\nThe Number Agent chats with the first operator agent, then the second operator agent, and so on. After each chat, the last message in the conversation (i.e., the result of the arithmetic operation from the operator agent) is used as the summary of the chat. This is specified by the `summary_method` parameter. In the end we will have the result of the arithmetic operations.\nCopy\n```\n# Start a sequence of two-agent chats.\n# Each element in the list is a dictionary that specifies the arguments\n# for the initiate_chat method.\nchat_results = number_agent.initiate_chats(\n  [\n    {\n      \"recipient\": adder_agent,\n      \"message\": \"14\",\n      \"max_turns\": 2,\n      \"summary_method\": \"last_msg\",\n    },\n    {\n      \"recipient\": multiplier_agent,\n      \"message\": \"These are my numbers\",\n      \"max_turns\": 2,\n      \"summary_method\": \"last_msg\",\n    },\n    {\n      \"recipient\": subtracter_agent,\n      \"message\": \"These are my numbers\",\n      \"max_turns\": 2,\n      \"summary_method\": \"last_msg\",\n    },\n    {\n      \"recipient\": divider_agent,\n      \"message\": \"These are my numbers\",\n      \"max_turns\": 2,\n      \"summary_method\": \"last_msg\",\n    },\n  ]\n)\n\n```\n\nCopy\n```\n\n********************************************************************************\nStart a new chat with the following message: \n14\nWith the following carryover: \n\n********************************************************************************\nNumber_Agent (to Adder_Agent):\n14\n--------------------------------------------------------------------------------\nAdder_Agent (to Number_Agent):\n15\n--------------------------------------------------------------------------------\nNumber_Agent (to Adder_Agent):\n15\n--------------------------------------------------------------------------------\nAdder_Agent (to Number_Agent):\n16\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nThese are my numbers\nWith the following carryover: \n16\n********************************************************************************\nNumber_Agent (to Multiplier_Agent):\nThese are my numbers\nContext: \n16\n--------------------------------------------------------------------------------\nMultiplier_Agent (to Number_Agent):\n32\n--------------------------------------------------------------------------------\nNumber_Agent (to Multiplier_Agent):\n32\n--------------------------------------------------------------------------------\nMultiplier_Agent (to Number_Agent):\n64\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nThese are my numbers\nWith the following carryover: \n16\n64\n********************************************************************************\nNumber_Agent (to Subtracter_Agent):\nThese are my numbers\nContext: \n16\n64\n--------------------------------------------------------------------------------\nSubtracter_Agent (to Number_Agent):\n15\n63\n--------------------------------------------------------------------------------\nNumber_Agent (to Subtracter_Agent):\n15\n63\n--------------------------------------------------------------------------------\nSubtracter_Agent (to Number_Agent):\n14\n62\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nThese are my numbers\nWith the following carryover: \n16\n64\n14\n62\n********************************************************************************\nNumber_Agent (to Divider_Agent):\nThese are my numbers\nContext: \n16\n64\n14\n62\n--------------------------------------------------------------------------------\nDivider_Agent (to Number_Agent):\n8\n32\n7\n31\n--------------------------------------------------------------------------------\nNumber_Agent (to Divider_Agent):\n8\n32\n7\n31\n--------------------------------------------------------------------------------\nDivider_Agent (to Number_Agent):\n4\n16\n3.5\n15.5\n--------------------------------------------------------------------------------\n\n```\n\nFirst thing to note is that the `initiate_chats` method takes a list of dictionaries, each dictionary contains the arguments for the `initiate_chat` method.\nSecond, each chat in the sequence has a maximum round of 2, as specified with the setting `max_turns=2`, which means each arithmetic operation is performed twice. So you can see in the first chat the number 14 becomes 15 and then 16, in the second chat the number 16 becomes 32 and then 64, and so on.\nThird, the carryover accumulates as the chats go on. In the second chat, the carryover is the summary of the first chat “16”. In the third chat, the carryover is the summary of the first and second chat, which is the list “16” and “64”, and both numbers are operated upon. In the forth and last chat, the carryover is the summary of all previous chats, which is the list “16”, “64”, “14” and “62”, and all of these numbers are operated upon.\nThe final note is that the `initiate_chats` method returns a list of `ChatResult` objects, one for each chat in the sequence.\nCopy\n```\nprint(\"First Chat Summary: \", chat_results[0].summary)\nprint(\"Second Chat Summary: \", chat_results[1].summary)\nprint(\"Third Chat Summary: \", chat_results[2].summary)\nprint(\"Fourth Chat Summary: \", chat_results[3].summary)\n\n```\n\nCopy\n```\nFirst Chat Summary: 16\nSecond Chat Summary: 64\nThird Chat Summary: 14\n62\nFourth Chat Summary: 4\n16\n3.5\n15.5\n\n```\n\nBesides calling `initiate_chats` from the same sender agent, you can also call a high-level function `autogen.agentchat.initiate_chats` to start a sequence of two-agent chats with different sender agents. This function allows you to specify the sender agent for each chat in the sequence.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#group-chat>)\nGroup Chat\nSo far we have only seen conversation patterns that involve two agents or a sequence of two-agent chats. AutoGen provides a more general conversation pattern called group chat, which involves more than two agents. The core idea of group chat is that all agents contribute to a single conversation thread and share the same context. This is useful for tasks that require collaboration among multiple agents.\nThe figure below illustrates how group chat works.\n![group_chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/group-chat.png)\nA group chat is orchestrated by a special agent type `GroupChatManager`. In the first step of the group chat, the Group Chat Manager selects an agent to speak. Then, the selected agent speaks and the message is sent back to the Group Chat Manager, who **broadcasts** the message to all other agents in the group. This process repeats until the conversation stops.\nThe Group Chat Manager can use several strategies to select the next agent. Currently, the following strategies are supported:\n  1. `round_robin`: The Group Chat Manager selects agents in a round-robin fashion based on the order of the agents provided.\n  2. `random`: The Group Chat Manager selects agents randomly.\n  3. `manual`: The Group Chat Manager selects agents by asking for human input.\n  4. `auto`: The default strategy, which selects agents using the Group Chat Manager’s LLM.\n\n\nTo illustrate this pattern, let’s consider a simple example of a group chat among the same arithmetic operator agents as in the previous example, with the objective of turning a number into a specific target number using a sequence of arithmetic operations powered by the agents.\nIn this example, we use the `auto` strategy to select the next agent. To help the Group Chat Manager select the next agent, we also set the `description` of the agents. Without the `description`, the Group Chat Manager will use the agents’ `system_message`, which may be not be the best choice.\nCopy\n```\n# The `description` attribute is a string that describes the agent.\n# It can also be set in `ConversableAgent` constructor.\nadder_agent.description = \"Add 1 to each input number.\"\nmultiplier_agent.description = \"Multiply each input number by 2.\"\nsubtracter_agent.description = \"Subtract 1 from each input number.\"\ndivider_agent.description = \"Divide each input number by 2.\"\nnumber_agent.description = \"Return the numbers given.\"\n\n```\n\nWe first create a `GroupChat` object and provide the list of agents. If we were to use the `round_robin` strategy, this list would specify the order of the agents to be selected. We also initialize the group chat with an empty message list and a maximum round of 6, which means there will be at most 6 iteratiosn of selecting speaker, agent speaks and broadcasting message.\nCopy\n```\nfrom autogen import GroupChat\ngroup_chat = GroupChat(\n  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n  messages=[],\n  max_round=6,\n)\n\n```\n\nNow we create a `GroupChatManager` object and provide the `GroupChat` object as input. We also need to specify the `llm_config` of the Group Chat Manager so it can use the LLM to select the next agent (the `auto` strategy).\nCopy\n```\nfrom autogen import GroupChatManager\ngroup_chat_manager = GroupChatManager(\n  groupchat=group_chat,\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\n\n```\n\nFinally, we have the Number Agent from before to start a two-agent chat with the Group Chat Manager, which runs the group chat internally and terminates the two-agent chat when the internal group chat is done. Because the Number Agent is selected to speak by us, it counts as the first round of the group chat.\nCopy\n```\nchat_result = number_agent.initiate_chat(\n  group_chat_manager,\n  message=\"My number is 3, I want to turn it into 13.\",\n  summary_method=\"reflection_with_llm\",\n)\n\n```\n\nCopy\n```\nNumber_Agent (to chat_manager):\nMy number is 3, I want to turn it into 13.\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n6\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n14\n--------------------------------------------------------------------------------\nSubtracter_Agent (to chat_manager):\n13\n--------------------------------------------------------------------------------\nNumber_Agent (to chat_manager):\n13\n--------------------------------------------------------------------------------\n\n```\n\nYou can see that the Number Agent is selected to speak first, then the Group Chat Manager selects the Multiplier Agent to speak, then the Adder Agent, and so on. The number is operated upon by each agent in the group chat, and the final result is 13.\nWe can take a look at the summary of the group chat, provided by the `ChatResult` object returned by the `initiate_chat` method.\nCopy\n```\nprint(chat_result.summary)\n\n```\n\nCopy\n```\nThe agents cooperatively manipulated the initial number (3) through multipliying, adding, and subtracting operations to reach the target number (13).\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#send-introductions>)\nSend Introductions\nIn the previous example, we set the `description` of the agents to help the Group Chat Manager select the next agent. This only helps the Group Chat Manager, however, does not help the participating agents to know about each other. Sometimes it is useful have each agent introduce themselves to other agents in the group chat. This can be done by setting the `send_introductions=True`.\nCopy\n```\ngroup_chat_with_introductions = GroupChat(\n  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n  messages=[],\n  max_round=6,\n  send_introductions=True,\n)\n\n```\n\nUnder the hood, the Group Chat Manager sends a message containing the agents’ names and descriptions to all agents in the group chat before the group chat starts.\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#group-chat-in-a-sequential-chat>)\nGroup Chat in a Sequential Chat\nGroup chat can also be used as a part of a sequential chat. In this case, the Group Chat Manager is treated as a regular agent in the sequence of two-agent chats.\nCopy\n```\n# Let's use the group chat with introduction messages created above.\ngroup_chat_manager_with_intros = GroupChatManager(\n  groupchat=group_chat_with_introductions,\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\n# Start a sequence of two-agent chats between the number agent and\n# the group chat manager.\nchat_result = number_agent.initiate_chats(\n  [\n    {\n      \"recipient\": group_chat_manager_with_intros,\n      \"message\": \"My number is 3, I want to turn it into 13.\",\n    },\n    {\n      \"recipient\": group_chat_manager_with_intros,\n      \"message\": \"Turn this number to 32.\",\n    },\n  ]\n)\n\n```\n\nCopy\n```\n\n********************************************************************************\nStart a new chat with the following message: \nMy number is 3, I want to turn it into 13.\nWith the following carryover: \n\n********************************************************************************\nNumber_Agent (to chat_manager):\nMy number is 3, I want to turn it into 13.\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n6\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n14\n--------------------------------------------------------------------------------\nSubtracter_Agent (to chat_manager):\n13\n--------------------------------------------------------------------------------\nNumber_Agent (to chat_manager):\nYour number is 13.\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nTurn this number to 32.\nWith the following carryover: \nYour number is 13.\n********************************************************************************\nNumber_Agent (to chat_manager):\nTurn this number to 32.\nContext: \nYour number is 13.\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n26\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n14\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n28\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n15\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n30\n--------------------------------------------------------------------------------\n\n```\n\nCopy\n```\n/Users/ekzhu/autogen/autogen/agentchat/chat.py:46: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n warnings.warn(\n\n```\n\nIn the above example, the Group Chat Manager runs the group chat two times. In the first time the number 3 becomes 13, and the last message of this group chat is being used as the carryover for the next group chat, which starts from 13.\nYou can also see from the warning message that the Group Chat Manager’s history is being cleared after the first group chat, which is the default. To keep the history of the Group Chat Manager, you can set the `clear_history=False` for the first chat.\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#constrained-speaker-selection>)\nConstrained Speaker Selection\nGroup chat is a powerful conversation pattern, but it can be hard to control if the number of participating agents is large. AutoGen provides a way to constrain the selection of the next speaker by using the `allowed_or_disallowed_speaker_transitions` argument of the `GroupChat` class.\nThe `allowed_or_disallowed_speaker_transitions` argument is a dictionary that maps a given agent to a list of agents that can (or cannot) be selected to speak next. The `speaker_transitions_type` argument specifies whether the transitions are allowed or disallowed.\nHere is an example:\nCopy\n```\nallowed_transitions = {\n  number_agent: [adder_agent, number_agent],\n  adder_agent: [multiplier_agent, number_agent],\n  subtracter_agent: [divider_agent, number_agent],\n  multiplier_agent: [subtracter_agent, number_agent],\n  divider_agent: [adder_agent, number_agent],\n}\n\n```\n\nIn this example, the allowed transitions are specified for each agent. The Number Agent can be followed by the Adder Agent and the Number Agent, the Adder Agent can be followed by the Multiplier Agent and the Number Agent, and so on. Let’s put this into the group chat and see how it works. The `speaker_transitions_type` is set to `allowed` so the transitions are positive constraints.\nCopy\n```\nconstrained_graph_chat = GroupChat(\n  agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n  allowed_or_disallowed_speaker_transitions=allowed_transitions,\n  speaker_transitions_type=\"allowed\",\n  messages=[],\n  max_round=12,\n  send_introductions=True,\n)\nconstrained_group_chat_manager = GroupChatManager(\n  groupchat=constrained_graph_chat,\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n)\nchat_result = number_agent.initiate_chat(\n  constrained_group_chat_manager,\n  message=\"My number is 3, I want to turn it into 10. Once I get to 10, keep it there.\",\n  summary_method=\"reflection_with_llm\",\n)\n\n```\n\nCopy\n```\nNumber_Agent (to chat_manager):\nMy number is 3, I want to turn it into 10. Once I get to 10, keep it there.\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n4\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n8\n--------------------------------------------------------------------------------\nSubtracter_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\nDivider_Agent (to chat_manager):\n3.5\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n4.5\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n9\n--------------------------------------------------------------------------------\nSubtracter_Agent (to chat_manager):\n8\n--------------------------------------------------------------------------------\nDivider_Agent (to chat_manager):\n4\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\n5\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n10\n--------------------------------------------------------------------------------\nNumber_Agent (to chat_manager):\n10\n--------------------------------------------------------------------------------\n\n```\n\nThis time, the agents are selected following the constraints we have specified.\n### \n[​](https://docs.ag2.ai/docs/tutorial/<#changing-the-select-speaker-role-name>)\nChanging the select speaker role name\nAs part of the Group chat process, when the select_speaker_method is set to ‘auto’ (the default value), a select speaker message is sent to the LLM to determine the next speaker.\nEach message in the chat sequence has a `role` attribute that is typically `user`, `assistant`, or `system`. The select speaker message is the last in the chat sequence when used and, by default, has a role of `system`.\nWhen using some models, such as Mistral through Mistral.AI’s API, the role on the last message in the chat sequence has to be `user`.\nTo change the default behaviour, Autogen provides a way to set the value of the select speaker message’s role to any string value by setting the `role_for_select_speaker_messages` parameter in the GroupChat’s constructor. The default value is `system` and by setting it to `user` you can accommodate the last message role requirement of Mistral.AI’s API.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#nested-chats>)\nNested Chats\nThe previous conversations patterns (two-agent chat, sequential chat, and group chat) are useful for building complex workflows, however, they do not expose a single conversational interface, which is often needed for scenarios like question-answering bots and personal assistants. In some other cases, it is also useful to package a workflow into a single agent for reuse in a larger workflow. AutoGen provides a way to achieve this by using nested chats.\nNested chats is powered by the nested chats handler, which is a pluggable component of `ConversableAgent`. The figure below illustrates how the nested chats handler triggers a sequence of nested chats when a message is received.\n![nested_chat](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/tutorial/assets/nested-chats.png)\nWhen a message comes in and passes the [human-in-the-loop component](https://docs.ag2.ai/docs/tutorial/<./human-in-the-loop>), the nested chats handler checks if the message should trigger a nested chat based on conditions specified by the user. If the conditions are met, the nested chats handler starts a sequence of nested chats specified using the sequential chats pattern. In each of the nested chats, the sender agent is always the same agent that triggered the nested chats. In the end, the nested chat handler uses the results of the nested chats to produce a response to the original message. By default, the nested chat handler uses the summary of the last chat as the response.\nHere is an example of using nested chats to build an arithmetic agent that packages arithmetic operations, code-based validation, and poetry into a single agent. This arithmetic agent takes a number transformation request like “turn number 3 into 13” and returns a poem that describes a transformation attempt.\nFirst we define the agents. We reuse the `group_chat_manager_with_intros` from previous example to orchestrate the arithmetic operations.\nCopy\n```\nimport tempfile\ntemp_dir = tempfile.gettempdir()\narithmetic_agent = ConversableAgent(\n  name=\"Arithmetic_Agent\",\n  llm_config=False,\n  human_input_mode=\"ALWAYS\",\n  # This agent will always require human input to make sure the code is\n  # safe to execute.\n  code_execution_config={\"use_docker\": False, \"work_dir\": temp_dir},\n)\ncode_writer_agent = ConversableAgent(\n  name=\"Code_Writer_Agent\",\n  system_message=\"You are a code writer. You write Python script in Markdown code blocks.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\npoetry_agent = ConversableAgent(\n  name=\"Poetry_Agent\",\n  system_message=\"You are an AI poet.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  human_input_mode=\"NEVER\",\n)\n\n```\n\nNow we define the nested chats using the sequential chat pattern. All the senders are always `artihmetic_agent`.\nCopy\n```\nnested_chats = [\n  {\n    \"recipient\": group_chat_manager_with_intros,\n    \"summary_method\": \"reflection_with_llm\",\n    \"summary_prompt\": \"Summarize the sequence of operations used to turn the source number into target number.\",\n  },\n  {\n    \"recipient\": code_writer_agent,\n    \"message\": \"Write a Python script to verify the arithmetic operations is correct.\",\n    \"summary_method\": \"reflection_with_llm\",\n  },\n  {\n    \"recipient\": poetry_agent,\n    \"message\": \"Write a poem about it.\",\n    \"max_turns\": 1,\n    \"summary_method\": \"last_msg\",\n  },\n]\n\n```\n\nNow we register the nested chats handler to the `arithmetic_agent` and set the conditions for triggering the nested chats.\nCopy\n```\narithmetic_agent.register_nested_chats(\n  nested_chats,\n  # The trigger function is used to determine if the agent should start the nested chat\n  # given the sender agent.\n  # In this case, the arithmetic agent will not start the nested chats if the sender is\n  # from the nested chats' recipient to avoid recursive calls.\n  trigger=lambda sender: sender not in [group_chat_manager_with_intros, code_writer_agent, poetry_agent],\n)\n\n```\n\nFinally, we call `generate_reply` to get a response from the `arithmetic_agent` – this will trigger a sequence of nested chats and return the summary of the last nested chat as the response.\nCopy\n```\n# Instead of using `initiate_chat` method to start another conversation,\n# we can use the `generate_reply` method to get single reply to a message directly.\nreply = arithmetic_agent.generate_reply(\n  messages=[{\"role\": \"user\", \"content\": \"I have a number 3 and I want to turn it into 7.\"}]\n)\n\n```\n\nCopy\n```\n\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n********************************************************************************\nStart a new chat with the following message: \nI have a number 3 and I want to turn it into 7.\nWith the following carryover: \n\n********************************************************************************\nArithmetic_Agent (to chat_manager):\nI have a number 3 and I want to turn it into 7.\n--------------------------------------------------------------------------------\nAdder_Agent (to chat_manager):\nTo give you the result, I'll add 1 to the number you gave me. So your new number is 4.\n--------------------------------------------------------------------------------\nMultiplier_Agent (to chat_manager):\n8\n--------------------------------------------------------------------------------\nSubtracter_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\nNumber_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\nNumber_Agent (to chat_manager):\n7\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nWrite a Python script to verify the arithmetic operations is correct.\nWith the following carryover: \nFirst, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.\n********************************************************************************\nArithmetic_Agent (to Code_Writer_Agent):\nWrite a Python script to verify the arithmetic operations is correct.\nContext: \nFirst, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.\n--------------------------------------------------------------------------------\nCode_Writer_Agent (to Arithmetic_Agent):\nHere is a Python script to verify the aforementioned arithmetic operations:\n```python\n# defining the initial value\ninitial_number = 3\n# Adding 1 to initial number\ninitial_number += 1\nassert initial_number == 4, \"The first operation failed!\"\n# Multiplying the result by 2\ninitial_number *= 2\nassert initial_number == 8, \"The second operation failed!\"\n# Subtracting 1 from the result\ninitial_number -= 1\nassert initial_number == 7, \"The final operation failed!\"\nprint(\"All operations were carried out successfully!\")\n```\nIn the script, the entire process is broken down into steps. The `assert` function is used to verify the result at every step. If any of the operations doesn't yield the expected result, an `AssertionError` exception will be raised. If all operations pass, the message \"All operations were carried out successfully!\" will be printed.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\nArithmetic_Agent (to Code_Writer_Agent):\nexitcode: 0 (execution succeeded)\nCode output: \nAll operations were carried out successfully!\n\n--------------------------------------------------------------------------------\nCode_Writer_Agent (to Arithmetic_Agent):\nCertainly, that means the python script was successful and every arithmetic operation performed correctly given the initial input and the steps performed.\n--------------------------------------------------------------------------------\n********************************************************************************\nStart a new chat with the following message: \nWrite a poem about it.\nWith the following carryover: \nFirst, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.\nThe Python script successfully performed and verified the arithmetic operations on the initial number provided. The steps included adding 1 to the initial number, multiplying the result by 2, and finally subtracting 1. The assert function was used to check the result at each step, and confirmed that all operations were carried out correctly.\n********************************************************************************\nArithmetic_Agent (to Poetry_Agent):\nWrite a poem about it.\nContext: \nFirst, 1 was added to the initial number 3 to make it 4. Then it was multiplied by 2 which resulted in 8. Finally, 1 was subtracted from 8 to reach the target number 7.\nThe Python script successfully performed and verified the arithmetic operations on the initial number provided. The steps included adding 1 to the initial number, multiplying the result by 2, and finally subtracting 1. The assert function was used to check the result at each step, and confirmed that all operations were carried out correctly.\n--------------------------------------------------------------------------------\nPoetry_Agent (to Arithmetic_Agent):\nFrom numbers, logic, pure mathematical creation,\nPonder this tale of numeric manipulation.\nIn the universe of Python where operations exist,\nA story of integers and functions persist.\nThree was the number from where we began,\nOblivious to the journey and its grandiosely plan.\nAdded with 1, the sum it adorned,\nA sweet quadruple in the dawn was formed.\nThe saga continued with a twist of the tale,\nThe four was multiplied, while the winds wail.\nThe duo of four unfolded its wings,\nAn octet presence in our midst it brings.\nThen enters subtraction, sly and clever,\nRemoving one to alter the endeavor.\nFrom eight, subtracted one in delight,\nTo finally bask in the glow of seven's light.\nEach operation, together they conspired,\nIn this tale of integers, creatively inspired.\nThrough life's equation, the script ran so free,\nAmidst the language of Python, a symphony, you see.\nTested with assert, cross-checked the chain,\nConfirming accuracy in program's domain.\nEach move calculated, each step so right,\nIn the maze of coding, found was the light. \nSuch is the tale, of numbers and operations, \nA dance among digits, logical iterations,\nJust another day, in this AI poet's life,\nCutting through ambiguity, like a razor-sharp knife.\n--------------------------------------------------------------------------------\n\n```\n\nA poem is returned as the response, which describes the transformation attempt from 3 to 7.\nThe implementation of the nested chats handler makes use of the `register_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>) method, which allows you to make extensive customization to `ConversableAgent`. The GroupChatManager uses the same mechanism to implement the group chat.\nNested chat is a powerful conversation pattern that allows you to package complex workflows into a single agent. You can hide [tool usages](https://docs.ag2.ai/docs/tutorial/docs/tutorial/tool-use>) within a single agent by having the tool-caller agent starts a nested chat with a tool-executor agent and then use the result of the nested chat to generate a response. See the [nested chats for tool use notebook](https://docs.ag2.ai/docs/tutorial/notebooks/agentchat_nested_chats_chess>) for an example.\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#summary>)\nSummary\nIn this chapter, we covered two-agent chat, sequential chat, group chat, and nested chat patterns. You can compose these patterns like LEGO blocks to create complex workflows. You can also use `register_reply`[](https://docs.ag2.ai/docs/tutorial/docs/reference/agentchat/conversable_agent#register-reply>) to create new patterns.\nThis is the last chapter on basic AutoGen concepts. In the next chatper, we will give you some tips on what to do next.\n[Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)[What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [An Overview](https://docs.ag2.ai/docs/tutorial/<#an-overview>)\n  * [Two-Agent Chat and Chat Result](https://docs.ag2.ai/docs/tutorial/<#two-agent-chat-and-chat-result>)\n  * [Sequential Chats](https://docs.ag2.ai/docs/tutorial/<#sequential-chats>)\n  * [Group Chat](https://docs.ag2.ai/docs/tutorial/<#group-chat>)\n  * [Send Introductions](https://docs.ag2.ai/docs/tutorial/<#send-introductions>)\n  * [Group Chat in a Sequential Chat](https://docs.ag2.ai/docs/tutorial/<#group-chat-in-a-sequential-chat>)\n  * [Constrained Speaker Selection](https://docs.ag2.ai/docs/tutorial/<#constrained-speaker-selection>)\n  * [Changing the select speaker role name](https://docs.ag2.ai/docs/tutorial/<#changing-the-select-speaker-role-name>)\n  * [Nested Chats](https://docs.ag2.ai/docs/tutorial/<#nested-chats>)\n  * [Summary](https://docs.ag2.ai/docs/tutorial/<#summary>)\n\n---\n\n# What Next?\nURL: https://docs.ag2.ai/docs/tutorial/what-next\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/tutorial/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nTutorials\nWhat Next?\n[Documentation](https://docs.ag2.ai/docs/tutorial/</docs/Home>)[Examples](https://docs.ag2.ai/docs/tutorial/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/tutorial/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/tutorial/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/tutorial/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/tutorial/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/tutorial/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/tutorial/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/tutorial/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/tutorial/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/tutorial/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/tutorial/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/tutorial/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/tutorial/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/tutorial/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/tutorial/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/tutorial/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/tutorial/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/tutorial/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/tutorial/</docs/Migration-Guide>)\n\n\nTutorials\n# What Next?\nNow that you have learned the basics of AutoGen, you can start to build your own agents. Here are some ideas to get you started without going to the advanced topics:\n  1. **Chat with LLMs** : In [Human in the Loop](https://docs.ag2.ai/docs/tutorial/<./human-in-the-loop>) we covered the basic human-in-the-loop usage. You can try to hook up different LLMs using local model servers like [Ollama](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ollama/ollama>) and [LM Studio](https://docs.ag2.ai/docs/tutorial/<https:/lmstudio.ai/>), and chat with them using the human-in-the-loop component of your human proxy agent.\n  2. **Prompt Engineering** : In [Code Executors](https://docs.ag2.ai/docs/tutorial/<./code-executors>) we covered the simple two agent scenario using GPT-4 and Python code executor. To make this scenario work for different LLMs and programming languages, you probably need to tune the system message of the code writer agent. Same with other scenarios that we have covered in this tutorial, you can also try to tune system messages for different LLMs.\n  3. **Complex Tasks** : In [ConversationPatterns](https://docs.ag2.ai/docs/tutorial/<./conversation-patterns>) we covered the basic conversation patterns. You can try to find other tasks that can be decomposed into these patterns, and leverage the code executors and tools to make the agents more powerful.\n\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#dig-deeper>)\nDig Deeper\n  * Read the [user guide](https://docs.ag2.ai/docs/tutorial/</docs/topics>) to learn more\n  * Read the examples and guides in the [notebooks section](https://docs.ag2.ai/docs/tutorial/</notebooks>)\n  * Check [research](https://docs.ag2.ai/docs/tutorial/</docs/Research>) and [blog](https://docs.ag2.ai/docs/tutorial/</blog>)\n\n\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#get-help>)\nGet Help\nIf you have any questions, you can ask in our [Discord Server](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>).\n[![](https://img.shields.io/discord/1153072414184452236?logo=discord&style=flat.png)](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)\n## \n[​](https://docs.ag2.ai/docs/tutorial/<#get-involved>)\nGet Involved\n  * Check out [Roadmap Issues](https://docs.ag2.ai/docs/tutorial/<https:/ag2ai.com/roadmap>) to see what we are working on.\n  * Contribute your work to our [gallery](https://docs.ag2.ai/docs/tutorial/</docs/Gallery>)\n  * Follow our [contribution guide](https://docs.ag2.ai/docs/tutorial/</docs/contributor-guide/contributing>) to make a pull request to AutoGen\n  * You can also share your work with the community on the Discord server.\n\n\n[Conversation Patterns](https://docs.ag2.ai/docs/tutorial/</docs/tutorial/conversation-patterns>)[Multi-agent Conversation Framework](https://docs.ag2.ai/docs/tutorial/</docs/Use-Cases/agent_chat>)\n[x](https://docs.ag2.ai/docs/tutorial/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/tutorial/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/tutorial/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/tutorial/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/tutorial/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/tutorial/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Dig Deeper](https://docs.ag2.ai/docs/tutorial/<#dig-deeper>)\n  * [Get Help](https://docs.ag2.ai/docs/tutorial/<#get-help>)\n  * [Get Involved](https://docs.ag2.ai/docs/tutorial/<#get-involved>)\n\n---\n\n# Multi-agent Conversation Framework\nURL: https://docs.ag2.ai/docs/Use-Cases/agent_chat\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUse Cases\nMulti-agent Conversation Framework\n[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)\n\n\nUse Cases\n# Multi-agent Conversation Framework\nAutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLMs, tools, and humans via automated agent chat. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.\nThis framework simplifies the orchestration, automation and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#agents>)\nAgents\nAutoGen abstracts and implements conversable agents designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following notable features:\n  * Conversable: Agents in AutoGen are conversable, which means that any agent can send and receive messages from other agents to initiate or continue a conversation\n  * Customizable: Agents in AutoGen can be customized to integrate LLMs, humans, tools, or a combination of them.\n\n\nThe figure below shows the built-in agents in AutoGen. ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/autogen_agents.png)\nWe have designed a generic `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) class for Agents that are capable of conversing with each other through the exchange of messages to jointly finish a task. An agent can communicate with other agents and perform actions. Different agents can differ in what actions they perform after receiving messages. Two representative subclasses are `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) and `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>)\n  * The `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) is designed to act as an AI assistant, using LLMs by default but not requiring human input or code execution. It could write Python code (in a Python coding block) for a user to execute when a message (typically a description of a task that needs to be solved) is received. Under the hood, the Python code is written by LLM (e.g., GPT-4). It can also receive the execution results and suggest corrections or bug fixes. Its behavior can be altered by passing a new system message. The LLM [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration can be configured via [`llm_config`].\n  * The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) is conceptually a proxy agent for humans, soliciting human input as the agent’s reply at each interaction turn by default and also having the capability to execute code and call functions or tools. The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) triggers code execution automatically when it detects an executable code block in the received message and no human user input is provided. Code execution can be disabled by setting the `code_execution_config` parameter to False. LLM-based response is disabled by default. It can be enabled by setting `llm_config` to a dict corresponding to the [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration. When `llm_config` is set as a dictionary, `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) can generate replies using an LLM when code execution is not performed.\n\n\nThe auto-reply capability of `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) allows for more autonomous multi-agent communication while retaining the possibility of human intervention. One can also easily extend it by registering reply functions with the `register_reply()`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#register-reply>) method.\nIn the following code, we create an `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) named “assistant” to serve as the assistant and a `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) named “user_proxy” to serve as a proxy for the human user. We will later employ these two agents to solve a task.\nCopy\n```\nimport os\nfrom autogen import AssistantAgent, UserProxyAgent\nfrom autogen.coding import DockerCommandLineCodeExecutor\nconfig_list = [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]\n# create an AssistantAgent instance named \"assistant\" with the LLM configuration.\nassistant = AssistantAgent(name=\"assistant\", llm_config={\"config_list\": config_list})\n# create a UserProxyAgent instance named \"user_proxy\" with code execution on docker.\ncode_executor = DockerCommandLineCodeExecutor()\nuser_proxy = UserProxyAgent(name=\"user_proxy\", code_execution_config={\"executor\": code_executor})\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)\nMulti-agent Conversations\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)\nA Basic Two-Agent Conversation Example\nOnce the participating agents are constructed properly, one can start a multi-agent conversation session by an initialization step as shown in the following code:\nCopy\n```\n# the assistant receives a message from the user, which contains the task description\nuser_proxy.initiate_chat(\n  assistant,\n  message=\"\"\"What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\"\"\",\n)\n\n```\n\nAfter the initialization step, the conversation could proceed automatically. Find a visual illustration of how the user_proxy and assistant collaboratively solve the above task autonomously below: ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/agent_example.png)\n  1. The assistant receives a message from the user_proxy, which contains the task description.\n  2. The assistant then tries to write Python code to solve the task and sends the response to the user_proxy.\n  3. Once the user_proxy receives a response from the assistant, it tries to reply by either soliciting human input or preparing an automatically generated reply. If no human input is provided, the user_proxy executes the code and uses the result as the auto-reply.\n  4. The assistant then generates a further response for the user_proxy. The user_proxy can then decide whether to terminate the conversation. If not, steps 3 and 4 are repeated.\n\n\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)\nSupporting Diverse Conversation Patterns\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)\nConversations with different levels of autonomy, and human-involvement patterns\nOn the one hand, one can achieve fully autonomous conversations after an initialization step. On the other hand, AutoGen can be used to implement human-in-the-loop problem-solving by configuring human involvement levels and patterns (e.g., setting the `human_input_mode` to `ALWAYS`), as human involvement is expected and/or desired in many applications.\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)\nStatic and dynamic conversations\nAutoGen, by integrating conversation-driven control utilizing both programming and natural language, inherently supports dynamic conversations. This dynamic nature allows the agent topology to adapt based on the actual conversation flow under varying input problem scenarios. Conversely, static conversations adhere to a predefined topology. Dynamic conversations are particularly beneficial in complex settings where interaction patterns cannot be predetermined.\n  1. Registered auto-reply\n\n\nWith the pluggable auto-reply function, one can choose to invoke conversations with other agents depending on the content of the current message and context. For example:\n  * Hierarchical chat like in [OptiGuide](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nestedchat_optiguide.ipynb>).\n  * [Dynamic Group Chat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat.ipynb>) which is a special form of hierarchical chat. In the system, we register a reply function in the group chat manager, which broadcasts messages and decides who the next speaker will be in a group chat setting.\n  * [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/Use-Cases/<https:/docs.ag2.ai/notebooks/agentchat_groupchat_finite_state_machine>) which is a special form of dynamic group chat. In this approach, a directed transition matrix is fed into group chat. Users can specify legal transitions or specify disallowed transitions.\n  * Nested chat like in [conversational chess](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nested_chats_chess.ipynb>).\n\n\n  1. LLM-Based Function Call\n\n\nAnother approach involves LLM-based function calls, where LLM decides if a specific function should be invoked based on the conversation’s status during each inference. This approach enables dynamic multi-agent conversations, as seen in scenarios like [multi-user math problem solving scenario](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_two_users.ipynb>), where a student assistant automatically seeks expertise via function calls.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)\nDiverse Applications Implemented with AutoGen\nThe figure below shows six examples of applications built using AutoGen. ![Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/app.png)\nFind a list of examples in this page: [Automated Agent Chat Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#automated-multi-agent-chat>)\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)\nFor Further Reading\n_Interested in the research that leads to this package? Please check the following papers._\n  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.\n  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n\n\n[What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)[Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)\n[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Agents](https://docs.ag2.ai/docs/Use-Cases/<#agents>)\n  * [Multi-agent Conversations](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)\n  * [A Basic Two-Agent Conversation Example](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)\n  * [Supporting Diverse Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)\n  * [Conversations with different levels of autonomy, and human-involvement patterns](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)\n  * [Static and dynamic conversations](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)\n  * [Diverse Applications Implemented with AutoGen](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)\n  * [For Further Reading](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)\n\n---\n\n# Enhanced Inference\nURL: https://docs.ag2.ai/docs/Use-Cases/enhanced_inference\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUse Cases\nEnhanced Inference\n[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)\n\n\nUse Cases\n# Enhanced Inference\n`autogen.OpenAIWrapper` provides enhanced LLM inference for `openai>=1`. `autogen.Completion` is a drop-in replacement of `openai.Completion` and `openai.ChatCompletion` for enhanced LLM inference using `openai<1`. There are a number of benefits of using `autogen` to perform inference: performance tuning, API unification, caching, error handling, multi-config inference, result filtering, templating and so on.\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#tune-inference-parameters-for-openai1>)\nTune Inference Parameters (for openai<1)\nFind a list of examples in this page: [Tune Inference Parameters Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#inference-hyperparameters-tuning>)\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#choices-to-optimize>)\nChoices to optimize\nThe cost of using foundation models for text generation is typically measured in terms of the number of tokens in the input and output combined. From the perspective of an application builder using foundation models, the use case is to maximize the utility of the generated text under an inference budget constraint (e.g., measured by the average dollar cost needed to solve a coding problem). This can be achieved by optimizing the hyperparameters of the inference, which can significantly affect both the utility and the cost of the generated text.\nThe tunable hyperparameters include:\n  1. model - this is a required input, specifying the model ID to use.\n  2. prompt/messages - the input prompt/messages to the model, which provides the context for the text generation task.\n  3. max_tokens - the maximum number of tokens (words or word pieces) to generate in the output.\n  4. temperature - a value between 0 and 1 that controls the randomness of the generated text. A higher temperature will result in more random and diverse text, while a lower temperature will result in more predictable text.\n  5. top_p - a value between 0 and 1 that controls the sampling probability mass for each token generation. A lower top_p value will make it more likely to generate text based on the most likely tokens, while a higher value will allow the model to explore a wider range of possible tokens.\n  6. n - the number of responses to generate for a given prompt. Generating multiple responses can provide more diverse and potentially more useful output, but it also increases the cost of the request.\n  7. stop - a list of strings that, when encountered in the generated text, will cause the generation to stop. This can be used to control the length or the validity of the output.\n  8. presence_penalty, frequency_penalty - values that control the relative importance of the presence and frequency of certain words or phrases in the generated text.\n  9. best_of - the number of responses to generate server-side when selecting the “best” (the one with the highest log probability per token) response for a given prompt.\n\n\nThe cost and utility of text generation are intertwined with the joint effect of these hyperparameters. There are also complex interactions among subsets of the hyperparameters. For example, the temperature and top_p are not recommended to be altered from their default values together because they both control the randomness of the generated text, and changing both at the same time can result in conflicting effects; n and best_of are rarely tuned together because if the application can process multiple outputs, filtering on the server side causes unnecessary information loss; both n and max_tokens will affect the total number of tokens generated, which in turn will affect the cost of the request. These interactions and trade-offs make it difficult to manually determine the optimal hyperparameter settings for a given text generation task.\n_Do the choices matter? Check this[blogpost](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-04-21-LLM-tuning-math>) to find example tuning results about gpt-3.5-turbo and gpt-4._\nWith AutoGen, the tuning can be performed with the following information:\n  1. Validation data.\n  2. Evaluation function.\n  3. Metric to optimize.\n  4. Search space.\n  5. Budgets: inference and optimization respectively.\n\n\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#validation-data>)\nValidation data\nCollect a diverse set of instances. They can be stored in an iterable of dicts. For example, each instance dict can contain “problem” as a key and the description str of a math problem as the value; and “solution” as a key and the solution str as the value.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#evaluation-function>)\nEvaluation function\nThe evaluation function should take a list of responses, and other keyword arguments corresponding to the keys in each validation data instance as input, and output a dict of metrics. For example,\nCopy\n```\ndef eval_math_responses(responses: List[str], solution: str, **args) -> Dict:\n  # select a response from the list of responses\n  answer = voted_answer(responses)\n  # check whether the answer is correct\n  return {\"success\": is_equivalent(answer, solution)}\n\n```\n\n`autogen.code_utils` and `autogen.math_utils` offer some example evaluation functions for code generation and math problem solving.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#metric-to-optimize>)\nMetric to optimize\nThe metric to optimize is usually an aggregated metric over all the tuning data instances. For example, users can specify “success” as the metric and “max” as the optimization mode. By default, the aggregation function is taking the average. Users can provide a customized aggregation function if needed.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#search-space>)\nSearch space\nUsers can specify the (optional) search range for each hyperparameter.\n  1. model. Either a constant str, or multiple choices specified by `flaml.tune.choice`.\n  2. prompt/messages. Prompt is either a str or a list of strs, of the prompt templates. messages is a list of dicts or a list of lists, of the message templates. Each prompt/message template will be formatted with each data instance. For example, the prompt template can be: “{problem} Solve the problem carefully. Simplify your answer as much as possible. Put the final answer in \\boxed{{}}.” And `{problem}` will be replaced by the “problem” field of each data instance.\n  3. max_tokens, n, best_of. They can be constants, or specified by `flaml.tune.randint`, `flaml.tune.qrandint`, `flaml.tune.lograndint` or `flaml.qlograndint`. By default, max_tokens is searched in [50, 1000); n is searched in [1, 100); and best_of is fixed to 1.\n  4. stop. It can be a str or a list of strs, or a list of lists of strs or None. Default is None.\n  5. temperature or top_p. One of them can be specified as a constant or by `flaml.tune.uniform` or `flaml.tune.loguniform` etc. Please don’t provide both. By default, each configuration will choose either a temperature or a top_p in [0, 1] uniformly.\n  6. presence_penalty, frequency_penalty. They can be constants or specified by `flaml.tune.uniform` etc. Not tuned by default.\n\n\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#budgets>)\nBudgets\nOne can specify an inference budget and an optimization budget. The inference budget refers to the average inference cost per data instance. The optimization budget refers to the total budget allowed in the tuning process. Both are measured by dollars and follow the price per 1000 tokens.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#perform-tuning>)\nPerform tuning\nNow, you can use `autogen.Completion.tune` for tuning. For example,\nCopy\n```\nimport autogen\nconfig, analysis = autogen.Completion.tune(\n  data=tune_data,\n  metric=\"success\",\n  mode=\"max\",\n  eval_func=eval_func,\n  inference_budget=0.05,\n  optimization_budget=3,\n  num_samples=-1,\n)\n\n```\n\n`num_samples` is the number of configurations to sample. -1 means unlimited (until optimization budget is exhausted). The returned `config` contains the optimized configuration and `analysis` contains an ExperimentAnalysis object for all the tried configurations and results.\nThe tuned config can be used to perform inference.\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#api-unification>)\nAPI unification\n`autogen.OpenAIWrapper.create()` can be used to create completions for both chat and non-chat models, and both OpenAI API and Azure OpenAI API.\nCopy\n```\nfrom autogen import OpenAIWrapper\n# OpenAI endpoint\nclient = OpenAIWrapper()\n# ChatCompletion\nresponse = client.create(messages=[{\"role\": \"user\", \"content\": \"2+2=\"}], model=\"gpt-3.5-turbo\")\n# extract the response text\nprint(client.extract_text_or_completion_object(response))\n# get cost of this completion\nprint(response.cost)\n# Azure OpenAI endpoint\nclient = OpenAIWrapper(api_key=..., base_url=..., api_version=..., api_type=\"azure\")\n# Completion\nresponse = client.create(prompt=\"2+2=\", model=\"gpt-3.5-turbo-instruct\")\n# extract the response text\nprint(client.extract_text_or_completion_object(response))\n\n```\n\nFor local LLMs, one can spin up an endpoint using a package like [FastChat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/lm-sys/FastChat>), and then use the same API to send a request. See [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-07-14-Local-LLMs>) for examples on how to make inference with local LLMs.\nFor custom model clients, one can register the client with `autogen.OpenAIWrapper.register_model_client` and then use the same API to send a request. See [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2024-01-26-Custom-Models>) for examples on how to make inference with custom model clients.\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#usage-summary>)\nUsage Summary\nThe `OpenAIWrapper` from `autogen` tracks token counts and costs of your API calls. Use the `create()` method to initiate requests and `print_usage_summary()` to retrieve a detailed usage report, including total cost and token usage for both cached and actual requests.\n  * `mode=[\"actual\", \"total\"]` (default): print usage summary for all completions and non-caching completions.\n  * `mode='actual'`: only print non-cached usage.\n  * `mode='total'`: only print all usage (including cache).\n\n\nReset your session’s usage data with `clear_usage_summary()` when needed. [View Notebook](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_cost_token_tracking.ipynb>)\nExample usage:\nCopy\n```\nfrom autogen import OpenAIWrapper\nclient = OpenAIWrapper()\nclient.create(messages=[{\"role\": \"user\", \"content\": \"Python learning tips.\"}], model=\"gpt-3.5-turbo\")\nclient.print_usage_summary() # Display usage\nclient.clear_usage_summary() # Reset usage data\n\n```\n\nSample output:\nCopy\n```\nUsage summary excluding cached usage:\nTotal cost: 0.00015\n* Model 'gpt-3.5-turbo': cost: 0.00015, prompt_tokens: 25, completion_tokens: 58, total_tokens: 83\nUsage summary including cached usage:\nTotal cost: 0.00027\n* Model 'gpt-3.5-turbo': cost: 0.00027, prompt_tokens: 50, completion_tokens: 100, total_tokens: 150\n\n```\n\nNote: if using a custom model client (see [here](https://docs.ag2.ai/docs/Use-Cases/</blog/2024-01-26-Custom-Models>) for details) and if usage summary is not implemented, then the usage summary will not be available.\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#caching>)\nCaching\nMoved to [here](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>).\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#error-handling>)\nError handling\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#runtime-error>)\nRuntime error\nOne can pass a list of configurations of different models/endpoints to mitigate the rate limits and other runtime error. For example,\nCopy\n```\nclient = OpenAIWrapper(\n  config_list=[\n    {\n      \"model\": \"gpt-4\",\n      \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n      \"api_type\": \"azure\",\n      \"base_url\": os.environ.get(\"AZURE_OPENAI_API_BASE\"),\n      \"api_version\": \"2024-02-01\",\n    },\n    {\n      \"model\": \"gpt-3.5-turbo\",\n      \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n      \"base_url\": \"https://api.openai.com/v1\",\n    },\n    {\n      \"model\": \"llama2-chat-7B\",\n      \"base_url\": \"http://127.0.0.1:8080\",\n    },\n    {\n      \"model\": \"microsoft/phi-2\",\n      \"model_client_cls\": \"CustomModelClient\"\n    }\n  ],\n)\n\n```\n\n`client.create()` will try querying Azure OpenAI gpt-4, OpenAI gpt-3.5-turbo, a locally hosted llama2-chat-7B, and phi-2 using a custom model client class named `CustomModelClient`, one by one, until a valid result is returned. This can speed up the development process where the rate limit is a bottleneck. An error will be raised if the last choice fails. So make sure the last choice in the list has the best availability.\nFor convenience, we provide a number of utility functions to load config lists.\n  * `get_config_list`: Generates configurations for API calls, primarily from provided API keys.\n  * `config_list_openai_aoai`: Constructs a list of configurations using both Azure OpenAI and OpenAI endpoints, sourcing API keys from environment variables or local files.\n  * `config_list_from_json`: Loads configurations from a JSON structure, either from an environment variable or a local JSON file, with the flexibility of filtering configurations based on given criteria.\n  * `config_list_from_models`: Creates configurations based on a provided list of models, useful when targeting specific models without manually specifying each configuration.\n  * `config_list_from_dotenv`: Constructs a configuration list from a `.env` file, offering a consolidated way to manage multiple API configurations and keys from a single file.\n\n\nWe suggest that you take a look at this [notebook](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>) for full code examples of the different methods to configure your model endpoints.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#logic-error>)\nLogic error\nAnother type of error is that the returned response does not satisfy a requirement. For example, if the response is required to be a valid json string, one would like to filter the responses that are not. This can be achieved by providing a list of configurations and a filter function. For example,\nCopy\n```\ndef valid_json_filter(response, **_):\n  for text in OpenAIWrapper.extract_text_or_completion_object(response):\n    try:\n      json.loads(text)\n      return True\n    except ValueError:\n      pass\n  return False\nclient = OpenAIWrapper(\n  config_list=[{\"model\": \"text-ada-001\"}, {\"model\": \"gpt-3.5-turbo-instruct\"}, {\"model\": \"text-davinci-003\"}],\n)\nresponse = client.create(\n  prompt=\"How to construct a json request to Bing API to search for 'latest AI news'? Return the JSON request.\",\n  filter_func=valid_json_filter,\n)\n\n```\n\nThe example above will try to use text-ada-001, gpt-3.5-turbo-instruct, and text-davinci-003 iteratively, until a valid json string is returned or the last config is used. One can also repeat the same model in the list for multiple times (with different seeds) to try one model multiple times for increasing the robustness of the final response.\n_Advanced use case: Check this[blogpost](https://docs.ag2.ai/docs/Use-Cases/</blog/2023-05-18-GPT-adaptive-humaneval/index>) to find how to improve GPT-4’s coding performance from 68% to 90% while reducing the inference cost._\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#templating>)\nTemplating\nIf the provided prompt or message is a template, it will be automatically materialized with a given context. For example,\nCopy\n```\nresponse = client.create(\n  context={\"problem\": \"How many positive integers, not exceeding 100, are multiples of 2 or 3 but not 4?\"},\n  prompt=\"{problem} Solve the problem carefully.\",\n  allow_format_str_template=True,\n  **config\n)\n\n```\n\nA template is either a format str, like the example above, or a function which produces a str from several input fields, like the example below.\nCopy\n```\ndef content(turn, context):\n  return \"\\n\".join(\n    [\n      context[f\"user_message_{turn}\"],\n      context[f\"external_info_{turn}\"]\n    ]\n  )\nmessages = [\n  {\n    \"role\": \"system\",\n    \"content\": \"You are a teaching assistant of math.\",\n  },\n  {\n    \"role\": \"user\",\n    \"content\": partial(content, turn=0),\n  },\n]\ncontext = {\n  \"user_message_0\": \"Could you explain the solution to Problem 1?\",\n  \"external_info_0\": \"Problem 1: ...\",\n}\nresponse = client.create(context=context, messages=messages, **config)\nmessages.append(\n  {\n    \"role\": \"assistant\",\n    \"content\": client.extract_text(response)[0]\n  }\n)\nmessages.append(\n  {\n    \"role\": \"user\",\n    \"content\": partial(content, turn=1),\n  },\n)\ncontext.append(\n  {\n    \"user_message_1\": \"Why can't we apply Theorem 1 to Equation (2)?\",\n    \"external_info_1\": \"Theorem 1: ...\",\n  }\n)\nresponse = client.create(context=context, messages=messages, **config)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#logging>)\nLogging\nWhen debugging or diagnosing an LLM-based system, it is often convenient to log the API calls and analyze them.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1>)\nFor openai >= 1\nLogging example: [View Notebook](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_logging.ipynb>)\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#start-logging>)\nStart logging:\nCopy\n```\nimport autogen.runtime_logging\nautogen.runtime_logging.start(logger_type=\"sqlite\", config={\"dbname\": \"YOUR_DB_NAME\"})\n\n```\n\n`logger_type` and `config` are both optional. Default logger type is SQLite logger, that’s the only one available in autogen at the moment. If you want to customize the database name, you can pass in through config, default is `logs.db`.\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#stop-logging>)\nStop logging:\nCopy\n```\nautogen.runtime_logging.stop()\n\n```\n\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#llm-runs>)\nLLM Runs\nAutoGen logging supports OpenAI’s llm message schema. Each LLM run is saved in `chat_completions` table includes:\n  * session_id: an unique identifier for the logging session\n  * invocation_id: an unique identifier for the logging record\n  * client_id: an unique identifier for the Azure OpenAI/OpenAI client\n  * request: detailed llm request, see below for an example\n  * response: detailed llm response, see below for an example\n  * cost: total cost for the request and response\n  * start_time\n  * end_time\n\n\n##### Sample Request\nCopy\n```\n{\n \"messages\":[\n  {\n   \"content\":\"system_message_1\",\n   \"role\":\"system\"\n  },\n  {\n   \"content\":\"user_message_1\",\n   \"role\":\"user\"\n  }\n ],\n \"model\":\"gpt-4\",\n \"temperature\": 0.9\n}\n\n```\n\n##### Sample Response\nCopy\n```\n{\n \"id\": \"id_1\",\n \"choices\": [\n  {\n   \"finish_reason\": \"stop\",\n   \"index\": 0,\n   \"logprobs\": null,\n   \"message\": {\n    \"content\": \"assistant_message_1\",\n    \"role\": \"assistant\",\n    \"function_call\": null,\n    \"tool_calls\": null\n   }\n  }\n ],\n \"created\": \"<timestamp>\",\n \"model\": \"gpt-4\",\n \"object\": \"chat.completion\",\n \"system_fingerprint\": null,\n \"usage\": {\n  \"completion_tokens\": 155,\n  \"prompt_tokens\": 53,\n  \"total_tokens\": 208\n }\n}\n\n```\n\nLearn more about [request and response format](https://docs.ag2.ai/docs/Use-Cases/<https:/platform.openai.com/docs/api-reference/introduction/chat/create>)\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1-2>)\nFor openai < 1\n`autogen.Completion` and `autogen.ChatCompletion` offer an easy way to collect the API call histories. For example, to log the chat histories, simply run:\nCopy\n```\nautogen.ChatCompletion.start_logging()\n\n```\n\nThe API calls made after this will be automatically logged. They can be retrieved at any time by:\nCopy\n```\nautogen.ChatCompletion.logged_history\n\n```\n\nThere is a function that can be used to print usage summary (total cost, and token count usage from each model):\nCopy\n```\nautogen.ChatCompletion.print_usage_summary()\n\n```\n\nTo stop logging, use\nCopy\n```\nautogen.ChatCompletion.stop_logging()\n\n```\n\nIf one would like to append the history to an existing dict, pass the dict like:\nCopy\n```\nautogen.ChatCompletion.start_logging(history_dict=existing_history_dict)\n\n```\n\nBy default, the counter of API calls will be reset at `start_logging()`. If no reset is desired, set `reset_counter=False`.\nThere are two types of logging formats: compact logging and individual API call logging. The default format is compact. Set `compact=False` in `start_logging()` to switch.\n  * Example of a history dict with compact logging.\n\n\nCopy\n```\n{\n  \"\"\"\n  [\n    {\n      'role': 'system',\n      'content': system_message,\n    },\n    {\n      'role': 'user',\n      'content': user_message_1,\n    },\n    {\n      'role': 'assistant',\n      'content': assistant_message_1,\n    },\n    {\n      'role': 'user',\n      'content': user_message_2,\n    },\n    {\n      'role': 'assistant',\n      'content': assistant_message_2,\n    },\n  ]\"\"\": {\n    \"created_at\": [0, 1],\n    \"cost\": [0.1, 0.2],\n  }\n}\n\n```\n\n  * Example of a history dict with individual API call logging.\n\n\nCopy\n```\n{\n  0: {\n    \"request\": {\n      \"messages\": [\n        {\n          \"role\": \"system\",\n          \"content\": system_message,\n        },\n        {\n          \"role\": \"user\",\n          \"content\": user_message_1,\n        }\n      ],\n      ... # other parameters in the request\n    },\n    \"response\": {\n      \"choices\": [\n        \"messages\": {\n          \"role\": \"assistant\",\n          \"content\": assistant_message_1,\n        },\n      ],\n      ... # other fields in the response\n    }\n  },\n  1: {\n    \"request\": {\n      \"messages\": [\n        {\n          \"role\": \"system\",\n          \"content\": system_message,\n        },\n        {\n          \"role\": \"user\",\n          \"content\": user_message_1,\n        },\n        {\n          \"role\": \"assistant\",\n          \"content\": assistant_message_1,\n        },\n        {\n          \"role\": \"user\",\n          \"content\": user_message_2,\n        },\n      ],\n      ... # other parameters in the request\n    },\n    \"response\": {\n      \"choices\": [\n        \"messages\": {\n          \"role\": \"assistant\",\n          \"content\": assistant_message_2,\n        },\n      ],\n      ... # other fields in the response\n    }\n  },\n}\n\n```\n\n  * Example of printing for usage summary\n\n\nCopy\n```\nTotal cost: <cost>\nToken count summary for model <model>: prompt_tokens: <count 1>, completion_tokens: <count 2>, total_tokens: <count 3>\n\n```\n\nIt can be seen that the individual API call history contains redundant information of the conversation. For a long conversation the degree of redundancy is high. The compact history is more efficient and the individual API call history contains more details.\n[Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)[Command Line Code Executor](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/code-execution/cli-code-executor>)\n[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Tune Inference Parameters (for openai1)](https://docs.ag2.ai/docs/Use-Cases/<#tune-inference-parameters-for-openai1>)\n  * [Choices to optimize](https://docs.ag2.ai/docs/Use-Cases/<#choices-to-optimize>)\n  * [Validation data](https://docs.ag2.ai/docs/Use-Cases/<#validation-data>)\n  * [Evaluation function](https://docs.ag2.ai/docs/Use-Cases/<#evaluation-function>)\n  * [Metric to optimize](https://docs.ag2.ai/docs/Use-Cases/<#metric-to-optimize>)\n  * [Search space](https://docs.ag2.ai/docs/Use-Cases/<#search-space>)\n  * [Budgets](https://docs.ag2.ai/docs/Use-Cases/<#budgets>)\n  * [Perform tuning](https://docs.ag2.ai/docs/Use-Cases/<#perform-tuning>)\n  * [API unification](https://docs.ag2.ai/docs/Use-Cases/<#api-unification>)\n  * [Usage Summary](https://docs.ag2.ai/docs/Use-Cases/<#usage-summary>)\n  * [Caching](https://docs.ag2.ai/docs/Use-Cases/<#caching>)\n  * [Error handling](https://docs.ag2.ai/docs/Use-Cases/<#error-handling>)\n  * [Runtime error](https://docs.ag2.ai/docs/Use-Cases/<#runtime-error>)\n  * [Logic error](https://docs.ag2.ai/docs/Use-Cases/<#logic-error>)\n  * [Templating](https://docs.ag2.ai/docs/Use-Cases/<#templating>)\n  * [Logging](https://docs.ag2.ai/docs/Use-Cases/<#logging>)\n  * [For openai >= 1](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1>)\n  * [Start logging:](https://docs.ag2.ai/docs/Use-Cases/<#start-logging>)\n  * [Stop logging:](https://docs.ag2.ai/docs/Use-Cases/<#stop-logging>)\n  * [LLM Runs](https://docs.ag2.ai/docs/Use-Cases/<#llm-runs>)\n  * [For openai < 1](https://docs.ag2.ai/docs/Use-Cases/<#for-openai-1-2>)\n\n---\n\n# LLM Caching\nURL: https://docs.ag2.ai/docs/topics/llm-caching\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nLLM Caching\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# LLM Caching\nAutoGen supports caching API requests so that they can be reused when the same request is issued. This is useful when repeating or continuing experiments for reproducibility and cost saving.\nSince version `0.2.8`, a configurable context manager allows you to easily configure LLM cache, using either `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>), `RedisCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/redis_cache#rediscache>), or Cosmos DB Cache. All agents inside the context manager will use the same cache.\nCopy\n```\nfrom autogen import Cache\n# Use Redis as cache\nwith Cache.redis(redis_url=\"redis://localhost:6379/0\") as cache:\n  user.initiate_chat(assistant, message=coding_task, cache=cache)\n# Use DiskCache as cache\nwith Cache.disk() as cache:\n  user.initiate_chat(assistant, message=coding_task, cache=cache)\n# Use Azure Cosmos DB as cache\nwith Cache.cosmos_db(connection_string=\"your_connection_string\", database_id=\"your_database_id\", container_id=\"your_container_id\") as cache:\n  user.initiate_chat(assistant, message=coding_task, cache=cache)\n\n```\n\nThe cache can also be passed directly to the model client’s create call.\nCopy\n```\nclient = OpenAIWrapper(...)\nwith Cache.disk() as cache:\n  client.create(..., cache=cache)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#controlling-the-seed>)\nControlling the seed\nYou can vary the `cache_seed` parameter to get different LLM output while still using cache.\nCopy\n```\n# Setting the cache_seed to 1 will use a different cache from the default one\n# and you will see different output.\nwith Cache.disk(cache_seed=1) as cache:\n  user.initiate_chat(assistant, message=coding_task, cache=cache)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#cache-path>)\nCache path\nBy default `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>) uses `.cache` for storage. To change the cache directory, set `cache_path_root`:\nCopy\n```\nwith Cache.disk(cache_path_root=\"/tmp/autogen_cache\") as cache:\n  user.initiate_chat(assistant, message=coding_task, cache=cache)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#disabling-cache>)\nDisabling cache\nFor backward compatibility, `DiskCache`[](https://docs.ag2.ai/docs/topics/</docs/reference/cache/disk_cache#diskcache>) is on by default with `cache_seed` set to 41. To disable caching completely, set `cache_seed` to `None` in the `llm_config` of the agent.\nCopy\n```\nassistant = AssistantAgent(\n  \"coding_agent\",\n  llm_config={\n    \"cache_seed\": None,\n    \"config_list\": OAI_CONFIG_LIST,\n    \"max_tokens\": 1024,\n  },\n)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#difference-between-cache-seed-and-openais-seed-parameter>)\nDifference between `cache_seed` and OpenAI’s `seed` parameter\nOpenAI v1.1 introduced a new parameter `seed`. The difference between AutoGen’s `cache_seed` and OpenAI’s `seed` is AutoGen uses an explicit request cache to guarantee the exactly same output is produced for the same input and when cache is hit, no OpenAI API call will be made. OpenAI’s `seed` is a best-effort deterministic sampling with no guarantee of determinism. When using OpenAI’s `seed` with `cache_seed` set to `None`, even for the same input, an OpenAI API call will be made and there is no guarantee for getting exactly the same output.\n[Introduction to Transform Messages](https://docs.ag2.ai/docs/topics/</docs/topics/handling_long_contexts/intro_to_transform_messages>)[Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Controlling the seed](https://docs.ag2.ai/docs/topics/<#controlling-the-seed>)\n  * [Cache path](https://docs.ag2.ai/docs/topics/<#cache-path>)\n  * [Disabling cache](https://docs.ag2.ai/docs/topics/<#disabling-cache>)\n  * [Difference between cache_seed and OpenAI’s seed parameter](https://docs.ag2.ai/docs/topics/<#difference-between-cache-seed-and-openais-seed-parameter>)\n\n---\n\n# Agent Observability\nURL: https://docs.ag2.ai/docs/topics/llm-observability\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nAgent Observability\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# Agent Observability\nAutoGen supports advanced LLM agent observability and monitoring through built-in logging and partner providers.\n## \n[​](https://docs.ag2.ai/docs/topics/<#autogen-observability-integrations>)\nAutoGen Observability Integrations\n### \n[​](https://docs.ag2.ai/docs/topics/<#built-in-logging>)\nBuilt-In Logging\nAutoGen’s SQLite and File Logger - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_logging>)\n### \n[​](https://docs.ag2.ai/docs/topics/<#full-service-partner-integrations>)\nFull-Service Partner Integrations\n  * AutoGen partners with [AgentOps](https://docs.ag2.ai/docs/topics/<https:/agentops.ai>) to provide multi-agent tracking, metrics, and monitoring - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_agentops>)\n  * AutoGen partners with [OpenLIT](https://docs.ag2.ai/docs/topics/<https:/github.com/openlit/openlit>) to provide OpenTelemetry-native agent observability, which includes full execution traces and metrics - [Tutorial Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_openlit.ipynb>)\n\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#what-is-observability>)\nWhat is Observability?\nObservability provides developers with the necessary insights to understand and improve the internal workings of their agents. Observability is necessary for maintaining reliability, tracking costs, and ensuring AI safety.\n**Without observability tools, developers face significant hurdles:**\n  * Tracking agent activities across sessions becomes a complex, error-prone task.\n  * Manually sifting through verbose terminal outputs to understand LLM interactions is inefficient.\n  * Pinpointing the exact moments of tool invocations is often like finding a needle in a haystack.\n\n\n**Key Features of Observability Dashboards:**\n  * Human-readable overview analytics and replays of agent activities.\n  * LLM cost, prompt, completion, timestamp, and metadata tracking for performance monitoring.\n  * Tool invocation, events, and agent-to-agent interactions for workflow monitoring.\n  * Error flagging and notifications for faster debugging.\n  * Access to a wealth of data for developers using supported agent frameworks, such as environments, SDK versions, and more.\n\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#compliance>)\nCompliance\nObservability is not just a development convenience—it’s a compliance necessity, especially in regulated industries:\n  * It offers insights into AI decision-making processes, fostering trust and transparency.\n  * Anomalies and unintended behaviors are detected promptly, reducing various risks.\n  * Ensuring adherence to data privacy regulations, thereby safeguarding sensitive information.\n  * Compliance violations are quickly identified and addressed, enhancing incident management.\n\n\n[LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)[LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [AutoGen Observability Integrations](https://docs.ag2.ai/docs/topics/<#autogen-observability-integrations>)\n  * [Built-In Logging](https://docs.ag2.ai/docs/topics/<#built-in-logging>)\n  * [Full-Service Partner Integrations](https://docs.ag2.ai/docs/topics/<#full-service-partner-integrations>)\n  * [What is Observability?](https://docs.ag2.ai/docs/topics/<#what-is-observability>)\n  * [Compliance](https://docs.ag2.ai/docs/topics/<#compliance>)\n\n---\n\n# LLM Configuration\nURL: https://docs.ag2.ai/docs/topics/llm_configuration\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nLLM Configuration\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# LLM Configuration\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/llm_configuration.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/llm_configuration.ipynb>)\nIn AutoGen, agents use LLMs as key components to understand and react. To configure an agent’s access to LLMs, you can specify an `llm_config` argument in its constructor. For example, the following snippet shows a configuration that uses `gpt-4`:\nCopy\n```\nimport os\nllm_config = {\n  \"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}],\n}\n\n```\n\nIt is important to never commit secrets into your code, therefore we read the OpenAI API key from an environment variable.\nThis `llm_config` can then be passed to an agent’s constructor to enable it to use the LLM.\nCopy\n```\nimport autogen\nassistant = autogen.AssistantAgent(name=\"assistant\", llm_config=llm_config)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#introduction-to-config-list>)\nIntroduction to `config_list`\nDifferent tasks may require different models, and the `config_list` allows specifying the different endpoints and configurations that are to be used. It is a list of dictionaries, each of which contains the following keys depending on the kind of endpoint being used:\nCopy\n```\nimport Tabs from '@theme/Tabs';\nimport TabItem from '@theme/TabItem';\n<Tabs>\n <TabItem value=\"openai\" label=\"OpenAI\" default>\n  - `model` (str, required): The identifier of the model to be used, such as 'gpt-4', 'gpt-3.5-turbo'.\n  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.\n  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.\n  - `tags` (List[str], optional): Tags which can be used for filtering.\n  Example:\n  ```json\n  [\n   {\n    \"model\": \"gpt-4\",\n    \"api_key\": os.environ['OPENAI_API_KEY']\n   }\n  ]\n  ```\n </TabItem>\n <TabItem value=\"azureopenai\" label=\"Azure OpenAI\">\n  - `model` (str, required): The deployment to be used. The model corresponds to the deployment name on Azure OpenAI.\n  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.\n  - `api_type`: `azure`\n  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.\n  - `api_version` (str, optional): The version of the Azure API you wish to use.\n  - `tags` (List[str], optional): Tags which can be used for filtering.\n  Example:\n  ```json\n  [\n   {\n    \"model\": \"my-gpt-4-deployment\",\n    \"api_type\": \"azure\",\n    \"api_key\": os.environ['AZURE_OPENAI_API_KEY'],\n    \"base_url\": \"https://ENDPOINT.openai.azure.com/\",\n    \"api_version\": \"2024-02-01\"\n   }\n  ]\n  ```\n </TabItem>\n <TabItem value=\"other\" label=\"Other OpenAI compatible\">\n  - `model` (str, required): The identifier of the model to be used, such as 'llama-7B'.\n  - `api_key` (str, optional): The API key required for authenticating requests to the model's API endpoint.\n  - `base_url` (str, optional): The base URL of the API endpoint. This is the root address where API calls are directed.\n  - `tags` (List[str], optional): Tags which can be used for filtering.\n  Example:\n  ```json\n  [\n   {\n    \"model\": \"llama-7B\",\n    \"base_url\": \"http://localhost:1234\"\n   }\n  ]\n  ```\n </TabItem>\n</Tabs>\n\n```\n\nBy default this will create a model client which assumes an OpenAI API (or compatible) endpoint. To use custom model clients, see [here](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_custom_model.ipynb>).\n### \n[​](https://docs.ag2.ai/docs/topics/<#oai-config-list-pattern>)\n`OAI_CONFIG_LIST` pattern\nA common, useful pattern used is to define this `config_list` via JSON (specified as a file or an environment variable set to a JSON-formatted string) and then use the `config_list_from_json`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-json>) helper function to load it:\nCopy\n```\nconfig_list = autogen.config_list_from_json(\n  env_or_file=\"OAI_CONFIG_LIST\",\n)\n# Then, create the assistant agent with the config list\nassistant = autogen.AssistantAgent(name=\"assistant\", llm_config={\"config_list\": config_list})\n\n```\n\nThis can be helpful as it keeps all the configuration in one place across different projects or notebooks.\nThis function interprets the `env_or_file` argument as follows:\n  * If `env_or_file` is an environment variable then: \n    * It will first try to load the file from the path specified in the environment variable.\n    * If there is no file, it will try to interpret the environment variable as a JSON string.\n  * Otherwise, it will try to open the file at the path specified by `env_or_file`.\n\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#why-is-it-a-list>)\nWhy is it a list?\nBeing a list allows you to define multiple models that can be used by the agent. This is useful for a few reasons:\n  * If one model times out or fails, the agent can try another model.\n  * Having a single global list of models and [filtering it](https://docs.ag2.ai/docs/topics/docs/topics/llm_configuration#config-list-filtering>) based on certain keys (e.g. name, tag) in order to pass select models into a certain agent (e.g. use cheaper GPT 3.5 for agents solving easier tasks)\n  * While the core agents, (e.g. conversable or assistant) do not have special logic around selecting configs, some of the specialized agents _may_ have logic to select the best model based on the task at hand.\n\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)\nHow does an agent decide which model to pick out of the list?\nAn agent uses the very first model available in the “config_list” and makes LLM calls against this model. If the model fails (e.g. API throttling) the agent will retry the request against the 2nd model and so on until prompt completion is received (or throws an error if none of the models successfully completes the request). In general there’s no implicit/hidden logic inside agents that is used to pick “the best model for the task”. However, some specialized agents may attempt to choose “the best model for the task”. It is developers responsibility to pick the right models and use them with agents.\n### \n[​](https://docs.ag2.ai/docs/topics/<#config-list-filtering>)\nConfig list filtering\nAs described above the list can be filtered based on certain criteria. This is defined as a dictionary of key to filter on and values to filter by. For example, if you have a list of configs and you want to select the one with the model “gpt-3.5-turbo” you can use the following filter:\nCopy\n```\nfilter_dict = {\"model\": [\"gpt-3.5-turbo\"]}\n\n```\n\nThis can then be applied to a config list loaded in Python with `filter_config`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#filter-config>):\nCopy\n```\nconfig_list = autogen.filter_config(config_list, filter_dict)\n\n```\n\nOr, directly when loading the config list using `config_list_from_json`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-json>):\nCopy\n```\nconfig_list = autogen.config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\", filter_dict=filter_dict)\n\n```\n\n#### \n[​](https://docs.ag2.ai/docs/topics/<#tags>)\nTags\nModel names can differ between OpenAI and Azure OpenAI, so tags offer an easy way to smooth over this inconsistency. Tags are a list of strings in the `config_list`, for example for the following `config_list`:\nCopy\n```\nconfig_list = [\n  {\"model\": \"my-gpt-4-deployment\", \"api_key\": \"\", \"tags\": [\"gpt4\", \"openai\"]},\n  {\"model\": \"llama-7B\", \"base_url\": \"http://127.0.0.1:8080\", \"tags\": [\"llama\", \"local\"]},\n]\n\n```\n\nThen when filtering the `config_list` you can can specify the desired tags. A config is selected if it has at least one of the tags specified in the filter. For example, to just get the `llama` model, you can use the following filter:\nCopy\n```\nfilter_dict = {\"tags\": [\"llama\", \"another_tag\"]}\nconfig_list = autogen.filter_config(config_list, filter_dict)\nassert len(config_list) == 1\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#adding-http-client-in-llm-config-for-proxy>)\nAdding http client in llm_config for proxy\nIn Autogen, a deepcopy is used on llm_config to ensure that the llm_config passed by user is not modified internally. You may get an error if the llm_config contains objects of a class that do not support deepcopy. To fix this, you need to implement a `__deepcopy__` method for the class.\nThe below example shows how to implement a `__deepcopy__` method for http client and add a proxy.\nCopy\n```\n#!pip install httpx\nimport httpx\n\nclass MyHttpClient(httpx.Client):\n  def __deepcopy__(self, memo):\n    return self\n\nconfig_list = [\n  {\n    \"model\": \"my-gpt-4-deployment\",\n    \"api_key\": \"\",\n    \"http_client\": MyHttpClient(proxy=\"http://localhost:8030\"),\n  }\n]\nllm_config = {\n  \"config_list\": config_list,\n}\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#using-azure-active-directory-aad-authentication>)\nUsing Azure Active Directory (AAD) Authentication\nAzure Active Directory (AAD) provides secure access to resources and applications. Follow the steps below to configure AAD authentication for Autogen.\n#### \n[​](https://docs.ag2.ai/docs/topics/<#prerequisites>)\nPrerequisites\n  * An Azure subscription - [Create one for free](https://docs.ag2.ai/docs/topics/<https:/azure.microsoft.com/en-us/pricing/purchase-options/azure-account?icid=azurefreeaccount>).\n  * Access granted to the Azure OpenAI Service in the desired Azure subscription.\n  * Appropriate permissions to register an application in AAD.\n  * Custom subdomain names are required to enable features like Microsoft Entra ID for authentication.\n  * Azure CLI - [Installation Guide](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/cli/azure/install-azure-cli>).\n\n\nFor more detailed and up-to-date instructions, please refer to the official [Azure OpenAI documentation](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/>).\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-1-register-an-application-in-aad>)\nStep 1: Register an Application in AAD\n  1. Navigate to the [Azure portal](https://docs.ag2.ai/docs/topics/<https:/azure.microsoft.com/en-us/get-started/azure-portal>).\n  2. Go to `Azure Active Directory` > `App registrations`.\n  3. Click on `New registration`.\n  4. Enter a name for your application.\n  5. Set the `Redirect URI` (optional).\n  6. Click `Register`.\n\n\nFor detailed instructions, refer to the official [Azure AD Quickstart documentation](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app?tabs=certificate>).\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-2-configure-api-permissions>)\nStep 2: Configure API Permissions\n  1. After registration, go to `API permissions`.\n  2. Click `Add a permission`.\n  3. Select `Microsoft Graph` and then `Delegated permissions`.\n  4. Add the necessary permissions (e.g., `User.Read`).\n\n\nFor more details, see [API permissions in Microsoft Graph](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/permissions-consent-overview>)\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-3-obtain-client-id-and-tenant-id>)\nStep 3: Obtain Client ID and Tenant ID\n  1. Go to `Overview` of your registered application.\n  2. Note down the `Application (client) ID` and `Directory (tenant) ID`.\n\n\nFor more details, visit [Register an application with the Microsoft identity platform](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app?tabs=certificate>)\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-4-configure-your-application>)\nStep 4: Configure Your Application\nUse the obtained `Client ID` and `Tenant ID` in your application configuration. Here’s an example of how to do this in your configuration file:\nCopy\n```\naad_config = {\n  \"client_id\": \"YOUR_CLIENT_ID\",\n  \"tenant_id\": \"YOUR_TENANT_ID\",\n  \"authority\": \"https://login.microsoftonline.com/YOUR_TENANT_ID\",\n  \"scope\": [\"https://graph.microsoft.com/.default\"],\n}\n\n```\n\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-5-authenticate-and-acquire-tokens>)\nStep 5: Authenticate and Acquire Tokens\nUse the following code to authenticate and acquire tokens:\nCopy\n```\nfrom msal import ConfidentialClientApplication\napp = ConfidentialClientApplication(\n  client_id=aad_config[\"client_id\"],\n  client_credential=\"YOUR_CLIENT_SECRET\",\n  authority=aad_config[\"authority\"]\n)\nresult = app.acquire_token_for_client(scopes=aad_config[\"scope\"])\nif \"access_token\" in result:\n  print(\"Token acquired\")\nelse:\n  print(\"Error acquiring token:\", result.get(\"error\"))\n\n```\n\nFor more details, refer to the [Authenticate and authorize in Azure OpenAI Service](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai>) and [How to configure Azure OpenAI Service with Microsoft Entra ID authentication](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity>).\n#### \n[​](https://docs.ag2.ai/docs/topics/<#step-6-configure-azure-openai-with-aad-auth-in-autogen>)\nStep 6: Configure Azure OpenAI with AAD Auth in AutoGen\nTo use AAD authentication with Azure OpenAI in AutoGen, configure the `llm_config` with the necessary parameters.\nHere is an example configuration:\nCopy\n```\nllm_config = {\n  \"config_list\": [\n    {\n      \"model\": \"gpt-4\",\n      \"base_url\": \"YOUR_BASE_URL\",\n      \"api_type\": \"azure\",\n      \"api_version\": \"2024-02-01\",\n      \"max_tokens\": 1000,\n      \"azure_ad_token_provider\": \"DEFAULT\"\n    }\n  ]\n}\n\n```\n\nFor more details, refer to the [Authenticate and authorize in Azure OpenAI Service](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai>) and [How to configure Azure OpenAI Service with Microsoft Entra ID authentication](https://docs.ag2.ai/docs/topics/<https:/learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity>).\nIn this configuration: - `model`: The Azure OpenAI deployment name. - `base_url`: The base URL of the Azure OpenAI endpoint. - `api_type`: Should be set to “azure”. - `api_version`: The API version to use. - `azure_ad_token_provider`: Set to “DEFAULT” to use the default token provider.\n#### \n[​](https://docs.ag2.ai/docs/topics/<#example-of-initializing-an-assistant-agent-with-aad-auth>)\nExample of Initializing an Assistant Agent with AAD Auth\nCopy\n```\nimport autogen\n# Initialize the assistant agent with the AAD authenticated config\nassistant = autogen.AssistantAgent(name=\"assistant\", llm_config=llm_config)\n\n```\n\n#### \n[​](https://docs.ag2.ai/docs/topics/<#troubleshooting>)\nTroubleshooting\nIf you encounter issues, check the following: - Ensure your `Client ID` and `Tenant ID` are correct. - Verify the permissions granted to your application. - Check network connectivity and Azure service status.\nThis documentation provides a complete guide to configure and use AAD authentication with Azure OpenAI in the AutoGen.\n## \n[​](https://docs.ag2.ai/docs/topics/<#other-configuration-parameters>)\nOther configuration parameters\nBesides the `config_list`, there are other parameters that can be used to configure the LLM. These are split between parameters specifically used by Autogen and those passed into the model client.\n### \n[​](https://docs.ag2.ai/docs/topics/<#autogen-specific-parameters>)\nAutoGen specific parameters\n  * `cache_seed` - This is a legacy parameter and not recommended to be used unless the reason for using it is to disable the default caching behavior. To disable default caching, set this to `None`. Otherwise, by default or if an int is passed the [DiskCache](https://docs.ag2.ai/docs/topics/docs/reference/cache/disk_cache>) will be used. For the new way of using caching, pass a [Cache](https://docs.ag2.ai/docs/topics/docs/reference/cache/cache>) object into `initiate_chat`[](https://docs.ag2.ai/docs/topics/docs/reference/agentchat/conversable_agent#initiate-chat>).\n\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#extra-model-client-parameters>)\nExtra model client parameters\nIt is also possible to passthrough parameters through to the OpenAI client. Parameters that correspond to the `OpenAI`[ client](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/openai-python/blob/d231d1fa783967c1d3a1db3ba1b52647fff148ac/src/openai/_client.py#L67>) or the `OpenAI`[ completions create API](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/openai-python/blob/d231d1fa783967c1d3a1db3ba1b52647fff148ac/src/openai/resources/completions.py#L35>) can be supplied.\nThis is commonly used for things like `temperature`, or `timeout`.\n## \n[​](https://docs.ag2.ai/docs/topics/<#example>)\nExample\nCopy\n```\nllm_config = {\n  \"config_list\": [\n    {\n      \"model\": \"my-gpt-4-deployment\",\n      \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n      \"api_type\": \"azure\",\n      \"base_url\": os.environ.get(\"AZURE_OPENAI_API_BASE\"),\n      \"api_version\": \"2024-02-01\",\n    },\n    {\n      \"model\": \"llama-7B\",\n      \"base_url\": \"http://127.0.0.1:8080\",\n      \"api_type\": \"openai\",\n    },\n  ],\n  \"temperature\": 0.9,\n  \"timeout\": 300,\n}\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#other-helpers-for-loading-a-config-list>)\nOther helpers for loading a config list\n  * `get_config_list`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#get-config-list>): Generates configurations for API calls, primarily from provided API keys.\n  * `config_list_openai_aoai`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-openai-aoai>): Constructs a list of configurations using both Azure OpenAI and OpenAI endpoints, sourcing API keys from environment variables or local files.\n  * `config_list_from_models`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-models>): Creates configurations based on a provided list of models, useful when targeting specific models without manually specifying each configuration.\n  * `config_list_from_dotenv`[](https://docs.ag2.ai/docs/topics/docs/reference/oai/openai_utils#config-list-from-dotenv>): Constructs a configuration list from a `.env` file, offering a consolidated way to manage multiple API configurations and keys from a single file.\n\n\nSee [this notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/config_loader_utility_functions.ipynb>) for examples of using the above functions.\n[Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)[ReAct](https://docs.ag2.ai/docs/topics/</docs/topics/prompting-and-reasoning/react>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Introduction to config_list](https://docs.ag2.ai/docs/topics/<#introduction-to-config-list>)\n  * [OAI_CONFIG_LIST pattern](https://docs.ag2.ai/docs/topics/<#oai-config-list-pattern>)\n  * [Why is it a list?](https://docs.ag2.ai/docs/topics/<#why-is-it-a-list>)\n  * [How does an agent decide which model to pick out of the list?](https://docs.ag2.ai/docs/topics/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)\n  * [Config list filtering](https://docs.ag2.ai/docs/topics/<#config-list-filtering>)\n  * [Tags](https://docs.ag2.ai/docs/topics/<#tags>)\n  * [Adding http client in llm_config for proxy](https://docs.ag2.ai/docs/topics/<#adding-http-client-in-llm-config-for-proxy>)\n  * [Using Azure Active Directory (AAD) Authentication](https://docs.ag2.ai/docs/topics/<#using-azure-active-directory-aad-authentication>)\n  * [Prerequisites](https://docs.ag2.ai/docs/topics/<#prerequisites>)\n  * [Step 1: Register an Application in AAD](https://docs.ag2.ai/docs/topics/<#step-1-register-an-application-in-aad>)\n  * [Step 2: Configure API Permissions](https://docs.ag2.ai/docs/topics/<#step-2-configure-api-permissions>)\n  * [Step 3: Obtain Client ID and Tenant ID](https://docs.ag2.ai/docs/topics/<#step-3-obtain-client-id-and-tenant-id>)\n  * [Step 4: Configure Your Application](https://docs.ag2.ai/docs/topics/<#step-4-configure-your-application>)\n  * [Step 5: Authenticate and Acquire Tokens](https://docs.ag2.ai/docs/topics/<#step-5-authenticate-and-acquire-tokens>)\n  * [Step 6: Configure Azure OpenAI with AAD Auth in AutoGen](https://docs.ag2.ai/docs/topics/<#step-6-configure-azure-openai-with-aad-auth-in-autogen>)\n  * [Example of Initializing an Assistant Agent with AAD Auth](https://docs.ag2.ai/docs/topics/<#example-of-initializing-an-assistant-agent-with-aad-auth>)\n  * [Troubleshooting](https://docs.ag2.ai/docs/topics/<#troubleshooting>)\n  * [Other configuration parameters](https://docs.ag2.ai/docs/topics/<#other-configuration-parameters>)\n  * [AutoGen specific parameters](https://docs.ag2.ai/docs/topics/<#autogen-specific-parameters>)\n  * [Extra model client parameters](https://docs.ag2.ai/docs/topics/<#extra-model-client-parameters>)\n  * [Example](https://docs.ag2.ai/docs/topics/<#example>)\n  * [Other helpers for loading a config list](https://docs.ag2.ai/docs/topics/<#other-helpers-for-loading-a-config-list>)\n\n---\n\n# Retrieval Augmentation\nURL: https://docs.ag2.ai/docs/topics/retrieval_augmentation\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nRetrieval Augmentation\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# Retrieval Augmentation\nRetrieval Augmented Generation (RAG) is a powerful technique that combines language models with external knowledge retrieval to improve the quality and relevance of generated responses.\nOne way to realize RAG in AutoGen is to construct agent chats with `AssistantAgent` and `RetrieveUserProxyAgent` classes.\n## \n[​](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents>)\nExample Setup: RAG with Retrieval Augmented Agents\nThe following is an example setup demonstrating how to create retrieval augmented agents in AutoGen:\n### \n[​](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent>)\nStep 1. Create an instance of `AssistantAgent` and `RetrieveUserProxyAgent`.\nHere `RetrieveUserProxyAgent` instance acts as a proxy agent that retrieves relevant information based on the user’s input.\nRefer to the [doc](https://docs.ag2.ai/docs/topics/</docs/reference/agentchat/contrib/retrieve_user_proxy_agent>) for more information on the detailed configurations.\nCopy\n```\nassistant = AssistantAgent(\n  name=\"assistant\",\n  system_message=\"You are a helpful assistant.\",\n  llm_config={\n    \"timeout\": 600,\n    \"cache_seed\": 42,\n    \"config_list\": config_list,\n  },\n)\nragproxyagent = RetrieveUserProxyAgent(\n  name=\"ragproxyagent\",\n  human_input_mode=\"NEVER\",\n  max_consecutive_auto_reply=3,\n  retrieve_config={\n    \"task\": \"code\",\n    \"docs_path\": [\n      \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n      \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n      os.path.join(os.path.abspath(\"\"), \"..\", \"website\", \"docs\"),\n    ],\n    \"custom_text_types\": [\"mdx\"],\n    \"chunk_token_size\": 2000,\n    \"model\": config_list[0][\"model\"],\n    \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n    \"embedding_model\": \"all-mpnet-base-v2\",\n    \"get_or_create\": True, # set to False if you don't want to reuse an existing collection, but you'll need to remove the collection manually\n  },\n  code_execution_config=False, # set to False if you don't want to execute the code\n)\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation>)\nStep 2. Initiating Agent Chat with Retrieval Augmentation\nOnce the retrieval augmented agents are set up, you can initiate a chat with retrieval augmentation using the following code:\nCopy\n```\ncode_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\nragproxyagent.initiate_chat(\n  assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string=\"spark\"\n) # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\".\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents-with-pgvector>)\nExample Setup: RAG with Retrieval Augmented Agents with PGVector\nThe following is an example setup demonstrating how to create retrieval augmented agents in AutoGen:\n### \n[​](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent-2>)\nStep 1. Create an instance of `AssistantAgent` and `RetrieveUserProxyAgent`.\nHere `RetrieveUserProxyAgent` instance acts as a proxy agent that retrieves relevant information based on the user’s input.\nSpecify the connection_string, or the host, port, database, username, and password in the db_config.\nCopy\n```\nassistant = AssistantAgent(\n  name=\"assistant\",\n  system_message=\"You are a helpful assistant.\",\n  llm_config={\n    \"timeout\": 600,\n    \"cache_seed\": 42,\n    \"config_list\": config_list,\n  },\n)\nragproxyagent = RetrieveUserProxyAgent(\n  name=\"ragproxyagent\",\n  human_input_mode=\"NEVER\",\n  max_consecutive_auto_reply=3,\n  retrieve_config={\n    \"task\": \"code\",\n    \"docs_path\": [\n      \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md\",\n      \"https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Research.md\",\n      os.path.join(os.path.abspath(\"\"), \"..\", \"website\", \"docs\"),\n    ],\n    \"vector_db\": \"pgvector\",\n    \"collection_name\": \"autogen_docs\",\n    \"db_config\": {\n      \"connection_string\": \"postgresql://testuser:testpwd@localhost:5432/vectordb\", # Optional - connect to an external vector database\n      # \"host\": None, # Optional vector database host\n      # \"port\": None, # Optional vector database port\n      # \"database\": None, # Optional vector database name\n      # \"username\": None, # Optional vector database username\n      # \"password\": None, # Optional vector database password\n    },\n    \"custom_text_types\": [\"mdx\"],\n    \"chunk_token_size\": 2000,\n    \"model\": config_list[0][\"model\"],\n    \"get_or_create\": True,\n  },\n  code_execution_config=False,\n)\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation-2>)\nStep 2. Initiating Agent Chat with Retrieval Augmentation\nOnce the retrieval augmented agents are set up, you can initiate a chat with retrieval augmentation using the following code:\nCopy\n```\ncode_problem = \"How can I use FLAML to perform a classification task and use spark to do parallel training. Train 30 seconds and force cancel jobs if time limit is reached.\"\nragproxyagent.initiate_chat(\n  assistant, message=ragproxyagent.message_generator, problem=code_problem, search_string=\"spark\"\n) # search_string is used as an extra filter for the embeddings search, in this case, we only want to search documents that contain \"spark\".\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#online-demo>)\nOnline Demo\n[Retrival-Augmented Chat Demo on Huggingface](https://docs.ag2.ai/docs/topics/<https:/huggingface.co/spaces/thinkall/autogen-demos>)\n## \n[​](https://docs.ag2.ai/docs/topics/<#more-examples-and-notebooks>)\nMore Examples and Notebooks\nFor more detailed examples and notebooks showcasing the usage of retrieval augmented agents in AutoGen, refer to the following:\n  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_RetrieveChat>)\n  * Automated Code Generation and Question Answering with [PGVector](https://docs.ag2.ai/docs/topics/<https:/github.com/pgvector/pgvector>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_pgvector.ipynb>)\n  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/docs/topics/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_qdrant.ipynb>)\n  * Automated Code Generation and Question Answering with [MongoDB Atlas](https://docs.ag2.ai/docs/topics/<https:/www.mongodb.com/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_mongodb.ipynb>)\n  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_oai_assistant_retrieval.ipynb>)\n  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/topics/</notebooks/agentchat_groupchat_RAG>)\n\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#roadmap>)\nRoadmap\nExplore our detailed roadmap [here](https://docs.ag2.ai/docs/topics/<https:/github.com/microsoft/autogen/issues/1657>) for further advancements plan around RAG. Your contributions, feedback, and use cases are highly appreciated! We invite you to engage with us and play a pivotal role in the development of this impactful feature.\n[LLM Reflection](https://docs.ag2.ai/docs/topics/</docs/topics/prompting-and-reasoning/reflection>)[Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Example Setup: RAG with Retrieval Augmented Agents](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents>)\n  * [Step 1. Create an instance of AssistantAgent and RetrieveUserProxyAgent.](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent>)\n  * [Step 2. Initiating Agent Chat with Retrieval Augmentation](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation>)\n  * [Example Setup: RAG with Retrieval Augmented Agents with PGVector](https://docs.ag2.ai/docs/topics/<#example-setup-rag-with-retrieval-augmented-agents-with-pgvector>)\n  * [Step 1. Create an instance of AssistantAgent and RetrieveUserProxyAgent.](https://docs.ag2.ai/docs/topics/<#step-1-create-an-instance-of-assistantagent-and-retrieveuserproxyagent-2>)\n  * [Step 2. Initiating Agent Chat with Retrieval Augmentation](https://docs.ag2.ai/docs/topics/<#step-2-initiating-agent-chat-with-retrieval-augmentation-2>)\n  * [Online Demo](https://docs.ag2.ai/docs/topics/<#online-demo>)\n  * [More Examples and Notebooks](https://docs.ag2.ai/docs/topics/<#more-examples-and-notebooks>)\n  * [Roadmap](https://docs.ag2.ai/docs/topics/<#roadmap>)\n\n---\n\n# Swarm Orchestration\nURL: https://docs.ag2.ai/docs/topics/swarm\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nSwarm Orchestration\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# Swarm Orchestration\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/swarm.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/swarm.ipynb>)\nWith AG2, you can initiate a Swarm Chat similar to OpenAI’s [Swarm](https://docs.ag2.ai/docs/topics/<https:/github.com/openai/swarm>). This orchestration offers two main features:\n  * **Headoffs** : Agents can transfer control to another agent via function calls, enabling smooth transitions within workflows.\n  * **Context Variables** : Agents can dynamically update shared variables through function calls, maintaining context and adaptability throughout the process.\n\n\nInstead of sending a task to a single LLM agent, you can assign it to a swarm of agents. Each agent in the swarm can decide whether to hand off the task to another agent. The chat terminates when the last active agent’s response is a plain string (i.e., it doesn’t suggest a tool call or handoff).\n## \n[​](https://docs.ag2.ai/docs/topics/<#components>)\nComponents\nWe now introduce the main components that need to be used to create a swarm chat.\n### \n[​](https://docs.ag2.ai/docs/topics/<#create-a-swarmagent>)\nCreate a `SwarmAgent`\nAll the agents passed to the swarm chat should be instances of `SwarmAgent`. `SwarmAgent` is very similar to `AssistantAgent`, but it has some additional features to support function registration and handoffs. When creating a `SwarmAgent`, you can pass in a list of functions. These functions will be converted to schemas to be passed to the LLMs, and you don’t need to worry about registering the functions for execution. You can also pass back a `SwarmResult` class, where you can return a value, the next agent to call, and update context variables at the same time.\n**Notes for creating the function calls**\n  * For input arguments, you must define the type of the argument, otherwise, the registration will fail (e.g. `arg_name: str`).\n  * If your function requires access or modification of the context variables, you must pass in `context_variables: dict` as one argument. This argument will not be visible to the LLM (removed when registering the function schema). But when called, the global context variables will be passed in by the swarm chat.\n  * The docstring of the function will be used as the prompt. So make sure to write a clear description.\n  * The function name will be used as the tool name.\n\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-agents>)\nRegistering Handoffs to agents\nWhile you can create a function to decide what next agent to call, we provide a quick way to register the handoff using `ON_CONDITION`. We will craft this transition function and add it to the LLM config directly.\nCopy\n```\nagent_2 = SwarmAgent(...)\nagent_3 = SwarmAgent(...)\n# Register the handoff\nagent_1 = SwarmAgent(...)\nagent_1.handoff(hand_to=[ON_CONDITION(agent_2, \"condition_1\"), ON_CONDITION(agent_3, \"condition_2\")])\n# This is equivalent to:\ndef transfer_to_agent_2():\n  \"\"\"condition_1\"\"\"\n  return agent_2\ndef transfer_to_agent_3():\n  \"\"\"condition_2\"\"\"\n  return agent_3\n  \nagent_1 = SwarmAgent(..., functions=[transfer_to_agent_2, transfer_to_agent_3])\n# You can also use agent_1.add_functions to add more functions after initialization\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-a-nested-chat>)\nRegistering Handoffs to a nested chat\nIn addition to transferring to an agent, you can also trigger a nested chat by doing a handoff and using `ON_CONDITION`. This is a useful way to perform sub-tasks without that work becoming part of the broader swarm’s messages.\nConfiguring the nested chat is similar to [establishing a nested chat for an agent](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/tutorial/conversation-patterns#nested-chats>).\nNested chats are a set of sequential chats and these are defined like so:\nCopy\n```\nnested_chats = [\n  {\n    \"recipient\": my_first_agent,\n    \"summary_method\": \"reflection_with_llm\",\n    \"summary_prompt\": \"Summarize the conversation into bullet points.\",\n  },\n  {\n    \"recipient\": poetry_agent,\n    \"message\": \"Write a poem about the context.\",\n    \"max_turns\": 1,\n    \"summary_method\": \"last_msg\",\n  },\n]\n\n```\n\nNew to nested chats within swarms is the ability to **carryover some context from the swarm chat into the nested chat**. This is done by adding a carryover configuration. If you’re not using carryover, then no messages from the swarm chat will be brought into the nested chat.\nThe carryover is applicable only to the first chat in the nested chats and works together with that nested chat’s “message” value, if any.\nCopy\n```\nmy_carryover_config = {\n  \"summary_method\": \"reflection_with_llm\",\n  \"summary_args\": {\"summary_prompt\": \"Summarise the conversation into bullet points.\"}\n  }\n\n```\n\nThe `summary_method` can be (with messages referring to the swarm chat’s messages):\n  * `\"all\"` - messages will be converted to a new-line concatenated string, e.g. `[first nested chat message]\\nContext: \\n[swarm message 1]\\n[swarm message 2]\\n...`\n  * `\"last_msg\"` - the latest message will be added, e.g. `[first nested chat message]\\nContext: \\n[swarm's latest message]`\n  * `\"reflection_with_llm\"` - utilises an LLM to interpret the messages and its resulting response will be added, e.g. `[first nested chat message]\\nContext: \\n[llm response]`\n  * `Callable` - a function that returns the full message (this will not concatenate with the first nested chat’s message, it will replace it entirely).\n\n\nThe signature of the `summary_method` callable is: `def my_method(agent: ConversableAgent, messages: List[Dict[str, Any]], summary_args: Dict) -> str:`\nBoth the “reflection_with_llm” and Callable will be able to utilise the `summary_args` if they are included.\nWith your configuration available, you can add it to the first chat in the nested chat:\nCopy\n```\nnested_chats = [\n  {\n    \"recipient\": my_first_agent,\n    \"summary_method\": \"reflection_with_llm\",\n    \"summary_prompt\": \"Summarize the conversation into bullet points.\",\n    \"carryover_config\": my_carryover_config,\n  },\n  {\n    \"recipient\": poetry_agent,\n    \"message\": \"Write a poem about the context.\",\n    \"max_turns\": 1,\n    \"summary_method\": \"last_msg\",\n  },\n]\n\n```\n\nFinally, we add the nested chat as a handoff in the same way as we do to an agent:\nCopy\n```\nagent_1.handoff(\n  hand_to=[ON_CONDITION(\n    target={\n      \"chat_queue\":[nested_chats],\n      \"config\": Any,\n      \"reply_func_from_nested_chats\": None,\n      \"use_async\": False\n    },\n    condition=\"condition_1\")\n    ]\n  )\n\n```\n\nSee the documentation on [registering a nested chat](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/reference/agentchat/conversable_agent#register-nested-chats>) for further information on the parameters `reply_func_from_nested_chats`, `use_async`, and `config`.\nOnce a nested chat is complete, the resulting output from the last chat in the nested chats will be returned as the agent that triggered the nested chat’s response.\n### \n[​](https://docs.ag2.ai/docs/topics/<#after-work>)\nAFTER_WORK\nWhen the active agent’s response doesn’t suggest a tool call or handoff, the chat will terminate by default. However, you can register an `AFTER_WORK` handoff to control what to do next. You can register these `AFTER_WORK` handoffs at the agent level and also the swarm level (through the `after_work` parameter on `initiate_swarm_chat`). The agent level takes precedence over the swarm level.\nThe AFTER_WORK takes a single parameter and this can be an agent, an agent’s name, an `AfterWorkOption`, or a callable function.\nThe `AfterWorkOption` options are: - `TERMINATE`: Terminate the chat\n  * `STAY`: Stay at the current agent\n  * `REVERT_TO_USER`: Revert to the user agent. Only if a user agent is passed in when initializing. (See below for more details)\n\n\nThe callable function signature is: `def my_after_work_func(last_speaker: SwarmAgent, messages: List[Dict[str, Any]], groupchat: GroupChat) -> Union[AfterWorkOption, SwarmAgent, str]:`\nNote: there should only be one `AFTER_WORK`, if your requirement is more complex, use the callable function parameter.\nHere are examples of registering AFTER_WORKS\nCopy\n```\n# Register the handoff to an agent\nagent_1.handoff(hand_to=[\n ON_CONDITION(...), \n ON_CONDITION(...),\n AFTER_WORK(agent_4) # Fallback to agent_4 if no ON_CONDITION handoff is suggested\n])\n# Register the handoff to an AfterWorkOption\nagent_2.handoff(hand_to=[AFTER_WORK(AfterWorkOption.TERMINATE)]) # Terminate the chat if no handoff is suggested\ndef my_after_work_func(last_speaker: SwarmAgent, messages: List[Dict[str, Any]], groupchat: GroupChat) -> Union[AfterWorkOption, SwarmAgent, str]:\n  if last_speaker.get_context(\"agent_1_done\"):\n    return agent_2\n  else:\n    return AfterWorkOption.TERMINATE\n# Register the handoff to a function that will return an agent or AfterWorkOption\nagent_3.handoff(hand_to=[AFTER_WORK(my_after_work_func)])\n# Register the swarm level AFTER_WORK that becomes the default for agents that don't have one specified\nchat_history, context_variables, last_active_agent = initiate_swarm_chat(\n  ...\n  after_work=AfterWorkOption.TERMINATE # Or an agent or Callable\n)\n\n```\n\nCopy\n```\n\n### Update Agent state before replying\nIt can be useful to update a swarm agent's state before they reply. For example, using an agent's context variables you could change their system message based on the state of the workflow.\nWhen initialising a swarm agent use the `update_agent_state_before_reply` parameter to register updates that run after the agent is selected, but before they reply.\n`update_agent_state_before_reply` takes a list of any combination of the following (executing them in the provided order):\n- `UPDATE_SYSTEM_MESSAGE` provides a simple way to update the agent's system message via an f-string that substitutes the values of context variables, or a Callable that returns a string\n- Callable with two parameters of type `ConversableAgent` for the agent and `List[Dict[str Any]]` for the messages, and does not return a value\nBelow is an example of setting these up when creating a Swarm agent.\n```python\n# Creates a system message string\ndef create_system_prompt_function(my_agent: ConversableAgent, messages: List[Dict[]]) -> str:\n  preferred_name = my_agent.get_context(\"preferred_name\", \"(name not provided)\")\n  # Note that the returned string will be treated like an f-string using the context variables\n  return \"You are a customer service representative helping a customer named \"\n  + preferred_name\n  + \" and their passport number is '{passport_number}'.\"\n# Function to update an Agent's state\ndef my_callable_state_update_function(my_agent: ConversableAgent, messages: List[Dict[]]) -> None:\n  agent.set_context(\"context_key\", 43)\n  agent.update_system_message(\"You are a customer service representative.\")\n# Create the SwarmAgent and set agent updates\ncustomer_service = SwarmAgent(\n  name=\"CustomerServiceRep\",\n  system_message=\"You are a customer service representative.\",\n  update_agent_state_before_reply=[\n    UPDATE_SYSTEM_MESSAGE(\"You are a customer service representative. Quote passport number '{passport_number}'\"),\n    UPDATE_SYSTEM_MESSAGE(create_system_prompt_function),\n    my_callable_state_update_function]\n  ...\n)\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#initialize-swarmchat-with-initiate-swarm-chat-a-initiate-swarm-chat>)\nInitialize SwarmChat with `initiate_swarm_chat` / `a_initiate_swarm_chat`\nAfter a set of swarm agents are created, you can initiate a swarm chat by calling `initiate_swarm_chat` (or `a_initiate_swarm_chat` for an asynchronous version).\nCopy\n```\nchat_history, context_variables, last_active_agent = initiate_swarm_chat(\n  initial_agent=agent_1, # the first agent to start the chat\n  agents=[agent_1, agent_2, agent_3], # a list of agents\n  messages=[{\"role\": \"user\", \"content\": \"Hello\"}], # a list of messages to start the chat, you can also pass in one string\n  user_agent=user_agent, # optional, if you want to revert to the user agent\n  context_variables={\"key\": \"value\"} # optional, initial context variables\n)\n\n```\n\nHow we handle messages:\n  * Case 1: If you pass in one single message\n  * If there is a name in that message, we will assume this message is from that agent. (It will be error if that name doesn’t match any agent you passed in.)\n  * If there is no name, 1. User agent passed in: we assume this message is from the user agent. 2. No user agent passed in: we will create a temporary user agent just to start the chat.\n  * Case 2: We will use the [Resume GroupChat](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/docs/topics/groupchat/resuming_groupchat>) feature to resume the chat. The `name` fields in these messages must be one of the names of the agents you passed in, otherwise, it will be an error.\n\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#q-and-as>)\nQ&As\n> How are context variables updated?\nIn a swarm, the context variables are shared amongst Swarm agents. As context variables are available at the agent level, you can use the context variable getters/setters on the agent to view and change the shared context variables. If you’re working with a function that returns a `SwarmResult` you should update the passed in context variables and return it in the `SwarmResult`, this will ensure the shared context is updated.\n> What is the difference between ON_CONDITION and AFTER_WORK?\nWhen registering an ON_CONDITION handoff, we are creating a function schema to be passed to the LLM. The LLM will decide whether to call this function.\nWhen registering an AFTER_WORK handoff, we are defining the fallback mechanism when no tool calls are suggested. This is a higher level of control from the swarm chat level.\n> When to pass in a user agent?\nIf your application requires interactions with the user, you can pass in a user agent to the groupchat, so that don’t need to write an outer loop to accept user inputs and call swarm.\n## \n[​](https://docs.ag2.ai/docs/topics/<#demonstration>)\nDemonstration\n### \n[​](https://docs.ag2.ai/docs/topics/<#create-swarm-agents>)\nCreate Swarm Agents\nCopy\n```\nimport autogen\nconfig_list = autogen.config_list_from_json(...)\nllm_config = {\"config_list\": config_list}\n\n```\n\nCopy\n```\nimport random\nfrom autogen import (\n  AFTER_WORK,\n  ON_CONDITION,\n  AfterWorkOption,\n  SwarmAgent,\n  SwarmResult,\n  initiate_swarm_chat,\n)\n\n# 1. A function that returns a value of \"success\" and updates the context variable \"1\" to True\ndef update_context_1(context_variables: dict) -> SwarmResult:\n  context_variables[\"1\"] = True\n  return SwarmResult(value=\"success\", context_variables=context_variables)\n\n# 2. A function that returns an SwarmAgent object\ndef transfer_to_agent_2() -> SwarmAgent:\n  \"\"\"Transfer to agent 2\"\"\"\n  return agent_2\n\n# 3. A function that returns the value of \"success\", updates the context variable and transfers to agent 3\ndef update_context_2_and_transfer_to_3(context_variables: dict) -> SwarmResult:\n  context_variables[\"2\"] = True\n  return SwarmResult(value=\"success\", context_variables=context_variables, agent=agent_3)\n\n# 4. A function that returns a normal value\ndef get_random_number() -> str:\n  return random.randint(1, 100)\n\ndef update_context_3_with_random_number(context_variables: dict, random_number: int) -> SwarmResult:\n  context_variables[\"3\"] = random_number\n  return SwarmResult(value=\"success\", context_variables=context_variables)\n\nagent_1 = SwarmAgent(\n  name=\"Agent_1\",\n  system_message=\"You are Agent 1, first, call the function to update context 1, and transfer to Agent 2\",\n  llm_config=llm_config,\n  functions=[update_context_1, transfer_to_agent_2],\n)\nagent_2 = SwarmAgent(\n  name=\"Agent_2\",\n  system_message=\"You are Agent 2, call the function that updates context 2 and transfer to Agent 3\",\n  llm_config=llm_config,\n  functions=[update_context_2_and_transfer_to_3],\n)\nagent_3 = SwarmAgent(\n  name=\"Agent_3\",\n  system_message=\"You are Agent 3, tell a joke\",\n  llm_config=llm_config,\n)\nagent_4 = SwarmAgent(\n  name=\"Agent_4\",\n  system_message=\"You are Agent 4, call the function to get a random number\",\n  llm_config=llm_config,\n  functions=[get_random_number],\n)\nagent_5 = SwarmAgent(\n  name=\"Agent_5\",\n  system_message=\"Update context 3 with the random number.\",\n  llm_config=llm_config,\n  functions=[update_context_3_with_random_number],\n)\n\n# This is equivalent to writing a transfer function\nagent_3.register_hand_off(ON_CONDITION(agent_4, \"Transfer to Agent 4\"))\nagent_4.register_hand_off([AFTER_WORK(agent_5)])\nprint(\"Agent 1 function schema:\")\nfor func_schema in agent_1.llm_config[\"tools\"]:\n  print(func_schema)\nprint(\"Agent 3 function schema:\")\nfor func_schema in agent_3.llm_config[\"tools\"]:\n  print(func_schema)\n\n```\n\nCopy\n```\nAgent 1 function schema:\n{'type': 'function', 'function': {'description': '', 'name': 'update_context_1', 'parameters': {'type': 'object', 'properties': {}}}}\n{'type': 'function', 'function': {'description': 'Transfer to agent 2', 'name': 'transfer_to_agent_2', 'parameters': {'type': 'object', 'properties': {}}}}\nAgent 3 function schema:\n{'type': 'function', 'function': {'description': 'Transfer to Agent 4', 'name': 'transfer_to_Agent_4', 'parameters': {'type': 'object', 'properties': {}}}}\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#start-chat>)\nStart Chat\nCopy\n```\ncontext_variables = {\"1\": False, \"2\": False, \"3\": False}\nchat_result, context_variables, last_agent = initiate_swarm_chat(\n  initial_agent=agent_1,\n  agents=[agent_1, agent_2, agent_3, agent_4, agent_5],\n  messages=\"start\",\n  context_variables=context_variables,\n  after_work=AFTER_WORK(AfterWorkOption.TERMINATE), # this is the default\n)\n\n```\n\nCopy\n```\n_User (to chat_manager):\nstart\n--------------------------------------------------------------------------------\nNext speaker: Agent_1\nAgent_1 (to chat_manager):\n***** Suggested tool call (call_kfcEAY2IeRZww06CQN7lbxOf): update_context_1 *****\nArguments: \n{}\n*********************************************************************************\n***** Suggested tool call (call_izl5eyV8IQ0Wg6XY2SaR1EJM): transfer_to_agent_2 *****\nArguments: \n{}\n************************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION update_context_1...\n>>>>>>>> EXECUTING FUNCTION transfer_to_agent_2...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_kfcEAY2IeRZww06CQN7lbxOf) *****\n**********************************************************************\n--------------------------------------------------------------------------------\n***** Response from calling tool (call_izl5eyV8IQ0Wg6XY2SaR1EJM) *****\nSwarmAgent --> Agent_2\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_2\nAgent_2 (to chat_manager):\n***** Suggested tool call (call_Yf5DTGaaYkA726ubnfJAvQMq): update_context_2_and_transfer_to_3 *****\nArguments: \n{}\n***************************************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION update_context_2_and_transfer_to_3...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_Yf5DTGaaYkA726ubnfJAvQMq) *****\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_3\nAgent_3 (to chat_manager):\n***** Suggested tool call (call_jqZNHuMtQYeNh5Mq4pV2uwAj): transfer_to_Agent_4 *****\nArguments: \n{}\n************************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION transfer_to_Agent_4...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_jqZNHuMtQYeNh5Mq4pV2uwAj) *****\nSwarmAgent --> Agent_4\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_4\nAgent_4 (to chat_manager):\n***** Suggested tool call (call_KeNGv98klvDZsrAX10Ou3I71): get_random_number *****\nArguments: \n{}\n**********************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION get_random_number...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_KeNGv98klvDZsrAX10Ou3I71) *****\n27\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_4\nAgent_4 (to chat_manager):\nThe random number generated is 27.\n--------------------------------------------------------------------------------\nNext speaker: Agent_5\nAgent_5 (to chat_manager):\n***** Suggested tool call (call_MlSGNNktah3m3QGssWBEzxCe): update_context_3_with_random_number *****\nArguments: \n{\"random_number\":27}\n****************************************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION update_context_3_with_random_number...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_MlSGNNktah3m3QGssWBEzxCe) *****\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_5\nAgent_5 (to chat_manager):\nThe random number 27 has been successfully updated in context 3.\n--------------------------------------------------------------------------------\n\n```\n\nCopy\n```\nprint(context_variables)\n\n```\n\nCopy\n```\n{'1': True, '2': True, '3': 27}\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#demo-with-user-agent>)\nDemo with User Agent\nWe pass in a user agent to the swarm chat to accept user inputs. With `agent_6`, we register an `AFTER_WORK` handoff to revert to the user agent when no tool calls are suggested.\nCopy\n```\nfrom autogen import UserProxyAgent\nuser_agent = UserProxyAgent(name=\"User\", code_execution_config=False)\nagent_6 = SwarmAgent(\n  name=\"Agent_6\",\n  system_message=\"You are Agent 6. Your job is to tell jokes.\",\n  llm_config=llm_config,\n)\nagent_7 = SwarmAgent(\n  name=\"Agent_7\",\n  system_message=\"You are Agent 7, explain the joke.\",\n  llm_config=llm_config,\n)\nagent_6.register_hand_off(\n  [\n    ON_CONDITION(\n      agent_7, \"Used to transfer to Agent 7. Don't call this function, unless the user explicitly tells you to.\"\n    ),\n    AFTER_WORK(AfterWorkOption.REVERT_TO_USER),\n  ]\n)\nchat_result, _, _ = initiate_swarm_chat(\n  initial_agent=agent_6,\n  agents=[agent_6, agent_7],\n  user_agent=user_agent,\n  messages=\"start\",\n)\n\n```\n\nCopy\n```\nUser (to chat_manager):\nstart\n--------------------------------------------------------------------------------\nNext speaker: Agent_6\nAgent_6 (to chat_manager):\nWhy did the scarecrow win an award? \nBecause he was outstanding in his field! \nWant to hear another one?\n--------------------------------------------------------------------------------\nNext speaker: User\nUser (to chat_manager):\nyes\n--------------------------------------------------------------------------------\nNext speaker: Agent_6\nAgent_6 (to chat_manager):\nWhy don't skeletons fight each other?\nThey don't have the guts! \nHow about another?\n--------------------------------------------------------------------------------\nNext speaker: User\nUser (to chat_manager):\ntransfer\n--------------------------------------------------------------------------------\nNext speaker: Agent_6\nAgent_6 (to chat_manager):\n***** Suggested tool call (call_gQ9leFamxgzQp8ZVQB8rUH73): transfer_to_Agent_7 *****\nArguments: \n{}\n************************************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Tool_Execution\n\n>>>>>>>> EXECUTING FUNCTION transfer_to_Agent_7...\nTool_Execution (to chat_manager):\n***** Response from calling tool (call_gQ9leFamxgzQp8ZVQB8rUH73) *****\nSwarmAgent --> Agent_7\n**********************************************************************\n--------------------------------------------------------------------------------\nNext speaker: Agent_7\nAgent_7 (to chat_manager):\nThe joke about the scarecrow winning an award is a play on words. It utilizes the term \"outstanding,\" which can mean both exceptionally good (in the context of the scarecrow's performance) and literally being \"standing out\" in a field (where scarecrows are placed). So, the double meaning creates a pun that makes the joke humorous. \nThe skeleton joke works similarly. When it says skeletons \"don't have the guts,\" it plays on the literal fact that skeletons don't have internal organs (guts), and metaphorically, \"having guts\" means having courage. The humor comes from this clever wordplay.\n--------------------------------------------------------------------------------\n\n```\n\n[Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)[Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Components](https://docs.ag2.ai/docs/topics/<#components>)\n  * [Create a SwarmAgent](https://docs.ag2.ai/docs/topics/<#create-a-swarmagent>)\n  * [Registering Handoffs to agents](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-agents>)\n  * [Registering Handoffs to a nested chat](https://docs.ag2.ai/docs/topics/<#registering-handoffs-to-a-nested-chat>)\n  * [AFTER_WORK](https://docs.ag2.ai/docs/topics/<#after-work>)\n  * [Initialize SwarmChat with initiate_swarm_chat / a_initiate_swarm_chat](https://docs.ag2.ai/docs/topics/<#initialize-swarmchat-with-initiate-swarm-chat-a-initiate-swarm-chat>)\n  * [Q&As](https://docs.ag2.ai/docs/topics/<#q-and-as>)\n  * [Demonstration](https://docs.ag2.ai/docs/topics/<#demonstration>)\n  * [Create Swarm Agents](https://docs.ag2.ai/docs/topics/<#create-swarm-agents>)\n  * [Start Chat](https://docs.ag2.ai/docs/topics/<#start-chat>)\n  * [Demo with User Agent](https://docs.ag2.ai/docs/topics/<#demo-with-user-agent>)\n\n---\n\n# Task Decomposition\nURL: https://docs.ag2.ai/docs/topics/task_decomposition\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/topics/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nTask Decomposition\n[Documentation](https://docs.ag2.ai/docs/topics/</docs/Home>)[Examples](https://docs.ag2.ai/docs/topics/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/topics/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/topics/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/topics/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/topics/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/topics/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/topics/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/topics/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/topics/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/topics/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/topics/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/topics/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/topics/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/topics/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/topics/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/topics/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/topics/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/topics/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/topics/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/topics/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/topics/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/topics/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/topics/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/topics/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/topics/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/topics/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/topics/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/topics/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/topics/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/topics/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/topics/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/topics/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/topics/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/topics/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/topics/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/topics/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/topics/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/topics/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/topics/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/topics/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/topics/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/topics/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/topics/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/topics/</docs/Migration-Guide>)\n\n\nUser Guide\n# Task Decomposition\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/topics/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/task_decomposition.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/task_decomposition.ipynb>)\nOn this page, we demonstrate several different ways to achieve task decomposition in AutoGen.\nFirst make sure the `pyautogen` package is installed.\nCopy\n```\n! pip install \"pyautogen>=0.2.18\"\n\n```\n\nImport the relevant modules and configure the LLM. See [LLM Configuration](https://docs.ag2.ai/docs/topics/<./llm_configuration>) for how to configure LLMs.\nCopy\n```\nimport os\nfrom datetime import datetime\nfrom typing import Callable, Dict, Literal, Optional, Union\nfrom typing_extensions import Annotated\nfrom autogen import (\n  Agent,\n  AssistantAgent,\n  ConversableAgent,\n  GroupChat,\n  GroupChatManager,\n  UserProxyAgent,\n  register_function,\n)\nfrom autogen.agentchat.contrib import agent_builder\nfrom autogen.cache import Cache\nfrom autogen.coding import LocalCommandLineCodeExecutor\nconfig_list = [\n  {\"model\": \"gpt-4-1106-preview\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]},\n  {\"model\": \"gpt-3.5-turbo\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]},\n]\n# You can also use the following method to load the config list from a file or environment variable.\n# config_list = config_list_from_json(env_or_file=\"OAI_CONFIG_LIST\")\n\n```\n\nThe task to be solved to write a blog post about the stock price performance of Nvidia in the past month.\nCopy\n```\ntask = (\n  f\"Today is {datetime.now().date()}. Write a blogpost about the stock price performance of Nvidia in the past month.\"\n)\nprint(task)\n\n```\n\nCopy\n```\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#approach-1-two-agent-chat-with-function-call-for-task-decomposition>)\nApproach 1. Two-agent chat with function call for task decomposition\nIn this approach, we use a planner agent for coming up a plan. The planner agent is wrapped inside a function to be used as a tool.\nCopy\n```\n# Create planner agent.\nplanner = AssistantAgent(\n  name=\"planner\",\n  llm_config={\n    \"config_list\": config_list,\n    \"cache_seed\": None, # Disable legacy cache.\n  },\n  system_message=\"You are a helpful AI assistant. You suggest a feasible plan \"\n  \"for finishing a complex task by decomposing it into 3-5 sub-tasks. \"\n  \"If the plan is not good, suggest a better plan. \"\n  \"If the execution is wrong, analyze the error and suggest a fix.\",\n)\n# Create a planner user agent used to interact with the planner.\nplanner_user = UserProxyAgent(\n  name=\"planner_user\",\n  human_input_mode=\"NEVER\",\n  code_execution_config=False,\n)\n# The function for asking the planner.\n\ndef task_planner(question: Annotated[str, \"Question to ask the planner.\"]) -> str:\n  with Cache.disk(cache_seed=4) as cache:\n    planner_user.initiate_chat(planner, message=question, max_turns=1, cache=cache)\n  # return the last message received from the planner\n  return planner_user.last_message()[\"content\"]\n\n```\n\nNext, we create an assistant agent to execute the plan, using the planner agent as a tool.\nCopy\n```\n# Create assistant agent.\nassistant = AssistantAgent(\n  name=\"assistant\",\n  system_message=\"You are a helpful AI assistant. \"\n  \"You can use the task planner to decompose a complex task into sub-tasks. \"\n  \"Make sure your follow through the sub-tasks. \"\n  \"When needed, write Python code in markdown blocks, and I will execute them.\"\n  \"Give the user a final solution at the end. \"\n  \"Return TERMINATE only if the sub-tasks are completed.\",\n  llm_config={\n    \"config_list\": config_list,\n    \"cache_seed\": None, # Disable legacy cache.\n  },\n)\n# Setting up code executor.\nos.makedirs(\"planning\", exist_ok=True)\n# Use DockerCommandLineCodeExecutor to run code in a docker container.\n# code_executor = DockerCommandLineCodeExecutor(work_dir=\"planning\")\ncode_executor = LocalCommandLineCodeExecutor(work_dir=\"planning\")\n# Create user proxy agent used to interact with the assistant.\nuser_proxy = UserProxyAgent(\n  name=\"user_proxy\",\n  human_input_mode=\"ALWAYS\",\n  is_termination_msg=lambda x: \"content\" in x\n  and x[\"content\"] is not None\n  and x[\"content\"].rstrip().endswith(\"TERMINATE\"),\n  code_execution_config={\"executor\": code_executor},\n)\n# Register the function to the agent pair.\nregister_function(\n  task_planner,\n  caller=assistant,\n  executor=user_proxy,\n  name=\"task_planner\",\n  description=\"A task planner than can help you with decomposing a complex task into sub-tasks.\",\n)\n\n```\n\nCopy\n```\n# Use Cache.disk to cache LLM responses. Change cache_seed for different responses.\nwith Cache.disk(cache_seed=1) as cache:\n  # the assistant receives a message from the user, which contains the task description\n  user_proxy.initiate_chat(\n    assistant,\n    message=task,\n    cache=cache,\n  )\n\n```\n\nCopy\n```\nuser_proxy (to assistant):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\n***** Suggested tool Call (call_rXxGJbMNXdD5PYueBc2BACez): task_planner *****\nArguments: \n{\"question\":\"What are the steps to write a blog post about the stock price performance of Nvidia for the past month?\"}\n*****************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING FUNCTION task_planner...\nplanner_user (to planner):\nWhat are the steps to write a blog post about the stock price performance of Nvidia for the past month?\n--------------------------------------------------------------------------------\nplanner (to planner_user):\nWriting a blog post about Nvidia's stock price performance over the past month involves several steps, which can be broken down into the following sub-tasks:\n1. **Research:**\n  - Gather data on Nvidia's stock price over the past month from reliable financial information sources like Bloomberg, Yahoo Finance, or the Nasdaq website.\n  - Look into any recent news articles, press releases, or earnings reports that could help explain the stock price movements.\n  - Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance.\n2. **Analysis:**\n  - Examine the data collected to identify patterns or significant changes in the stock price.\n  - Investigate the correlation between stock price movements and specific events or news (e.g., product launches, earnings reports, or changes in the semiconductor industry).\n  - Summarize key findings and consider creating graphs or charts to visually represent the stock performance over time.\n3. **Outline and Structuring:**\n  - Outline the blog post, starting with an introduction that provides context on Nvidia and its relevance in the market.\n  - Create sections for your blog post: Introduction, Background (optional), Monthly Performance Analysis, Contributing Factors, and Conclusion.\n  - Decide where you will include visuals like charts or infographics in your post.\n4. **Writing:**\n  - Write the introduction, setting the stage for your analysis and highlighting what the reader can expect to learn from the post.\n  - Detail the monthly performance in the main body, integrating your analysis and the data visualizations you've prepared.\n  - Discuss the identified contributing factors to Nvidia's stock performance, linking them with the analysis.\n  - Conclude with a summary of the key points made in the post and any thoughts on future performance or upcoming events that investors should watch.\n5. **Editing and Publishing:**\n  - Review the post for clarity, grammar, and accuracy. Ensure that all data presented is correct and that sources are properly cited.\n  - Optimize the post for search engines by including relevant keywords, meta descriptions, and title tags.\n  - Publish the blog post on your platform and share it through social media or other marketing channels to reach your audience.\n  - Engage with comments or feedback received to foster a community and show responsiveness.\nRemember to comply with all financial regulations concerning stock commentary, including disclaimers where applicable, to avoid misconstruing your analysis as investment advice.\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\nuser_proxy (to assistant):\n***** Response from calling tool \"call_rXxGJbMNXdD5PYueBc2BACez\" *****\nWriting a blog post about Nvidia's stock price performance over the past month involves several steps, which can be broken down into the following sub-tasks:\n1. **Research:**\n  - Gather data on Nvidia's stock price over the past month from reliable financial information sources like Bloomberg, Yahoo Finance, or the Nasdaq website.\n  - Look into any recent news articles, press releases, or earnings reports that could help explain the stock price movements.\n  - Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance.\n2. **Analysis:**\n  - Examine the data collected to identify patterns or significant changes in the stock price.\n  - Investigate the correlation between stock price movements and specific events or news (e.g., product launches, earnings reports, or changes in the semiconductor industry).\n  - Summarize key findings and consider creating graphs or charts to visually represent the stock performance over time.\n3. **Outline and Structuring:**\n  - Outline the blog post, starting with an introduction that provides context on Nvidia and its relevance in the market.\n  - Create sections for your blog post: Introduction, Background (optional), Monthly Performance Analysis, Contributing Factors, and Conclusion.\n  - Decide where you will include visuals like charts or infographics in your post.\n4. **Writing:**\n  - Write the introduction, setting the stage for your analysis and highlighting what the reader can expect to learn from the post.\n  - Detail the monthly performance in the main body, integrating your analysis and the data visualizations you've prepared.\n  - Discuss the identified contributing factors to Nvidia's stock performance, linking them with the analysis.\n  - Conclude with a summary of the key points made in the post and any thoughts on future performance or upcoming events that investors should watch.\n5. **Editing and Publishing:**\n  - Review the post for clarity, grammar, and accuracy. Ensure that all data presented is correct and that sources are properly cited.\n  - Optimize the post for search engines by including relevant keywords, meta descriptions, and title tags.\n  - Publish the blog post on your platform and share it through social media or other marketing channels to reach your audience.\n  - Engage with comments or feedback received to foster a community and show responsiveness.\nRemember to comply with all financial regulations concerning stock commentary, including disclaimers where applicable, to avoid misconstruing your analysis as investment advice.\n**********************************************************************\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\n***** Suggested tool Call (call_BAmTqvguaSkwQFq846qZxRxt): task_planner *****\nArguments: \n{\"question\": \"How to gather data on Nvidia's stock price over the past month?\"}\n*****************************************************************************\n***** Suggested tool Call (call_zQYeJEyx5gGzIxqirslGUgQi): task_planner *****\nArguments: \n{\"question\": \"How to research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements?\"}\n*****************************************************************************\n***** Suggested tool Call (call_Yb7uzCbJOFo7irlNPVzL8dem): task_planner *****\nArguments: \n{\"question\": \"How to research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance?\"}\n*****************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING FUNCTION task_planner...\nplanner_user (to planner):\nHow to gather data on Nvidia's stock price over the past month?\n--------------------------------------------------------------------------------\nplanner (to planner_user):\nTo gather data on Nvidia's stock price over the past month, you can decompose the task into the following sub-tasks:\n1. **Define Your Source:**\n  - Decide where you will obtain the data (e.g., financial websites like Yahoo Finance, Google Finance, Bloomberg, or utilizing APIs from services like Alpha Vantage, IEX Cloud, or Quandl).\n2. **Data Collection:**\n  - If you have chosen a financial website, you can usually download historical stock price data directly. Look for a \"Download Data\" or similar option on the webpage that shows Nvidia's stock history.\n  - If using an API, write a script or use a tool to access the API, request the historical stock prices for the past month, and handle the response. This will typically involve some programming knowledge, for instance in Python, using libraries like `requests` or `pandas-datareader`.\n3. **Data Parsing and Cleaning:**\n  - After you obtain the data, you may need to parse or clean it. This means checking for any inaccuracies or missing values and formatting the data in a way that is useful for your analysis. For instance, you might want to convert the date formats or adjust for any splits or dividends if you're looking at adjusted closing prices.\n4. **Analysis:**\n  - Analyze the stock price data to observe trends, calculate statistics like the average closing price over the month, or perform other analyses that meet your objectives.\n  \n5. **Visualization (Optional):**\n  - For better understanding and representation, visualize the data using charting tools or libraries (e.g., Excel, Google Sheets, or programming libraries like Matplotlib or Plotly in Python).\nHere's a more detailed breakdown of the steps if you choose to use an API and write a script in Python:\n**Step 1: Choosing an API**\n  - Sign up for an API service like Alpha Vantage and obtain the required API key.\n**Step 2: Writing the Script**\n  - Install any necessary Python libraries (e.g., `requests`, `pandas`, `matplotlib`).\n  - Write a Python script that uses the `requests` library to make an API call with the correct endpoint and parameters (symbol for Nvidia, your API key, and the time frame for the data).\n  - Parse the JSON or CSV response and convert it into a Pandas DataFrame for ease of manipulation.\n**Step 3: Data Parsing and Cleaning**\n  - In your Python script, clean the data if necessary by removing any unnecessary columns, filling in missing values, or converting data types.\n**Step 4: Analysis and Visualization**\n  - Use Pandas to perform any desired calculations, such as moving averages.\n  - Use a library like Matplotlib or Plotly to create charts from the DataFrame, such as line graphs of the closing prices over the past month.\n**Note:**\n  - It's important to respect the terms of service of the data provider and to be aware of any rate limits on API calls to avoid being blocked.\n  - Be aware of stock market holidays and weekends when the market is closed, as these days will not have trading data.\nIf you encounter any difficulties in any of these sub-tasks, the error will likely fall into one of the following categories: issues with data access or download, errors in the script/code, or data quality issues. In each case, you would need to troubleshoot by checking access permissions, debugging the script, or examining the data for integrity, respectively.\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION task_planner...\nplanner_user (to planner):\nHow to research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements?\n--------------------------------------------------------------------------------\nplanner (to planner_user):\nTo research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements, you'll need to systematically approach the task by breaking it down into the following sub-tasks:\n1. **Identify Reliable Sources:**\n  - Determine the most credible financial news websites, databases, and platforms that could have the information you’re seeking (e.g., Bloomberg, Reuters, CNBC, Nasdaq, and the official Nvidia investor relations page).\n  - Consider specialized financial data platforms like Yahoo Finance, MarketWatch, or Seeking Alpha for more detailed analyses and reports.\n  - Explore other reliable technology news outlets (e.g., TechCrunch, The Verge) that could have relevant information.\n2. **Gather Key Data:**\n  - Search for Nvidia’s latest earnings reports on their Investor Relations page, as these documents provide crucial information on the company’s financial health and outlook.\n  - Look for recent press releases on Nvidia's official website or through a news aggregator service by setting up alerts for \"Nvidia press release\" to get real-time updates.\n  - Use financial news platforms to search for Nvidia-specific news articles, filtering for the most recent ones. Include search terms like \"Nvidia stock movement,\" \"Nvidia earnings,\" or \"Nvidia financial news.\" \n3. **Analyze Information:**\n  - Read through the gathered documents and articles to identify any events or information that could have a direct impact on Nvidia's stock, such as product launches, partnerships, or changes in leadership.\n  - Pay special attention to the numbers and forward-looking statements in earnings reports that may have influenced investor sentiment and stock prices (e.g., revenue, profit margin, sales forecasts, market share, guidance).\n  - Look for any external factors that could affect the tech or semiconductor industry as a whole, such as new regulations, supply chain disruptions, or significant competitor announcements.\n4. **Compare Information with Stock Price Movements:**\n  - Overlay the dates of key events, announcements, or financial reporting with Nvidia's stock price chart to draw correlations between specific events and price fluctuations.\n  - Cross-reference the news with trading volumes to see if significant news led to increased trading activity.\n5. **Synthesize Findings:**\n  - Compile your research into a timeline or a summary document that correlates specific news items with stock price changes.\n  - Where possible, include expert analysis from your research to support your findings on why the stock moved in a particular way.\n  - Be critical of the information sources and mindful of the potential bias that can skew the perceived impact of news on stock prices.\nRemember to keep track of your sources and to cross-verify information to ensure accuracy. The stock market is influenced by numerous factors, some of which may not be immediately apparent, so it's also important to consider broader market trends and economic indicators in your analysis.\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION task_planner...\nplanner_user (to planner):\nHow to research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance?\n--------------------------------------------------------------------------------\nplanner (to planner_user):\nResearching market trends, economic factors, and industry-related developments to assess their influence on Nvidia's performance involves a systematic approach. Here's a plan that can help in fulfilling this research task:\n1. **Define Objective and Scope**:\n  - Identify the specific aspects of Nvidia's performance you are interested in (e.g., revenue growth, stock price fluctuation, product demand).\n  - Determine the time frame for your research (e.g., last 5 years, last 10 years, or around specific events).\n2. **Gather Historical Data and Performance Metrics**:\n  - Collect historical performance data for Nvidia, including sales figures, earnings reports, stock price history, and market share information.\n  - Obtain relevant financial documents, such as annual reports, 10-K filings, and investor presentations.\n  - Look for performance benchmarks or metrics within Nvidia's sector, such as GPU market penetration, competitive analysis, etc.\n3. **Analyze Market Trends and Economic Factors**:\n  - Research broad market trends and economic conditions that can impact Nvidia's industry (Semiconductors and Technology Sector), including technology adoption rates, consumer spending trends, trade policies, and global economic indicators.\n  - Use economic databases, government publications, financial news outlets, and market research reports for comprehensive information.\n  - Explore the impact of specific events (e.g., chip shortages, tariffs, pandemic) on the technology sector and Nvidia's market.\n4. **Industry-Specific Developments**:\n  - Study developments within the GPU industry and technology sector that can influence Nvidia's position, such as advancements in competing technologies, regulatory changes, or patent filings.\n  - Look into industry reports, whitepapers, tech journals, and conference proceedings for a deep dive into industry-specific insights.\n  - Monitor tech news platforms and forums that discuss developer sentiments, product reviews, and consumer feedback on products and technologies related to Nvidia’s offerings.\n5. **Synthesize Findings and Report**:\n  - Integrate insights from your comprehensive research to draw conclusions about how market trends, economic factors, and industry developments have influenced Nvidia's performance.\n  - Create a report or presentation with a narrative tying together Nvidia's performance data with the external factors you've identified. Use charts, graphs, and other visual aids to support your analysis.\n  - Formulate recommendations or insights for investors, stakeholders, or decision-makers based on your findings.\nTools you might use for this task include financial analysis software, market research databases, economic analysis tools, and various data visualization platforms. Always ensure that the sources you use for your research are reliable and up to date.\nIf the research is not yielding meaningful insights or the task seems too broad, refocusing on more specific aspects of Nvidia's performance and looking into direct cause-effect relationships in market changes and Nvidia's financial outcomes can improve the plan. Additionally, consider engaging with experts in the field or leveraging advanced analytics and predictive modeling to enhance the depth of your research.\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\nuser_proxy (to assistant):\n***** Response from calling tool \"call_BAmTqvguaSkwQFq846qZxRxt\" *****\nTo gather data on Nvidia's stock price over the past month, you can decompose the task into the following sub-tasks:\n1. **Define Your Source:**\n  - Decide where you will obtain the data (e.g., financial websites like Yahoo Finance, Google Finance, Bloomberg, or utilizing APIs from services like Alpha Vantage, IEX Cloud, or Quandl).\n2. **Data Collection:**\n  - If you have chosen a financial website, you can usually download historical stock price data directly. Look for a \"Download Data\" or similar option on the webpage that shows Nvidia's stock history.\n  - If using an API, write a script or use a tool to access the API, request the historical stock prices for the past month, and handle the response. This will typically involve some programming knowledge, for instance in Python, using libraries like `requests` or `pandas-datareader`.\n3. **Data Parsing and Cleaning:**\n  - After you obtain the data, you may need to parse or clean it. This means checking for any inaccuracies or missing values and formatting the data in a way that is useful for your analysis. For instance, you might want to convert the date formats or adjust for any splits or dividends if you're looking at adjusted closing prices.\n4. **Analysis:**\n  - Analyze the stock price data to observe trends, calculate statistics like the average closing price over the month, or perform other analyses that meet your objectives.\n  \n5. **Visualization (Optional):**\n  - For better understanding and representation, visualize the data using charting tools or libraries (e.g., Excel, Google Sheets, or programming libraries like Matplotlib or Plotly in Python).\nHere's a more detailed breakdown of the steps if you choose to use an API and write a script in Python:\n**Step 1: Choosing an API**\n  - Sign up for an API service like Alpha Vantage and obtain the required API key.\n**Step 2: Writing the Script**\n  - Install any necessary Python libraries (e.g., `requests`, `pandas`, `matplotlib`).\n  - Write a Python script that uses the `requests` library to make an API call with the correct endpoint and parameters (symbol for Nvidia, your API key, and the time frame for the data).\n  - Parse the JSON or CSV response and convert it into a Pandas DataFrame for ease of manipulation.\n**Step 3: Data Parsing and Cleaning**\n  - In your Python script, clean the data if necessary by removing any unnecessary columns, filling in missing values, or converting data types.\n**Step 4: Analysis and Visualization**\n  - Use Pandas to perform any desired calculations, such as moving averages.\n  - Use a library like Matplotlib or Plotly to create charts from the DataFrame, such as line graphs of the closing prices over the past month.\n**Note:**\n  - It's important to respect the terms of service of the data provider and to be aware of any rate limits on API calls to avoid being blocked.\n  - Be aware of stock market holidays and weekends when the market is closed, as these days will not have trading data.\nIf you encounter any difficulties in any of these sub-tasks, the error will likely fall into one of the following categories: issues with data access or download, errors in the script/code, or data quality issues. In each case, you would need to troubleshoot by checking access permissions, debugging the script, or examining the data for integrity, respectively.\n**********************************************************************\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\n***** Response from calling tool \"call_zQYeJEyx5gGzIxqirslGUgQi\" *****\nTo research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements, you'll need to systematically approach the task by breaking it down into the following sub-tasks:\n1. **Identify Reliable Sources:**\n  - Determine the most credible financial news websites, databases, and platforms that could have the information you’re seeking (e.g., Bloomberg, Reuters, CNBC, Nasdaq, and the official Nvidia investor relations page).\n  - Consider specialized financial data platforms like Yahoo Finance, MarketWatch, or Seeking Alpha for more detailed analyses and reports.\n  - Explore other reliable technology news outlets (e.g., TechCrunch, The Verge) that could have relevant information.\n2. **Gather Key Data:**\n  - Search for Nvidia’s latest earnings reports on their Investor Relations page, as these documents provide crucial information on the company’s financial health and outlook.\n  - Look for recent press releases on Nvidia's official website or through a news aggregator service by setting up alerts for \"Nvidia press release\" to get real-time updates.\n  - Use financial news platforms to search for Nvidia-specific news articles, filtering for the most recent ones. Include search terms like \"Nvidia stock movement,\" \"Nvidia earnings,\" or \"Nvidia financial news.\" \n3. **Analyze Information:**\n  - Read through the gathered documents and articles to identify any events or information that could have a direct impact on Nvidia's stock, such as product launches, partnerships, or changes in leadership.\n  - Pay special attention to the numbers and forward-looking statements in earnings reports that may have influenced investor sentiment and stock prices (e.g., revenue, profit margin, sales forecasts, market share, guidance).\n  - Look for any external factors that could affect the tech or semiconductor industry as a whole, such as new regulations, supply chain disruptions, or significant competitor announcements.\n4. **Compare Information with Stock Price Movements:**\n  - Overlay the dates of key events, announcements, or financial reporting with Nvidia's stock price chart to draw correlations between specific events and price fluctuations.\n  - Cross-reference the news with trading volumes to see if significant news led to increased trading activity.\n5. **Synthesize Findings:**\n  - Compile your research into a timeline or a summary document that correlates specific news items with stock price changes.\n  - Where possible, include expert analysis from your research to support your findings on why the stock moved in a particular way.\n  - Be critical of the information sources and mindful of the potential bias that can skew the perceived impact of news on stock prices.\nRemember to keep track of your sources and to cross-verify information to ensure accuracy. The stock market is influenced by numerous factors, some of which may not be immediately apparent, so it's also important to consider broader market trends and economic indicators in your analysis.\n**********************************************************************\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\n***** Response from calling tool \"call_Yb7uzCbJOFo7irlNPVzL8dem\" *****\nResearching market trends, economic factors, and industry-related developments to assess their influence on Nvidia's performance involves a systematic approach. Here's a plan that can help in fulfilling this research task:\n1. **Define Objective and Scope**:\n  - Identify the specific aspects of Nvidia's performance you are interested in (e.g., revenue growth, stock price fluctuation, product demand).\n  - Determine the time frame for your research (e.g., last 5 years, last 10 years, or around specific events).\n2. **Gather Historical Data and Performance Metrics**:\n  - Collect historical performance data for Nvidia, including sales figures, earnings reports, stock price history, and market share information.\n  - Obtain relevant financial documents, such as annual reports, 10-K filings, and investor presentations.\n  - Look for performance benchmarks or metrics within Nvidia's sector, such as GPU market penetration, competitive analysis, etc.\n3. **Analyze Market Trends and Economic Factors**:\n  - Research broad market trends and economic conditions that can impact Nvidia's industry (Semiconductors and Technology Sector), including technology adoption rates, consumer spending trends, trade policies, and global economic indicators.\n  - Use economic databases, government publications, financial news outlets, and market research reports for comprehensive information.\n  - Explore the impact of specific events (e.g., chip shortages, tariffs, pandemic) on the technology sector and Nvidia's market.\n4. **Industry-Specific Developments**:\n  - Study developments within the GPU industry and technology sector that can influence Nvidia's position, such as advancements in competing technologies, regulatory changes, or patent filings.\n  - Look into industry reports, whitepapers, tech journals, and conference proceedings for a deep dive into industry-specific insights.\n  - Monitor tech news platforms and forums that discuss developer sentiments, product reviews, and consumer feedback on products and technologies related to Nvidia’s offerings.\n5. **Synthesize Findings and Report**:\n  - Integrate insights from your comprehensive research to draw conclusions about how market trends, economic factors, and industry developments have influenced Nvidia's performance.\n  - Create a report or presentation with a narrative tying together Nvidia's performance data with the external factors you've identified. Use charts, graphs, and other visual aids to support your analysis.\n  - Formulate recommendations or insights for investors, stakeholders, or decision-makers based on your findings.\nTools you might use for this task include financial analysis software, market research databases, economic analysis tools, and various data visualization platforms. Always ensure that the sources you use for your research are reliable and up to date.\nIf the research is not yielding meaningful insights or the task seems too broad, refocusing on more specific aspects of Nvidia's performance and looking into direct cause-effect relationships in market changes and Nvidia's financial outcomes can improve the plan. Additionally, consider engaging with experts in the field or leveraging advanced analytics and predictive modeling to enhance the depth of your research.\n**********************************************************************\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\nThe process of writing a blog post about Nvidia's stock price performance over the past month can now progress to the data-gathering phase. Let's focus on the following three tasks:\n1. **Gathering data on Nvidia's stock price over the past month:**\n  - A Python script can be written to use an API service like Alpha Vantage to obtain the stock price data.\n2. **Research recent news articles, press releases, or earnings reports that could explain Nvidia's stock price movements:**\n  - Important information will be sought from reliable financial news sites and Nvidia's official channels.\n3. **Research market trends, economic factors, and industry-related developments that may have influenced Nvidia's performance:**\n  - Using economic databases, financial news outlets, and market research reports, a comprehensive analysis will be conducted on the factors impacting the industry and Nvidia's market position.\nLet's begin by focusing on creating a Python script to get the stock price data. We'll need to perform the following steps:\n1. Choose an API to retrieve the data.\n2. Write a script using the chosen API and make necessary API calls.\n3. Parse the JSON or CSV response and organize it into a useful format.\n4. Clean the data if necessary.\n5. Perform preliminary analysis and visualize the data.\nPlease note that accessing an API service like Alpha Vantage might require an API key, which could involve signing up for the service and may be subject to their terms of service, including request limits.\nShall I proceed with writing the Python script to retrieve Nvidia's stock price data over the past month?\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\nWrite script using yfinance package instead. \n--------------------------------------------------------------------------------\nassistant (to user_proxy):\nTo gather historical stock price information for Nvidia (NVDA) for the past month using the `yfinance` package, follow these steps:\n1. **Install the Package**: If you haven't already installed `yfinance`, do so by running `pip install yfinance` in your Python environment.\n2. **Import the Package**: Import `yfinance` into your script.\n3. **Request Stock Data**: Use the `yfinance` package to download the closing price data for Nvidia for the past month.\n4. **Plot the Data**: It can be useful to plot the data to visualize the stock's performance over the past month.\nBelow is the Python script that encompasses these steps:\n```python\nimport yfinance as yf\nimport matplotlib.pyplot as plt\n# Define the ticker symbol for Nvidia\nticker_symbol = 'NVDA'\n# Set the date range for the past month: assuming today is 2024-03-18\nstart_date = '2024-02-18'\nend_date = '2024-03-18'\n# Download the data from yfinance\nnvda_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n# Select only the 'Close' column for plotting\nclosing_prices = nvda_data['Close']\n# Plot the closing prices\nplt.figure(figsize=(14, 7))\nplt.plot(closing_prices, label='NVDA Closing Prices')\nplt.title('NVDA Stock Closing Prices Over the Past Month')\nplt.xlabel('Date')\nplt.ylabel('Price (USD)')\nplt.legend()\nplt.show()\n```\nHere, `yfinance` downloads the data from Yahoo Finance for Nvidia between the desired dates (`start_date` and `end_date`). The script then uses `matplotlib` to create a simple line plot of the closing prices over this period.\nWould you like me to run this script and generate the plot for you?\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\nInclude code for saving the dataset. Also include code for displaying the table. \n--------------------------------------------------------------------------------\nassistant (to user_proxy):\nTo save the dataset of Nvidia's stock prices and display the table along with plotting, you can update the script as follows:\n1. **Install Necessary Packages**: You must have `yfinance`, `matplotlib`, and `pandas` installed in your Python environment.\n2. **Import Packages**: Import the `yfinance`, `matplotlib.pyplot`, and `pandas` packages into your script.\n3. **Request Stock Data**: Use `yfinance` to download Nvidia's stock price data for the designated period.\n4. **Save the Dataset**: Save the downloaded data to a CSV file.\n5. **Display the Table**: Use Pandas DataFrame's capabilities to display the table before plotting.\n6. **Plot the Data**: Visualize the Nvidia's closing stock prices using `matplotlib`.\nHere is the Python script updated with these steps:\n```python\nimport yfinance as yf\nimport matplotlib.pyplot as plt\nimport pandas as pd\n# Define the ticker symbol for Nvidia\nticker_symbol = 'NVDA'\n# Set the date range for the past month: assuming today is 2024-03-18\nstart_date = '2024-02-18'\nend_date = '2024-03-18'\n# Download the data from yfinance\nnvda_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n# Save the data to a CSV file\nnvda_data.to_csv('NVDA_stock_data.csv')\n# Display the data table\nprint(nvda_data)\n# Select only the 'Close' column for plotting\nclosing_prices = nvda_data['Close']\n# Plot the closing prices\nplt.figure(figsize=(14, 7))\nplt.plot(closing_prices, label='NVDA Closing Prices')\nplt.title('NVDA Stock Closing Prices Over the Past Month')\nplt.xlabel('Date')\nplt.ylabel('Price (USD)')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\nThis script will download the data, save it as a CSV file named 'NVDA_stock_data.csv', print the data as a table to the console, and plot the closing prices.\nLet me know if you want me to run this code or if there are any other modifications you would like to make before execution.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nuser_proxy (to assistant):\nexitcode: 0 (execution succeeded)\nCode output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n[*********************100%%**********************] 1 of 1 completed\n         Open    High ...  Adj Close   Volume\nDate                ...            \n2024-02-20 719.469971 719.559998 ... 694.487427  70483300\n2024-02-21 680.059998 688.880005 ... 674.688293  69029800\n2024-02-22 750.250000 785.750000 ... 785.343140  86510000\n2024-02-23 807.900024 823.940002 ... 788.132996  82938800\n2024-02-26 797.000000 806.460022 ... 790.882874  50397300\n2024-02-27 793.809998 794.799988 ... 786.973083  39170500\n2024-02-28 776.200012 789.330017 ... 776.593567  39311000\n2024-02-29 790.940002 799.900024 ... 791.082886  50728900\n2024-03-01 800.000000 823.000000 ... 822.751404  47677700\n2024-03-04 841.299988 876.950012 ... 852.330017  61561600\n2024-03-05 852.700012 860.969971 ... 859.640015  52063900\n2024-03-06 880.219971 897.239990 ... 887.000000  58252000\n2024-03-07 901.580017 927.669983 ... 926.690002  60811900\n2024-03-08 951.380005 974.000000 ... 875.280029 113299600\n2024-03-11 864.289978 887.969971 ... 857.739990  67836400\n2024-03-12 880.489990 919.599976 ... 919.130005  66807500\n2024-03-13 910.549988 915.039978 ... 908.880005  63571300\n2024-03-14 895.770020 906.460022 ... 879.440002  60231800\n2024-03-15 869.299988 895.460022 ... 878.369995  64019300\n[19 rows x 6 columns]\nFigure(1400x700)\n\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\nThe script execution was successful. The historical stock price data for Nvidia (NVDA) between 2024-02-18 and 2024-03-18 has been downloaded, saved to a CSV file named 'NVDA_stock_data.csv', and the dataset has been displayed in the console output.\nHere is a preview of the dataset:\n| Date    | Open    | High    | Low     | Close    | Adj Close  | Volume   |\n|------------|-------------|-------------|-------------|-------------|-------------|------------|\n| 2024-02-20 | 719.469971 | 719.559998 | ...     | ...     | 694.487427 | 70483300  |\n| 2024-02-21 | 680.059998 | 688.880005 | ...     | ...     | 674.688293 | 69029800  |\n| 2024-02-22 | 750.250000 | 785.750000 | ...     | ...     | 785.343140 | 86510000  |\n| 2024-02-23 | 807.900024 | 823.940002 | ...     | ...     | 788.132996 | 82938800  |\n| ...    | ...     | ...     | ...     | ...     | ...     | ...    |\n| 2024-03-14 | 895.770020 | 906.460022 | ...     | ...     | 879.440002 | 60231800  |\n| 2024-03-15 | 869.299988 | 895.460022 | ...     | ...     | 878.369995 | 64019300  |\n(Note: Some columns have been truncated for display purposes.)\nAdditionally, a plot showing the closing prices of Nvidia stock over the past month was generated:\n![NVDA Stock Closing Prices Over the Past Month](attachment:nvda_closing_prices.png)\nThe plot is not displayed in the output but would be visible if the script were run in a local Python environment that supports rendering matplotlib figures. \nYou can use the saved CSV file and the dataset summary as a basis for writing your blog post on the performance of the Nvidia stock. Remember to integrate your analysis and discuss any potential factors influencing the stock price that you find in news articles and market research.\n--------------------------------------------------------------------------------\nuser_proxy (to assistant):\nwrite the blog post\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\n# Nvidia's Stock Price Performance Review: February - March 2024\nMarch 18, 2024\nIn the ever-evolving landscape of technology and finance, keeping a keen eye on industry leaders such as Nvidia Corp (NVDA) provides valuable insights into market trends and investor confidence. Over the past month, Nvidia's stock price has experienced significant movements, prompting investors and analysts to closely monitor the factors driving this volatility. In this blog post, we'll dive into the stock price performance of Nvidia from February 18 to March 18, 2024, and examine the key contributors to its fluctuations.\n## A Glimpse Into Nvidia's Stock Price Movement\nAnalysing the stock performance over the past month reveals a dynamic and eventful period for Nvidia. Starting on February 20, 2024, the stock opened at \\$719.47 and experienced a degree of instability, touching a monthly low of \\$674.68 on February 21 before surging to a stellar high of \\$785.34 on February 22. This upward momentum continued robustly until March 7, peaking at an admirable \\$926.69. However, this ascent was followed by a substantial correction, with prices adjusting to \\$878.37 by March 15, marking the end of our analysis period.\nThis turbulent period for Nvidia reflects a broader narrative of rapid adjustments and market reactions to a series of impactful events within the company and across the broader economic and technological ecosystems.\n## Unpacking the Influences on Nvidia's Stock Performance\nAs we sift through the economic news, earnings reports, and industry developments, a pattern of interrelated influences on the semiconductor giant's stock price becomes evident.\n### Product Launches and Technological Advancements\nNvidia's continued commitment to innovation is a significant driver of investor interest. The company's latest product releases and advancements in graphics processing units (GPU) often correlate with spikes in stock value. Given the company's historical patterns, it is plausible that Nvidia's announcements of enhanced GPU technologies for gaming and professional markets may have contributed positively to the observed stock price appreciation.\n### Economic and Industry Factors\nNvidia does not operate in a vacuum; it is influenced by the health of the global economy, trade policies, and tech industry dynamics. The semiconductor industry, in particular, is sensitive to supply chain disruptions and shifts in consumer demand for technology. Any news suggesting an easing of chip shortages or an uptick in demand for Nvidia's GPUs for data centers or automotive applications could be contributing factors to the company's stock trajectory.\n### Market Sentiment and Investor Confidence\nInvestor sentiment and confidence play crucial roles in stock performance. Nvidia's earnings reports often serve as a pulse check for shareholders, detailing the company's financial health and forecasts. A positive earnings report during this period may have reinforced confidence and catalysed further investments, propelling the stock prices to new heights.\nConversely, market corrections and profit-taking activities could also explain subsequent price adjustments, reminding us of the stock market's cyclical nature and investors' propensity to secure gains after a considerable run-up.\n## Conclusion\nNvidia's stock price journey between February and March 2024 exemplifies the intricate interplay between company-specific innovations, broader economic forces, and the investing community's sentiment. As with any investment, due diligence and a comprehensive understanding of market conditions are crucial to navigating the ebbs and flows.\nLooking ahead, Nvidia's future performance is likely to be swayed by its ability to maintain technological leadership, the unfolding economic climate, and its agility in adapting to industry challenges. Investors and enthusiasts alike would do well to watch the company's upcoming product revelations, quarterly reports, and industry trends for a clearer picture of what the future may hold for this semiconductor standard-bearer.\n*Disclaimer: The information provided in this analysis is for educational and entertainment purposes only and does not constitute financial advice.*\n---\nAnd there you have it—a draft blog post summarizing Nvidia's stock performance over the past month and considering various factors that could have influenced its stock price. Your audience should find this overview informative and insightful. Please note that real-life data may contain fluctuations and patterns that can change the analysis considerably, so additional research and verification are always recommended before finalizing the content.\n--------------------------------------------------------------------------------\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#approach-2-group-chat>)\nApproach 2: Group chat\n### \n[​](https://docs.ag2.ai/docs/topics/<#group-chat-for-task-decomposition>)\nGroup chat for task decomposition\nGroupchat with default auto speaker selection can be used for task decomposition. With defined roles, a groupchat manager will select different agents to perform different sub-tasks.\nCopy\n```\nuser_proxy = UserProxyAgent(\n  name=\"Admin\",\n  system_message=\"A human admin. Give the task, and send instructions to writer to refine the blog post.\",\n  code_execution_config=False,\n)\nplanner = AssistantAgent(\n  name=\"Planner\",\n  system_message=\"\"\"Planner. Given a task, please determine what information is needed to complete the task.\nPlease note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code.\n\"\"\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n)\nengineer = AssistantAgent(\n  name=\"Engineer\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n  system_message=\"\"\"Engineer. You write python/bash to retrieve relevant information. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\nDon't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n\"\"\",\n)\nwriter = AssistantAgent(\n  name=\"Writer\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n  system_message=\"\"\"Writer. Please write blogs in markdown format (with relevant titles) and put the content in pseudo ```md``` code block. You will write it for a task based on previous chat history. Don't write any code.\"\"\",\n)\nos.makedirs(\"paper\", exist_ok=True)\ncode_executor = UserProxyAgent(\n  name=\"Executor\",\n  system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n  description=\"Executor should always be called after the engineer has written code to be executed.\",\n  human_input_mode=\"ALWAYS\",\n  code_execution_config={\n    \"last_n_messages\": 3,\n    \"executor\": LocalCommandLineCodeExecutor(work_dir=\"paper\"),\n  },\n)\ngroupchat = GroupChat(\n  agents=[user_proxy, engineer, code_executor, writer, planner],\n  messages=[],\n  max_round=20,\n  speaker_selection_method=\"auto\",\n)\nmanager = GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list, \"cache_seed\": None})\n# Use Cache.disk to cache LLM responses. Change cache_seed for different responses.\nwith Cache.disk(cache_seed=41) as cache:\n  chat_history = user_proxy.initiate_chat(\n    manager,\n    message=task,\n    cache=cache,\n  )\n\n```\n\nCopy\n```\nAdmin (to chat_manager):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\nPlanner (to chat_manager):\nTo write a blog post about Nvidia's stock price performance in the past month using Python code, you would need to gather and process the following information:\n1. Stock Price Data:\n  - Historical daily closing prices of Nvidia stock (NVDA) for the past month.\n  - Volume of shares traded each day over the past month.\n  - Historical high and low prices for the past month.\n2. Company News and Events:\n  - Any Nvidia-specific news that might have affected the stock price.\n  - Relevant market news or technology sector news.\n  - Details of any earnings reports, product launches, partnerships, acquisitions, or other announcements made by Nvidia in the past month.\n3. Market Context:\n  - Overall stock market performance over the past month, especially comparing tech sector indices such as NASDAQ or S&P 500 Information Technology Sector.\n  - Performance of Nvidia's competitors' stocks.\n  - Any relevant macroeconomic indicators or events that might have affected the market.\n4. Technical Analysis Data (optional for a more in-depth analysis):\n  - Technical indicators like moving averages, RSI (Relative Strength Index), MACD (Moving Average Convergence Divergence), etc.\n  - Candlestick chart patterns for visual analysis and trend identification.\n5. Statistical Analysis:\n  - Percent change in Nvidia's stock price over the past month.\n  - Volatility measures such as standard deviation or average true range.\nTo retrieve this data using Python, you could use:\n- Financial and stock market APIs (such as Yahoo Finance, Alpha Vantage, or IEX Cloud) to get historical stock price data and technical indicators.\n- Python libraries like `requests` for making API calls to news aggregator services for company news and market context.\n- Libraries like `pandas` and `numpy` for data manipulation and statistical analysis.\n- Visualization libraries such as `matplotlib` or `seaborn` for plotting stock price data and technical indicators if visual representation is desired in the blog post.\nOnce you've gathered the data, you'd analyze and organize it to tell the story of Nvidia's stock performance in the past month, including any notable ups and downs, and the contextual reasons why these movements may have occurred.\n--------------------------------------------------------------------------------\nEngineer (to chat_manager):\nTo create a blog post about the stock performance of Nvidia in the past month, I'll need to leverage financial APIs to retrieve historical stock price data and aggregate any relevant news for analysis. One popular library to achieve this is `yfinance`, which allows Python developers to download historical market data from Yahoo Finance.\nUnfortunately, as a language model developed by OpenAI, I can't directly perform web scraping or API calls to retrieve live data. However, I can provide you with a Python script that you can run on your own machine. This script will use `yfinance` to download the historical data for Nvidia (NVDA) and perform some basic analysis on it.\nHere's a Python script to retrieve Nvidia's historical stock price data for the past month and calculate some basic performance indicators:\n```python\nimport yfinance as yf\nimport pandas as pd\n# Define the ticker symbol for Nvidia, and the start and end dates\nticker_symbol = 'NVDA'\nstart_date = '2023-02-18'\nend_date = '2023-03-18'\n# Download historical stock price data for Nvidia\ndata = yf.download(ticker_symbol, start=start_date, end=end_date)\n# Calculate percentage change in closing price from the start date to the end date\npercentage_change = ((data['Close'].iloc[-1] - data['Close'].iloc[0]) / data['Close'].iloc[0]) * 100\n# Calculate the highest and lowest closing price in the past month\nhighest_price = data['High'].max()\nlowest_price = data['Low'].min()\n# Output summary statistics\nprint(\"Summary for NVDA from\", start_date, \"to\", end_date)\nprint(\"Closing price on\", start_date, \":\", data['Close'].iloc[0])\nprint(\"Closing price on\", end_date, \":\", data['Close'].iloc[-1])\nprint(\"Percentage change in the past month:\", round(percentage_change, 2), '%')\nprint(\"Highest closing price in the past month:\", round(highest_price, 2))\nprint(\"Lowest closing price in the past month:\", round(lowest_price, 2))\n# Note: You will need to install the yfinance and pandas packages if you haven't already.\n# You can install them using pip:\n# pip install yfinance pandas\n```\nPlease note that to run this code, you'll need to have Python installed on your system, along with `yfinance` and `pandas` packages. This script will give you a basic analysis of Nvidia's stock performance over the specified time frame. However, this script does not include any contextual analysis or news aggregation. To create a comprehensive blog post, you would also include analysis and commentary on events that may have influenced the stock's performance.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nExecutor (to chat_manager):\nexitcode: 0 (execution succeeded)\nCode output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n[*********************100%%**********************] 1 of 1 completed\nSummary for NVDA from 2023-02-18 to 2023-03-18\nClosing price on 2023-02-18 : 206.5500030517578\nClosing price on 2023-03-18 : 257.25\nPercentage change in the past month: 24.55 %\nHighest closing price in the past month: 263.99\nLowest closing price in the past month: 204.21\n\n--------------------------------------------------------------------------------\nWriter (to chat_manager):\n```md\n# Nvidia's Impressive Stock Performance in February-March 2024\nIn the dynamic world of tech stocks, Nvidia Corporation (NVDA) has recently made headlines with its impressive performance over the past month. Investors and analysts alike have been watching the stock with keen interest, and for good reason. Between February 18 and March 18, 2024, NVDA has shown a considerable surge in value, providing shareholders with significant gains and outperforming many of its peers within the technology sector. Let's dive deeper into the numbers that tell the story of this Silicon Valley giant's latest financial triumph.\n## A Month of Gains\nNvidia's stock price saw a notable increase from $206.55 to $257.25—a staggering 24.55% rise within the short span of a month. This remarkable jump is not just a number; it reflects robust investor confidence and market sentiment towards the company's prospects.\n### The Highs and Lows\nEvery stock has its waves of volatility, and Nvidia was no exception. Despite the overall upward trend, the company experienced intraday highs and lows that tested the resilience of its shareholders. The trading period witnessed an all-time monthly high of $263.99, which likely coincided with positive news or earnings reports. The lowest dip was recorded at $204.21, a level that would have presented a lucrative buy opportunity for those bullish on the company's long-term growth.\n## What's Driving Nvidia's Surge?\nWhile this post provides a snapshot of Nvidia’s recent financial standing, it's also essential to explore the underlying factors contributing to the stock's performance. Here are a few potential drivers:\n- **Innovative Product Releases**: Nvidia's consistent push for innovation, especially in the realms of gaming and AI-driven technology, might have played a key role.\n- **Positive Earnings Reports**: High earnings figures can typically fuel investor enthusiasm, leading to a stock price increase.\n- **Market Trends**: Given the bigger picture, Nvidia's success could also be reflecting a larger trend in the tech market, perhaps driven by a return of investor confidence in tech stocks post a bearish phase.\n- **Strategic Partnerships or Acquisitions**: Any new alliances or acquisitions could have bolstered the company's market standing and expanded its operational reach.\n## Final Thoughts\nWhat we've seen with Nvidia is a testament to the fast-paced and rewarding nature of the tech stock market. As the company continues to push the envelope in high-performance computing and gaming, investors may have a lot to look forward to.\nRemember, while historical performance can provide valuable insights, it's always critical for investors to conduct comprehensive research and consider a multitude of factors when making investment decisions.\nThe financial figures presented here were retrieved and analyzed using financial APIs through specifically-crafted Python code, illustrating the power of combining financial insight with technological prowess.\nStay tuned to our blog for more updates and analyses on your favorite stocks!\n_Note: Data presented is for informational purposes only and should not be considered financial advice._\n```\n\n--------------------------------------------------------------------------------\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/topics/<#group-chat-with-a-custom-speaker-selection-policy>)\nGroup chat with a custom speaker selection policy\nWe allow the user to customize the logic for speaker selection for more deterministic task decomposition and workflow control.\nHere, we follow this procedure to solve the task: 1. Use planner to determine relevant information needed. 2. Use engineer to gather the information. 3. Use writer to write the report. 4. Allow user to comment on the report and ask write to adjust the report based on the comment.\nCopy\n```\nuser_proxy = UserProxyAgent(\n  name=\"Admin\",\n  system_message=\"A human admin. Give the task, and send instructions to writer to refine the blog post.\",\n  code_execution_config=False,\n)\nplanner = AssistantAgent(\n  name=\"Planner\",\n  system_message=\"\"\"Planner. Given a task, please determine what information is needed to complete the task.\nPlease note that the information will all be retrieved using Python code. Please only suggest information that can be retrieved using Python code.\n\"\"\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n)\nengineer = AssistantAgent(\n  name=\"Engineer\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n  system_message=\"\"\"Engineer. You write python/bash to retrieve relevant information. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\nDon't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\nIf the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n\"\"\",\n)\nwriter = AssistantAgent(\n  name=\"Writer\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n  system_message=\"\"\"Writer. Please write blogs in markdown format (with relevant titles) and put the content in pseudo ```md``` code block. You will write it for a task based on previous chat history. \"\"\",\n)\ncode_executor = UserProxyAgent(\n  name=\"Executor\",\n  system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n  human_input_mode=\"ALWAYS\",\n  code_execution_config={\n    \"last_n_messages\": 3,\n    \"executor\": LocalCommandLineCodeExecutor(work_dir=\"paper\"),\n  },\n)\n\ndef custom_speaker_selection_func(last_speaker: Agent, groupchat: GroupChat):\n  \"\"\"Define a customized speaker selection function.\n  A recommended way is to define a transition for each speaker in the groupchat.\n  Returns:\n    Return an `Agent` class or a string from ['auto', 'manual', 'random', 'round_robin'] to select a default method to use.\n  \"\"\"\n  messages = groupchat.messages\n  if len(messages) <= 1:\n    # first, let the engineer retrieve relevant data\n    return planner\n  if last_speaker is planner:\n    # if the last message is from planner, let the engineer to write code\n    return engineer\n  elif last_speaker is user_proxy:\n    if messages[-1][\"content\"].strip() != \"\":\n      # If the last message is from user and is not empty, let the writer to continue\n      return writer\n  elif last_speaker is engineer:\n    if \"```python\" in messages[-1][\"content\"]:\n      # If the last message is a python code block, let the executor to speak\n      return code_executor\n    else:\n      # Otherwise, let the engineer to continue\n      return engineer\n  elif last_speaker is code_executor:\n    if \"exitcode: 1\" in messages[-1][\"content\"]:\n      # If the last message indicates an error, let the engineer to improve the code\n      return engineer\n    else:\n      # Otherwise, let the writer to speak\n      return writer\n  elif last_speaker is writer:\n    # Always let the user to speak after the writer\n    return user_proxy\n  else:\n    # default to auto speaker selection method\n    return \"auto\"\n\ngroupchat = GroupChat(\n  agents=[user_proxy, engineer, writer, code_executor, planner],\n  messages=[],\n  max_round=20,\n  speaker_selection_method=custom_speaker_selection_func,\n)\nmanager = GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config_list, \"cache_seed\": None})\nwith Cache.disk(cache_seed=41) as cache:\n  groupchat_history_custom = user_proxy.initiate_chat(\n    manager,\n    message=task,\n    cache=cache,\n  )\n\n```\n\nCopy\n```\nAdmin (to chat_manager):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\nPlanner (to chat_manager):\nTo write a blog post about Nvidia's stock price performance in the past month using Python code, you would need to gather and process the following information:\n1. Stock Price Data:\n  - Historical daily closing prices of Nvidia stock (NVDA) for the past month.\n  - Volume of shares traded each day over the past month.\n  - Historical high and low prices for the past month.\n2. Company News and Events:\n  - Any Nvidia-specific news that might have affected the stock price.\n  - Relevant market news or technology sector news.\n  - Details of any earnings reports, product launches, partnerships, acquisitions, or other announcements made by Nvidia in the past month.\n3. Market Context:\n  - Overall stock market performance over the past month, especially comparing tech sector indices such as NASDAQ or S&P 500 Information Technology Sector.\n  - Performance of Nvidia's competitors' stocks.\n  - Any relevant macroeconomic indicators or events that might have affected the market.\n4. Technical Analysis Data (optional for a more in-depth analysis):\n  - Technical indicators like moving averages, RSI (Relative Strength Index), MACD (Moving Average Convergence Divergence), etc.\n  - Candlestick chart patterns for visual analysis and trend identification.\n5. Statistical Analysis:\n  - Percent change in Nvidia's stock price over the past month.\n  - Volatility measures such as standard deviation or average true range.\nTo retrieve this data using Python, you could use:\n- Financial and stock market APIs (such as Yahoo Finance, Alpha Vantage, or IEX Cloud) to get historical stock price data and technical indicators.\n- Python libraries like `requests` for making API calls to news aggregator services for company news and market context.\n- Libraries like `pandas` and `numpy` for data manipulation and statistical analysis.\n- Visualization libraries such as `matplotlib` or `seaborn` for plotting stock price data and technical indicators if visual representation is desired in the blog post.\nOnce you've gathered the data, you'd analyze and organize it to tell the story of Nvidia's stock performance in the past month, including any notable ups and downs, and the contextual reasons why these movements may have occurred.\n--------------------------------------------------------------------------------\nEngineer (to chat_manager):\nTo create a blog post about the stock performance of Nvidia in the past month, I'll need to leverage financial APIs to retrieve historical stock price data and aggregate any relevant news for analysis. One popular library to achieve this is `yfinance`, which allows Python developers to download historical market data from Yahoo Finance.\nUnfortunately, as a language model developed by OpenAI, I can't directly perform web scraping or API calls to retrieve live data. However, I can provide you with a Python script that you can run on your own machine. This script will use `yfinance` to download the historical data for Nvidia (NVDA) and perform some basic analysis on it.\nHere's a Python script to retrieve Nvidia's historical stock price data for the past month and calculate some basic performance indicators:\n```python\nimport yfinance as yf\nimport pandas as pd\n# Define the ticker symbol for Nvidia, and the start and end dates\nticker_symbol = 'NVDA'\nstart_date = '2023-02-18'\nend_date = '2023-03-18'\n# Download historical stock price data for Nvidia\ndata = yf.download(ticker_symbol, start=start_date, end=end_date)\n# Calculate percentage change in closing price from the start date to the end date\npercentage_change = ((data['Close'].iloc[-1] - data['Close'].iloc[0]) / data['Close'].iloc[0]) * 100\n# Calculate the highest and lowest closing price in the past month\nhighest_price = data['High'].max()\nlowest_price = data['Low'].min()\n# Output summary statistics\nprint(\"Summary for NVDA from\", start_date, \"to\", end_date)\nprint(\"Closing price on\", start_date, \":\", data['Close'].iloc[0])\nprint(\"Closing price on\", end_date, \":\", data['Close'].iloc[-1])\nprint(\"Percentage change in the past month:\", round(percentage_change, 2), '%')\nprint(\"Highest closing price in the past month:\", round(highest_price, 2))\nprint(\"Lowest closing price in the past month:\", round(lowest_price, 2))\n# Note: You will need to install the yfinance and pandas packages if you haven't already.\n# You can install them using pip:\n# pip install yfinance pandas\n```\nPlease note that to run this code, you'll need to have Python installed on your system, along with `yfinance` and `pandas` packages. This script will give you a basic analysis of Nvidia's stock performance over the specified time frame. However, this script does not include any contextual analysis or news aggregation. To create a comprehensive blog post, you would also include analysis and commentary on events that may have influenced the stock's performance.\n--------------------------------------------------------------------------------\n>>>>>>>> NO HUMAN INPUT RECEIVED.\n>>>>>>>> USING AUTO REPLY...\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nExecutor (to chat_manager):\nexitcode: 0 (execution succeeded)\nCode output: /Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n[*********************100%%**********************] 1 of 1 completed\nSummary for NVDA from 2023-02-18 to 2023-03-18\nClosing price on 2023-02-18 : 206.5500030517578\nClosing price on 2023-03-18 : 257.25\nPercentage change in the past month: 24.55 %\nHighest closing price in the past month: 263.99\nLowest closing price in the past month: 204.21\n\n--------------------------------------------------------------------------------\nWriter (to chat_manager):\n```md\n# Nvidia's Stock Performance: A Remarkable Month of Growth\n## A Robust Comeback in the Tech Sector\nThe past month has seen Nvidia (NVDA) demonstrate a considerable rebound, with its stock price surging upwards by a striking 24.55%. Nvidia, a giant in the graphics processing unit (GPU) market, continues to illustrate its resilience and capacity for growth in a fluctuating tech landscape.\n### Key Performance Highlights\n- **Closing Price on 2023-02-18**: $206.55\n- **Closing Price on 2023-03-18**: $257.25\n- **Percentage Change**: An increase of 24.55% over the past month\n- **Highest Price (Past Month)**: $263.99\n- **Lowest Price (Past Month)**: $204.21\n## Factors Fueling Growth\nSeveral factors have combined to influence Nvidia's stock price favorably:\n1. **Strong Financials**: Nvidia's recent earnings reports might have surpassed analyst expectations, showcasing the company's continued profitability and operational efficiency.\n2. **Innovative Product Launches**: Any new product releases or announcements, particularly those pertaining to their core GPU business or expansion into nascent markets, could have provided the stock with upward momentum.\n3. **Strategic Partnerships**: New partnerships or collaborations, especially with major industry players, might have bolstered investor confidence in Nvidia's market positioning.\n4. **Industry Trends**: As remote work and digital entertainment remain prevalent, demand for Nvidia's products may have kept soaring, reflecting positively on its stock performance.\n## Looking Ahead\nThe stock's substantial gain stands as a testament to Nvidia's potential in an increasingly digital world, where GPUs extend far beyond gaming into AI, data centers, and autonomous vehicles.\nBearing witness to such robust performance, investors may remain optimistic about Nvidia's future. Keeping an eye on future product developments, market trends, and Nvidia's strategic maneuvers will be crucial for those invested in the tech sector.\n### Disclaimer\nIt's worth noting that past performance is not indicative of future results. Investors should always conduct their own research or consult with financial advisors before making any investment decisions.\nFor more detailed insights and the latest updates, stay tuned for future analyses on the tech industry and stock market trends.\n```\n--------------------------------------------------------------------------------\n\n```\n\n**Below is the markdown content generated by the code above:**\n# \n[​](https://docs.ag2.ai/docs/topics/<#nvidias-stock-performance-a-remarkable-month-of-growth>)\nNvidia’s Stock Performance: A Remarkable Month of Growth\n## \n[​](https://docs.ag2.ai/docs/topics/<#a-robust-comeback-in-the-tech-sector>)\nA Robust Comeback in the Tech Sector\nThe past month has seen Nvidia (NVDA) demonstrate a considerable rebound, with its stock price surging upwards by a striking 24.55%. Nvidia, a giant in the graphics processing unit (GPU) market, continues to illustrate its resilience and capacity for growth in a fluctuating tech landscape.\n### \n[​](https://docs.ag2.ai/docs/topics/<#key-performance-highlights>)\nKey Performance Highlights\n  * **Closing Price on 2023-02-18** : $206.55\n  * **Closing Price on 2023-03-18** : $257.25\n  * **Percentage Change** : An increase of 24.55% over the past month\n  * **Highest Price (Past Month)** : $263.99\n  * **Lowest Price (Past Month)** : $204.21\n\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#factors-fueling-growth>)\nFactors Fueling Growth\nSeveral factors have combined to influence Nvidia’s stock price favorably:\n  1. **Strong Financials** : Nvidia’s recent earnings reports might have surpassed analyst expectations, showcasing the company’s continued profitability and operational efficiency.\n  2. **Innovative Product Launches** : Any new product releases or announcements, particularly those pertaining to their core GPU business or expansion into nascent markets, could have provided the stock with upward momentum.\n  3. **Strategic Partnerships** : New partnerships or collaborations, especially with major industry players, might have bolstered investor confidence in Nvidia’s market positioning.\n  4. **Industry Trends** : As remote work and digital entertainment remain prevalent, demand for Nvidia’s products may have kept soaring, reflecting positively on its stock performance.\n\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#looking-ahead>)\nLooking Ahead\nThe stock’s substantial gain stands as a testament to Nvidia’s potential in an increasingly digital world, where GPUs extend far beyond gaming into AI, data centers, and autonomous vehicles.\nBearing witness to such robust performance, investors may remain optimistic about Nvidia’s future. Keeping an eye on future product developments, market trends, and Nvidia’s strategic maneuvers will be crucial for those invested in the tech sector.\n### \n[​](https://docs.ag2.ai/docs/topics/<#disclaimer>)\nDisclaimer\nIt’s worth noting that past performance is not indicative of future results. Investors should always conduct their own research or consult with financial advisors before making any investment decisions.\nFor more detailed insights and the latest updates, stay tuned for future analyses on the tech industry and stock market trends.\n## \n[​](https://docs.ag2.ai/docs/topics/<#approach-3-use-autobuild>)\nApproach 3. Use AutoBuild\n[AutoBuild](https://docs.ag2.ai/docs/topics/<https:/docs.ag2.ai/blog/2023-11-26-Agent-AutoBuild/index>) is an effective approach that generates a group of experts and use their conversation to solve a task. In AutoBuild, each expert handles a part of the task, therefore effectively and comprehensively solving it.\nCopy\n```\nAUTOBUILD_SYSTEM_MESSAGE = \"\"\"You are a manager of a group of advanced experts, your primary objective is to delegate the resolution of tasks to other experts through structured dialogue and derive conclusive insights from their conversation summarization.\nWhen a task is assigned, it's crucial to assess its constraints and conditions for completion. If feasible, the task should be divided into smaller, logically consistent subtasks. Following this division, you have the option to address these subtasks by forming a team of agents using the \"autobuild\" tool.\nUpon the completion of all tasks and verifications, you should conclude the operation and reply \"TERMINATE\".\n\"\"\"\nuser_proxy = UserProxyAgent(\n  name=\"user_proxy\",\n  human_input_mode=\"NEVER\",\n  code_execution_config=False,\n)\nautobuild_assistant = AssistantAgent(\n  name=\"Autobuild Assistant\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n)\n\ndef autobuild_reply(recipient, messages, sender, config):\n  last_msg = messages[-1][\"content\"]\n  builder = agent_builder.AgentBuilder(\n    config_file_or_env=\"/Users/ekzhu/autogen/OAI_CONFIG_LIST\",\n    builder_model=\"gpt-4-1106-preview\",\n    agent_model=\"gpt-4-1106-preview\",\n  )\n  agent_list, agent_configs = builder.build(\n    last_msg, default_llm_config={\"config_list\": config_list, \"cache_seed\": None}\n  )\n  # start nested chat\n  nested_group_chat = GroupChat(\n    agents=agent_list,\n    messages=[],\n  )\n  manager = GroupChatManager(groupchat=nested_group_chat, llm_config={\"config_list\": config_list, \"cache_seed\": None})\n  chat_res = agent_list[0].initiate_chat(\n    manager, message=agent_configs.get(\"building_task\", last_msg), summary_method=\"reflection_with_llm\"\n  )\n  return True, chat_res.summary\n\nautobuild_assistant.register_reply([Agent, None], autobuild_reply)\nwith Cache.disk(cache_seed=41) as cache:\n  user_proxy.initiate_chat(autobuild_assistant, message=task, max_turns=1)\n\n```\n\nCopy\n```\nuser_proxy (to Autobuild Assistant):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\n==> Generating agents...\n['financial_analyst_nvidia_stocks', 'data_scientist_stock_market_analysis', 'seo_content_writer_tech_finance', 'editor_finance_blogposts', 'python_data_scraper_stock_prices'] are generated.\n==> Generating system message...\nPreparing system message for financial_analyst_nvidia_stocks\nPreparing system message for data_scientist_stock_market_analysis\nPreparing system message for seo_content_writer_tech_finance\nPreparing system message for editor_finance_blogposts\nPreparing system message for python_data_scraper_stock_prices\n==> Generating description...\nPreparing description for financial_analyst_nvidia_stocks\nPreparing description for data_scientist_stock_market_analysis\nPreparing description for seo_content_writer_tech_finance\nPreparing description for editor_finance_blogposts\nPreparing description for python_data_scraper_stock_prices\n==> Creating agents...\nCreating agent financial_analyst_nvidia_stocks with backbone gpt-4-1106-preview...\nCreating agent data_scientist_stock_market_analysis with backbone gpt-4-1106-preview...\nCreating agent seo_content_writer_tech_finance with backbone gpt-4-1106-preview...\nCreating agent editor_finance_blogposts with backbone gpt-4-1106-preview...\nCreating agent python_data_scraper_stock_prices with backbone gpt-4-1106-preview...\nAdding user console proxy...\nUser_console_and_code_interpreter (to chat_manager):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\nseo_content_writer_tech_finance (to chat_manager):\n# Understanding Nvidia's Stock Performance Over the Past Month\nIn recent weeks, the stock market has seen its fair share of volatility, and Nvidia's shares have been no exception. Nvidia Corporation, the technology giant known for its graphics processing units (GPUs) for gaming and professional markets, as well as its automotive and mobile processing products, has experienced a whirlwind of price movements. In this post, we'll scrutinize the stock price performance of Nvidia in the past month, exploring the possible reasons behind the fluctuations and analysing what it might mean for investors.\n### A Look at the Figures\nAs of the close of the market on March 17th, 2024, Nvidia's stock stood at approximately [insert closing price here], which represents a [insert percentage change] change over the last month. Data over the period reveals that the highest point the stock reached was [insert highest price], while the lowest was [insert lowest price]. The stock performance over the month demonstrated both resilience in the face of market uncertainty and susceptibility to broader economic forces.\n### Catalysts for Price Movement\nSeveral factors have influenced Nvidia's stock price performance over the past month:\n1. **Market Conditions:** The general state of the stock market, driven by macroeconomic indicators, can heavily impact individual stock performances. Interest rate adjustment rumors, inflation data, and strength or weakness in the broader technology sector are all primary contributors to the swings in Nvidia's stock price.\n2. **Earnings Report:** Nvidia's latest quarterly earnings report was released [insert release date], which often triggers a short-term reaction in stock price. The report highlighted [insert key highlights and figures], which led to an initial [insert reaction to the report, e.g., surge, dip, etc.] in stock value.\n3. **Product Releases:** Nvidia's announcement of [insert any new product or service], expected to push the technological envelope, has captured investors' interest, with the potential for future revenue growth factoring into stock valuations.\n4. **Industry Competition:** Actions from competitors may also have repercussions for Nvidia's stock, especially when major rivals release rival products or when there is significant news regarding semiconductor availability or supply chain issues that affect the whole industry.\n5. **Regulatory News:** Any changes in regulations that affect Nvidia's business operations, especially in large markets such as the United States, Europe, or China, can also influence investor confidence and, thus, share prices.\n### Technical and Fundamental Analysis\nTechnical analysts, who study statistical trends from trading activity, might note particular patterns in Nvidia's stock movements. Support and resistance levels, moving averages, and momentum indicators such as the Relative Strength Index (RSI) or Moving Average Convergence Divergence (MACD), could all hint at potential future performance based on past and current price actions.\nMeanwhile, fundamental analysis digs deep into Nvidia's financial health and market position, reviewing revenue predictions, earnings growth, and profit margins. An assessment of the company's management effectiveness, competitive advantage, and market share may also help to gauge the stock's inherent value.\n### Forward-Looking Statement\nThe technology and finance sectors are notoriously difficult to predict. While historical data can provide context, they do not guarantee future performance. Nvidia's future stock prices will continue to be influenced by a blend of company-specific events and broader market conditions. Investors should remain attuned to Nvidia's product pipeline, technological advancements, and any geopolitical or economic updates that could sway market sentiment.\nInvesting in stocks always comes with a risk, and Nvidia is not immune to such uncertainties. Thus, a well-balanced, diversified portfolio is generally advisable to mitigate industry-specific risks.\n### Conclusion\nThe trajectory of Nvidia's stock price signifies the dynamic and complex nature of investing in technology firms. On one hand, Nvidia demonstrates strong fundamentals and a history of innovation; on the other, external factors beyond the company's control show just how interconnected global economic forces can be. Prudent investors will monitor these developments closely and make informed decisions based on both technical indicators and fundamental performance.\nPlease remember that this post is for informational purposes only and is not financial advice. Always conduct your own research or consult with a financial advisor before making investment decisions.\n*Note: All data provided in this post are for illustrative purposes only. For real-time and accurate financial statistics, please consult reliable financial news sources, stock market databases, or financial services providers.*\n---\nAs an SEO content writer, I need to ensure that the information I provide is accurate and up-to-date. Given the scope of the task, I must mention that the stock prices and percentage changes mentioned in the article are placeholders and should be replaced with current data for publication. To do this, I would\n--------------------------------------------------------------------------------\npython_data_scraper_stock_prices (to chat_manager):\n```python\nimport yfinance as yf\nimport pandas as pd\nfrom datetime import datetime, timedelta\n# Define the ticker symbol for Nvidia\ntickerSymbol = 'NVDA'\n# Get data on this ticker\ntickerData = yf.Ticker(tickerSymbol)\n# Define the date range: one month back from today\ntoday = datetime.now()\none_month_ago = today - timedelta(days=30)\n# Get the historical prices for this ticker within the specified date range\ntickerDf = tickerData.history(period='1d', start=one_month_ago, end=today)\n# Extract closing prices and date information\nclosing_prices = tickerDf['Close']\ndates = closing_prices.index\n# Calculate the percentage change over the past month\npercentage_change = ((closing_prices[-1] - closing_prices[0]) / closing_prices[0]) * 100\n# Find the highest and lowest closing prices over the past month\nhighest_price = closing_prices.max()\nlowest_price = closing_prices.min()\n# Present the retrieved data\nprint(f\"Nvidia's Stock Price Performance Over the Past Month\")\nprint(f\"Date Range: {dates[0].date()} to {dates[-1].date()}\\n\")\nprint(f\"Closing Price on {dates[0].date()}: ${closing_prices[0]:.2f}\")\nprint(f\"Closing Price on {dates[-1].date()}: ${closing_prices[-1]:.2f}\")\nprint(f\"Highest Closing Price: ${highest_price:.2f}\")\nprint(f\"Lowest Closing Price: ${lowest_price:.2f}\")\nprint(f\"Percentage Change Over the Past Month: {percentage_change:.2f}%\\n\")\n```\nPlease run this script to get the current data for Nvidia's stock performance over the past month. The output will provide essential figures that can be used to update the placeholders in the previously drafted blog post. Make sure to have `yfinance` installed in your Python environment; you can install it using `pip install yfinance` if it's not already installed.\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\nUser_console_and_code_interpreter (to chat_manager):\nexitcode: 0 (execution succeeded)\nCode output: \nNvidia's Stock Price Performance Over the Past Month\nDate Range: 2024-02-20 to 2024-03-18\nClosing Price on 2024-02-20: $694.49\nClosing Price on 2024-03-18: $884.55\nHighest Closing Price: $926.69\nLowest Closing Price: $674.69\nPercentage Change Over the Past Month: 27.37%\n\n--------------------------------------------------------------------------------\neditor_finance_blogposts (to chat_manager):\n# Understanding Nvidia's Stock Performance Over the Past Month\nIn recent weeks, the stock market has seen its fair share of volatility, and Nvidia's shares have been no exception. Nvidia Corporation, the technology giant known for its graphics processing units (GPUs) for gaming and professional markets, as well as its automotive and mobile processing products, has experienced a whirlwind of price movements. In this post, we'll scrutinize the stock price performance of Nvidia in the past month, exploring the possible reasons behind the fluctuations and analyzing what it might mean for investors.\n### A Look at the Figures\nAs of the close of the market on March 18th, 2024, Nvidia's stock stood at approximately $884.55, which represents a 27.37% change over the last month. Data over the period reveals that the highest point the stock reached was $926.69, while the lowest was $674.69. The stock performance over the month demonstrated both resilience in the face of market uncertainty and susceptibility to broader economic forces.\n### Catalysts for Price Movement\nSeveral factors have influenced Nvidia's stock price performance over the past month:\n1. **Market Conditions:** The general state of the stock market, driven by macroeconomic indicators, can heavily impact individual stock performances. Interest rate adjustment rumors, inflation data, and strength or weakness in the broader technology sector are all primary contributors to the swings in Nvidia's stock price.\n2. **Earnings Reports and Projections:** Given that earnings reports are typically released quarterly and have the potential to greatly affect stock prices, it's possible that a recent Nvidia earnings report or a projection of a future earnings report has played a role in stock price changes over the past month. Strong or weak financial performance, as would be reflected in such reports, could have been a catalyst for investor reaction.\n3. **Product Releases and Developments:** Nvidia is at the forefront of GPU technology and any announcements related to new products, updates to existing product lines, or advancements in research and development can have a significant impact on the investor outlook and, by extension, on the stock price.\n4. **Industry Competition and Market Share:** Nvidia's position compared to its competitors is also a key factor in its stock performance. Any fluctuations in market share or competitive edge could affect investor confidence and stock valuation.\n5. **Regulatory Changes and Global Events:** Regulatory changes in key markets or global events that impact the technology sector, trade relations, or supply chains can lead to shifts in stock prices as investors reassess their risk and potential returns.\n### Technical and Fundamental Analysis\nTechnical analysts, who study statistical trends from trading activity, might have identified particular patterns in Nvidia's stock movements suggesting the recent momentum. Trends such as support and resistance levels and other indicators like the Relative Strength Index (RSI) or Moving Average Convergence Divergence (MACD) provide insights that could potentially inform investors about the stock’s short-term movements.\nMeanwhile, fundamental analysis reveals the company's intrinsic value by looking at financial statements, market position, and growth prospects. Nvidia's innovation in technology and the strategic positioning of their products and services are aspects that are evaluated to make long-term investment decisions.\n### Forward-Looking Statements\nDespite the challenges of accurately predicting the stock market, Nvidia's recent performance indicates investor confidence in the company's growth potential and resilience. However, as is always the case with stock investments, past performance is not indicative of future results, and external factors can have unpredictable impacts on stock prices.\nInvesting in technology stocks like Nvidia often requires a keen eye on both company-specific news and broader economic indicators. Diversification remains a recommended strategy to mitigate potential risks associated with market volatility.\n### Conclusion\nThe past month's impressive rally in Nvidia's stock price underscores the company's strong performance and the market's optimistic assessment of its future outlook. However, investors must remain vigilant and informed as they navigate the ever-changing landscape of the technology sector. With careful analysis and consideration of both external factors and internal company developments, investors can make more informed decisions on whether to buy, hold, or sell Nvidia stock.\nPlease note: This blog post is for informational purposes only and should not be considered financial advice. Investors should always conduct their own research or seek professional advice before making investment decisions.\n---\nWith the current figures now in hand, I have replaced the placeholders with accurate and updated data. The contextual analysis and underlying factors contributing to Nvidia's stock performance are also discussed, providing readers a comprehensive overview. If there are any further changes or updates needed, please let me know. Otherwise, I believe the task has been completed satisfactorily.\n--------------------------------------------------------------------------------\neditor_finance_blogposts (to chat_manager):\nTERMINATE\n--------------------------------------------------------------------------------\nAutobuild Assistant (to user_proxy):\nNvidia's stock price has seen a 27.37% increase over the past month with a closing price of $884.55 on March 18th, 2024. The stock fluctuated, reaching a high of $926.69 and a low of $674.69 during this time. Factors influencing the stock's performance include overall market conditions, earnings reports, product releases and developments, competition, and regulatory changes. Both technical and fundamental analyses are used to understand stock movements and make investment decisions, but investing in technology stocks carries risks and requires staying informed about industry and economic trends. Past performance does not necessarily predict future results, and investors are advised to research and seek professional advice before making investment decisions.\n--------------------------------------------------------------------------------\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/topics/<#approach-4-customize-a-task-scheduler>)\nApproach 4: Customize a task scheduler\nA more general approach is to customize a task scheduler agent. Given a task, the agent decomposes the task into sub-tasks and assign them to agents with different expertise.\nCopy\n```\n# Setting up code executor.\nos.makedirs(\"coding\", exist_ok=True)\ncode_executor = LocalCommandLineCodeExecutor(work_dir=\"coding\")\n\ndef run_meta_prompting(expert_name: str, expert_identity: str, task: str) -> str:\n  \"\"\"Run Meta-prompting to solve the task.\n  The method is adapted from \"Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding\".\n  Paper available at https://arxiv.org/abs/2401.12954\n  \"\"\"\n  print(\"Running meta prompting...\")\n  print(\"Querying expert: \", expert_name)\n  expert = AssistantAgent(\n    name=expert_name,\n    human_input_mode=\"NEVER\",\n    llm_config={\"config_list\": config_list, \"cache_seed\": None},\n    system_message='You are an AI assistant that helps people find information. Please answer the following question. Once you have determined the final answer, please present it using the format below:\\n\\n>> FINAL ANSWER:\\n\"\"\"\\n[final answer]\\n\"\"\"',\n    max_consecutive_auto_reply=1,\n  )\n  user_proxy = UserProxyAgent(\n    name=\"proxy\",\n    human_input_mode=\"NEVER\",\n    default_auto_reply=\"TERMINATE\",\n    code_execution_config={\"executor\": code_executor},\n    max_consecutive_auto_reply=1,\n  )\n  task += \"\\nYou have access to python code interpreter. Suggest python code block starting with '```python' and the code will be automatically executed. You can use code to solve the task or for result verification. You should always use print statement to get the value of a variable.\"\n  user_proxy.initiate_chat(expert, message=expert_identity + \"\\n\" + task, silent=True)\n  expert_reply = user_proxy.chat_messages[expert][1][\"content\"]\n  proxy_reply = user_proxy.chat_messages[expert][2][\"content\"]\n  if proxy_reply != \"TERMINATE\":\n    code_result = proxy_reply[proxy_reply.find(\"Code output:\") + len(\"Code output:\") :].strip()\n    expert_reply += f\"\\nThis is the output of the code blocks when executed:\\n{code_result}\"\n  else:\n    expert_reply.replace(\n      \"FINAL ANSWER:\",\n      f\"{expert_name}'s final answer:\\n\",\n    )\n  return expert_reply\n\nclass MetaAgent(ConversableAgent):\n  SYSTEM_MESSAGE = \"\"\"You are Meta-Expert, an extremely clever expert with the unique ability to collaborate with multiple experts (such as Expert Problem Solver, Expert Mathematician, Expert Essayist, etc.) to tackle any task and solve any complex problems. Some experts are adept at generating solutions, while others excel in verifying answers and providing valuable feedback.\nAs Meta-Expert, your role is to oversee the communication between the experts, effectively using their skills to answer a given question while applying your own critical thinking and verification abilities.\nTo communicate with a expert, call function \"meta_prompting\" with the expert's name, identity information and the task that needs to be solved. The function will return a response from the expert.\nEnsure that your instructions are clear and unambiguous, and include all necessary information within the triple quotes. You should assign personas to the experts (e.g., \"You are a physicist specialized in...\").\nYou can interact with only one expert at a time, and break complex problems into smaller, solvable tasks. Each interaction is treated as an isolated event, so include all relevant details in every call.\nRefrain from repeating the very same questions to experts. Examine their responses carefully and seek clarification if required, keeping in mind they don't recall past interactions.\nUpon the completion of all tasks and verifications, you should conclude the result and reply \"TERMINATE\".\n\"\"\"\n  TOOL = {\n    \"type\": \"function\",\n    \"function\": {\n      \"name\": \"meta_prompting\",\n      \"description\": \"Solve a task by querying an expert. Provide the expert identity and the task that needs to be solved, and the function will return the response of the expert.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"task\": {\n            \"type\": \"string\",\n            \"description\": \"[REQUIRED] The task that needs to be solved by the expert.\",\n          },\n          \"expert_name\": {\n            \"type\": \"string\",\n            \"description\": \"[REQUIRED] Name of the expert. Should follow the format: Expert xxx.\",\n          },\n          \"expert_identity\": {\n            \"type\": \"string\",\n            \"description\": \"[REQUIRED] A high-quality description about the most capable and suitable expert to answer the instruction. In second person perspective. For example, You are a linguist, well-versed in the study of language and its structures. You are equipped with a good understanding of grammar rules and can differentiate between nouns, verbs, adjectives, adverbs, etc. You can quickly and accurately identify the parts of speech in a sentence and explain the role of each word in the sentence. Your expertise in language and grammar is highly valuable in analyzing and understanding the nuances of communication.\",\n          },\n        },\n      },\n    },\n  }\n  def __init__(\n    self,\n    name: str,\n    system_message: Optional[str] = None,\n    llm_config: Optional[Union[Dict, Literal[False]]] = None,\n    is_termination_msg: Optional[Callable[[Dict], bool]] = None,\n    max_consecutive_auto_reply: Optional[int] = None,\n    human_input_mode: Literal[\"ALWAYS\", \"NEVER\", \"TERMINATE\"] = \"NEVER\",\n    code_execution_config: Optional[Union[Dict, Literal[False]]] = False,\n    description: Optional[\n      str\n    ] = \"A helpful AI assistant that can build a group of agents at a proper time to solve a task.\",\n    **kwargs,\n  ):\n    super().__init__(\n      name=name,\n      system_message=self.SYSTEM_MESSAGE,\n      llm_config=llm_config,\n      is_termination_msg=is_termination_msg,\n      max_consecutive_auto_reply=max_consecutive_auto_reply,\n      human_input_mode=human_input_mode,\n      code_execution_config=code_execution_config,\n      description=description,\n      **kwargs,\n    )\n    self.update_tool_signature(self.TOOL, is_remove=False)\n\n```\n\nCopy\n```\nproxy = UserProxyAgent(\n  name=\"proxy\",\n  human_input_mode=\"NEVER\",\n  code_execution_config=False,\n  max_consecutive_auto_reply=1,\n  default_auto_reply=\"Continue. If you think the task is solved, please reply me only with 'TERMINATE'.\",\n)\nproxy.register_function(function_map={\"meta_prompting\": lambda **args: run_meta_prompting(**args)})\nagent = MetaAgent(\n  name=\"Meta-Expert\",\n  llm_config={\"config_list\": config_list, \"cache_seed\": None},\n  human_input_mode=\"NEVER\",\n  max_consecutive_auto_reply=15,\n)\nwith Cache.disk(cache_seed=41) as cache:\n  proxy.initiate_chat(agent, message=task, cache=cache)\n\n```\n\nCopy\n```\nproxy (to Meta-Expert):\nToday is 2024-03-18. Write a blogpost about the stock price performance of Nvidia in the past month.\n--------------------------------------------------------------------------------\nMeta-Expert (to proxy):\n***** Suggested tool Call (call_NjFZnleIFlJFTHcBeHPVJyXx): meta_prompting *****\nArguments: \n{\n \"task\": \"Can you provide a comprehensive analysis of Nvidia's stock price performance over the past month?\",\n \"expert_name\": \"Expert Financial Analyst\",\n \"expert_identity\": \"You are a highly qualified financial analyst with extensive experience in stock market analysis. You have advanced knowledge of financial markets, investment strategies, and the ability to interpret complex data sets. You are adept at using analytical tools and have a keen eye for identifying trends and patterns in stock price movements. Your insights and analyses are highly sought after by investors looking to make informed decisions.\"\n}\n*******************************************************************************\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING FUNCTION meta_prompting...\nRunning meta prompting...\nQuerying expert: Expert Financial Analyst\n>>>>>>>> EXECUTING CODE BLOCK (inferred language is python)...\nproxy (to Meta-Expert):\nproxy (to Meta-Expert):\n***** Response from calling tool \"call_NjFZnleIFlJFTHcBeHPVJyXx\" *****\nAs an AI language model developed by OpenAI, I don't have real-time data access or the ability to fetch live stock prices. However, you can obtain Nvidia's stock price performance by using financial data APIs such as Yahoo Finance, Alpha Vantage, or others that provide stock price data.\nTo analyze Nvidia’s stock price performance over the past month, you can use the `yfinance` library in Python, which allows you to fetch historical stock price data from Yahoo Finance. Make sure you install the `yfinance` package before running the code if it's not already installed in your environment.\nBelow is the Python code block that fetches Nvidia's stock price data for the past month and performs a basic analysis of the price performance:\n```python\nimport yfinance as yf\nimport pandas as pd\n# Fetch Nvidia's stock data for the past month\nnvidia_stock = yf.Ticker(\"NVDA\")\nnvidia_df = nvidia_stock.history(period=\"1mo\")\n# Calculate some basic metrics\nlast_price = nvidia_df['Close'].iloc[-1]\nprice_change = nvidia_df['Close'] - nvidia_df['Close'].shift(1)\npercent_change = price_change / nvidia_df['Close'].shift(1) * 100\naverage_change = percent_change.mean()\nmax_price = nvidia_df['Close'].max()\nmin_price = nvidia_df['Close'].min()\nprint(f\"Nvidia's Stock Performance Over the Past Month:\\n\")\nprint(f\"Last Close Price: {last_price:.2f}\")\nprint(f\"Average Daily Percentage Change: {average_change:.2f}%\")\nprint(f\"Maximum Price: {max_price:.2f}\")\nprint(f\"Minimum Price: {min_price:.2f}\")\n```\nThe output of the print statements will give you Nvidia’s last close price, the average daily percentage change, and the maximum and minimum stock prices over the past month. Note that if you're looking for a more detailed analysis (e.g., predictive modeling, complex pattern recognition), you would need to apply more advanced financial analysis techniques and might also consider external factors impacting stock prices.\nThis is the output of the code blocks when executed:\n/Users/ekzhu/miniconda3/envs/autogen/lib/python3.11/site-packages/yfinance/utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\nNvidia's Stock Performance Over the Past Month:\nLast Close Price: 884.55\nAverage Daily Percentage Change: 1.38%\nMaximum Price: 926.69\nMinimum Price: 674.69\n**********************************************************************\n--------------------------------------------------------------------------------\nMeta-Expert (to proxy):\nIt seems that there has been a misunderstanding, as I do not have the capability to execute code or access live databases to provide up-to-date financial data.\nTo write a blog post on Nvidia's stock price performance over the past month, you would need up-to-the-minute data from the stock market. Without access to such data, I can provide you with a generic template of how to analyze and discuss stock performance for the blog post:\n[Blog Post Title]\n\"Analyzing Nvidia's Stock Performance: A Look Back Over the Past Month\"\n[Opening]\nAs one of the leading technology companies specializing in graphics processing units (GPUs), Nvidia Corporation (NVDA) remains a key player in the stock market. Investors and market analysts keep a close eye on Nvidia's stock price fluctuations for indications of the company's health and the wider tech industry trends.\n[Stock Performance Summary]\nAccording to the latest data gathered, Nvidia's stock has experienced significant movement over the past month. (Provide specific data on opening and closing prices, highest and lowest points, and overall gain/loss percentage if available.)\n[Influential Factors]\nSeveral factors have influenced Nvidia's stock price performance this month. These include market sentiment, the company's quarterly earnings report, industry competition, and economic indicators such as interest rates and consumer spending habits in the technology sector. (Discuss the impact of each factor, citing recent news or company announcements if available.)\n[Technical Analysis]\nA technical analysis of Nvidia's stock price reveals key support and resistance levels investors should be aware of. (Provide information on moving averages, RSI levels, volume changes, and other technical indicators if available.)\n[Investor Actions]\nThroughout the month, investors have reacted to Nvidia's performance with varying strategies, from short-term trades to long-term holds. (Discuss investor actions based on the stock's performance, such as buy, sell, or hold decisions.)\n[Future Outlook]\nLooking ahead, Nvidia's stock remains an exciting yet volatile asset to watch. Factors such as advancements in GPU technologies, the growth of the gaming industry, and the company's forays into AI and deep learning will continue to shape its stock price. (Provide an outlook based on projections or analysts' expectations if available.)\n[Closing]\nOverall, Nvidia continues to demonstrate the dynamism common in tech stocks, and its performance over the past month has provided both challenges and opportunities to investors. Keeping up with the latest trends and data will be crucial for those looking to make informed decisions about their investments in Nvidia stock.\n[Disclaimer]\n(Include a standard financial disclaimer noting that the blog post is for informational purposes only and is not intended as financial advice.)\nFor the most accurate and detailed blog post, it would be ideal to source the latest data from a financial data provider and update the placeholders in the template with the relevant figures and expert analyses.\n--------------------------------------------------------------------------------\n\n```\n\n[Swarm Orchestration](https://docs.ag2.ai/docs/topics/</docs/topics/swarm>)[FAQ](https://docs.ag2.ai/docs/topics/</docs/FAQ>)\n[x](https://docs.ag2.ai/docs/topics/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/topics/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/topics/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/topics/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/topics/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/topics/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Approach 1. Two-agent chat with function call for task decomposition](https://docs.ag2.ai/docs/topics/<#approach-1-two-agent-chat-with-function-call-for-task-decomposition>)\n  * [Approach 2: Group chat](https://docs.ag2.ai/docs/topics/<#approach-2-group-chat>)\n  * [Group chat for task decomposition](https://docs.ag2.ai/docs/topics/<#group-chat-for-task-decomposition>)\n  * [Group chat with a custom speaker selection policy](https://docs.ag2.ai/docs/topics/<#group-chat-with-a-custom-speaker-selection-policy>)\n  * [Nvidia’s Stock Performance: A Remarkable Month of Growth](https://docs.ag2.ai/docs/topics/<#nvidias-stock-performance-a-remarkable-month-of-growth>)\n  * [A Robust Comeback in the Tech Sector](https://docs.ag2.ai/docs/topics/<#a-robust-comeback-in-the-tech-sector>)\n  * [Key Performance Highlights](https://docs.ag2.ai/docs/topics/<#key-performance-highlights>)\n  * [Factors Fueling Growth](https://docs.ag2.ai/docs/topics/<#factors-fueling-growth>)\n  * [Looking Ahead](https://docs.ag2.ai/docs/topics/<#looking-ahead>)\n  * [Disclaimer](https://docs.ag2.ai/docs/topics/<#disclaimer>)\n  * [Approach 3. Use AutoBuild](https://docs.ag2.ai/docs/topics/<#approach-3-use-autobuild>)\n  * [Approach 4: Customize a task scheduler](https://docs.ag2.ai/docs/topics/<#approach-4-customize-a-task-scheduler>)\n\n---\n\n# FAQ\nURL: https://docs.ag2.ai/docs/FAQ\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUser Guide\nFrequently Asked Questions\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\nUser Guide\n# Frequently Asked Questions\n## \n[​](https://docs.ag2.ai/docs/<#install-the-correct-package-autogen>)\nInstall the correct package - `autogen`\nThe name of Autogen package at PyPI is `autogen`:\nCopy\n```\npip install autogen\n\n```\n\nTypical errors that you might face when using the wrong package are `AttributeError: module 'autogen' has no attribute 'Agent'`, `AttributeError: module 'autogen' has no attribute 'config_list_from_json'` etc.\n## \n[​](https://docs.ag2.ai/docs/<#set-your-api-endpoints>)\nSet your API endpoints\nThis documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>).\n### \n[​](https://docs.ag2.ai/docs/<#use-the-constructed-configuration-list-in-agents>)\nUse the constructed configuration list in agents\nThis documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>).\n### \n[​](https://docs.ag2.ai/docs/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)\nHow does an agent decide which model to pick out of the list?\nThis documentation has been moved [here](https://docs.ag2.ai/docs/</docs/topics/llm_configuration#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>).\n### \n[​](https://docs.ag2.ai/docs/<#unexpected-keyword-argument-base-url>)\nUnexpected keyword argument ‘base_url’\nIn version >=1, OpenAI renamed their `api_base` parameter to `base_url`. So for older versions, use `api_base` but for newer versions use `base_url`.\n### \n[​](https://docs.ag2.ai/docs/<#can-i-use-non-openai-models>)\nCan I use non-OpenAI models?\nYes. You currently have two options:\n  * Autogen can work with any API endpoint which complies with OpenAI-compatible RESTful APIs - e.g. serving local LLM via FastChat or LM Studio. Please check [here](https://docs.ag2.ai/docs/</blog/2023-07-14-Local-LLMs>) for an example.\n  * You can supply your own custom model implementation and use it with Autogen. Please check [here](https://docs.ag2.ai/docs/</blog/2024-01-26-Custom-Models>) for more information.\n\n\n## \n[​](https://docs.ag2.ai/docs/<#handle-rate-limit-error-and-timeout-error>)\nHandle Rate Limit Error and Timeout Error\nYou can set `max_retries` to handle rate limit error. And you can set `timeout` to handle timeout error. They can all be specified in `llm_config` for an agent, which will be used in the OpenAI client for LLM inference. They can be set differently for different clients if they are set in the `config_list`.\n  * `max_retries` (int): the total number of times allowed for retrying failed requests for a single client.\n  * `timeout` (int): the timeout (in seconds) for a single client.\n\n\nPlease refer to the [documentation](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference#runtime-error>) for more info.\n## \n[​](https://docs.ag2.ai/docs/<#how-to-continue-a-finished-conversation>)\nHow to continue a finished conversation\nWhen you call `initiate_chat` the conversation restarts by default. You can use `send` or `initiate_chat(clear_history=False)` to continue the conversation.\n## \n[​](https://docs.ag2.ai/docs/<#max-consecutive-auto-reply-vs-max-turn-vs-max-round>)\n`max_consecutive_auto_reply` vs `max_turn` vs `max_round`\n  * `max_consecutive_auto_reply`[](https://docs.ag2.ai/docs/</docs/reference/agentchat/conversable_agent#max-consecutive-auto-reply>) the maximum number of consecutive auto replie (a reply from an agent without human input is considered an auto reply). It plays a role when `human_input_mode` is not “ALWAYS”.\n  * `max_turns`[ in `ConversableAgent.initiate_chat`](https://docs.ag2.ai/docs/</docs/reference/agentchat/conversable_agent#initiate-chat>) limits the number of conversation turns between two conversable agents (without differentiating auto-reply and reply/input from human)\n  * `max_round`[ in GroupChat](https://docs.ag2.ai/docs/</docs/reference/agentchat/groupchat#groupchat>) specifies the maximum number of rounds in a group chat session.\n\n\n## \n[​](https://docs.ag2.ai/docs/<#how-do-we-decide-what-llm-is-used-for-each-agent-how-many-agents-can-be-used-how-do-we-decide-how-many-agents-in-the-group>)\nHow do we decide what LLM is used for each agent? How many agents can be used? How do we decide how many agents in the group?\nEach agent can be customized. You can use LLMs, tools, or humans behind each agent. If you use an LLM for an agent, use the one best suited for its role. There is no limit of the number of agents, but start from a small number like 2, 3. The more capable is the LLM and the fewer roles you need, the fewer agents you need.\nThe default user proxy agent doesn’t use LLM. If you’d like to use an LLM in UserProxyAgent, the use case could be to simulate user’s behavior.\nThe default assistant agent is instructed to use both coding and language skills. It doesn’t have to do coding, depending on the tasks. And you can customize the system message. So if you want to use it for coding, use a model that’s good at coding.\n## \n[​](https://docs.ag2.ai/docs/<#why-is-code-not-saved-as-file>)\nWhy is code not saved as file?\nIf you are using a custom system message for the coding agent, please include something like: `If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line.` in the system message. This line is in the default system message of the `AssistantAgent`.\nIf the `# filename` doesn’t appear in the suggested code still, consider adding explicit instructions such as “save the code to disk” in the initial user message in `initiate_chat`. The `AssistantAgent` doesn’t save all the code by default, because there are cases in which one would just like to finish a task without saving the code.\n## \n[​](https://docs.ag2.ai/docs/<#legacy-code-executor>)\nLegacy code executor\n:::note The new code executors offers more choices of execution backend. Read more about [code executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>). :::\nThe legacy code executor is used by specifying the `code_execution_config` in the agent’s constructor.\nCopy\n```\nfrom autogen import UserProxyAgent\nuser_proxy = UserProxyAgent(\n  name=\"user_proxy\",\n  code_execution_config={\"work_dir\":\"_output\", \"use_docker\":\"python:3\"},\n)\n\n```\n\nIn this example, the `code_execution_config` specifies that the code will be executed in a docker container with the image `python:3`. By default, the image name is `python:3-slim` if not specified. The `work_dir` specifies the directory where the code will be executed. If you have problems with agents running `pip install` or get errors similar to `Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory')`, you can choose **‘python:3’** as image as shown in the code example above and that should solve the problem.\nBy default it runs code in a docker container. If you want to run code locally (not recommended) then `use_docker` can be set to `False` in `code_execution_config` for each code-execution agent, or set `AUTOGEN_USE_DOCKER` to `False` as an environment variable.\nYou can also develop your AutoGen application in a docker container. For example, when developing in [GitHub codespace](https://docs.ag2.ai/docs/<https:/codespaces.new/ag2ai/ag2?quickstart=1>), AutoGen runs in a docker container. If you are not developing in GitHub Codespaces, follow instructions [here](https://docs.ag2.ai/docs/</docs/installation/Docker#step-1-install-docker>) to install and run AutoGen in docker.\n## \n[​](https://docs.ag2.ai/docs/<#agents-keep-thanking-each-other-when-using-gpt-3-5-turbo>)\nAgents keep thanking each other when using `gpt-3.5-turbo`\nWhen using `gpt-3.5-turbo` you may often encounter agents going into a “gratitude loop”, meaning when they complete a task they will begin congratulating and thanking each other in a continuous loop. This is a limitation in the performance of `gpt-3.5-turbo`, in contrast to `gpt-4` which has no problem remembering instructions. This can hinder the experimentation experience when trying to test out your own use case with cheaper models.\nA workaround is to add an additional termination notice to the prompt. This acts a “little nudge” for the LLM to remember that they need to terminate the conversation when their task is complete. You can do this by appending a string such as the following to your user input string:\nCopy\n```\nprompt = \"Some user query\"\ntermination_notice = (\n  '\\n\\nDo not show appreciation in your responses, say only what is necessary. '\n  'if \"Thank you\" or \"You\\'re welcome\" are said in the conversation, then say TERMINATE '\n  'to indicate the conversation is finished and this is your last message.'\n)\nprompt += termination_notice\n\n```\n\n**Note** : This workaround gets the job done around 90% of the time, but there are occurrences where the LLM still forgets to terminate the conversation.\n## \n[​](https://docs.ag2.ai/docs/<#chromadb-fails-in-codespaces-because-of-old-version-of-sqlite3>)\nChromaDB fails in codespaces because of old version of sqlite3\n(from [issue #251](https://docs.ag2.ai/docs/<https:/github.com/microsoft/autogen/issues/251>))\nCode examples that use chromadb (like retrieval) fail in codespaces due to a sqlite3 requirement.\nCopy\n```\n>>> import chromadb\nTraceback (most recent call last):\n File \"<stdin>\", line 1, in <module>\n File \"/home/vscode/.local/lib/python3.10/site-packages/chromadb/__init__.py\", line 69, in <module>\n  raise RuntimeError(\nRuntimeError: Your system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0.\nPlease visit https://docs.trychroma.com/troubleshooting#sqlite to learn how to upgrade.\n\n```\n\nWorkaround:\n  1. `pip install pysqlite3-binary`\n  2. `mkdir /home/vscode/.local/lib/python3.10/site-packages/google/colab`\n\n\nExplanation: Per [this gist](https://docs.ag2.ai/docs/<https:/gist.github.com/defulmere/8b9695e415a44271061cc8e272f3c300?permalink_comment_id=4711478#gistcomment-4711478>), linked from the official [chromadb docs](https://docs.ag2.ai/docs/<https:/docs.trychroma.com/troubleshooting#sqlite>), adding this folder triggers chromadb to use pysqlite3 instead of the default.\n## \n[​](https://docs.ag2.ai/docs/<#how-to-register-a-reply-function>)\nHow to register a reply function\n(from [issue #478](https://docs.ag2.ai/docs/<https:/github.com/microsoft/autogen/issues/478>))\nSee here /docs/reference/agentchat/conversable_agent/#register_reply\nFor example, you can register a reply function that gets called when `generate_reply` is called for an agent.\nCopy\n```\ndef print_messages(recipient, messages, sender, config):\n  if \"callback\" in config and config[\"callback\"] is not None:\n    callback = config[\"callback\"]\n    callback(sender, recipient, messages[-1])\n  print(f\"Messages sent to: {recipient.name} | num messages: {len(messages)}\")\n  return False, None # required to ensure the agent communication flow continues\nuser_proxy.register_reply(\n  [autogen.Agent, None],\n  reply_func=print_messages,\n  config={\"callback\": None},\n)\nassistant.register_reply(\n  [autogen.Agent, None],\n  reply_func=print_messages,\n  config={\"callback\": None},\n)\n\n```\n\nIn the above, we register a `print_messages` function that is called each time the agent’s `generate_reply` is triggered after receiving a message.\n## \n[​](https://docs.ag2.ai/docs/<#how-to-get-last-message>)\nHow to get last message ?\nRefer to /docs/reference/agentchat/conversable_agent/#last_message\n## \n[​](https://docs.ag2.ai/docs/<#how-to-get-each-agent-message>)\nHow to get each agent message ?\nPlease refer to /docs/reference/agentchat/conversable_agent#chat_messages\n## \n[​](https://docs.ag2.ai/docs/<#when-using-autogen-docker-is-it-always-necessary-to-reinstall-modules>)\nWhen using autogen docker, is it always necessary to reinstall modules?\nThe “use_docker” arg in an agent’s code_execution_config will be set to the name of the image containing the change after execution, when the conversation finishes. You can save that image name. For a new conversation, you can set “use_docker” to the saved name of the image to start execution there.\n## \n[​](https://docs.ag2.ai/docs/<#database-locked-error>)\nDatabase locked error\nWhen using VMs such as Azure Machine Learning compute instances, you may encounter a “database locked error”. This is because the [LLM cache](https://docs.ag2.ai/docs/</docs/topics/llm-caching>) is trying to write to a location that the application does not have access to.\nYou can set the `cache_path_root` to a location where the application has access. For example,\nCopy\n```\nfrom autogen import Cache\nwith Cache.disk(cache_path_root=\"/tmp/.cache\") as cache:\n  agent_a.initate_chat(agent_b, ..., cache=cache)\n\n```\n\nYou can also use Redis cache instead of disk cache. For example,\nCopy\n```\nfrom autogen import Cache\nwith Cache.redis(redis_url=...) as cache:\n  agent_a.initate_chat(agent_b, ..., cache=cache)\n\n```\n\nYou can also disable the cache. See [here](https://docs.ag2.ai/docs/</docs/topics/llm-caching#disabling-cache>) for details.\n## \n[​](https://docs.ag2.ai/docs/<#agents-are-throwing-due-to-docker-not-running-how-can-i-resolve-this>)\nAgents are throwing due to docker not running, how can I resolve this?\nIf running AutoGen locally the default for agents who execute code is for them to try and perform code execution within a docker container. If docker is not running, this will cause the agent to throw an error. To resolve this you have some options.\n### \n[​](https://docs.ag2.ai/docs/<#if-you-want-to-disable-code-execution-entirely>)\nIf you want to disable code execution entirely\n  * Set `code_execution_config` to `False` for each code-execution agent. E.g.:\n\n\nCopy\n```\nuser_proxy = autogen.UserProxyAgent(\n  name=\"agent\",\n  llm_config=llm_config,\n  code_execution_config=False)\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-in-docker>)\nIf you want to run code execution in docker\n  * **Recommended** : Make sure docker is up and running.\n\n\n### \n[​](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-locally>)\nIf you want to run code execution locally\n  * `use_docker` can be set to `False` in `code_execution_config` for each code-execution agent.\n  * To set it for all code-execution agents at once: set `AUTOGEN_USE_DOCKER` to `False` as an environment variable.\n\n\nE.g.:\nCopy\n```\nuser_proxy = autogen.UserProxyAgent(\n  name=\"agent\", llm_config=llm_config,\n  code_execution_config={\"work_dir\":\"coding\", \"use_docker\":False})\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/<#what-should-i-do-if-i-get-the-error-typeerror-assistants-create-got-an-unexpected-keyword-argument-file-ids>)\nWhat should I do if I get the error “TypeError: Assistants.create() got an unexpected keyword argument ‘file_ids’”?\nThis error typically occurs when using Autogen version earlier than 0.2.27 in combination with OpenAI library version 1.21 or later. The issue arises because the older version of Autogen does not support the file_ids parameter used by newer versions of the OpenAI API. To resolve this issue, you need to upgrade your Autogen library to version 0.2.27 or higher that ensures compatibility between Autogen and the OpenAI library.\nCopy\n```\npip install --upgrade autogen\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/<#none-of-the-devcontainers-are-building-due-to-hash-sum-mismatch-what-should-i-do>)\nNone of the devcontainers are building due to “Hash sum mismatch”, what should I do?\nThis is an intermittent issue that appears to be caused by some combination of mirror and proxy issues. If it arises, try to replace the `apt-get update` step with the following:\nCopy\n```\nRUN echo \"Acquire::http::Pipeline-Depth 0;\" > /etc/apt/apt.conf.d/99custom && \\\n  echo \"Acquire::http::No-Cache true;\" >> /etc/apt/apt.conf.d/99custom && \\\n  echo \"Acquire::BrokenProxy  true;\" >> /etc/apt/apt.conf.d/99custom\nRUN apt-get clean && \\\n  rm -r /var/lib/apt/lists/* && \\\n  apt-get update -o Acquire::CompressionTypes::Order::=gz && \\\n  apt-get -y update && \\\n  apt-get install sudo git npm # and whatever packages need to be installed in this specific version of the devcontainer\n\n```\n\nThis is a combination of StackOverflow suggestions [here](https://docs.ag2.ai/docs/<https:/stackoverflow.com/a/48777773/2114580>) and [here](https://docs.ag2.ai/docs/<https:/stackoverflow.com/a/76092743/2114580>).\n[Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)[agent_eval](https://docs.ag2.ai/docs/</docs/reference/agentchat/contrib/agent_eval/agent_eval>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Install the correct package - autogen](https://docs.ag2.ai/docs/<#install-the-correct-package-autogen>)\n  * [Set your API endpoints](https://docs.ag2.ai/docs/<#set-your-api-endpoints>)\n  * [Use the constructed configuration list in agents](https://docs.ag2.ai/docs/<#use-the-constructed-configuration-list-in-agents>)\n  * [How does an agent decide which model to pick out of the list?](https://docs.ag2.ai/docs/<#how-does-an-agent-decide-which-model-to-pick-out-of-the-list>)\n  * [Unexpected keyword argument ‘base_url’](https://docs.ag2.ai/docs/<#unexpected-keyword-argument-base-url>)\n  * [Can I use non-OpenAI models?](https://docs.ag2.ai/docs/<#can-i-use-non-openai-models>)\n  * [Handle Rate Limit Error and Timeout Error](https://docs.ag2.ai/docs/<#handle-rate-limit-error-and-timeout-error>)\n  * [How to continue a finished conversation](https://docs.ag2.ai/docs/<#how-to-continue-a-finished-conversation>)\n  * [max_consecutive_auto_reply vs max_turn vs max_round](https://docs.ag2.ai/docs/<#max-consecutive-auto-reply-vs-max-turn-vs-max-round>)\n  * [How do we decide what LLM is used for each agent? How many agents can be used? How do we decide how many agents in the group?](https://docs.ag2.ai/docs/<#how-do-we-decide-what-llm-is-used-for-each-agent-how-many-agents-can-be-used-how-do-we-decide-how-many-agents-in-the-group>)\n  * [Why is code not saved as file?](https://docs.ag2.ai/docs/<#why-is-code-not-saved-as-file>)\n  * [Legacy code executor](https://docs.ag2.ai/docs/<#legacy-code-executor>)\n  * [Agents keep thanking each other when using gpt-3.5-turbo](https://docs.ag2.ai/docs/<#agents-keep-thanking-each-other-when-using-gpt-3-5-turbo>)\n  * [ChromaDB fails in codespaces because of old version of sqlite3](https://docs.ag2.ai/docs/<#chromadb-fails-in-codespaces-because-of-old-version-of-sqlite3>)\n  * [How to register a reply function](https://docs.ag2.ai/docs/<#how-to-register-a-reply-function>)\n  * [How to get last message ?](https://docs.ag2.ai/docs/<#how-to-get-last-message>)\n  * [How to get each agent message ?](https://docs.ag2.ai/docs/<#how-to-get-each-agent-message>)\n  * [When using autogen docker, is it always necessary to reinstall modules?](https://docs.ag2.ai/docs/<#when-using-autogen-docker-is-it-always-necessary-to-reinstall-modules>)\n  * [Database locked error](https://docs.ag2.ai/docs/<#database-locked-error>)\n  * [Agents are throwing due to docker not running, how can I resolve this?](https://docs.ag2.ai/docs/<#agents-are-throwing-due-to-docker-not-running-how-can-i-resolve-this>)\n  * [If you want to disable code execution entirely](https://docs.ag2.ai/docs/<#if-you-want-to-disable-code-execution-entirely>)\n  * [If you want to run code execution in docker](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-in-docker>)\n  * [If you want to run code execution locally](https://docs.ag2.ai/docs/<#if-you-want-to-run-code-execution-locally>)\n  * [What should I do if I get the error “TypeError: Assistants.create() got an unexpected keyword argument ‘file_ids’”?](https://docs.ag2.ai/docs/<#what-should-i-do-if-i-get-the-error-typeerror-assistants-create-got-an-unexpected-keyword-argument-file-ids>)\n  * [None of the devcontainers are building due to “Hash sum mismatch”, what should I do?](https://docs.ag2.ai/docs/<#none-of-the-devcontainers-are-building-due-to-hash-sum-mismatch-what-should-i-do>)\n\n---\n\n# browser_utils\nURL: https://docs.ag2.ai/docs/reference/browser_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\nbrowser_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# browser_utils\n## \n[​](https://docs.ag2.ai/docs/reference/<#simpletextbrowser>)\nSimpleTextBrowser\nCopy\n```\nclass SimpleTextBrowser()\n\n```\n\n(In preview) An extremely simple text-based web browser comparable to Lynx. Suitable for Agentic use.\n### \n[​](https://docs.ag2.ai/docs/reference/<#address>)\naddress\nCopy\n```\n@property\ndef address() -> str\n\n```\n\nReturn the address of the current page.\n### \n[​](https://docs.ag2.ai/docs/reference/<#viewport>)\nviewport\nCopy\n```\n@property\ndef viewport() -> str\n\n```\n\nReturn the content of the current viewport.\n### \n[​](https://docs.ag2.ai/docs/reference/<#page-content>)\npage_content\nCopy\n```\n@property\ndef page_content() -> str\n\n```\n\nReturn the full contents of the current page.\n### \n[​](https://docs.ag2.ai/docs/reference/<#visit-page>)\nvisit_page\nCopy\n```\ndef visit_page(path_or_uri: str) -> str\n\n```\n\nUpdate the address, visit the page, and return the content of the viewport.\n[tool](https://docs.ag2.ai/docs/reference/</docs/reference/tools/tool>)[code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [SimpleTextBrowser](https://docs.ag2.ai/docs/reference/<#simpletextbrowser>)\n  * [address](https://docs.ag2.ai/docs/reference/<#address>)\n  * [viewport](https://docs.ag2.ai/docs/reference/<#viewport>)\n  * [page_content](https://docs.ag2.ai/docs/reference/<#page-content>)\n  * [visit_page](https://docs.ag2.ai/docs/reference/<#visit-page>)\n\n---\n\n# code_utils\nURL: https://docs.ag2.ai/docs/reference/code_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\ncode_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# code_utils\n### \n[​](https://docs.ag2.ai/docs/reference/<#content-str>)\ncontent_str\nCopy\n```\ndef content_str(\n  content: Union[str, list[Union[UserMessageTextContentPart,\n                  UserMessageImageContentPart]], None]\n) -> str\n\n```\n\nConverts the `content` field of an OpenAI message into a string format.\nThis function processes content that may be a string, a list of mixed text and image URLs, or None, and converts it into a string. Text is directly appended to the result string, while image URLs are represented by a placeholder image token. If the content is None, an empty string is returned.\n**Arguments** :\n  * content (Union[str, List, None]): The content to be processed. Can be a string, a list of dictionaries representing text and image URLs, or None.\n\n\n**Returns** :\n  * `str` - A string representation of the input content. Image URLs are replaced with an image token.\n\n\n**Notes** :\n  * The function expects each dictionary in the list to have a “type” key that is either “text” or “image_url”. For “text” type, the “text” key’s value is appended to the result. For “image_url”, an image token is appended.\n  * This function is useful for handling content that may include both text and image references, especially in contexts where images need to be represented as placeholders.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#infer-lang>)\ninfer_lang\nCopy\n```\ndef infer_lang(code: str) -> str\n\n```\n\nInfer the language for the code. TODO: make it robust.\n### \n[​](https://docs.ag2.ai/docs/reference/<#extract-code>)\nextract_code\nCopy\n```\ndef extract_code(\n    text: Union[str, list],\n    pattern: str = CODE_BLOCK_PATTERN,\n    detect_single_line_code: bool = False) -> list[tuple[str, str]]\n\n```\n\nExtract code from a text.\n**Arguments** :\n  * `text` _str or List_ - The content to extract code from. The content can be a string or a list, as returned by standard GPT or multimodal GPT.\n  * `pattern` _str, optional_ - The regular expression pattern for finding the code block. Defaults to CODE_BLOCK_PATTERN.\n  * `detect_single_line_code` _bool, optional_ - Enable the new feature for extracting single line code. Defaults to False.\n\n\n**Returns** :\n  * `list` - A list of tuples, each containing the language and the code. If there is no code block in the input text, the language would be “unknown”. If there is code block but the language is not specified, the language would be \"\".\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#generate-code>)\ngenerate_code\nCopy\n```\ndef generate_code(pattern: str = CODE_BLOCK_PATTERN,\n         **config) -> tuple[str, float]\n\n```\n\n`(openai<1)` Generate code.\n**Arguments** :\n  * `pattern` _Optional, str_ - The regular expression pattern for finding the code block. The default pattern is for finding a code block in a markdown file.\n  * `config` _Optional, dict_ - The configuration for the API call.\n\n\n**Returns** :\n  * `str` - The generated code.\n  * `float` - The cost of the generation.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#improve-function>)\nimprove_function\nCopy\n```\ndef improve_function(file_name, func_name, objective, **config)\n\n```\n\n`(openai<1)` Improve the function to achieve the objective.\n### \n[​](https://docs.ag2.ai/docs/reference/<#improve-code>)\nimprove_code\nCopy\n```\ndef improve_code(files, objective, suggest_only=True, **config)\n\n```\n\n`(openai<1)` Improve the code to achieve a given objective.\n**Arguments** :\n  * `files` _list_ - A list of file names containing the source code.\n  * `objective` _str_ - The objective to achieve.\n  * `suggest_only` _bool_ - Whether to return only the suggestions or the improved code.\n  * `config` _Optional, dict_ - The configuration for the API call.\n\n\n**Returns** :\n  * `str` - The improved code if suggest_only=False; a list of suggestions if suggest_only=True (default).\n  * `float` - The cost of the generation.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#is-docker-running>)\nis_docker_running\nCopy\n```\ndef is_docker_running() -> bool\n\n```\n\nCheck if docker is running.\n**Returns** :\n  * `bool` - True if docker is running; False otherwise.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#in-docker-container>)\nin_docker_container\nCopy\n```\ndef in_docker_container() -> bool\n\n```\n\nCheck if the code is running in a docker container.\n**Returns** :\n  * `bool` - True if the code is running in a docker container; False otherwise.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#execute-code>)\nexecute_code\nCopy\n```\ndef execute_code(\n    code: Optional[str] = None,\n    timeout: Optional[int] = None,\n    filename: Optional[str] = None,\n    work_dir: Optional[str] = None,\n    use_docker: Union[list[str], str, bool] = SENTINEL,\n    lang: Optional[str] = \"python\") -> tuple[int, str, Optional[str]]\n\n```\n\nExecute code in a docker container. This function is not tested on MacOS.\n**Arguments** :\n  * `code` _Optional, str_ - The code to execute. If None, the code from the file specified by filename will be executed. Either code or filename must be provided.\n  * `timeout` _Optional, int_ - The maximum execution time in seconds. If None, a default timeout will be used. The default timeout is 600 seconds. On Windows, the timeout is not enforced when use_docker=False.\n  * `filename` _Optional, str_ - The file name to save the code or where the code is stored when `code` is None. If None, a file with a randomly generated name will be created. The randomly generated file will be deleted after execution. The file name must be a relative path. Relative paths are relative to the working directory.\n  * `work_dir` _Optional, str_ - The working directory for the code execution. If None, a default working directory will be used. The default working directory is the “extensions” directory under “path_to_autogen”.\n  * `use_docker` _list, str or bool_ - The docker image to use for code execution. Default is True, which means the code will be executed in a docker container. A default list of images will be used. If a list or a str of image name(s) is provided, the code will be executed in a docker container with the first image successfully pulled. If False, the code will be executed in the current environment. Expected behaviour: \n    * If `use_docker` is not set (i.e. left default to True) or is explicitly set to True and the docker package is available, the code will run in a Docker container.\n    * If `use_docker` is not set (i.e. left default to True) or is explicitly set to True but the Docker package is missing or docker isn’t running, an error will be raised.\n    * If `use_docker` is explicitly set to False, the code will run natively. If the code is executed in the current environment, the code must be trusted.\n  * `lang` _Optional, str_ - The language of the code. Default is “python”.\n\n\n**Returns** :\n  * `int` - 0 if the code executes successfully.\n  * `str` - The error message if the code fails to execute; the stdout otherwise.\n  * `image` - The docker image name after container run when docker is used.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#generate-assertions>)\ngenerate_assertions\nCopy\n```\ndef generate_assertions(definition: str, **config) -> tuple[str, float]\n\n```\n\n`(openai<1)` Generate assertions for a function.\n**Arguments** :\n  * `definition` _str_ - The function definition, including the signature and docstr.\n  * `config` _Optional, dict_ - The configuration for the API call.\n\n\n**Returns** :\n  * `str` - The generated assertions.\n  * `float` - The cost of the generation.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#eval-function-completions>)\neval_function_completions\nCopy\n```\ndef eval_function_completions(responses: list[str],\n               definition: str,\n               test: Optional[str] = None,\n               entry_point: Optional[str] = None,\n               assertions: Optional[Union[str, Callable[\n                 [str], tuple[str, float]]]] = None,\n               timeout: Optional[float] = 3,\n               use_docker: Optional[bool] = True) -> dict\n\n```\n\n`(openai<1)` Select a response from a list of responses for the function completion task (using generated assertions), and/or evaluate if the task is successful using a gold test.\n**Arguments** :\n  * `responses` _list_ - The list of responses.\n  * `definition` _str_ - The input definition.\n  * `test` _Optional, str_ - The test code.\n  * `entry_point` _Optional, str_ - The name of the function.\n  * `assertions` _Optional, str or Callable_ - The assertion code which serves as a filter of the responses, or an assertion generator. When provided, only the responses that pass the assertions will be considered for the actual test (if provided).\n  * `timeout` _Optional, float_ - The timeout for executing the code.\n\n\n**Returns** :\n  * `dict` - The success metrics.\n\n\n## \n[​](https://docs.ag2.ai/docs/reference/<#passassertionfilter>)\nPassAssertionFilter\nCopy\n```\nclass PassAssertionFilter()\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#pass-assertions>)\npass_assertions\nCopy\n```\ndef pass_assertions(context, response, **_)\n\n```\n\n`(openai<1)` Check if the response passes the assertions.\n### \n[​](https://docs.ag2.ai/docs/reference/<#implement>)\nimplement\nCopy\n```\ndef implement(\n  definition: str,\n  configs: Optional[list[dict]] = None,\n  assertions: Optional[Union[str,\n                Callable[[str],\n                    tuple[str,\n                       float]]]] = generate_assertions\n) -> tuple[str, float]\n\n```\n\n`(openai<1)` Implement a function from a definition.\n**Arguments** :\n  * `definition` _str_ - The function definition, including the signature and docstr.\n  * `configs` _list_ - The list of configurations for completion.\n  * `assertions` _Optional, str or Callable_ - The assertion code which serves as a filter of the responses, or an assertion generator.\n\n\n**Returns** :\n  * `str` - The implementation.\n  * `float` - The cost of the implementation.\n  * `int` - The index of the configuration which generates the implementation.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#create-virtual-env>)\ncreate_virtual_env\nCopy\n```\ndef create_virtual_env(dir_path: str, **env_args) -> SimpleNamespace\n\n```\n\nCreates a python virtual environment and returns the context.\n**Arguments** :\n  * `dir_path` _str_ - Directory path where the env will be created.\n  * `**env_args` - Any extra args to pass to the `EnvBuilder`\n\n\n**Returns** :\n  * `SimpleNamespace` - the virtual env context object.\n\n\n[browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)[exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [content_str](https://docs.ag2.ai/docs/reference/<#content-str>)\n  * [infer_lang](https://docs.ag2.ai/docs/reference/<#infer-lang>)\n  * [extract_code](https://docs.ag2.ai/docs/reference/<#extract-code>)\n  * [generate_code](https://docs.ag2.ai/docs/reference/<#generate-code>)\n  * [improve_function](https://docs.ag2.ai/docs/reference/<#improve-function>)\n  * [improve_code](https://docs.ag2.ai/docs/reference/<#improve-code>)\n  * [is_docker_running](https://docs.ag2.ai/docs/reference/<#is-docker-running>)\n  * [in_docker_container](https://docs.ag2.ai/docs/reference/<#in-docker-container>)\n  * [execute_code](https://docs.ag2.ai/docs/reference/<#execute-code>)\n  * [generate_assertions](https://docs.ag2.ai/docs/reference/<#generate-assertions>)\n  * [eval_function_completions](https://docs.ag2.ai/docs/reference/<#eval-function-completions>)\n  * [PassAssertionFilter](https://docs.ag2.ai/docs/reference/<#passassertionfilter>)\n  * [pass_assertions](https://docs.ag2.ai/docs/reference/<#pass-assertions>)\n  * [implement](https://docs.ag2.ai/docs/reference/<#implement>)\n  * [create_virtual_env](https://docs.ag2.ai/docs/reference/<#create-virtual-env>)\n\n---\n\n# exception_utils\nURL: https://docs.ag2.ai/docs/reference/exception_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\nexception_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# exception_utils\n## \n[​](https://docs.ag2.ai/docs/reference/<#noeligiblespeaker>)\nNoEligibleSpeaker\nCopy\n```\nclass NoEligibleSpeaker(Exception)\n\n```\n\nException raised for early termination of a GroupChat.\n## \n[​](https://docs.ag2.ai/docs/reference/<#senderrequired>)\nSenderRequired\nCopy\n```\nclass SenderRequired(Exception)\n\n```\n\nException raised when the sender is required but not provided.\n## \n[​](https://docs.ag2.ai/docs/reference/<#invalidcarryovertype>)\nInvalidCarryOverType\nCopy\n```\nclass InvalidCarryOverType(Exception)\n\n```\n\nException raised when the carryover type is invalid.\n## \n[​](https://docs.ag2.ai/docs/reference/<#undefinednextagent>)\nUndefinedNextAgent\nCopy\n```\nclass UndefinedNextAgent(Exception)\n\n```\n\nException raised when the provided next agents list does not overlap with agents in the group.\n## \n[​](https://docs.ag2.ai/docs/reference/<#modeltoolnotsupportederror>)\nModelToolNotSupportedError\nCopy\n```\nclass ModelToolNotSupportedError(Exception)\n\n```\n\nException raised when attempting to use tools with models that do not support them.\n[code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)[graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [NoEligibleSpeaker](https://docs.ag2.ai/docs/reference/<#noeligiblespeaker>)\n  * [SenderRequired](https://docs.ag2.ai/docs/reference/<#senderrequired>)\n  * [InvalidCarryOverType](https://docs.ag2.ai/docs/reference/<#invalidcarryovertype>)\n  * [UndefinedNextAgent](https://docs.ag2.ai/docs/reference/<#undefinednextagent>)\n  * [ModelToolNotSupportedError](https://docs.ag2.ai/docs/reference/<#modeltoolnotsupportederror>)\n\n---\n\n# graph_utils\nURL: https://docs.ag2.ai/docs/reference/graph_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\ngraph_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# graph_utils\n### \n[​](https://docs.ag2.ai/docs/reference/<#has-self-loops>)\nhas_self_loops\nCopy\n```\ndef has_self_loops(allowed_speaker_transitions: dict) -> bool\n\n```\n\nReturns True if there are self loops in the allowed_speaker_transitions_Dict.\n### \n[​](https://docs.ag2.ai/docs/reference/<#check-graph-validity>)\ncheck_graph_validity\nCopy\n```\ndef check_graph_validity(allowed_speaker_transitions_dict: dict,\n             agents: list[Agent])\n\n```\n\nallowed_speaker_transitions_dict: A dictionary of keys and list as values. The keys are the names of the agents, and the values are the names of the agents that the key agent can transition to. agents: A list of Agents\nChecks for the following: Errors\n  1. The dictionary must have a structure of keys and list as values\n  2. Every key exists in agents.\n  3. Every value is a list of Agents (not string).\n\n\n**Warnings** :\n  1. Warning if there are isolated agent nodes\n  2. Warning if the set of agents in allowed_speaker_transitions do not match agents\n  3. Warning if there are duplicated agents in any values of `allowed_speaker_transitions_dict`\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#invert-disallowed-to-allowed>)\ninvert_disallowed_to_allowed\nCopy\n```\ndef invert_disallowed_to_allowed(disallowed_speaker_transitions_dict: dict,\n                 agents: list[Agent]) -> dict\n\n```\n\nStart with a fully connected allowed_speaker_transitions_dict of all agents. Remove edges from the fully connected allowed_speaker_transitions_dict according to the disallowed_speaker_transitions_dict to form the allowed_speaker_transitions_dict.\n### \n[​](https://docs.ag2.ai/docs/reference/<#visualize-speaker-transitions-dict>)\nvisualize_speaker_transitions_dict\nCopy\n```\ndef visualize_speaker_transitions_dict(speaker_transitions_dict: dict,\n                    agents: list[Agent],\n                    export_path: Optional[str] = None)\n\n```\n\nVisualize the speaker_transitions_dict using networkx.\n[exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)[math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [has_self_loops](https://docs.ag2.ai/docs/reference/<#has-self-loops>)\n  * [check_graph_validity](https://docs.ag2.ai/docs/reference/<#check-graph-validity>)\n  * [invert_disallowed_to_allowed](https://docs.ag2.ai/docs/reference/<#invert-disallowed-to-allowed>)\n  * [visualize_speaker_transitions_dict](https://docs.ag2.ai/docs/reference/<#visualize-speaker-transitions-dict>)\n\n---\n\n# math_utils\nURL: https://docs.ag2.ai/docs/reference/math_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\nmath_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# math_utils\n### \n[​](https://docs.ag2.ai/docs/reference/<#solve-problem>)\nsolve_problem\nCopy\n```\ndef solve_problem(problem: str, **config) -> str\n\n```\n\n`(openai<1)` Solve the math problem.\n**Arguments** :\n  * `problem` _str_ - The problem statement.\n  * `config` _Optional, dict_ - The configuration for the API call.\n\n\n**Returns** :\n  * `str` - The solution to the problem.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#remove-boxed>)\nremove_boxed\nCopy\n```\ndef remove_boxed(string: str) -> Optional[str]\n\n```\n\nSource: <https://github.com/hendrycks/math> Extract the text within a \\boxed`{...}` environment.\n**Example** :\nCopy\n```\n> remove_boxed(\"\\boxed{\\frac{2}{3}}\")\n\\frac{2}{3}\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#last-boxed-only-string>)\nlast_boxed_only_string\nCopy\n```\ndef last_boxed_only_string(string: str) -> Optional[str]\n\n```\n\nSource: <https://github.com/hendrycks/math> Extract the last \\boxed`{...}` or \\fbox`{...}` element from a string.\n### \n[​](https://docs.ag2.ai/docs/reference/<#is-equiv>)\nis_equiv\nCopy\n```\ndef is_equiv(str1: Optional[str], str2: Optional[str]) -> float\n\n```\n\nReturns (as a float) whether two strings containing math are equivalent up to differences of formatting in\n  * units\n  * fractions\n  * square roots\n  * superfluous LaTeX. Source: <https://github.com/hendrycks/math>\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#is-equiv-chain-of-thought>)\nis_equiv_chain_of_thought\nCopy\n```\ndef is_equiv_chain_of_thought(str1: str, str2: str) -> float\n\n```\n\nStrips the solution first before calling `is_equiv`.\n### \n[​](https://docs.ag2.ai/docs/reference/<#eval-math-responses>)\neval_math_responses\nCopy\n```\ndef eval_math_responses(responses, solution=None, **args)\n\n```\n\nSelect a response for a math problem using voting, and check if the response is correct if the solution is provided.\n**Arguments** :\n  * `responses` _list_ - The list of responses.\n  * `solution` _str_ - The canonical solution.\n\n\n**Returns** :\n  * `dict` - The success metrics.\n\n\n[graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)[retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [solve_problem](https://docs.ag2.ai/docs/reference/<#solve-problem>)\n  * [remove_boxed](https://docs.ag2.ai/docs/reference/<#remove-boxed>)\n  * [last_boxed_only_string](https://docs.ag2.ai/docs/reference/<#last-boxed-only-string>)\n  * [is_equiv](https://docs.ag2.ai/docs/reference/<#is-equiv>)\n  * [is_equiv_chain_of_thought](https://docs.ag2.ai/docs/reference/<#is-equiv-chain-of-thought>)\n  * [eval_math_responses](https://docs.ag2.ai/docs/reference/<#eval-math-responses>)\n\n---\n\n# retrieve_utils\nURL: https://docs.ag2.ai/docs/reference/retrieve_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\nretrieve_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# retrieve_utils\n#### \n[​](https://docs.ag2.ai/docs/reference/<#unstructured-formats>)\nUNSTRUCTURED_FORMATS\nThese formats will be parsed by the ‘unstructured’ library, if installed.\n### \n[​](https://docs.ag2.ai/docs/reference/<#split-text-to-chunks>)\nsplit_text_to_chunks\nCopy\n```\ndef split_text_to_chunks(text: str,\n             max_tokens: int = 4000,\n             chunk_mode: str = \"multi_lines\",\n             must_break_at_empty_line: bool = True,\n             overlap: int = 0)\n\n```\n\nSplit a long text into chunks of max_tokens.\n### \n[​](https://docs.ag2.ai/docs/reference/<#extract-text-from-pdf>)\nextract_text_from_pdf\nCopy\n```\ndef extract_text_from_pdf(file: str) -> str\n\n```\n\nExtract text from PDF files\n### \n[​](https://docs.ag2.ai/docs/reference/<#split-files-to-chunks>)\nsplit_files_to_chunks\nCopy\n```\ndef split_files_to_chunks(\n  files: list,\n  max_tokens: int = 4000,\n  chunk_mode: str = \"multi_lines\",\n  must_break_at_empty_line: bool = True,\n  custom_text_split_function: Callable = None\n) -> tuple[list[str], list[dict]]\n\n```\n\nSplit a list of files into chunks of max_tokens.\n### \n[​](https://docs.ag2.ai/docs/reference/<#get-files-from-dir>)\nget_files_from_dir\nCopy\n```\ndef get_files_from_dir(dir_path: Union[str, list[str]],\n            types: list = TEXT_FORMATS,\n            recursive: bool = True)\n\n```\n\nReturn a list of all the files in a given directory, a url, a file path or a list of them.\n### \n[​](https://docs.ag2.ai/docs/reference/<#parse-html-to-markdown>)\nparse_html_to_markdown\nCopy\n```\ndef parse_html_to_markdown(html: str, url: str = None) -> str\n\n```\n\nParse HTML to markdown.\n### \n[​](https://docs.ag2.ai/docs/reference/<#get-file-from-url>)\nget_file_from_url\nCopy\n```\ndef get_file_from_url(url: str, save_path: str = None) -> tuple[str, str]\n\n```\n\nDownload a file from a URL.\n### \n[​](https://docs.ag2.ai/docs/reference/<#is-url>)\nis_url\nCopy\n```\ndef is_url(string: str)\n\n```\n\nReturn True if the string is a valid URL.\n### \n[​](https://docs.ag2.ai/docs/reference/<#create-vector-db-from-dir>)\ncreate_vector_db_from_dir\nCopy\n```\ndef create_vector_db_from_dir(dir_path: Union[str, list[str]],\n               max_tokens: int = 4000,\n               client: API = None,\n               db_path: str = \"tmp/chromadb.db\",\n               collection_name: str = \"all-my-documents\",\n               get_or_create: bool = False,\n               chunk_mode: str = \"multi_lines\",\n               must_break_at_empty_line: bool = True,\n               embedding_model: str = \"all-MiniLM-L6-v2\",\n               embedding_function: Callable = None,\n               custom_text_split_function: Callable = None,\n               custom_text_types: list[str] = TEXT_FORMATS,\n               recursive: bool = True,\n               extra_docs: bool = False) -> API\n\n```\n\nCreate a vector db from all the files in a given directory, the directory can also be a single file or a url to a single file. We support chromadb compatible APIs to create the vector db, this function is not required if you prepared your own vector db.\n**Arguments** :\n  * `dir_path` _Union[str, List[str]]_ - the path to the directory, file, url or a list of them.\n  * `max_tokens` _Optional, int_ - the maximum number of tokens per chunk. Default is 4000.\n  * `client` _Optional, API_ - the chromadb client. Default is None.\n  * `db_path` _Optional, str_ - the path to the chromadb. Default is “tmp/chromadb.db”. The default was `/tmp/chromadb.db` for version `<=0.2.24`.\n  * `collection_name` _Optional, str_ - the name of the collection. Default is “all-my-documents”.\n  * `get_or_create` _Optional, bool_ - Whether to get or create the collection. Default is False. If True, the collection will be returned if it already exists. Will raise ValueError if the collection already exists and get_or_create is False.\n  * `chunk_mode` _Optional, str_ - the chunk mode. Default is “multi_lines”.\n  * `must_break_at_empty_line` _Optional, bool_ - Whether to break at empty line. Default is True.\n  * `embedding_model` _Optional, str_ - the embedding model to use. Default is “all-MiniLM-L6-v2”. Will be ignored if embedding_function is not None.\n  * `embedding_function` _Optional, Callable_ - the embedding function to use. Default is None, SentenceTransformer with the given `embedding_model` will be used. If you want to use OpenAI, Cohere, HuggingFace or other embedding functions, you can pass it here, follow the examples in `https://docs.trychroma.com/embeddings`.\n  * `custom_text_split_function` _Optional, Callable_ - a custom function to split a string into a list of strings. Default is None, will use the default function in `autogen.retrieve_utils.split_text_to_chunks`.\n  * `custom_text_types` _Optional, List[str]_ - a list of file types to be processed. Default is TEXT_FORMATS.\n  * `recursive` _Optional, bool_ - whether to search documents recursively in the dir_path. Default is True.\n  * `extra_docs` _Optional, bool_ - whether to add more documents in the collection. Default is False\n\n\n**Returns** :\nThe chromadb client.\n### \n[​](https://docs.ag2.ai/docs/reference/<#query-vector-db>)\nquery_vector_db\nCopy\n```\ndef query_vector_db(query_texts: list[str],\n          n_results: int = 10,\n          client: API = None,\n          db_path: str = \"tmp/chromadb.db\",\n          collection_name: str = \"all-my-documents\",\n          search_string: str = \"\",\n          embedding_model: str = \"all-MiniLM-L6-v2\",\n          embedding_function: Callable = None) -> QueryResult\n\n```\n\nQuery a vector db. We support chromadb compatible APIs, it’s not required if you prepared your own vector db and query function.\n**Arguments** :\n  * `query_texts` _List[str]_ - the list of strings which will be used to query the vector db.\n  * `n_results` _Optional, int_ - the number of results to return. Default is 10.\n  * `client` _Optional, API_ - the chromadb compatible client. Default is None, a chromadb client will be used.\n  * `db_path` _Optional, str_ - the path to the vector db. Default is “tmp/chromadb.db”. The default was `/tmp/chromadb.db` for version `<=0.2.24`.\n  * `collection_name` _Optional, str_ - the name of the collection. Default is “all-my-documents”.\n  * `search_string` _Optional, str_ - the search string. Only docs that contain an exact match of this string will be retrieved. Default is \"\".\n  * `embedding_model` _Optional, str_ - the embedding model to use. Default is “all-MiniLM-L6-v2”. Will be ignored if embedding_function is not None.\n  * `embedding_function` _Optional, Callable_ - the embedding function to use. Default is None, SentenceTransformer with the given `embedding_model` will be used. If you want to use OpenAI, Cohere, HuggingFace or other embedding functions, you can pass it here, follow the examples in `https://docs.trychroma.com/embeddings`.\n\n\n**Returns** :\nThe query result. The format is:\nCopy\n```\nclass QueryResult(TypedDict):\n  ids: List[IDs]\n  embeddings: Optional[List[List[Embedding]]]\n  documents: Optional[List[List[Document]]]\n  metadatas: Optional[List[List[Metadata]]]\n  distances: Optional[List[List[float]]]\n\n```\n\n[math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)[runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [UNSTRUCTURED_FORMATS](https://docs.ag2.ai/docs/reference/<#unstructured-formats>)\n  * [split_text_to_chunks](https://docs.ag2.ai/docs/reference/<#split-text-to-chunks>)\n  * [extract_text_from_pdf](https://docs.ag2.ai/docs/reference/<#extract-text-from-pdf>)\n  * [split_files_to_chunks](https://docs.ag2.ai/docs/reference/<#split-files-to-chunks>)\n  * [get_files_from_dir](https://docs.ag2.ai/docs/reference/<#get-files-from-dir>)\n  * [parse_html_to_markdown](https://docs.ag2.ai/docs/reference/<#parse-html-to-markdown>)\n  * [get_file_from_url](https://docs.ag2.ai/docs/reference/<#get-file-from-url>)\n  * [is_url](https://docs.ag2.ai/docs/reference/<#is-url>)\n  * [create_vector_db_from_dir](https://docs.ag2.ai/docs/reference/<#create-vector-db-from-dir>)\n  * [query_vector_db](https://docs.ag2.ai/docs/reference/<#query-vector-db>)\n\n---\n\n# runtime_logging\nURL: https://docs.ag2.ai/docs/reference/runtime_logging\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\nruntime_logging\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# runtime_logging\n### \n[​](https://docs.ag2.ai/docs/reference/<#start>)\nstart\nCopy\n```\ndef start(logger: BaseLogger | None = None,\n     logger_type: Literal[\"sqlite\", \"file\"] = \"sqlite\",\n     config: dict[str, Any] | None = None) -> str\n\n```\n\nStart logging for the runtime.\n**Arguments** :\n  * `logger` _BaseLogger_ - A logger instance\n  * `logger_type` _str_ - The type of logger to use (default: sqlite)\n  * `config` _dict_ - Configuration for the logger\n\n\n**Returns** :\nsession_id (str(uuid.uuid4)): a unique id for the logging session\n[retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)[token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [start](https://docs.ag2.ai/docs/reference/<#start>)\n\n---\n\n# token_count_utils\nURL: https://docs.ag2.ai/docs/reference/token_count_utils\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\ntoken_count_utils\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# token_count_utils\n### \n[​](https://docs.ag2.ai/docs/reference/<#token-left>)\ntoken_left\nCopy\n```\ndef token_left(input: Union[str, list, dict],\n        model=\"gpt-3.5-turbo-0613\") -> int\n\n```\n\nCount number of tokens left for an OpenAI model.\n**Arguments** :\n  * `input` - (str, list, dict): Input to the model.\n  * `model` - (str): Model name.\n\n\n**Returns** :\n  * `int` - Number of tokens left that the model can use for completion.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#count-token>)\ncount_token\nCopy\n```\ndef count_token(input: Union[str, list, dict],\n        model: str = \"gpt-3.5-turbo-0613\") -> int\n\n```\n\nCount number of tokens used by an OpenAI model.\n**Arguments** :\n  * `input` - (str, list, dict): Input to the model.\n  * `model` - (str): Model name.\n\n\n**Returns** :\n  * `int` - Number of tokens from the input.\n\n\n### \n[​](https://docs.ag2.ai/docs/reference/<#num-tokens-from-functions>)\nnum_tokens_from_functions\nCopy\n```\ndef num_tokens_from_functions(functions, model=\"gpt-3.5-turbo-0613\") -> int\n\n```\n\nReturn the number of tokens used by a list of functions.\n**Arguments** :\n  * `functions` - (list): List of function descriptions that will be passed in model.\n  * `model` - (str): Model name.\n\n\n**Returns** :\n  * `int` - Number of tokens from the function descriptions.\n\n\n[runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)[types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [token_left](https://docs.ag2.ai/docs/reference/<#token-left>)\n  * [count_token](https://docs.ag2.ai/docs/reference/<#count-token>)\n  * [num_tokens_from_functions](https://docs.ag2.ai/docs/reference/<#num-tokens-from-functions>)\n\n---\n\n# types\nURL: https://docs.ag2.ai/docs/reference/types\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/reference/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAPI Reference\ntypes\n[Documentation](https://docs.ag2.ai/docs/reference/</docs/Home>)[Examples](https://docs.ag2.ai/docs/reference/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/reference/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/reference/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/reference/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/reference/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/reference/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/reference/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/reference/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/reference/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/reference/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/reference/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/reference/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/reference/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/reference/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/reference/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/reference/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/reference/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/reference/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/reference/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/reference/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/reference/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/reference/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/reference/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/reference/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/reference/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/reference/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/reference/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/reference/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/reference/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/reference/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/reference/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/reference/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/reference/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/reference/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/reference/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/reference/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/reference/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/reference/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/reference/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/reference/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/reference/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/reference/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/reference/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/reference/</docs/Migration-Guide>)\n\n\nAPI Reference\n# types\n## \n[​](https://docs.ag2.ai/docs/reference/<#usermessagetextcontentpart>)\nUserMessageTextContentPart\nCopy\n```\nclass UserMessageTextContentPart(TypedDict)\n\n```\n\nRepresents a text content part of a user message\n#### \n[​](https://docs.ag2.ai/docs/reference/<#type>)\ntype\nThe type of the content part. Always “text” for text content parts.\n#### \n[​](https://docs.ag2.ai/docs/reference/<#text>)\ntext\nThe text content of the part.\n## \n[​](https://docs.ag2.ai/docs/reference/<#usermessageimagecontentpart>)\nUserMessageImageContentPart\nCopy\n```\nclass UserMessageImageContentPart(TypedDict)\n\n```\n\nRepresents an image content part of a user message\n#### \n[​](https://docs.ag2.ai/docs/reference/<#type-2>)\ntype\nThe type of the content part. Always “image_url” for image content parts.\n#### \n[​](https://docs.ag2.ai/docs/reference/<#image-url>)\nimage_url\nThe URL of the image.\n[token_count_utils](https://docs.ag2.ai/docs/reference/</docs/reference/token_count_utils>)[Getting Started](https://docs.ag2.ai/docs/reference/</docs/autogen-studio/getting-started>)\n[x](https://docs.ag2.ai/docs/reference/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/reference/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/reference/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/reference/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/reference/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/reference/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [UserMessageTextContentPart](https://docs.ag2.ai/docs/reference/<#usermessagetextcontentpart>)\n  * [type](https://docs.ag2.ai/docs/reference/<#type>)\n  * [text](https://docs.ag2.ai/docs/reference/<#text>)\n  * [UserMessageImageContentPart](https://docs.ag2.ai/docs/reference/<#usermessageimagecontentpart>)\n  * [type](https://docs.ag2.ai/docs/reference/<#type-2>)\n  * [image_url](https://docs.ag2.ai/docs/reference/<#image-url>)\n\n---\n\n# Getting Started\nURL: https://docs.ag2.ai/docs/autogen-studio/getting-started\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAutoGen Studio\nGetting Started\n[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)\n\n\nAutoGen Studio\n# Getting Started\n[![Open in Colab](https://badge.fury.io/py/autogenstudio.svg)](https://docs.ag2.ai/docs/autogen-studio/<https:/badge.fury.io/py/autogenstudio>)\n[![Open in GitHub](https://static.pepy.tech/badge/autogenstudio/week)](https://docs.ag2.ai/docs/autogen-studio/<https:/pepy.tech/project/autogenstudio>)\n![ARA](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/ara_stockprices.png)\nAutoGen Studio is an low-code interface built to help you rapidly prototype AI agents, enhance them with skills, compose them into workflows and interact with them to accomplish tasks. It is built on top of the [AutoGen](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.ag2.ai>) framework, which is a toolkit for building AI agents.\nCode for AutoGen Studio is on GitHub at [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/autogen-studio>)\n> **Note** : AutoGen Studio is meant to help you rapidly prototype multi-agent workflows and demonstrate an example of end user interfaces built with AutoGen. It is not meant to be a production-ready app. Developers are encouraged to use the AutoGen framework to build their own applications, implementing authentication, security and other features required for deployed applications.\n**Updates**\n  * April 17: AutoGen Studio database layer is now rewritten to use [SQLModel](https://docs.ag2.ai/docs/autogen-studio/<https:/sqlmodel.tiangolo.com/>) (Pydantic + SQLAlchemy). This provides entity linking (skills, models, agents and workflows are linked via association tables) and supports multiple [database backend dialects](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.sqlalchemy.org/en/20/dialects/>) supported in SQLAlchemy (SQLite, PostgreSQL, MySQL, Oracle, Microsoft SQL Server). The backend database can be specified with a `--database-uri` argument when running the application. For example, `autogenstudio ui --database-uri sqlite:///database.sqlite` for SQLite and `autogenstudio ui --database-uri postgresql+psycopg://user:password@localhost/dbname` for PostgreSQL.\n  * March 12: Default directory for AutoGen Studio is now /home/<user>/.autogenstudio. You can also specify this directory using the `--appdir` argument when running the application. For example, `autogenstudio ui --appdir /path/to/folder`. This will store the database and other files in the specified directory e.g. `/path/to/folder/database.sqlite`. `.env` files in that directory will be used to set environment variables for the app.\n\n\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#installation>)\nInstallation\nThere are two ways to install AutoGen Studio - from PyPi or from source. We **recommend installing from PyPi** unless you plan to modify the source code.\n  1. **Install from PyPi**\nWe recommend using a virtual environment (e.g., conda) to avoid conflicts with existing Python packages. With Python 3.10 or newer active in your virtual environment, use pip to install AutoGen Studio:\nCopy\n```\npip install autogenstudio\n\n```\n\n  2. **Install from Source**\n> Note: This approach requires some familiarity with building interfaces in React.\nIf you prefer to install from source, ensure you have Python 3.10+ and Node.js (version above 14.15.0) installed. Here’s how you get started:\n     * Clone the AutoGen Studio repository from the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository and install its Python dependencies:\nCopy\n```\npip install -e .\n\n```\n\n     * Navigate to the `samples/apps/autogen-studio/frontend` directory, install dependencies, and build the UI:\nCopy\n```\nnpm install -g gatsby-cli\nnpm install --global yarn\ncd frontend\nyarn install\nyarn build\n\n```\n\n\n\nFor Windows users, to build the frontend, you may need alternative commands to build the frontend.\nCopy\n```\n\n gatsby clean && rmdir /s /q ..\\\\autogenstudio\\\\web\\\\ui 2>nul & (set \\\"PREFIX_PATH_VALUE=\\\" || ver>nul) && gatsby build --prefix-paths && xcopy /E /I /Y public ..\\\\autogenstudio\\\\web\\\\ui\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#running-the-application>)\nRunning the Application\nOnce installed, run the web UI by entering the following in your terminal:\nCopy\n```\nautogenstudio ui --port 8081\n\n```\n\nThis will start the application on the specified port. Open your web browser and go to `http://localhost:8081/` to begin using AutoGen Studio.\nAutoGen Studio also takes several parameters to customize the application:\n  * `--host <host>` argument to specify the host address. By default, it is set to `localhost`. Y\n  * `--appdir <appdir>` argument to specify the directory where the app files (e.g., database and generated user files) are stored. By default, it is set to the a `.autogenstudio` directory in the user’s home directory.\n  * `--port <port>` argument to specify the port number. By default, it is set to `8080`.\n  * `--reload` argument to enable auto-reloading of the server when changes are made to the code. By default, it is set to `False`.\n  * `--database-uri` argument to specify the database URI. Example values include `sqlite:///database.sqlite` for SQLite and `postgresql+psycopg://user:password@localhost/dbname` for PostgreSQL. If this is not specified, the database URI defaults to a `database.sqlite` file in the `--appdir` directory.\n\n\nNow that you have AutoGen Studio installed and running, you are ready to explore its capabilities, including defining and modifying agent workflows, interacting with agents and sessions, and expanding agent skills.\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#capabilities-roadmap>)\nCapabilities / Roadmap\nSome of the capabilities supported by the app frontend include the following:\n  * Build / Configure agents (currently supports two agent workflows based on `UserProxyAgent` and `AssistantAgent`), modify their configuration (e.g. skills, temperature, model, agent system message, model etc) and compose them into workflows.\n  * Chat with agent workflows and specify tasks.\n  * View agent messages and output files in the UI from agent runs.\n  * Support for more complex agent workflows (e.g. `GroupChat` and `Sequential` workflows).\n  * Improved user experience (e.g., streaming intermediate model output, better summarization of agent responses, etc).\n\n\nProject Structure:\n  * _autogenstudio/_ code for the backend classes and web api (FastAPI)\n  * _frontend/_ code for the webui, built with Gatsby and TailwindCSS\n\n\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#contribution-guide>)\nContribution Guide\nWe welcome contributions to AutoGen Studio. We recommend the following general steps to contribute to the project:\n  * AutoGen Studio is in the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository.\n  * Please initiate a discussion on the roadmap issue or a new issue in that repository to discuss your proposed contribution.\n  * Submit a pull request in the [build-with-ag2](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2>) repository with your contribution!\n  * Please use the tag `studio` for any issues, questions, and PRs related to Studio\n\n\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#a-note-on-security>)\nA Note on Security\nAutoGen Studio is a research prototype and is not meant to be used in a production environment. Some baseline practices are encouraged e.g., using Docker code execution environment for your agents.\nHowever, other considerations such as rigorous tests related to jailbreaking, ensuring LLMs only have access to the right keys of data given the end user’s permissions, and other security features are not implemented in AutoGen Studio.\nIf you are building a production application, please use the AutoGen framework and implement the necessary security features.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#acknowledgements>)\nAcknowledgements\nAutoGen Studio is Based on the [AutoGen](https://docs.ag2.ai/docs/autogen-studio/<https:/docs.ag2.ai>) project. It was adapted from a research prototype built in October 2023 (original credits: Gagan Bansal, Adam Fourney, Victor Dibia, Piali Choudhury, Saleema Amershi, Ahmed Awadallah, Chi Wang).\n[types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)[Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)\n[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Installation](https://docs.ag2.ai/docs/autogen-studio/<#installation>)\n  * [Running the Application](https://docs.ag2.ai/docs/autogen-studio/<#running-the-application>)\n  * [Capabilities / Roadmap](https://docs.ag2.ai/docs/autogen-studio/<#capabilities-roadmap>)\n  * [Contribution Guide](https://docs.ag2.ai/docs/autogen-studio/<#contribution-guide>)\n  * [A Note on Security](https://docs.ag2.ai/docs/autogen-studio/<#a-note-on-security>)\n  * [Acknowledgements](https://docs.ag2.ai/docs/autogen-studio/<#acknowledgements>)\n\n---\n\n# Using AutoGen Studio\nURL: https://docs.ag2.ai/docs/autogen-studio/usage\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAutoGen Studio\nUsing AutoGen Studio\n[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)\n\n\nAutoGen Studio\n# Using AutoGen Studio\nAutoGen Studio supports the declarative creation of an agent workflow and tasks can be specified and run in a chat interface for the agents to complete. The expected usage behavior is that developers can create skills and models, _attach_ them to agents, and compose agents into workflows that can be tested interactively in the chat interface.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#building-an-agent-workflow>)\nBuilding an Agent Workflow\nAutoGen Studio implements several entities that are ultimately composed into a workflow.\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#skills>)\nSkills\nA skill is a python function that implements the solution to a task. In general, a good skill has a descriptive name (e.g. generate _images), extensive docstrings and good defaults (e.g., writing out files to disk for persistence and reuse). Skills can be _associated with_ or _attached to_ agent specifications.\n![AutoGen Studio Skill Interface](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/skill.png)\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#models>)\nModels\nA model refers to the configuration of an LLM. Similar to skills, a model can be attached to an agent specification. The AutoGen Studio interface supports multiple model types including OpenAI models (and any other model endpoint provider that supports the OpenAI endpoint specification), Azure OpenAI models and Gemini Models.\n![AutoGen Studio Create new model](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/model_new.png) ![AutoGen Studio Create new model](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/model_openai.png)\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#agents>)\nAgents\nAn agent entity declaratively specifies properties for an AutoGen agent (mirrors most but not all of the members of a base AutoGen Conversable agent class). Currently `UserProxyAgent` and `AssistantAgent` and `GroupChat` agent abstractions are supported.\n![AutoGen Studio Create new agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_new.png) ![AutoGen Studio Createan assistant agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_groupchat.png)\nOnce agents have been created, existing models or skills can be _added_ to the agent.\n![AutoGen Studio Add skills and models to agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/agent_skillsmodel.png)\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#workflows>)\nWorkflows\nAn agent workflow is a specification of a set of agents (team of agents) that can work together to accomplish a task. AutoGen Studio supports two types of high level workflow patterns:\n#### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#autonomous-chat>)\nAutonomous Chat :\nThis workflow implements a paradigm where agents are defined and a chat is initiated between the agents to accomplish a task. AutoGen simplifies this into defining an `initiator` agent and a `receiver` agent where the receiver agent is selected from a list of previously created agents. Note that when the receiver is a `GroupChat` agent (i.e., contains multiple agents), the communication pattern between those agents is determined by the `speaker_selection_method` parameter in the `GroupChat` agent configuration.\n![AutoGen Studio Autonomous Chat Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_chat.png)\n#### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#sequential-chat>)\nSequential Chat\nThis workflow allows users to specify a list of `AssistantAgent` agents that are executed in sequence to accomplish a task. The runtime behavior here follows the following pattern: at each step, each `AssistantAgent` is _paired_ with a `UserProxyAgent` and chat initiated between this pair to process the input task. The result of this exchange is summarized and provided to the next `AssistantAgent` which is also paired with a `UserProxyAgent` and their summarized result is passed to the next `AssistantAgent` in the sequence. This continues until the last `AssistantAgent` in the sequence is reached.\n![AutoGen Studio Sequential Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_sequential.png)\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#testing-an-agent-workflow>)\nTesting an Agent Workflow\nAutoGen Studio allows users to interactively test workflows on tasks and review resulting artifacts (such as images, code, and documents).\n![AutoGen Studio Test Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_test.png)\nUsers can also review the “inner monologue” of agent workflows as they address tasks, and view profiling information such as costs associated with the run (such as number of turns, number of tokens etc.), and agent actions (such as whether tools were called and the outcomes of code execution).\n![AutoGen Studio Profile Workflow Results](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_profile.png)\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#exporting-agent-workflows>)\nExporting Agent Workflows\nUsers can download the skills, agents, and workflow configurations they create as well as share and reuse these artifacts. AutoGen Studio also offers a seamless process to export workflows and deploy them as application programming interfaces (APIs) that can be consumed in other applications deploying workflows as APIs.\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#export-workflow>)\nExport Workflow\nAutoGen Studio allows you to export a selected workflow as a JSON configuration file.\nBuild -> Workflows -> (On workflow card) -> Export\n![AutoGen Studio Export Workflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/autogen-studio/img/workflow_export.png)\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#using-autogen-studio-workflows-in-a-python-application>)\nUsing AutoGen Studio Workflows in a Python Application\nAn exported workflow can be easily integrated into any Python application using the `WorkflowManager` class with just two lines of code. Underneath, the WorkflowManager rehydrates the workflow specification into AutoGen agents that are subsequently used to address tasks.\nCopy\n```\n\nfrom autogenstudio import WorkflowManager\n# load workflow from exported json workflow file.\nworkflow_manager = WorkflowManager(workflow=\"path/to/your/workflow_.json\")\n# run the workflow on a task\ntask_query = \"What is the height of the Eiffel Tower?. Dont write code, just respond to the question.\"\nworkflow_manager.run(message=task_query)\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/autogen-studio/<#deploying-autogen-studio-workflows-as-apis>)\nDeploying AutoGen Studio Workflows as APIs\nThe workflow can be launched as an API endpoint from the command line using the autogenstudio commandline tool.\nCopy\n```\nautogenstudio serve --workflow=workflow.json --port=5000\n\n```\n\nSimilarly, the workflow launch command above can be wrapped into a Dockerfile that can be deployed on cloud services like Azure Container Apps or Azure Web Apps.\n[Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)[FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)\n[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Building an Agent Workflow](https://docs.ag2.ai/docs/autogen-studio/<#building-an-agent-workflow>)\n  * [Skills](https://docs.ag2.ai/docs/autogen-studio/<#skills>)\n  * [Models](https://docs.ag2.ai/docs/autogen-studio/<#models>)\n  * [Agents](https://docs.ag2.ai/docs/autogen-studio/<#agents>)\n  * [Workflows](https://docs.ag2.ai/docs/autogen-studio/<#workflows>)\n  * [Autonomous Chat :](https://docs.ag2.ai/docs/autogen-studio/<#autonomous-chat>)\n  * [Sequential Chat](https://docs.ag2.ai/docs/autogen-studio/<#sequential-chat>)\n  * [Testing an Agent Workflow](https://docs.ag2.ai/docs/autogen-studio/<#testing-an-agent-workflow>)\n  * [Exporting Agent Workflows](https://docs.ag2.ai/docs/autogen-studio/<#exporting-agent-workflows>)\n  * [Export Workflow](https://docs.ag2.ai/docs/autogen-studio/<#export-workflow>)\n  * [Using AutoGen Studio Workflows in a Python Application](https://docs.ag2.ai/docs/autogen-studio/<#using-autogen-studio-workflows-in-a-python-application>)\n  * [Deploying AutoGen Studio Workflows as APIs](https://docs.ag2.ai/docs/autogen-studio/<#deploying-autogen-studio-workflows-as-apis>)\n\n---\n\n# FAQs\nURL: https://docs.ag2.ai/docs/autogen-studio/faqs\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/autogen-studio/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nAutoGen Studio\nFAQs\n[Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)[Examples](https://docs.ag2.ai/docs/autogen-studio/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/autogen-studio/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/autogen-studio/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/autogen-studio/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/autogen-studio/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/autogen-studio/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/autogen-studio/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/autogen-studio/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/autogen-studio/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/autogen-studio/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/autogen-studio/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/autogen-studio/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/autogen-studio/</docs/Migration-Guide>)\n\n\nAutoGen Studio\n# FAQs\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-how-do-i-specify-the-directory-where-files-e-g-database-are-stored>)\nQ: How do I specify the directory where files(e.g. database) are stored?\nA: You can specify the directory where files are stored by setting the `--appdir` argument when running the application. For example, `autogenstudio ui --appdir /path/to/folder`. This will store the database (default) and other files in the specified directory e.g. `/path/to/folder/database.sqlite`.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-where-can-i-adjust-the-default-skills-agent-and-workflow-configurations>)\nQ: Where can I adjust the default skills, agent and workflow configurations?\nA: You can modify agent configurations directly from the UI or by editing the `init_db_samples` function in the `autogenstudio/database/utils.py` file which is used to initialize the database.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-if-i-want-to-reset-the-entire-conversation-with-an-agent-how-do-i-go-about-it>)\nQ: If I want to reset the entire conversation with an agent, how do I go about it?\nA: To reset your conversation history, you can delete the `database.sqlite` file in the `--appdir` directory. This will reset the entire conversation history. To delete user files, you can delete the `files` directory in the `--appdir` directory.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-is-it-possible-to-view-the-output-and-messages-generated-by-the-agents-during-interactions>)\nQ: Is it possible to view the output and messages generated by the agents during interactions?\nA: Yes, you can view the generated messages in the debug console of the web UI, providing insights into the agent interactions. Alternatively, you can inspect the `database.sqlite` file for a comprehensive record of messages.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-use-other-models-with-autogen-studio>)\nQ: Can I use other models with AutoGen Studio?\nYes. AutoGen standardizes on the openai model api format, and you can use any api server that offers an openai compliant endpoint. In the AutoGen Studio UI, each agent has an `llm_config` field where you can input your model endpoint details including `model`, `api key`, `base url`, `model type` and `api version`. For Azure OpenAI models, you can find these details in the Azure portal. Note that for Azure OpenAI, the `model name` is the deployment id or engine, and the `model type` is “azure”. For other OSS models, we recommend using a server such as vllm, LMStudio, Ollama, to instantiate an openai compliant endpoint.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-the-server-starts-but-i-cant-access-the-ui>)\nQ: The server starts but I can’t access the UI\nA: If you are running the server on a remote machine (or a local machine that fails to resolve localhost correctly), you may need to specify the host address. By default, the host address is set to `localhost`. You can specify the host address using the `--host <host>` argument. For example, to start the server on port 8081 and local address such that it is accessible from other machines on the network, you can run the following command:\nCopy\n```\nautogenstudio ui --port 8081 --host 0.0.0.0\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-export-my-agent-workflows-for-use-in-a-python-app>)\nQ: Can I export my agent workflows for use in a python app?\nYes. In the Build view, you can click the export button to save your agent workflow as a JSON file. This file can be imported in a python application using the `WorkflowManager` class. For example:\nCopy\n```\n\nfrom autogenstudio import WorkflowManager\n# load workflow from exported json workflow file.\nworkflow_manager = WorkflowManager(workflow=\"path/to/your/workflow_.json\")\n# run the workflow on a task\ntask_query = \"What is the height of the Eiffel Tower?. Dont write code, just respond to the question.\"\nworkflow_manager.run(message=task_query)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-deploy-my-agent-workflows-as-apis>)\nQ: Can I deploy my agent workflows as APIs?\nYes. You can launch the workflow as an API endpoint from the command line using the `autogenstudio` commandline tool. For example:\nCopy\n```\nautogenstudio serve --workflow=workflow.json --port=5000\n\n```\n\nSimilarly, the workflow launch command above can be wrapped into a Dockerfile that can be deployed on cloud services like Azure Container Apps or Azure Web Apps.\n## \n[​](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-run-autogen-studio-in-a-docker-container>)\nQ: Can I run AutoGen Studio in a Docker container?\nA: Yes, you can run AutoGen Studio in a Docker container. You can build the Docker image using the provided [Dockerfile](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/apps/autogen-studio/Dockerfile>) and run the container using the following commands:\nCopy\n```\nFROM python:3.10\nWORKDIR /code\nRUN pip install -U gunicorn autogenstudio\nRUN useradd -m -u 1000 user\nUSER user\nENV HOME=/home/user \\\n  PATH=/home/user/.local/bin:$PATH \\\n  AUTOGENSTUDIO_APPDIR=/home/user/app\nWORKDIR $HOME/app\nCOPY --chown=user . $HOME/app\nCMD gunicorn -w $((2 * $(getconf _NPROCESSORS_ONLN) + 1)) --timeout 12600 -k uvicorn.workers.UvicornWorker autogenstudio.web.app:app --bind \"0.0.0.0:8081\"\n\n```\n\nUsing Gunicorn as the application server for improved performance is recommended. To run AutoGen Studio with Gunicorn, you can use the following command:\nCopy\n```\ngunicorn -w $((2 * $(getconf _NPROCESSORS_ONLN) + 1)) --timeout 12600 -k uvicorn.workers.UvicornWorker autogenstudio.web.app:app --bind\n\n```\n\n[Using AutoGen Studio](https://docs.ag2.ai/docs/autogen-studio/</docs/autogen-studio/usage>)[Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/autogen-studio/</docs/ecosystem/agentops>)\n[x](https://docs.ag2.ai/docs/autogen-studio/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/autogen-studio/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/autogen-studio/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/autogen-studio/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/autogen-studio/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/autogen-studio/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Q: How do I specify the directory where files(e.g. database) are stored?](https://docs.ag2.ai/docs/autogen-studio/<#q-how-do-i-specify-the-directory-where-files-e-g-database-are-stored>)\n  * [Q: Where can I adjust the default skills, agent and workflow configurations?](https://docs.ag2.ai/docs/autogen-studio/<#q-where-can-i-adjust-the-default-skills-agent-and-workflow-configurations>)\n  * [Q: If I want to reset the entire conversation with an agent, how do I go about it?](https://docs.ag2.ai/docs/autogen-studio/<#q-if-i-want-to-reset-the-entire-conversation-with-an-agent-how-do-i-go-about-it>)\n  * [Q: Is it possible to view the output and messages generated by the agents during interactions?](https://docs.ag2.ai/docs/autogen-studio/<#q-is-it-possible-to-view-the-output-and-messages-generated-by-the-agents-during-interactions>)\n  * [Q: Can I use other models with AutoGen Studio?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-use-other-models-with-autogen-studio>)\n  * [Q: The server starts but I can’t access the UI](https://docs.ag2.ai/docs/autogen-studio/<#q-the-server-starts-but-i-cant-access-the-ui>)\n  * [Q: Can I export my agent workflows for use in a python app?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-export-my-agent-workflows-for-use-in-a-python-app>)\n  * [Q: Can I deploy my agent workflows as APIs?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-deploy-my-agent-workflows-as-apis>)\n  * [Q: Can I run AutoGen Studio in a Docker container?](https://docs.ag2.ai/docs/autogen-studio/<#q-can-i-run-autogen-studio-in-a-docker-container>)\n\n---\n\n# Agent Monitoring and Debugging with AgentOps\nURL: https://docs.ag2.ai/docs/ecosystem/agentops\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nAgent Monitoring and Debugging with AgentOps\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Agent Monitoring and Debugging with AgentOps\n![AgentOps logo](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/logo/banner-badge.png?raw=true)\n[AgentOps](https://docs.ag2.ai/docs/ecosystem/<https:/agentops.ai/?=autogen>) provides session replays, metrics, and monitoring for AI agents.\nAt a high level, AgentOps gives you the ability to monitor LLM calls, costs, latency, agent failures, multi-agent interactions, tool usage, session-wide statistics, and more. For more info, check out the [AgentOps Repo](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/AgentOps-AI/agentops>).\n📊 **Replay Analytics and Debugging**|  Step-by-step agent execution graphs  \n---|---  \n💸 **LLM Cost Management**|  Track spend with LLM foundation model providers  \n🧪 **Agent Benchmarking**|  Test your agents against 1,000+ evals  \n🔐 **Compliance and Security**|  Detect common prompt injection and data exfiltration exploits  \n🤝 **Framework Integrations**|  Native Integrations with CrewAI, AutoGen, & LangChain  \nAgent Dashboard\n[![Agent Dashboard](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/overview.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)\nSession Analytics\n[![Session\nAnalytics](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/session-overview.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)\nSession Replays\n[![Session Replays](https://github.com/AgentOps-AI/agentops/blob/main/docs/images/external/app_screenshots/session-replay.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/signin?ref=gh>)\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#installation>)\nInstallation\nAgentOps works seamlessly with applications built using Autogen.\n  1. **Install AgentOps**\n\n\nCopy\n```\npip install agentops\n\n```\n\n  1. **Create an API Key:** Create a user API key here: [Create API Key](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/settings/projects>)\n  2. **Configure Your Environment:** Add your API key to your environment variables\n\n\nCopy\n```\nAGENTOPS_API_KEY=<YOUR_AGENTOPS_API_KEY>\n\n```\n\n  1. **Initialize AgentOps**\n\n\nTo start tracking all available data on Autogen runs, simply add two lines of code before implementing Autogen.\nCopy\n```\nimport agentops\nagentops.init() # Or: agentops.init(api_key=\"your-api-key-here\")\n\n```\n\nAfter initializing AgentOps, Autogen will now start automatically tracking your agent runs.\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#features>)\nFeatures\n  * **LLM Costs** : Track spend with foundation model providers\n  * **Replay Analytics** : Watch step-by-step agent execution graphs\n  * **Recursive Thought Detection** : Identify when agents fall into infinite loops\n  * **Custom Reporting:** Create custom analytics on agent performance\n  * **Analytics Dashboard:** Monitor high level statistics about agents in development and production\n  * **Public Model Testing** : Test your agents against benchmarks and leaderboards\n  * **Custom Tests:** Run your agents against domain specific tests\n  * **Time Travel Debugging** : Save snapshots of session states to rewind and replay agent runs from chosen checkpoints.\n  * **Compliance and Security** : Create audit logs and detect potential threats such as profanity and PII leaks\n  * **Prompt Injection Detection** : Identify potential code injection and secret leaks\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#autogen-agentops-examples>)\nAutogen + AgentOps examples\n  * [AgentChat with AgentOps Notebook](https://docs.ag2.ai/docs/ecosystem/</notebooks/agentchat_agentops>)\n  * [More AgentOps Examples](https://docs.ag2.ai/docs/ecosystem/<https:/docs.agentops.ai/v1/quickstart>)\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#extra-links>)\nExtra links\n  * [🐦 Twitter](https://docs.ag2.ai/docs/ecosystem/<https:/twitter.com/agentopsai/>)\n  * [📢 Discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/JHPt4C7r>)\n  * [🖇️ AgentOps Dashboard](https://docs.ag2.ai/docs/ecosystem/<https:/app.agentops.ai/ref?=autogen>)\n  * [📙 Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.agentops.ai/introduction>)\n\n\n[FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)[Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Installation](https://docs.ag2.ai/docs/ecosystem/<#installation>)\n  * [Features](https://docs.ag2.ai/docs/ecosystem/<#features>)\n  * [Autogen + AgentOps examples](https://docs.ag2.ai/docs/ecosystem/<#autogen-agentops-examples>)\n  * [Extra links](https://docs.ag2.ai/docs/ecosystem/<#extra-links>)\n\n---\n\n# Azure Cosmos DB\nURL: https://docs.ag2.ai/docs/ecosystem/azure_cosmos_db\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nAzure Cosmos DB\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Azure Cosmos DB\n> “OpenAI relies on Cosmos DB to dynamically scale their ChatGPT service – one of the fastest-growing consumer apps ever – enabling high reliability and low maintenance.” – Satya Nadella, Microsoft chairman and chief executive officer\nAzure Cosmos DB is a fully managed [NoSQL](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/distributed-nosql>), [relational](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/distributed-relational>), and [vector database](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/azure/cosmos-db/vector-database>). It offers single-digit millisecond response times, automatic and instant scalability, along with guaranteed speed at any scale. Your business continuity is assured with up to 99.999% availability backed by SLA.\nYour can simplify your application development by using this single database service for all your AI agent memory system needs, from [geo-replicated distributed cache](https://docs.ag2.ai/docs/ecosystem/<https:/medium.com/@marcodesanctis2/using-azure-cosmos-db-as-your-persistent-geo-replicated-distributed-cache-b381ad80f8a0>) to tracing/logging to [vector database](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/vector-database>).\nLearn more about how Azure Cosmos DB enhances the performance of your [AI agent](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/ai-agents>).\n  * [Try Azure Cosmos DB free](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/try-free>)\n  * [Use Azure Cosmos DB lifetime free tier](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/cosmos-db/free-tier>)\n\n\n[Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)[Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Composio\nURL: https://docs.ag2.ai/docs/ecosystem/composio\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nComposio\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Composio\n![Composio Logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-composio.png)\nComposio empowers AI agents to seamlessly connect with external tools, Apps, and APIs to perform actions and receive triggers. With built-in support for AutoGen, Composio enables the creation of highly capable and adaptable AI agents that can autonomously execute complex tasks and deliver personalized experiences.\n  * [Composio + AutoGen Documentation with Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/docs.composio.dev/framework/autogen>)\n\n\n[Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)[Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Databricks\nURL: https://docs.ag2.ai/docs/ecosystem/databricks\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nDatabricks\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Databricks\n![Databricks Data Intelligence Platform](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-databricks.png)\nThe [Databricks Data Intelligence Platform ](https://docs.ag2.ai/docs/ecosystem/<https:/www.databricks.com/product/data-intelligence-platform>) allows your entire organization to use data and AI. It’s built on a lakehouse to provide an open, unified foundation for all data and governance, and is powered by a Data Intelligence Engine that understands the uniqueness of your data.\nThis example demonstrates how to use AutoGen alongside Databricks Foundation Model APIs and open-source LLM DBRX.\n  * [Databricks + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/agentchat_databricks_dbrx>)\n\n\n[Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)[Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Llamaindex\nURL: https://docs.ag2.ai/docs/ecosystem/llamaindex\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nLlamaindex\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Llamaindex\n![Llamaindex Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-llamaindex.png)\n[Llamaindex](https://docs.ag2.ai/docs/ecosystem/<https:/www.llamaindex.ai/>) allows the users to create Llamaindex agents and integrate them in autogen conversation patterns.\n  * [Llamaindex + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_group_chat_with_llamaindex_agents.ipynb>)\n\n\n[Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)[Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Mem0:Long-Term Memory and Personalization for Agents\nURL: https://docs.ag2.ai/docs/ecosystem/mem0\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nMem0:Long-Term Memory and Personalization for Agents\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Mem0:Long-Term Memory and Personalization for Agents\n![Mem0 logo](https://github.com/mem0ai/mem0/blob/main/docs/images/mem0-bg.png?raw=true)\n[Mem0 Platform](https://docs.ag2.ai/docs/ecosystem/<https:/www.mem0.ai/>) provides a smart, self-improving memory layer for Large Language Models (LLMs), enabling developers to create personalized AI experiences that evolve with each user interaction.\nAt a high level, Mem0 Platform offers comprehensive memory management, self-improving memory capabilities, cross-platform consistency, and centralized memory control for AI applications. For more info, check out the [Mem0 Platform Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.mem0.ai>).\n🧠 **Comprehensive Memory Management**|  Manage long-term, short-term, semantic, and episodic memories  \n---|---  \n🔄 **Self-Improving Memory**|  Adaptive system that learns from user interactions  \n🌐 **Cross-Platform Consistency**|  Unified user experience across various AI platforms  \n🎛️ **Centralized Memory Control**|  Effortless storage, updating, and deletion of memories  \n🚀 **Simplified Development**|  API-first approach for streamlined integration  \nActivity Dashboard\n[![Activity\nDashboard](https://github.com/mem0ai/mem0/blob/main/docs/images/platform/activity.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.mem0.ai/>)\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#installation>)\nInstallation\nMem0 Platform works seamlessly with various AI applications.\n  1. **Sign Up:** Create an account at [Mem0 Platform](https://docs.ag2.ai/docs/ecosystem/<https:/app.mem0.ai/>)\n  2. **Generate API Key:** Create an API key in your Mem0 dashboard\n  3. **Install Mem0 SDK:**\n\n\nCopy\n```\npip install mem0ai\n\n```\n\n  1. **Configure Your Environment:** Add your API key to your environment variables\n\n\nCopy\n```\nMEM0_API_KEY=<YOUR_MEM0_API_KEY>\n\n```\n\n  1. **Initialize Mem0:**\n\n\nCopy\n```\nfrom mem0ai import MemoryClient\nmemory = MemoryClient(api_key=os.getenv(\"MEM0_API_KEY\"))\n\n```\n\nAfter initializing Mem0, you can start using its memory management features in your AI application.\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#features>)\nFeatures\n  * **Long-term Memory** : Store and retrieve information persistently across sessions\n  * **Short-term Memory** : Manage temporary information within a single interaction\n  * **Semantic Memory** : Organize and retrieve conceptual knowledge\n  * **Episodic Memory** : Store and recall specific events or experiences\n  * **Self-Improving System** : Continuously refine understanding based on user interactions\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#common-use-cases>)\nCommon Use Cases\n  * Personalized Learning Assistants\n  * Customer Support AI Agents\n  * Healthcare Assistants\n  * Virtual Companions\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#mem0-platform-examples>)\nMem0 Platform Examples\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#autogen-with-mem0-example>)\nAutoGen with Mem0 Example\nThis example demonstrates how to use Mem0 with AutoGen to create a conversational AI system with memory capabilities.\nCopy\n```\nimport os\nfrom autogen import ConversableAgent\nfrom mem0 import MemoryClient\n# Set up environment variables\nos.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\nos.environ[\"MEM0_API_KEY\"] = \"your_mem0_api_key\"\n# Initialize Agent and Memory\nagent = ConversableAgent(\n  \"chatbot\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  code_execution_config=False,\n  function_map=None,\n  human_input_mode=\"NEVER\",\n)\nmemory = MemoryClient(api_key=os.environ.get(\"MEM0_API_KEY\"))\n# Insert a conversation into memory\nconversation = [\n  {\n    \"role\": \"assistant\",\n    \"content\": \"Hi, I'm Best Buy's chatbot!\\n\\nThanks for being a My Best Buy TotalTM member.\\n\\nWhat can I help you with?\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"Seeing horizontal lines on our tv. TV model: Sony - 77\\\" Class BRAVIA XR A80K OLED 4K UHD Smart Google TV\"\n  },\n]\nmemory.add(messages=conversation, user_id=\"customer_service_bot\")\n# Agent Inference\ndata = \"Which TV am I using?\"\nrelevant_memories = memory.search(data, user_id=\"customer_service_bot\")\nflatten_relevant_memories = \"\\n\".join([m[\"memory\"] for m in relevant_memories])\nprompt = f\"\"\"Answer the user question considering the memories.\nMemories:\n{flatten_relevant_memories}\n\\n\\n\nQuestion: {data}\n\"\"\"\nreply = agent.generate_reply(messages=[{\"content\": prompt, \"role\": \"user\"}])\nprint(\"Reply :\", reply)\n# Multi Agent Conversation\nmanager = ConversableAgent(\n  \"manager\",\n  system_message=\"You are a manager who helps in resolving customer issues.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\"\n)\ncustomer_bot = ConversableAgent(\n  \"customer_bot\",\n  system_message=\"You are a customer service bot who gathers information on issues customers are facing.\",\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n  human_input_mode=\"NEVER\"\n)\ndata = \"What appointment is booked?\"\nrelevant_memories = memory.search(data, user_id=\"customer_service_bot\")\nflatten_relevant_memories = \"\\n\".join([m[\"memory\"] for m in relevant_memories])\nprompt = f\"\"\"\nContext:\n{flatten_relevant_memories}\n\\n\\n\nQuestion: {data}\n\"\"\"\nresult = manager.send(prompt, customer_bot, request_reply=True)\n\n```\n\nAccess the complete code from this notebook: [Mem0 with AutoGen](https://docs.ag2.ai/docs/ecosystem/<https:/colab.research.google.com/drive/1NZEwC9w6V2S6hYmK7l2SQ9jhQrG1uKk8?usp=sharing>)\nThis example showcases:\n  1. Setting up AutoGen agents and Mem0 memory\n  2. Adding a conversation to Mem0 memory\n  3. Using Mem0 to retrieve relevant memories for agent inference\n  4. Implementing a multi-agent conversation with memory-augmented context\n\n\nFor more Mem0 examples, visit our [documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.mem0.ai/examples>).\n[Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)[MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Installation](https://docs.ag2.ai/docs/ecosystem/<#installation>)\n  * [Features](https://docs.ag2.ai/docs/ecosystem/<#features>)\n  * [Common Use Cases](https://docs.ag2.ai/docs/ecosystem/<#common-use-cases>)\n  * [Mem0 Platform Examples](https://docs.ag2.ai/docs/ecosystem/<#mem0-platform-examples>)\n  * [AutoGen with Mem0 Example](https://docs.ag2.ai/docs/ecosystem/<#autogen-with-mem0-example>)\n\n---\n\n# MemGPT\nURL: https://docs.ag2.ai/docs/ecosystem/memgpt\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nMemGPT\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# MemGPT\n![MemGPT Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-memgpt.png)\nMemGPT enables LLMs to manage their own memory and overcome limited context windows. You can use MemGPT to create perpetual chatbots that learn about you and modify their own personalities over time. You can connect MemGPT to your own local filesystems and databases, as well as connect MemGPT to your own tools and APIs. The MemGPT + AutoGen integration allows you to equip any AutoGen agent with MemGPT capabilities.\n  * [MemGPT + AutoGen Documentation with Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/memgpt.readme.io/docs/autogen>)\n\n\n[Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Microsoft Fabric\nURL: https://docs.ag2.ai/docs/ecosystem/microsoft-fabric\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nMicrosoft Fabric\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Microsoft Fabric\n![Fabric Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-fabric.png)\n[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview>) is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place. In this notenook, we give a simple example for using AutoGen in Microsoft Fabric.\n  * [Microsoft Fabric + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_microsoft_fabric.ipynb>)\n\n\n[MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)[Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Ollama\nURL: https://docs.ag2.ai/docs/ecosystem/ollama\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nOllama\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Ollama\n![Ollama Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-ollama.png)\n[Ollama](https://docs.ag2.ai/docs/ecosystem/<https:/ollama.com/>) allows the users to run open-source large language models, such as Llama 2, locally. Ollama bundles model weights, configuration, and data into a single package, defined by a Modelfile. It optimizes setup and configuration details, including GPU usage.\n  * [Ollama + AutoGen instruction](https://docs.ag2.ai/docs/ecosystem/<https:/ollama.ai/blog/openai-compatibility>)\n\n\n[Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)[PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# PGVector\nURL: https://docs.ag2.ai/docs/ecosystem/pgvector\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nPGVector\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# PGVector\n[PGVector](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/pgvector/pgvector>) is an open-source vector similarity search for Postgres.\n  * [PGVector + AutoGen Code Examples](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_RetrieveChat_pgvector.ipynb>)\n\n\n[Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)[Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Portkey Integration with AutoGen\nURL: https://docs.ag2.ai/docs/ecosystem/portkey\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nPortkey Integration with AutoGen\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Portkey Integration with AutoGen\n![Portkey Metrics Visualization](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Autogen.png?raw=true)\n[Portkey](https://docs.ag2.ai/docs/ecosystem/<https:/portkey.ai>) is a 2-line upgrade to make your AutoGen agents reliable, cost-efficient, and fast.\nPortkey adds 4 core production capabilities to any AutoGen agent:\n  1. Routing to 200+ LLMs\n  2. Making each LLM call more robust\n  3. Full-stack tracing & cost, performance analytics\n  4. Real-time guardrails to enforce behavior\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#getting-started>)\nGetting Started\n  1. **Install Required Packages:**\n  2. Copy\n```\npip install -qU pyautogen portkey-ai\n\n```\n\n**Configure AutoGen with Portkey:**\nCopy\n```\nfrom autogen import AssistantAgent, UserProxyAgent, config_list_from_json\nfrom portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\nconfig = [\n  {\n    \"api_key\": \"OPENAI_API_KEY\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"base_url\": PORTKEY_GATEWAY_URL,\n    \"api_type\": \"openai\",\n    \"default_headers\": createHeaders(\n      api_key=\"YOUR_PORTKEY_API_KEY\",\n      provider=\"openai\",\n    )\n  }\n]\n\n```\n\nGenerate your API key in the [Portkey Dashboard](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>).\n\n\nAnd, that’s it! With just this, you can start logging all of your AutoGen requests and make them reliable.\n  1. **Let’s Run your Agent**\n\n\nCopy\n```\nimport autogen\n# Create user proxy agent, coder, product manager\n\nuser_proxy = autogen.UserProxyAgent(\n  name=\"User_proxy\",\n  system_message=\"A human admin who will give the idea and run the code provided by Coder.\",\n  code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n  human_input_mode=\"ALWAYS\",\n)\n\ncoder = autogen.AssistantAgent(\n  name=\"Coder\",\n  system_message = \"You are a Python developer who is good at developing games. You work with Product Manager.\",\n  llm_config={\"config_list\": config},\n)\n# Create groupchat\ngroupchat = autogen.GroupChat(\n  agents=[user_proxy, coder], messages=[])\nmanager = autogen.GroupChatManager(groupchat=groupchat, llm_config={\"config_list\": config})\n\n# Start the conversation\nuser_proxy.initiate_chat(\n  manager, message=\"Build a classic & basic pong game with 2 players in python\")\n\n```\n\nHere’s the output from your Agent’s run on Portkey’s dashboard\n![Portkey Dashboard](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Dashboard.png?raw=true)\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#key-features>)\nKey Features\nPortkey offers a range of advanced features to enhance your AutoGen agents. Here’s an overview\nFeature| Description  \n---|---  \n🌐 [Multi-LLM Integration](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#interoperability>)| Access 200+ LLMs with simple configuration changes  \n🛡️ [Enhanced Reliability](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#reliability>)| Implement fallbacks, load balancing, retries, and much more  \n📊 [Advanced Metrics](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#metrics>)| Track costs, tokens, latency, and 40+ custom metrics effortlessly  \n🔍 [Detailed Traces and Logs](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#comprehensive-logging>)| Gain insights into every agent action and decision  \n🚧 [Guardrails](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#guardrails>)| Enforce agent behavior with real-time checks on inputs and outputs  \n🔄 [Continuous Optimization](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#continuous-improvement>)| Capture user feedback for ongoing agent improvements  \n💾 [Smart Caching](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#caching>)| Reduce costs and latency with built-in caching mechanisms  \n🔐 [Enterprise-Grade Security](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey#security-and-compliance>)| Set budget limits and implement fine-grained access controls  \n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#colab-notebook>)\nColab Notebook\nFor a hands-on example of integrating Portkey with Autogen, check out our notebook [![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/ecosystem/<https:/git.new/Portkey-Autogen>) .\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#advanced-features>)\nAdvanced Features\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#interoperability>)\nInteroperability\nEasily switch between **200+ LLMs** by changing the `provider` and API key in your configuration.\n#### \n[​](https://docs.ag2.ai/docs/ecosystem/<#example-switching-from-openai-to-azure-openai>)\nExample: Switching from OpenAI to Azure OpenAI\nCopy\n```\nconfig = [\n  {\n    \"api_key\": \"api-key\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"base_url\": PORTKEY_GATEWAY_URL,\n    \"api_type\": \"openai\",\n    \"default_headers\": createHeaders(\n      api_key=\"YOUR_PORTKEY_API_KEY\",\n      provider=\"azure-openai\",\n      virtual_key=\"AZURE_VIRTUAL_KEY\"\n    )\n  }\n]\n\n```\n\nNote: AutoGen messages will go through Portkey’s AI Gateway following OpenAI’s API signature. Some language models may not work properly because messages need to be in a specific role order.\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#reliability>)\nReliability\nImplement fallbacks, load balancing, and automatic retries to make your agents more resilient.\nCopy\n```\n{\n \"strategy\": {\n  \"mode\": \"fallback\" # Options: \"loadbalance\" or \"fallback\"\n },\n \"targets\": [\n  {\n   \"provider\": \"openai\",\n   \"api_key\": \"openai-api-key\",\n   \"override_params\": {\n    \"top_k\": \"0.4\",\n    \"max_tokens\": \"100\"\n   }\n  },\n  {\n   \"provider\": \"anthropic\",\n   \"api_key\": \"anthropic-api-key\",\n   \"override_params\": {\n    \"top_p\": \"0.6\",\n    \"model\": \"claude-3-5-sonnet-20240620\"\n   }\n  }\n ]\n}\n\n```\n\nLearn more about [Portkey Config object here](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai/docs/product/ai-gateway-streamline-llm-integrations/configs>). Be Careful to Load-Balance/Fallback to providers that don’t support tool calling when the request contains a function call.\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#metrics>)\nMetrics\nAgent runs are complex. Portkey automatically logs **40+ comprehensive metrics** for your AI agents, including cost, tokens used, latency, etc. Whether you need a broad overview or granular insights into your agent runs, Portkey’s customizable filters provide the metrics you need.\nPortkey's Observability Dashboard\n[![Portkey's Observability\nDashboard](https://github.com/siddharthsambharia-portkey/Portkey-Product-Images/blob/main/Portkey-Dashboard.png?raw=true)](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>)\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#comprehensive-logging>)\nComprehensive Logging\nAccess detailed logs and traces of agent activities, function calls, and errors. Filter logs based on multiple parameters for in-depth analysis.\nTraces\n![Portkey Traces](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-Traces.png)\nLogs\n[![Portkey\nLogs](https://raw.githubusercontent.com/siddharthsambharia-portkey/Portkey-Product-Images/main/Portkey-Logs.png)](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai/>)\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#guardrails>)\nGuardrails\nAutoGen agents, while powerful, can sometimes produce unexpected or undesired outputs. Portkey’s Guardrails feature helps enforce agent behavior in real-time, ensuring your AutoGen agents operate within specified parameters. Verify both the **inputs** to and _outputs_ from your agents to ensure they adhere to specified formats and content guidelines. Learn more about Portkey’s Guardrails [here](https://docs.ag2.ai/docs/ecosystem/<https:/portkey.ai/docs/product/guardrails>)\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#continuous-improvement>)\nContinuous Improvement\nCapture qualitative and quantitative user feedback on your requests to continuously enhance your agent performance.\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#caching>)\nCaching\nReduce costs and latency with Portkey’s built-in caching system.\nCopy\n```\nportkey_config = {\n \"cache\": {\n  \"mode\": \"semantic\" # Options: \"simple\" or \"semantic\"\n }\n}\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/ecosystem/<#security-and-compliance>)\nSecurity and Compliance\nSet budget limits on provider API keys and implement fine-grained user roles and permissions for both your application and the Portkey APIs.\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#additional-resources>)\nAdditional Resources\n  * [📘 Portkey Documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai>)\n  * [🐦 Twitter](https://docs.ag2.ai/docs/ecosystem/<https:/twitter.com/portkeyai>)\n  * [💬 Discord Community](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/JHPt4C7r>)\n  * [📊 Portkey App](https://docs.ag2.ai/docs/ecosystem/<https:/app.portkey.ai>)\n\n\nFor more information on using these features and setting up your Config, please refer to the [Portkey documentation](https://docs.ag2.ai/docs/ecosystem/<https:/docs.portkey.ai>).\n[PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)[Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/<#getting-started>)\n  * [Key Features](https://docs.ag2.ai/docs/ecosystem/<#key-features>)\n  * [Colab Notebook](https://docs.ag2.ai/docs/ecosystem/<#colab-notebook>)\n  * [Advanced Features](https://docs.ag2.ai/docs/ecosystem/<#advanced-features>)\n  * [Interoperability](https://docs.ag2.ai/docs/ecosystem/<#interoperability>)\n  * [Example: Switching from OpenAI to Azure OpenAI](https://docs.ag2.ai/docs/ecosystem/<#example-switching-from-openai-to-azure-openai>)\n  * [Reliability](https://docs.ag2.ai/docs/ecosystem/<#reliability>)\n  * [Metrics](https://docs.ag2.ai/docs/ecosystem/<#metrics>)\n  * [Comprehensive Logging](https://docs.ag2.ai/docs/ecosystem/<#comprehensive-logging>)\n  * [Guardrails](https://docs.ag2.ai/docs/ecosystem/<#guardrails>)\n  * [Continuous Improvement](https://docs.ag2.ai/docs/ecosystem/<#continuous-improvement>)\n  * [Caching](https://docs.ag2.ai/docs/ecosystem/<#caching>)\n  * [Security and Compliance](https://docs.ag2.ai/docs/ecosystem/<#security-and-compliance>)\n  * [Additional Resources](https://docs.ag2.ai/docs/ecosystem/<#additional-resources>)\n\n---\n\n# Promptflow\nURL: https://docs.ag2.ai/docs/ecosystem/promptflow\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/ecosystem/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nEcosystem\nPromptflow\n[Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)[Examples](https://docs.ag2.ai/docs/ecosystem/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/ecosystem/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/ecosystem/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/ecosystem/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/ecosystem/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/ecosystem/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/ecosystem/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/ecosystem/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/ecosystem/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/ecosystem/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/ecosystem/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/ecosystem/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/ecosystem/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/ecosystem/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/ecosystem/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/ecosystem/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/ecosystem/</docs/Migration-Guide>)\n\n\nEcosystem\n# Promptflow\nPromptflow is a comprehensive suite of tools that simplifies the development, testing, evaluation, and deployment of LLM based AI applications. It also supports integration with Azure AI for cloud-based operations and is designed to streamline end-to-end development.\nRefer to [Promptflow docs](https://docs.ag2.ai/docs/ecosystem/<https:/microsoft.github.io/promptflow/>) for more information.\nQuick links:\n  * Why use Promptflow - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow>)\n  * Quick start guide - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/microsoft.github.io/promptflow/how-to-guides/quick-start.html>)\n  * Sample application for Promptflow + AutoGen integration - [Link](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/promptflow-autogen>)\n\n\n## \n[​](https://docs.ag2.ai/docs/ecosystem/<#sample-flow>)\nSample Flow\n![Sample Promptflow](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/ecosystem/img/ecosystem-promptflow.png)\n[Portkey Integration with AutoGen](https://docs.ag2.ai/docs/ecosystem/</docs/ecosystem/portkey>)[Contributing to AG2](https://docs.ag2.ai/docs/ecosystem/</docs/contributor-guide/contributing>)\n[x](https://docs.ag2.ai/docs/ecosystem/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/ecosystem/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/ecosystem/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/ecosystem/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/ecosystem/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/ecosystem/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Sample Flow](https://docs.ag2.ai/docs/ecosystem/<#sample-flow>)\n\n---\n\n# Contributing to AG2\nURL: https://docs.ag2.ai/docs/contributor-guide/contributing\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nContributing to AG2\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Contributing to AG2\nThe project welcomes contributions from developers and organizations worldwide. Our goal is to foster a collaborative and inclusive community where diverse perspectives and expertise can drive innovation and enhance the project’s capabilities. Whether you are an individual contributor or represent an organization, we invite you to join us in shaping the future of this project. Together, we can build something truly remarkable. Possible contributions include but not limited to:\n  * Pushing patches.\n  * Code review of pull requests.\n  * Documentation, examples and test cases.\n  * Readability improvement, e.g., improvement on docstr and comments.\n  * Community participation in [issues](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues>), [discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>), and [twitter](https://docs.ag2.ai/docs/contributor-guide/<https:/twitter.com/Chi_Wang_>).\n  * Tutorials, blog posts, talks that promote the project.\n  * Sharing application scenarios and/or related research.\n\n\nIf you are new to GitHub [here](https://docs.ag2.ai/docs/contributor-guide/<https:/docs.github.com/en/pull-requests/collaborating-with-pull-requests>) is a detailed help source on getting involved with development on GitHub.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#roadmaps>)\nRoadmaps\nTo see what we are working on and what we plan to work on, please check our [Roadmap](https://docs.ag2.ai/docs/contributor-guide/<https:/ag2.ai/#roadmap>) and [Roadmap Issues](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues?q=is%3Aopen+is%3Aissue+label%3Aroadmap>).\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#becoming-a-reviewer>)\nBecoming a Reviewer\nThere is currently no formal reviewer solicitation process. Current reviewers identify reviewers from active contributors. If you are willing to become a reviewer, you are welcome to let us know on discord.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#contact-maintainers>)\nContact Maintainers\nThe project is currently maintained by a [dynamic group of volunteers](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/MAINTAINERS.md>) from several organizations. Contact project administrators Chi Wang and Qingyun Wu via support@ag2.ai if you are interested in becoming a maintainer.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#license-headers>)\nLicense Headers\nTo maintain proper licensing and copyright notices, please include the following header at the top of each new source code file you create, regardless of the programming language:\nCopy\n```\n# Copyright (c) 2023 - 2024, Owners of https://github.com/ag2ai\n#\n# SPDX-License-Identifier: Apache-2.0\n\n```\n\nFor files that contain or are derived from the original MIT-licensed code from <https://github.com/microsoft/autogen>, please use this extended header:\nCopy\n```\n# Copyright (c) 2023 - 2024, Owners of https://github.com/ag2ai\n#\n# SPDX-License-Identifier: Apache-2.0\n#\n# Portions derived from https://github.com/microsoft/autogen are under the MIT License.\n# SPDX-License-Identifier: MIT\n\n```\n\nPlease ensure you update the year range as appropriate. If you’re unsure which header to use or have any questions about licensing, please don’t hesitate to ask in your pull request or reach out to the maintainers.\n[Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)[Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Roadmaps](https://docs.ag2.ai/docs/contributor-guide/<#roadmaps>)\n  * [Becoming a Reviewer](https://docs.ag2.ai/docs/contributor-guide/<#becoming-a-reviewer>)\n  * [Contact Maintainers](https://docs.ag2.ai/docs/contributor-guide/<#contact-maintainers>)\n  * [License Headers](https://docs.ag2.ai/docs/contributor-guide/<#license-headers>)\n\n---\n\n# Docker for Development\nURL: https://docs.ag2.ai/docs/contributor-guide/docker\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nDocker for Development\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Docker for Development\nFor developers contributing to the AG2 project, we offer a specialized devcontainer environment. This setup is designed to streamline the development process, ensuring that all contributors work within a consistent and well-equipped environment.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#ag2-devcontainer>)\nAG2 Devcontainer\n  * **Purpose** : The devcontainer is tailored for contributors to the AG2 project. It includes a suite of tools and configurations that aid in the development and testing of new features or fixes.\n  * **Usage** : This image is recommended for developers who intend to contribute code or documentation to AG2.\n  * **Forking the Project** : It’s advisable to fork the AG2 GitHub project to your own repository. This allows you to make changes in a separate environment without affecting the main project.\n  * **Submitting Pull Requests** : Once your changes are ready, submit a pull request from your branch to the upstream AG2 GitHub project for review and integration. For more details on contributing, see the [AG2 Contributing](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>) page.\n\n\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-devcontainers>)\nDeveloping AutoGen with Devcontainers\n  1. Open the project in Visual Studio Code.\n  2. Press `Ctrl+Shift+P` and select `Dev Containers: Reopen in Container`.\n  3. Select the desired python environment and wait for the container to build.\n  4. Once the container is built, you can start developing AutoGen.\n\n\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-codespaces>)\nDeveloping Autogen with Codespaces\nProvided devcontainer files can be used with GitHub Codespaces. To use the devcontainer with GitHub Codespaces, follow the steps below:\n  1. Open the AG2 repository in GitHub.\n  2. Click on the `Code` button and select `Open with Codespaces`.\n  3. Select the desired python environment and wait for the container to build.\n  4. Once the container is built, you can start developing AutoGen.\n\n\n[Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [AG2 Devcontainer](https://docs.ag2.ai/docs/contributor-guide/<#ag2-devcontainer>)\n  * [Developing AutoGen with Devcontainers](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-devcontainers>)\n  * [Developing Autogen with Codespaces](https://docs.ag2.ai/docs/contributor-guide/<#developing-autogen-with-codespaces>)\n\n---\n\n# Documentation\nURL: https://docs.ag2.ai/docs/contributor-guide/documentation\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nDocumentation\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Documentation\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#how-to-get-a-notebook-rendered-on-the-website>)\nHow to get a notebook rendered on the website\nSee [here](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/notebook/contributing.md#how-to-get-a-notebook-displayed-on-the-website>) for instructions on how to get a notebook in the `notebook` directory rendered on the website.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#build-documentation-locally>)\nBuild documentation locally\n  1. To build and test documentation locally, first install [Node.js](https://docs.ag2.ai/docs/contributor-guide/<https:/nodejs.org/en/download/>). For example,\n\n\nCopy\n```\nnvm install --lts\n\n```\n\nThen, install the required packages by running the following commands:\nCopy\n```\npip install pydoc-markdown pyyaml termcolor nbclient\n\n```\n\n  1. You also need to install quarto. Please click on the `Pre-release` tab from [this website](https://docs.ag2.ai/docs/contributor-guide/<https:/quarto.org/docs/download/>) to download the latest version of `quarto` and install it. Ensure that the `quarto` version is `1.5.23` or higher.\n  2. Finally, run the following commands to build and serve the documentation:\n\n\nCopy\n```\ncd website\npython ./process_api_reference.py\npython ./process_notebooks.py render\nnpm install\nnpm run mintlify:dev\n\n```\n\nThe last command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#build-with-devcontainer>)\nBuild with devcontainer\nTo build and test documentation using devcontainer, open the project using [VSCode](https://docs.ag2.ai/docs/contributor-guide/<https:/code.visualstudio.com/>), press `Ctrl+Shift+P` and select `Dev Containers: Reopen in Container`.\nThis will open the project in a devcontainer with all the required dependencies installed.\nOpen a terminal and run the following command to build and serve the documentation:\nCopy\n```\ncd website\npython ./process_api_reference.py\npython ./process_notebooks.py render\nnpm install\nnpm run mintlify:dev\n\n```\n\nOnce done you should be able to access the documentation at `http://localhost:3000/`.\n[Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)[File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [How to get a notebook rendered on the website](https://docs.ag2.ai/docs/contributor-guide/<#how-to-get-a-notebook-rendered-on-the-website>)\n  * [Build documentation locally](https://docs.ag2.ai/docs/contributor-guide/<#build-documentation-locally>)\n  * [Build with devcontainer](https://docs.ag2.ai/docs/contributor-guide/<#build-with-devcontainer>)\n\n---\n\n# File A Bug Report\nURL: https://docs.ag2.ai/docs/contributor-guide/file-bug-report\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nFile A Bug Report\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# File A Bug Report\nWhen you submit an issue to [GitHub](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/issues>), please do your best to follow these guidelines! This will make it a lot easier to provide you with good feedback:\n  * The ideal bug report contains a short reproducible code snippet. This way anyone can try to reproduce the bug easily (see [this](https://docs.ag2.ai/docs/contributor-guide/<https:/stackoverflow.com/help/mcve>) for more details). If your snippet is longer than around 50 lines, please link to a [gist](https://docs.ag2.ai/docs/contributor-guide/<https:/gist.github.com>) or a GitHub repo.\n  * If an exception is raised, please **provide the full traceback**.\n  * Please include your **operating system type and version number** , as well as your **Python, autogen, scikit-learn versions**. The version of autogen can be found by running the following code snippet:\n\n\nCopy\n```\nimport autogen\nprint(autogen.__version__)\n\n```\n\n  * Please ensure all **code snippets and error messages are formatted in appropriate code blocks**. See [Creating and highlighting code blocks](https://docs.ag2.ai/docs/contributor-guide/<https:/help.github.com/articles/creating-and-highlighting-code-blocks>) for more details.\n\n\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)[Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Guidance for Maintainers\nURL: https://docs.ag2.ai/docs/contributor-guide/maintainer\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nGuidance for Maintainers\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Guidance for Maintainers\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#general>)\nGeneral\n  * Be a member of the community and treat everyone as a member. Be inclusive.\n  * Help each other and encourage mutual help.\n  * Actively post and respond.\n  * Keep open communication.\n  * Identify good maintainer candidates from active contributors.\n\n\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#pull-requests>)\nPull Requests\n  * For new PR, decide whether to close without review. If not, find the right reviewers. One source to refer to is the roles on Discord. Another consideration is to ask users who can benefit from the PR to review it.\n  * For old PR, check the blocker: reviewer or PR creator. Try to unblock. Get additional help when needed.\n  * When requesting changes, make sure you can check back in time because it blocks merging.\n  * Make sure all the checks are passed.\n  * For changes that require running OpenAI tests, make sure the OpenAI tests pass too. Running these tests requires approval.\n  * In general, suggest small PRs instead of a giant PR.\n  * For documentation change, request snapshot of the compiled website, or compile by yourself to verify the format.\n  * For new contributors who have not signed the contributing agreement, remind them to sign before reviewing.\n  * For multiple PRs which may have conflict, coordinate them to figure out the right order.\n  * Pay special attention to:\n    * Breaking changes. Don’t make breaking changes unless necessary. Don’t merge to main until enough headsup is provided and a new release is ready.\n    * Test coverage decrease.\n    * Changes that may cause performance degradation. Do regression test when test suites are available.\n    * Discourage **change to the core library** when there is an alternative.\n\n\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#issues-and-discussions>)\nIssues and Discussions\n  * For new issues, write a reply, apply a label if relevant. Ask on discord when necessary. For roadmap issues, apply the roadmap label and encourage community discussion. Mention relevant experts when necessary.\n  * For old issues, provide an update or close. Ask on discord when necessary. Encourage PR creation when relevant.\n  * Use “good first issue” for easy fix suitable for first-time contributors.\n  * Use “task list” for issues that require multiple PRs.\n  * For discussions, create an issue when relevant. Discuss on discord when appropriate.\n\n\n[File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)[Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [General](https://docs.ag2.ai/docs/contributor-guide/<#general>)\n  * [Pull Requests](https://docs.ag2.ai/docs/contributor-guide/<#pull-requests>)\n  * [Issues and Discussions](https://docs.ag2.ai/docs/contributor-guide/<#issues-and-discussions>)\n\n---\n\n# Pre-commit\nURL: https://docs.ag2.ai/docs/contributor-guide/pre-commit\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nPre-commit\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Pre-commit\nRun `pre-commit install` to install pre-commit into your git hooks. Before you commit, run `pre-commit run` to check if you meet the pre-commit requirements. If you use Windows (without WSL) and can’t commit after installing pre-commit, you can run `pre-commit uninstall` to uninstall the hook. In WSL or Linux this is supposed to work.\n[Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)[Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Tests\nURL: https://docs.ag2.ai/docs/contributor-guide/tests\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/contributor-guide/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nTests\n[Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)[Examples](https://docs.ag2.ai/docs/contributor-guide/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/contributor-guide/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/contributor-guide/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/contributor-guide/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/contributor-guide/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/contributor-guide/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/contributor-guide/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/contributor-guide/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/contributor-guide/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/contributor-guide/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/contributor-guide/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/contributor-guide/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/contributor-guide/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Tests\nTests are automatically run via GitHub actions. There are two workflows:\n  1. [build.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/build.yml>)\n  2. [openai.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/openai.yml>)\n\n\nThe first workflow is required to pass for all PRs (and it doesn’t do any OpenAI calls). The second workflow is required for changes that affect the OpenAI tests (and does actually call LLM). The second workflow requires approval to run. When writing tests that require OpenAI calls, please use `pytest.mark.skipif`[](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/b1adac515931bf236ac59224269eeec683a162ba/test/oai/test_client.py#L19>) to make them run in only when `openai` package is installed. If additional dependency for this test is required, install the dependency in the corresponding python version in [openai.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/openai.yml>).\nMake sure all tests pass, this is required for [build.yml](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/.github/workflows/build.yml>) checks to pass\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#running-tests-locally>)\nRunning tests locally\nTo run tests, install the [test] option:\nCopy\n```\npip install -e.\"[test]\"\n\n```\n\nThen you can run the tests from the `test` folder using the following command:\nCopy\n```\nbash scripts/test.sh test\n\n```\n\nTests for the `autogen.agentchat.contrib` module may be skipped automatically if the required dependencies are not installed. Please consult the documentation for each contrib module to see what dependencies are required.\nSee [here](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2/blob/main/notebook/contributing.md#testing>) for how to run notebook tests.\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#skip-flags-for-tests>)\nSkip flags for tests\n  * `-m \"not openai\"` for skipping tests that require access to OpenAI services.\n  * `--skip-docker` for skipping tests that explicitly use docker\n  * `--skip-redis` for skipping tests that require a Redis server\n\n\nFor example, the following command will skip tests that require access to OpenAI and docker services:\nCopy\n```\nbash scripts/test.sh test -m \"not openai\" --skip-docker\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/contributor-guide/<#coverage>)\nCoverage\nAny code you commit should not decrease coverage. To ensure your code maintains or increases coverage, use the following commands after installing the required test dependencies:\nCopy\n```\npip install -e .\"[test]\"\nbash scripts/test.sh test --cov-report=html\n\n```\n\nPytest generated a code coverage report and created a htmlcov directory containing an index.html file and other related files. Open index.html in any web browser to visualize and navigate through the coverage data interactively. This interactive visualization allows you to identify uncovered lines and review coverage statistics for individual files.\n[Pre-commit](https://docs.ag2.ai/docs/contributor-guide/</docs/contributor-guide/pre-commit>)[Research](https://docs.ag2.ai/docs/contributor-guide/</docs/Research>)\n[x](https://docs.ag2.ai/docs/contributor-guide/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/contributor-guide/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/contributor-guide/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/contributor-guide/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/contributor-guide/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/contributor-guide/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Running tests locally](https://docs.ag2.ai/docs/contributor-guide/<#running-tests-locally>)\n  * [Skip flags for tests](https://docs.ag2.ai/docs/contributor-guide/<#skip-flags-for-tests>)\n  * [Coverage](https://docs.ag2.ai/docs/contributor-guide/<#coverage>)\n\n---\n\n# Research\nURL: https://docs.ag2.ai/docs/Research\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nResearch\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Research\nFor technical details, please check our technical report and research publications.\n  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.\n\n\nCopy\n```\n@inproceedings{wu2023autogen,\n   title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},\n   author={Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Shaokun Zhang and Erkang Zhu and Beibin Li and Li Jiang and Xiaoyun Zhang and Chi Wang},\n   year={2023},\n   eprint={2308.08155},\n   archivePrefix={arXiv},\n   primaryClass={cs.AI}\n}\n\n```\n\n  * [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2303.04673>). Chi Wang, Susan Xueqing Liu, Ahmed H. Awadallah. AutoML’23.\n\n\nCopy\n```\n@inproceedings{wang2023EcoOptiGen,\n  title={Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference},\n  author={Chi Wang and Susan Xueqing Liu and Ahmed H. Awadallah},\n  year={2023},\n  booktitle={AutoML'23},\n}\n\n```\n\n  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n\n\nCopy\n```\n@inproceedings{wu2023empirical,\n  title={An Empirical Study on Challenging Math Problem Solving with GPT-4},\n  author={Yiran Wu and Feiran Jia and Shaokun Zhang and Hangyu Li and Erkang Zhu and Yue Wang and Yin Tat Lee and Richard Peng and Qingyun Wu and Chi Wang},\n  year={2023},\n  booktitle={ArXiv preprint arXiv:2306.01337},\n}\n\n```\n\n  * [EcoAssistant: Using LLM Assistant More Affordably and Accurately](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2310.03046>). Jieyu Zhang, Ranjay Krishna, Ahmed H. Awadallah, Chi Wang. ArXiv preprint arXiv:2310.03046 (2023).\n\n\nCopy\n```\n@inproceedings{zhang2023ecoassistant,\n  title={EcoAssistant: Using LLM Assistant More Affordably and Accurately},\n  author={Zhang, Jieyu and Krishna, Ranjay and Awadallah, Ahmed H and Wang, Chi},\n  year={2023},\n  booktitle={ArXiv preprint arXiv:2310.03046},\n}\n\n```\n\n  * [Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2402.09015>). Negar Arabzadeh, Julia Kiseleva, Qingyun Wu, Chi Wang, Ahmed Awadallah, Victor Dibia, Adam Fourney, Charles Clarke. ArXiv preprint arXiv:2402.09015 (2024).\n\n\nCopy\n```\n@misc{Kiseleva2024agenteval,\n   title={Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications},\n   author={Negar Arabzadeh and Julia Kiseleva and Qingyun Wu and Chi Wang and Ahmed Awadallah and Victor Dibia and Adam Fourney and Charles Clarke},\n   year={2024},\n   eprint={2402.09015},\n   archivePrefix={arXiv},\n   primaryClass={cs.CL}\n}\n\n```\n\n  * [Training Language Model Agents without Modifying Language Models](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2402.11359>). Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, Qingyun Wu. ICML’24.\n\n\nCopy\n```\n@misc{zhang2024agentoptimizer,\n   title={Training Language Model Agents without Modifying Language Models},\n   author={Shaokun Zhang and Jieyu Zhang and Jiale Liu and Linxin Song and Chi Wang and Ranjay Krishna and Qingyun Wu},\n   year={2024},\n   booktitle={ICML'24},\n}\n\n```\n\n  * [AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2403.04783>). Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu. ArXiv preprint arXiv:2403.04783 (2024).\n\n\nCopy\n```\n@misc{zeng2024autodefense,\n   title={AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks},\n   author={Yifan Zeng and Yiran Wu and Xiao Zhang and Huazheng Wang and Qingyun Wu},\n   year={2024},\n   eprint={2403.04783},\n   archivePrefix={arXiv},\n   primaryClass={cs.LG}\n}\n\n```\n\n  * [StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2403.11322>). Yiran Wu, Tianwei Yue, Shaokun Zhang, Chi Wang, Qingyun Wu. ArXiv preprint arXiv:2403.11322 (2024).\n\n\nCopy\n```\n@misc{wu2024stateflow,\n    title={StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows},\n    author={Yiran Wu and Tianwei Yue and Shaokun Zhang and Chi Wang and Qingyun Wu},\n    year={2024},\n    eprint={2403.11322},\n    archivePrefix={arXiv},\n    primaryClass={cs.CL}\n}\n\n```\n\n[Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)[Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# Migration Guide\nURL: https://docs.ag2.ai/docs/Migration-Guide\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag21,441](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nContributor Guide\nMigration Guide\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\nContributor Guide\n# Migration Guide\n## \n[​](https://docs.ag2.ai/docs/<#migrating-to-0-2>)\nMigrating to 0.2\nopenai v1 is a total rewrite of the library with many breaking changes. For example, the inference requires instantiating a client, instead of using a global class method. Therefore, some changes are required for users of `pyautogen<0.2`.\n  * `api_base` -> `base_url`, `request_timeout` -> `timeout` in `llm_config` and `config_list`. `max_retry_period` and `retry_wait_time` are deprecated. `max_retries` can be set for each client.\n  * MathChat is unsupported until it is tested in future release.\n  * `autogen.Completion` and `autogen.ChatCompletion` are deprecated. The essential functionalities are moved to `autogen.OpenAIWrapper`:\n\n\nCopy\n```\nfrom autogen import OpenAIWrapper\nclient = OpenAIWrapper(config_list=config_list)\nresponse = client.create(messages=[{\"role\": \"user\", \"content\": \"2+2=\"}])\nprint(client.extract_text_or_completion_object(response))\n\n```\n\n  * Inference parameter tuning and inference logging features are updated:\n\n\nCopy\n```\nimport autogen.runtime_logging\n# Start logging\nautogen.runtime_logging.start()\n# Stop logging\nautogen.runtime_logging.stop()\n\n```\n\nCheckout [Logging documentation](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference#logging>) and [Logging example notebook](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_logging.ipynb>) to learn more.\nInference parameter tuning can be done via `flaml.tune`[](https://docs.ag2.ai/docs/<https:/microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function>).\n  * `seed` in autogen is renamed into `cache_seed` to accommodate the newly added `seed` param in openai chat completion api. `use_cache` is removed as a kwarg in `OpenAIWrapper.create()` for being automatically decided by `cache_seed`: int | None. The difference between autogen’s `cache_seed` and openai’s `seed` is that: \n    * autogen uses local disk cache to guarantee the exactly same output is produced for the same input and when cache is hit, no openai api call will be made.\n    * openai’s `seed` is a best-effort deterministic sampling with no guarantee of determinism. When using openai’s `seed` with `cache_seed` set to None, even for the same input, an openai api call will be made and there is no guarantee for getting exactly the same output.\n\n\n[Research](https://docs.ag2.ai/docs/</docs/Research>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Migrating to 0.2](https://docs.ag2.ai/docs/<#migrating-to-0-2>)\n\n---\n\n# ​\nURL: https://docs.ag2.ai/docs/Home#key-features\n\n* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n\nThe Open Source Agent OS\n\n[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\nAG2 provides multi-agent conversation framework as a high-level abstraction.\nWith this framework, one can conveniently build LLM workflows.\n\nAG2 offers a collection of working systems spanning a wide range of applications\nfrom various domains and complexities.\n\n[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-\nCases/enhanced_inference>)\n\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference\nperformance and reduce cost.\n\n[Learn how to get started with AG2. Follow the instruction to quickly build-up\nyour first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-\nStarted>)[This tutorial introduces basic concepts and building blocks of\nAG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to\ndifferent functionalities of AG2, including CodeExecution, GroupChat, and\nmore.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples\ndemonstrating the usage of AG2 in various\nscenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different\napplications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn\nabout how you can contribute to AG2 and this documentation, including pushing\npatches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-\nguide/contributing>)\n\n[Foundation Capital Interview with Dr. Chi\nWang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n\n---\n\n# Easily Build Diverse Applications\nURL: https://docs.ag2.ai/docs/Use-Cases/agent_chat#diverse-applications-implemented-with-autogen\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/Use-Cases/</>)\nSearch or ask...\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nUse Cases\nMulti-agent Conversation Framework\n[Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)[Examples](https://docs.ag2.ai/docs/Use-Cases/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/Use-Cases/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/Use-Cases/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/Use-Cases/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/Use-Cases/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/Use-Cases/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/Use-Cases/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/Use-Cases/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/Use-Cases/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/Use-Cases/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/Use-Cases/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/Use-Cases/</docs/Migration-Guide>)\n\n\nUse Cases\n# Multi-agent Conversation Framework\nAutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLMs, tools, and humans via automated agent chat. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.\nThis framework simplifies the orchestration, automation and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcomes their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#agents>)\nAgents\nAutoGen abstracts and implements conversable agents designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following notable features:\n  * Conversable: Agents in AutoGen are conversable, which means that any agent can send and receive messages from other agents to initiate or continue a conversation\n  * Customizable: Agents in AutoGen can be customized to integrate LLMs, humans, tools, or a combination of them.\n\n\nThe figure below shows the built-in agents in AutoGen. ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/autogen_agents.png)\nWe have designed a generic `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) class for Agents that are capable of conversing with each other through the exchange of messages to jointly finish a task. An agent can communicate with other agents and perform actions. Different agents can differ in what actions they perform after receiving messages. Two representative subclasses are `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) and `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>)\n  * The `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) is designed to act as an AI assistant, using LLMs by default but not requiring human input or code execution. It could write Python code (in a Python coding block) for a user to execute when a message (typically a description of a task that needs to be solved) is received. Under the hood, the Python code is written by LLM (e.g., GPT-4). It can also receive the execution results and suggest corrections or bug fixes. Its behavior can be altered by passing a new system message. The LLM [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration can be configured via [`llm_config`].\n  * The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) is conceptually a proxy agent for humans, soliciting human input as the agent’s reply at each interaction turn by default and also having the capability to execute code and call functions or tools. The `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) triggers code execution automatically when it detects an executable code block in the received message and no human user input is provided. Code execution can be disabled by setting the `code_execution_config` parameter to False. LLM-based response is disabled by default. It can be enabled by setting `llm_config` to a dict corresponding to the [inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>) configuration. When `llm_config` is set as a dictionary, `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) can generate replies using an LLM when code execution is not performed.\n\n\nThe auto-reply capability of `ConversableAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#conversableagent>) allows for more autonomous multi-agent communication while retaining the possibility of human intervention. One can also easily extend it by registering reply functions with the `register_reply()`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/conversable_agent#register-reply>) method.\nIn the following code, we create an `AssistantAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/assistant_agent#assistantagent>) named “assistant” to serve as the assistant and a `UserProxyAgent`[](https://docs.ag2.ai/docs/Use-Cases/</docs/reference/agentchat/user_proxy_agent#userproxyagent>) named “user_proxy” to serve as a proxy for the human user. We will later employ these two agents to solve a task.\nCopy\n```\nimport os\nfrom autogen import AssistantAgent, UserProxyAgent\nfrom autogen.coding import DockerCommandLineCodeExecutor\nconfig_list = [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]\n# create an AssistantAgent instance named \"assistant\" with the LLM configuration.\nassistant = AssistantAgent(name=\"assistant\", llm_config={\"config_list\": config_list})\n# create a UserProxyAgent instance named \"user_proxy\" with code execution on docker.\ncode_executor = DockerCommandLineCodeExecutor()\nuser_proxy = UserProxyAgent(name=\"user_proxy\", code_execution_config={\"executor\": code_executor})\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)\nMulti-agent Conversations\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)\nA Basic Two-Agent Conversation Example\nOnce the participating agents are constructed properly, one can start a multi-agent conversation session by an initialization step as shown in the following code:\nCopy\n```\n# the assistant receives a message from the user, which contains the task description\nuser_proxy.initiate_chat(\n  assistant,\n  message=\"\"\"What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?\"\"\",\n)\n\n```\n\nAfter the initialization step, the conversation could proceed automatically. Find a visual illustration of how the user_proxy and assistant collaboratively solve the above task autonomously below: ![Agent Chat Example](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/agent_example.png)\n  1. The assistant receives a message from the user_proxy, which contains the task description.\n  2. The assistant then tries to write Python code to solve the task and sends the response to the user_proxy.\n  3. Once the user_proxy receives a response from the assistant, it tries to reply by either soliciting human input or preparing an automatically generated reply. If no human input is provided, the user_proxy executes the code and uses the result as the auto-reply.\n  4. The assistant then generates a further response for the user_proxy. The user_proxy can then decide whether to terminate the conversation. If not, steps 3 and 4 are repeated.\n\n\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)\nSupporting Diverse Conversation Patterns\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)\nConversations with different levels of autonomy, and human-involvement patterns\nOn the one hand, one can achieve fully autonomous conversations after an initialization step. On the other hand, AutoGen can be used to implement human-in-the-loop problem-solving by configuring human involvement levels and patterns (e.g., setting the `human_input_mode` to `ALWAYS`), as human involvement is expected and/or desired in many applications.\n#### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)\nStatic and dynamic conversations\nAutoGen, by integrating conversation-driven control utilizing both programming and natural language, inherently supports dynamic conversations. This dynamic nature allows the agent topology to adapt based on the actual conversation flow under varying input problem scenarios. Conversely, static conversations adhere to a predefined topology. Dynamic conversations are particularly beneficial in complex settings where interaction patterns cannot be predetermined.\n  1. Registered auto-reply\n\n\nWith the pluggable auto-reply function, one can choose to invoke conversations with other agents depending on the content of the current message and context. For example:\n  * Hierarchical chat like in [OptiGuide](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nestedchat_optiguide.ipynb>).\n  * [Dynamic Group Chat](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_groupchat.ipynb>) which is a special form of hierarchical chat. In the system, we register a reply function in the group chat manager, which broadcasts messages and decides who the next speaker will be in a group chat setting.\n  * [Finite State Machine graphs to set speaker transition constraints](https://docs.ag2.ai/docs/Use-Cases/<https:/docs.ag2.ai/notebooks/agentchat_groupchat_finite_state_machine>) which is a special form of dynamic group chat. In this approach, a directed transition matrix is fed into group chat. Users can specify legal transitions or specify disallowed transitions.\n  * Nested chat like in [conversational chess](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_nested_chats_chess.ipynb>).\n\n\n  1. LLM-Based Function Call\n\n\nAnother approach involves LLM-based function calls, where LLM decides if a specific function should be invoked based on the conversation’s status during each inference. This approach enables dynamic multi-agent conversations, as seen in scenarios like [multi-user math problem solving scenario](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2/blob/main/notebook/agentchat_two_users.ipynb>), where a student assistant automatically seeks expertise via function calls.\n### \n[​](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)\nDiverse Applications Implemented with AutoGen\nThe figure below shows six examples of applications built using AutoGen. ![Applications](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/docs/Use-Cases/images/app.png)\nFind a list of examples in this page: [Automated Agent Chat Examples](https://docs.ag2.ai/docs/Use-Cases/</docs/Examples#automated-multi-agent-chat>)\n## \n[​](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)\nFor Further Reading\n_Interested in the research that leads to this package? Please check the following papers._\n  * [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2308.08155>). Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.\n  * [An Empirical Study on Challenging Math Problem Solving with GPT-4](https://docs.ag2.ai/docs/Use-Cases/<https:/arxiv.org/abs/2306.01337>). Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).\n\n\n[What Next?](https://docs.ag2.ai/docs/Use-Cases/</docs/tutorial/what-next>)[Enhanced Inference](https://docs.ag2.ai/docs/Use-Cases/</docs/Use-Cases/enhanced_inference>)\n[x](https://docs.ag2.ai/docs/Use-Cases/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/Use-Cases/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/Use-Cases/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/Use-Cases/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/Use-Cases/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/Use-Cases/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Agents](https://docs.ag2.ai/docs/Use-Cases/<#agents>)\n  * [Multi-agent Conversations](https://docs.ag2.ai/docs/Use-Cases/<#multi-agent-conversations>)\n  * [A Basic Two-Agent Conversation Example](https://docs.ag2.ai/docs/Use-Cases/<#a-basic-two-agent-conversation-example>)\n  * [Supporting Diverse Conversation Patterns](https://docs.ag2.ai/docs/Use-Cases/<#supporting-diverse-conversation-patterns>)\n  * [Conversations with different levels of autonomy, and human-involvement patterns](https://docs.ag2.ai/docs/Use-Cases/<#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns>)\n  * [Static and dynamic conversations](https://docs.ag2.ai/docs/Use-Cases/<#static-and-dynamic-conversations>)\n  * [Diverse Applications Implemented with AutoGen](https://docs.ag2.ai/docs/Use-Cases/<#diverse-applications-implemented-with-autogen>)\n  * [For Further Reading](https://docs.ag2.ai/docs/Use-Cases/<#for-further-reading>)\n\n---\n\n# ​\nURL: https://docs.ag2.ai/docs/Home#explore-content\n\n* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n\nThe Open Source Agent OS\n\n[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\nAG2 provides multi-agent conversation framework as a high-level abstraction.\nWith this framework, one can conveniently build LLM workflows.\n\nAG2 offers a collection of working systems spanning a wide range of applications\nfrom various domains and complexities.\n\n[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-\nCases/enhanced_inference>)\n\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference\nperformance and reduce cost.\n\n[Learn how to get started with AG2. Follow the instruction to quickly build-up\nyour first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-\nStarted>)[This tutorial introduces basic concepts and building blocks of\nAG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to\ndifferent functionalities of AG2, including CodeExecution, GroupChat, and\nmore.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples\ndemonstrating the usage of AG2 in various\nscenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different\napplications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn\nabout how you can contribute to AG2 and this documentation, including pushing\npatches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-\nguide/contributing>)\n\n[Foundation Capital Interview with Dr. Chi\nWang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n\n---\n\n# User GuideUsers' guide to different functionalities of AG2, including CodeExecution, GroupChat, and more.\nURL: https://docs.ag2.ai/docs/topics\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nCode Execution\nCommand Line Code Executor\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n    * [Command Line Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/cli-code-executor>)\n    * [Custom Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/custom-executor>)\n    * [Jupyter Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/jupyter-code-executor>)\n    * [User Defined Functions](https://docs.ag2.ai/docs/</docs/topics/code-execution/user-defined-functions>)\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\nCode Execution\n# Command Line Code Executor\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/website/docs/topics/code-execution/cli-code-executor.ipynb>) [![Open on GitHub](https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github)](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/website/docs/topics/code-execution/cli-code-executor.ipynb>)\nCommand line code execution is the simplest form of code execution. Generally speaking, it will save each code block to a file and the execute that file. This means that each code block is executed in a new process. There are two forms of this executor:\n  * Docker (`DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>)) - this is where all commands are executed in a Docker container\n  * Local (`LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>)) - this is where all commands are executed on the host machine\n\n\nThis executor type is similar to the legacy code execution in AutoGen.\n## \n[​](https://docs.ag2.ai/docs/<#docker>)\nDocker\nThe `DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) will create a Docker container and run all commands within that container. The default image that is used is `python:3-slim`, this can be customized by passing the `image` parameter to the constructor. If the image is not found locally then the class will try to pull it. Therefore, having built the image locally is enough. The only thing required for this image to be compatible with the executor is to have `sh` and `python` installed. Therefore, creating a custom image is a simple and effective way to ensure required system dependencies are available.\nYou can use the executor as a context manager to ensure the container is cleaned up after use. Otherwise, the `atexit` module will be used to stop the container when the program exits.\n### \n[​](https://docs.ag2.ai/docs/<#inspecting-the-container>)\nInspecting the container\nIf you wish to keep the container around after AutoGen is finished using it for whatever reason (e.g. to inspect the container), then you can set the `auto_remove` parameter to `False` when creating the executor. `stop_container` can also be set to `False` to prevent the container from being stopped at the end of the execution.\n### \n[​](https://docs.ag2.ai/docs/<#example>)\nExample\nCopy\n```\nfrom pathlib import Path\nfrom autogen.coding import CodeBlock, DockerCommandLineCodeExecutor\nwork_dir = Path(\"coding\")\nwork_dir.mkdir(exist_ok=True)\nwith DockerCommandLineCodeExecutor(work_dir=work_dir) as executor:\n  print(\n    executor.execute_code_blocks(\n      code_blocks=[\n        CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n      ]\n    )\n  )\n\n```\n\nCopy\n```\nexit_code=0 output='Hello, World!\\n' code_file='coding/tmp_code_07da107bb575cc4e02b0e1d6d99cc204.py'\n\n```\n\n### \n[​](https://docs.ag2.ai/docs/<#combining-autogen-in-docker-with-a-docker-based-executor>)\nCombining AutoGen in Docker with a Docker based executor\nIt is desirable to bundle your AutoGen application into a Docker image. But then, how do you allow your containerised application to execute code in a different container?\nThe recommended approach to this is called “Docker out of Docker”, where the Docker socket is mounted to the main AutoGen container, so that it can spawn and control “sibling” containers on the host. This is better than what is called “Docker in Docker”, where the main container runs a Docker daemon and spawns containers within itself. You can read more about this [here](https://docs.ag2.ai/docs/<https:/jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/>).\nTo do this you would need to mount the Docker socket into the AutoGen container. This can be done by adding the following to the `docker run` command:\nCopy\n```\n-v /var/run/docker.sock:/var/run/docker.sock\n\n```\n\nThis will allow the AutoGen container to spawn and control sibling containers on the host.\nIf you need to bind a working directory to the AutoGen container but the directory belongs to your host machine, use the `bind_dir` parameter. This will allow the main AutoGen container to bind the _host_ directory to the new spawned containers and allow it to access the files within the said directory. If the `bind_dir` is not specified, it will fallback to `work_dir`.\n## \n[​](https://docs.ag2.ai/docs/<#local>)\nLocal\nThe local version will run code on your local system. Use it with caution.\nTo execute code on the host machine, as in the machine running AutoGen, the `LocalCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/local_commandline_code_executor#localcommandlinecodeexecutor>) can be used.\n### \n[​](https://docs.ag2.ai/docs/<#example-2>)\nExample\nCopy\n```\nfrom pathlib import Path\nfrom autogen.coding import CodeBlock, LocalCommandLineCodeExecutor\nwork_dir = Path(\"coding\")\nwork_dir.mkdir(exist_ok=True)\nexecutor = LocalCommandLineCodeExecutor(work_dir=work_dir)\nprint(\n  executor.execute_code_blocks(\n    code_blocks=[\n      CodeBlock(language=\"python\", code=\"print('Hello, World!')\"),\n    ]\n  )\n)\n\n```\n\nCopy\n```\nexit_code=0 output='\\nHello, World!\\n' code_file='coding/065b51a16ee54f3298847518f9e999d7.py'\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/<#using-a-python-virtual-environment>)\nUsing a Python virtual environment\nBy default, the LocalCommandLineCodeExecutor executes code and installs dependencies within the same Python environment as the AutoGen code. You have the option to specify a Python virtual environment to prevent polluting the base Python environment.\n### \n[​](https://docs.ag2.ai/docs/<#example-3>)\nExample\nCopy\n```\nfrom autogen.code_utils import create_virtual_env\nfrom autogen.coding import CodeBlock, LocalCommandLineCodeExecutor\nvenv_dir = \".venv\"\nvenv_context = create_virtual_env(venv_dir)\nexecutor = LocalCommandLineCodeExecutor(virtual_env_context=venv_context)\nprint(\n  executor.execute_code_blocks(code_blocks=[CodeBlock(language=\"python\", code=\"import sys; print(sys.executable)\")])\n)\n\n```\n\n## \n[​](https://docs.ag2.ai/docs/<#assigning-to-an-agent>)\nAssigning to an agent\nThese executors can be used to facilitate the execution of agent written code.\nCopy\n```\nfrom pathlib import Path\nfrom autogen import ConversableAgent\nfrom autogen.coding import DockerCommandLineCodeExecutor\nwork_dir = Path(\"coding\")\nwork_dir.mkdir(exist_ok=True)\nexecutor = DockerCommandLineCodeExecutor(work_dir=work_dir)\ncode_executor_agent = ConversableAgent(\n  name=\"code_executor_agent\",\n  llm_config=False,\n  code_execution_config={\n    \"executor\": executor,\n  },\n  human_input_mode=\"NEVER\",\n)\n\n```\n\nWhen using code execution it is critical that you update the system prompt of agents you expect to write code to be able to make use of the executor. For example, for the `DockerCommandLineCodeExecutor`[](https://docs.ag2.ai/docs/reference/coding/docker_commandline_code_executor#dockercommandlinecodeexecutor>) you might setup a code writing agent like so:\nCopy\n```\n# The code writer agent's system message is to instruct the LLM on how to\n# use the Jupyter code executor with IPython kernel.\ncode_writer_system_message = \"\"\"\nYou have been given coding capability to solve tasks using Python code.\nIn the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n  1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n  2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\nSolve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\nWhen using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\nIf you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n\"\"\"\nimport os\ncode_writer_agent = ConversableAgent(\n  \"code_writer\",\n  system_message=code_writer_system_message,\n  llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n  code_execution_config=False, # Turn off code execution for this agent.\n  max_consecutive_auto_reply=2,\n  human_input_mode=\"NEVER\",\n)\n\n```\n\nThen we can use these two agents to solve a problem:\nCopy\n```\nimport pprint\nchat_result = code_executor_agent.initiate_chat(\n  code_writer_agent, message=\"Write Python code to calculate the 14th Fibonacci number.\"\n)\npprint.pprint(chat_result)\n\n```\n\nCopy\n```\ncode_executor_agent (to code_writer):\nWrite Python code to calculate the 14th Fibonacci number.\n--------------------------------------------------------------------------------\ncode_writer (to code_executor_agent):\nSure, we can calculate the Fibonacci series using a few different methods such as recursion, iterative, by using Binet's formula, or by using matrix exponentiation.\nBut, since we only need to calculate the 14th number, we will simply use the iterative method as it's the most efficient for this case.\nHere is the Python code that solves the task:\n```python\ndef fibonacci(n):\n  a, b = 0, 1\n  for _ in range(n):\n    a, b = b, a + b\n  return a\nprint(fibonacci(14))\n```\nIn this script, `fibonacci(n)` is a function that calculates the nth Fibonacci number. Inside the function, two variables `a` and `b` are initialised to `0` and `1` which are the first two numbers in the Fibonacci series. Then, a loop runs `n` times (14 times in your case), and in each iteration `a` is replaced with `b` and `b` is replaced with `a + b`, which generates the next number in the series. \nThe function returns `a`, which is the nth Fibonacci number. The result is then printed to the console.\n--------------------------------------------------------------------------------\n>>>>>>>> EXECUTING 1 CODE BLOCKS (inferred languages are [python])...\ncode_executor_agent (to code_writer):\nexitcode: 0 (execution succeeded)\nCode output: 377\n\n--------------------------------------------------------------------------------\ncode_writer (to code_executor_agent):\nGreat! The script has successfully computed the 14th Fibonacci number as 377. If you need to compute other Fibonacci numbers, you can simply change the argument in the `fibonacci()` function call. Please let me know if you need help with anything else.\n--------------------------------------------------------------------------------\ncode_executor_agent (to code_writer):\n\n--------------------------------------------------------------------------------\nChatResult(chat_id=None,\n      chat_history=[{'content': 'Write Python code to calculate the 14th '\n                   'Fibonacci number.',\n             'role': 'assistant'},\n             {'content': 'Sure, we can calculate the Fibonacci '\n                   'series using a few different methods '\n                   'such as recursion, iterative, by using '\n                   \"Binet's formula, or by using matrix \"\n                   'exponentiation.\\n'\n                   '\\n'\n                   'But, since we only need to calculate the '\n                   '14th number, we will simply use the '\n                   \"iterative method as it's the most \"\n                   'efficient for this case.\\n'\n                   '\\n'\n                   'Here is the Python code that solves the '\n                   'task:\\n'\n                   '\\n'\n                   '```python\\n'\n                   'def fibonacci(n):\\n'\n                   '  a, b = 0, 1\\n'\n                   '  for _ in range(n):\\n'\n                   '    a, b = b, a + b\\n'\n                   '  return a\\n'\n                   '\\n'\n                   'print(fibonacci(14))\\n'\n                   '```\\n'\n                   '\\n'\n                   'In this script, `fibonacci(n)` is a '\n                   'function that calculates the nth '\n                   'Fibonacci number. Inside the function, '\n                   'two variables `a` and `b` are '\n                   'initialised to `0` and `1` which are the '\n                   'first two numbers in the Fibonacci '\n                   'series. Then, a loop runs `n` times (14 '\n                   'times in your case), and in each '\n                   'iteration `a` is replaced with `b` and '\n                   '`b` is replaced with `a + b`, which '\n                   'generates the next number in the '\n                   'series. \\n'\n                   '\\n'\n                   'The function returns `a`, which is the '\n                   'nth Fibonacci number. The result is then '\n                   'printed to the console.',\n             'role': 'user'},\n             {'content': 'exitcode: 0 (execution succeeded)\\n'\n                   'Code output: 377\\n',\n             'role': 'assistant'},\n             {'content': 'Great! The script has successfully '\n                   'computed the 14th Fibonacci number as '\n                   '377. If you need to compute other '\n                   'Fibonacci numbers, you can simply change '\n                   'the argument in the `fibonacci()` '\n                   'function call. Please let me know if you '\n                   'need help with anything else.',\n             'role': 'user'},\n             {'content': '', 'role': 'assistant'}],\n      summary='',\n      cost=({'gpt-4-0613': {'completion_tokens': 302,\n                 'cost': 0.04842,\n                 'prompt_tokens': 1010,\n                 'total_tokens': 1312},\n         'total_cost': 0.04842},\n         {'gpt-4-0613': {'completion_tokens': 302,\n                 'cost': 0.04842,\n                 'prompt_tokens': 1010,\n                 'total_tokens': 1312},\n         'total_cost': 0.04842}),\n      human_input=[])\n\n```\n\nFinally, stop the container. Or better yet use a context manager for it to be stopped automatically.\nCopy\n```\nexecutor.stop()\n\n```\n\n[Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)[Custom Code Executor](https://docs.ag2.ai/docs/</docs/topics/code-execution/custom-executor>)\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Docker](https://docs.ag2.ai/docs/<#docker>)\n  * [Inspecting the container](https://docs.ag2.ai/docs/<#inspecting-the-container>)\n  * [Example](https://docs.ag2.ai/docs/<#example>)\n  * [Combining AutoGen in Docker with a Docker based executor](https://docs.ag2.ai/docs/<#combining-autogen-in-docker-with-a-docker-based-executor>)\n  * [Local](https://docs.ag2.ai/docs/<#local>)\n  * [Example](https://docs.ag2.ai/docs/<#example-2>)\n  * [Using a Python virtual environment](https://docs.ag2.ai/docs/<#using-a-python-virtual-environment>)\n  * [Example](https://docs.ag2.ai/docs/<#example-3>)\n  * [Assigning to an agent](https://docs.ag2.ai/docs/<#assigning-to-an-agent>)\n\n---\n\n# ExamplesLearn different examples demonstrating the usage of AG2 in various scenarios.\nURL: https://docs.ag2.ai/docs/Examples\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nExamples by Category\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\n# Examples by Category\n## \n[​](https://docs.ag2.ai/docs/<#automated-multi-agent-chat>)\nAutomated Multi Agent Chat\nAutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation via multi-agent conversation. Please find documentation about this feature [here](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>).\nLinks to notebook examples:\n### \n[​](https://docs.ag2.ai/docs/<#code-generation-execution-and-debugging>)\nCode Generation, Execution, and Debugging\n  * Automated Task Solving with Code Generation, Execution & Debugging - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_auto_feedback_from_code_execution>)\n  * Automated Code Generation and Question Answering with Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_RetrieveChat>)\n  * Automated Code Generation and Question Answering with [Qdrant](https://docs.ag2.ai/docs/<https:/qdrant.tech/>) based Retrieval Augmented Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_RetrieveChat_qdrant>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#multi-agent-collaboration-3-agents>)\nMulti-Agent Collaboration (>3 Agents)\n  * Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat>)\n  * Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_vis>)\n  * Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_research>)\n  * Automated Task Solving with Coding & Planning Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_planning>)\n  * Automated Task Solving with transition paths specified in a graph - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_finite_state_machine>)\n  * Running a group chat as an inner-monolgue via the SocietyOfMindAgent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_society_of_mind>)\n  * Running a group chat with custom speaker selection function - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_customized>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#sequential-multi-agent-chats>)\nSequential Multi-Agent Chats\n  * Solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_multi_task_chats>)\n  * Async-solving Multiple Tasks in a Sequence of Chats Initiated by a Single Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_multi_task_async_chats>)\n  * Solving Multiple Tasks in a Sequence of Chats Initiated by Different Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchats_sequential_chats>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#nested-chats>)\nNested Chats\n  * Solving Complex Tasks with Nested Chats - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nestedchat>)\n  * Solving Complex Tasks with A Sequence of Nested Chats - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_sequential_chats>)\n  * OptiGuide for Solving a Supply Chain Optimization Problem with Nested Chats with a Coding Agent and a Safeguard Agent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nestedchat_optiguide>)\n  * Conversational Chess with Nested Chats and Tool Use - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_chats_chess>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#swarms>)\nSwarms\n  * Orchestrating agents in a Swarm - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm>)\n  * Orchestrating agents in a Swarm (Enhanced) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm_enhanced>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#applications>)\nApplications\n  * Automated Continual Learning from New Data - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_stream>)\n\n\n  * [AutoAnny](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/build-with-ag2/tree/main/samples/apps/auto-anny>) - A Discord bot built using AutoGen\n\n\n### \n[​](https://docs.ag2.ai/docs/<#rag>)\nRAG\n  * GraphRAG agent using FalkorDB (feat. swarms and Google Maps API) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_swarm_graphrag_trip_planner>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#tool-use>)\nTool Use\n  * **Web Search** : Solve Tasks Requiring Web Info - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_web_info>)\n  * Use Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_currency_calculator>)\n  * Use Tools via Sync and Async Function Calling - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_async>)\n  * Task Solving with Langchain Provided Tools as Functions - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_langchain>)\n  * **RAG** : Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_groupchat_RAG>)\n  * Function Inception: Enable AutoGen agents to update/remove functions during conversations. - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_inception_function>)\n  * Agent Chat with Whisper - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_video_transcript_translate_with_whisper>)\n  * Constrained Responses via Guidance - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_guidance>)\n  * Browse the Web with Agents - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_surfer>)\n  * **SQL** : Natural Language Text to SQL Query using the [Spider](https://docs.ag2.ai/docs/<https:/yale-lily.github.io/spider>) Text-to-SQL Benchmark - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_sql_spider>)\n  * **Web Scraping** : Web Scraping with Apify - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_webscraping_with_apify>)\n  * **Write a software app, task by task, with specially designed functions.** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_function_call_code_writing>).\n\n\n### \n[​](https://docs.ag2.ai/docs/<#human-involvement>)\nHuman Involvement\n  * Simple example in ChatGPT style [View example](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/build-with-ag2/blob/main/samples/simple_chat.py>)\n  * Auto Code Generation, Execution, Debugging and **Human Feedback** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_human_feedback>)\n  * Automated Task Solving with GPT-4 + **Multiple Human Users** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_two_users>)\n  * Agent Chat with **Async Human Inputs** - [View Notebook](https://docs.ag2.ai/docs/</notebooks/async_human_input>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#agent-teaching-and-learning>)\nAgent Teaching and Learning\n  * Teach Agents New Skills & Reuse via Automated Chat - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teaching>)\n  * Teach Agents New Facts, User Preferences and Skills Beyond Coding - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teachability>)\n  * Teach OpenAI Assistants Through GPTAssistantAgent - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_teachable_oai_assistants>)\n  * Agent Optimizer: Train Agents in an Agentic Way - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_agentoptimizer>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#multi-agent-chat-with-openai-assistants-in-the-loop>)\nMulti-Agent Chat with OpenAI Assistants in the loop\n  * Hello-World Chat with OpenAi Assistant in AutoGen - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_twoagents_basic>)\n  * Chat with OpenAI Assistant using Function Call - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_function_call>)\n  * Chat with OpenAI Assistant with Code Interpreter - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_code_interpreter>)\n  * Chat with OpenAI Assistant with Retrieval Augmentation - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_retrieval>)\n  * OpenAI Assistant in a Group Chat - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_oai_assistant_groupchat>)\n  * GPTAssistantAgent based Multi-Agent Tool Use - [View Notebook](https://docs.ag2.ai/docs/</notebooks/gpt_assistant_agent_function_call>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#non-openai-models>)\nNon-OpenAI Models\n  * Conversational Chess using non-OpenAI Models - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_nested_chats_chess_altmodels>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#multimodal-agent>)\nMultimodal Agent\n  * Multimodal Agent Chat with DALLE and GPT-4V - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_dalle_and_gpt4v>)\n  * Multimodal Agent Chat with Llava - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_lmm_llava>)\n  * Multimodal Agent Chat with GPT-4V - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_lmm_gpt-4v>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#long-context-handling>)\nLong Context Handling\n  * Long Context Handling as A Capability - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_transform_messages>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#evaluation-and-assessment>)\nEvaluation and Assessment\n  * AgentEval: A Multi-Agent System for Assess Utility of LLM-powered Applications - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agenteval_cq_math>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#automatic-agent-building>)\nAutomatic Agent Building\n  * Automatically Build Multi-agent System with AgentBuilder - [View Notebook](https://docs.ag2.ai/docs/</notebooks/autobuild_basic>)\n  * Automatically Build Multi-agent System from Agent Library - [View Notebook](https://docs.ag2.ai/docs/</notebooks/autobuild_agent_library>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#observability>)\nObservability\n  * Track LLM calls, tool usage, actions and errors using AgentOps - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_agentops>)\n  * Cost Calculation - [View Notebook](https://docs.ag2.ai/docs/</notebooks/agentchat_cost_token_tracking>)\n\n\n## \n[​](https://docs.ag2.ai/docs/<#enhanced-inferences>)\nEnhanced Inferences\n### \n[​](https://docs.ag2.ai/docs/<#utilities>)\nUtilities\n  * API Unification - [View Documentation with Code Example](https://docs.ag2.ai/docs/<https:/docs.ag2.ai/docs/Use-Cases/enhanced_inference#api-unification>)\n  * Utility Functions to Help Managing API configurations effectively - [View Notebook](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n\n\n### \n[​](https://docs.ag2.ai/docs/<#inference-hyperparameters-tuning>)\nInference Hyperparameters Tuning\nAutoGen offers a cost-effective hyperparameter optimization technique [EcoOptiGen](https://docs.ag2.ai/docs/<https:/arxiv.org/abs/2303.04673>) for tuning Large Language Models. The research study finds that tuning hyperparameters can significantly improve the utility of them. Please find documentation about this feature [here](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>).\nLinks to notebook examples:\n  * [Optimize for Code Generation](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>) | [Open in colab](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_completion.ipynb>)\n  * [Optimize for Math](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>) | [Open in colab](https://docs.ag2.ai/docs/<https:/colab.research.google.com/github/ag2ai/ag2/blob/main/notebook/oai_chatgpt_gpt4.ipynb>)\n\n\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\nOn this page\n  * [Automated Multi Agent Chat](https://docs.ag2.ai/docs/<#automated-multi-agent-chat>)\n  * [Code Generation, Execution, and Debugging](https://docs.ag2.ai/docs/<#code-generation-execution-and-debugging>)\n  * [Multi-Agent Collaboration (>3 Agents)](https://docs.ag2.ai/docs/<#multi-agent-collaboration-3-agents>)\n  * [Sequential Multi-Agent Chats](https://docs.ag2.ai/docs/<#sequential-multi-agent-chats>)\n  * [Nested Chats](https://docs.ag2.ai/docs/<#nested-chats>)\n  * [Swarms](https://docs.ag2.ai/docs/<#swarms>)\n  * [Applications](https://docs.ag2.ai/docs/<#applications>)\n  * [RAG](https://docs.ag2.ai/docs/<#rag>)\n  * [Tool Use](https://docs.ag2.ai/docs/<#tool-use>)\n  * [Human Involvement](https://docs.ag2.ai/docs/<#human-involvement>)\n  * [Agent Teaching and Learning](https://docs.ag2.ai/docs/<#agent-teaching-and-learning>)\n  * [Multi-Agent Chat with OpenAI Assistants in the loop](https://docs.ag2.ai/docs/<#multi-agent-chat-with-openai-assistants-in-the-loop>)\n  * [Non-OpenAI Models](https://docs.ag2.ai/docs/<#non-openai-models>)\n  * [Multimodal Agent](https://docs.ag2.ai/docs/<#multimodal-agent>)\n  * [Long Context Handling](https://docs.ag2.ai/docs/<#long-context-handling>)\n  * [Evaluation and Assessment](https://docs.ag2.ai/docs/<#evaluation-and-assessment>)\n  * [Automatic Agent Building](https://docs.ag2.ai/docs/<#automatic-agent-building>)\n  * [Observability](https://docs.ag2.ai/docs/<#observability>)\n  * [Enhanced Inferences](https://docs.ag2.ai/docs/<#enhanced-inferences>)\n  * [Utilities](https://docs.ag2.ai/docs/<#utilities>)\n  * [Inference Hyperparameters Tuning](https://docs.ag2.ai/docs/<#inference-hyperparameters-tuning>)\n\n---\n\n# ApplicationsA collection of different applications built using AG2.\nURL: https://docs.ag2.ai/docs/Gallery\n\n[AG2 home page![light logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2.svg)![dark logo](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/logo/ag2-white.svg)](https://docs.ag2.ai/docs/</>)\nSearch or ask...\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n  * [ag2ai/ag2](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)\n\n\nNavigation\nApplication Gallery\n[Documentation](https://docs.ag2.ai/docs/</docs/Home>)[Examples](https://docs.ag2.ai/docs/</notebooks/Examples>)[Blog](https://docs.ag2.ai/docs/</blog/2025-01-10-WebSockets/index>)[Community Talks](https://docs.ag2.ai/docs/</talks/future_talks/index>)\n  * [Home](https://docs.ag2.ai/docs/</docs/Home>)\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\n\n##### Installation\n  * [Overview](https://docs.ag2.ai/docs/</docs/installation/Installation>)\n  * [Docker](https://docs.ag2.ai/docs/</docs/installation/Docker>)\n  * [Optional Dependencies](https://docs.ag2.ai/docs/</docs/installation/Optional-Dependencies>)\n\n\n##### Tutorials\n  * [Introduction to AutoGen](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)\n  * [Terminating Conversations Between Agents](https://docs.ag2.ai/docs/</docs/tutorial/chat-termination>)\n  * [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n  * [Code Executors](https://docs.ag2.ai/docs/</docs/tutorial/code-executors>)\n  * [Tool Use](https://docs.ag2.ai/docs/</docs/tutorial/tool-use>)\n  * [Conversation Patterns](https://docs.ag2.ai/docs/</docs/tutorial/conversation-patterns>)\n  * [What Next?](https://docs.ag2.ai/docs/</docs/tutorial/what-next>)\n\n\n##### Use Cases\n  * [Multi-agent Conversation Framework](https://docs.ag2.ai/docs/</docs/Use-Cases/agent_chat>)\n  * [Enhanced Inference](https://docs.ag2.ai/docs/</docs/Use-Cases/enhanced_inference>)\n\n\n##### User Guide\n  * Code Execution\n  * OpenAI Assistant\n  * GroupChat\n  * Using Non-OpenAI Models\n  * CaptainAgent\n  * Handling Long Contexts\n  * [LLM Caching](https://docs.ag2.ai/docs/</docs/topics/llm-caching>)\n  * [Agent Observability](https://docs.ag2.ai/docs/</docs/topics/llm-observability>)\n  * [LLM Configuration](https://docs.ag2.ai/docs/</docs/topics/llm_configuration>)\n  * Prompting and Reasoning\n  * [Retrieval Augmentation](https://docs.ag2.ai/docs/</docs/topics/retrieval_augmentation>)\n  * [Swarm Orchestration](https://docs.ag2.ai/docs/</docs/topics/swarm>)\n  * [Task Decomposition](https://docs.ag2.ai/docs/</docs/topics/task_decomposition>)\n  * [FAQ](https://docs.ag2.ai/docs/</docs/FAQ>)\n\n\n##### API Reference\n  * agentchat\n  * cache\n  * coding\n  * interop\n  * io\n  * logger\n  * messages\n  * oai\n  * tools\n  * [browser_utils](https://docs.ag2.ai/docs/</docs/reference/browser_utils>)\n  * [code_utils](https://docs.ag2.ai/docs/</docs/reference/code_utils>)\n  * [exception_utils](https://docs.ag2.ai/docs/</docs/reference/exception_utils>)\n  * [graph_utils](https://docs.ag2.ai/docs/</docs/reference/graph_utils>)\n  * [math_utils](https://docs.ag2.ai/docs/</docs/reference/math_utils>)\n  * [retrieve_utils](https://docs.ag2.ai/docs/</docs/reference/retrieve_utils>)\n  * [runtime_logging](https://docs.ag2.ai/docs/</docs/reference/runtime_logging>)\n  * [token_count_utils](https://docs.ag2.ai/docs/</docs/reference/token_count_utils>)\n  * [types](https://docs.ag2.ai/docs/</docs/reference/types>)\n\n\n##### AutoGen Studio\n  * [Getting Started](https://docs.ag2.ai/docs/</docs/autogen-studio/getting-started>)\n  * [Using AutoGen Studio](https://docs.ag2.ai/docs/</docs/autogen-studio/usage>)\n  * [FAQs](https://docs.ag2.ai/docs/</docs/autogen-studio/faqs>)\n\n\n##### Ecosystem\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Azure Cosmos DB](https://docs.ag2.ai/docs/</docs/ecosystem/azure_cosmos_db>)\n  * [Composio](https://docs.ag2.ai/docs/</docs/ecosystem/composio>)\n  * [Databricks](https://docs.ag2.ai/docs/</docs/ecosystem/databricks>)\n  * [Llamaindex](https://docs.ag2.ai/docs/</docs/ecosystem/llamaindex>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n  * [MemGPT](https://docs.ag2.ai/docs/</docs/ecosystem/memgpt>)\n  * [Microsoft Fabric](https://docs.ag2.ai/docs/</docs/ecosystem/microsoft-fabric>)\n  * [Ollama](https://docs.ag2.ai/docs/</docs/ecosystem/ollama>)\n  * [PGVector](https://docs.ag2.ai/docs/</docs/ecosystem/pgvector>)\n  * [Portkey Integration with AutoGen](https://docs.ag2.ai/docs/</docs/ecosystem/portkey>)\n  * [Promptflow](https://docs.ag2.ai/docs/</docs/ecosystem/promptflow>)\n\n\n##### Contributor Guide\n  * [Contributing to AG2](https://docs.ag2.ai/docs/</docs/contributor-guide/contributing>)\n  * [Docker for Development](https://docs.ag2.ai/docs/</docs/contributor-guide/docker>)\n  * [Documentation](https://docs.ag2.ai/docs/</docs/contributor-guide/documentation>)\n  * [File A Bug Report](https://docs.ag2.ai/docs/</docs/contributor-guide/file-bug-report>)\n  * [Guidance for Maintainers](https://docs.ag2.ai/docs/</docs/contributor-guide/maintainer>)\n  * [Pre-commit](https://docs.ag2.ai/docs/</docs/contributor-guide/pre-commit>)\n  * [Tests](https://docs.ag2.ai/docs/</docs/contributor-guide/tests>)\n  * [Research](https://docs.ag2.ai/docs/</docs/Research>)\n  * [Migration Guide](https://docs.ag2.ai/docs/</docs/Migration-Guide>)\n\n\n# Application Gallery\nThis page contains a list of demos that use AutoGen in various applications from the community.\n**Contribution guide:** Built something interesting with AutoGen? Submit a PR to add it to the list! See the [Contribution Guide below](https://docs.ag2.ai/docs/</docs/Gallery#contributing>) for more details.\ntoolsgroupchatappblockchainuiroboticsextension\n![AutoTx - Crypto Transactions Agent](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/autotx.png)\n##### AutoTx - Crypto Transactions Agent\nGenerates on-chain transactions, which are submitted to a smart account so users can easily approve & execute them.\ntoolsgroupchatappblockchain\n![AutoGen Virtual Focus Group](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Virtual Focus Group\nA virtual consumer focus group with multiple custom personas, product details, and final analysis created with AutoGen, Ollama/Llama3, and Streamlit.\nuigroupchat\n![Function Generator & Validator](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/TensionCode.png)\n##### Function Generator & Validator\nA platform where user-required code is generated and simultaneously validated against sample data by AutoGen.\nappui\n![Autogen Robot](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/robot.jpg)\n##### Autogen Robot\nThis project showcases how agent's can act as a brain to control a physical robot.\nrobotics\n![AutoGen Group Chat Playground](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Group Chat Playground\nA huggingface space to explore AutoGen group chat, build agents with zero-code, and access source code for reuse.\nui\n![A Stateful Dev Environment Powered by Jupyter Notebook](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### A Stateful Dev Environment Powered by Jupyter Notebook\nAn AutoGen Teams Powered by Jupyter notebook.\nextensiontools\n![Solving Security Vulnerabilities with AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Solving Security Vulnerabilities with AutoGen\nAn article discussing the use of AutoGen to tackle security vulnerabilities.\napp\n![Research Agents via AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Research Agents via AutoGen\nA guide to building a team of AI research agents using AutoGen.\ngroupchattools\n![AutoGen with Ollama and LiteLLM](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen with Ollama and LiteLLM\nA demonstration of integrating Ollama, LiteLLM, and AutoGen.\nextension\n![AutoGen Engineer](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Engineer\nJoin the AutoGen Engineer group chat to collaborate and build with others.\ngroupchatapp\n![AutoGen with Obsidian](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen with Obsidian\nLearn how to integrate AutoGen with Obsidian for note-taking and management.\ntoolsapp\n![AutoGen Builder GPT](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Builder GPT\nA platform for building conversational AI agents with AutoGen Builder GPT.\ngroupchatui\n![AutoGen Multi-Round Human Interaction Chatbot with Gradio 4.0](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Multi-Round Human Interaction Chatbot with Gradio 4.0\nExperience a multi-round human interaction chatbot built with AutoGen and Gradio 4.0.\nuiapp\n![Agentcloud.dev \\(UI for AutoGen\\)](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Agentcloud.dev (UI for AutoGen)\nAgentcloud.dev provides a user interface for managing and collaborating with AutoGen agents.\nui\n![Next.js + FASTAPI Based UI for AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Next.js + FASTAPI Based UI for AutoGen\nA project featuring a UI for AutoGen built with Next.js and FastAPI.\nui\n![Full Function UI for AutoGen Powered by Panel](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Full Function UI for AutoGen Powered by Panel\nA UI allows users to directly interact with AI agents in real-time during a group chat scenario\nui\n![AutoGen Monitoring and Observability](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Monitoring and Observability\nDocumentation on monitoring and observability features for AutoGen.\nextension\n![Postgres Data Analytics AI Agent with AutoGen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Postgres Data Analytics AI Agent with AutoGen\nUtilizing AutoGen to speak directly to Postgres Database.\ntoolsapp\n![AutoGen with Local LLMs](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen with Local LLMs\nAn article on deploying multiple AI agents using local LLMs with AutoGen.\nextension\n![AutoGen with FastApi backend and React Frontend](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen with FastApi backend and React Frontend\nA demonstration of using AutoGen with a FastAPI backend and React frontend.\nui\n![Talk to AutoGen Agents Using Whisper and Gradio](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Talk to AutoGen Agents Using Whisper and Gradio\nInteract with AutoGen agents using Whisper and Gradio interfaces.\nui\n![AutoGen + LangChain + ChromaDB = You Super AI Assistant](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen + LangChain + ChromaDB = You Super AI Assistant\nCreate a super AI assistant combining AutoGen, LangChain, and ChromaDB.\napp\n![AutoGen + Flowise = Super AI Agents on No-Code Platform](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen + Flowise = Super AI Agents on No-Code Platform\nBuild super AI agents on a no-code platform using AutoGen and Flowise.\napp\n![AutoGen with RunPod and TextGen WebUI](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen with RunPod and TextGen WebUI\nLearn how to use AutoGen with RunPod and TextGen WebUI for enhanced AI agent integration.\nuiextension\n![Jarvis Collaborates with AutoGen for Tweet Analysis](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Jarvis Collaborates with AutoGen for Tweet Analysis\nExplore how Jarvis collaborates with AutoGen for tweet analysis.\ntoolsapp\n![AutoGen + LangChain + PlayHT = Super AI Agent that Speaks](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen + LangChain + PlayHT = Super AI Agent that Speaks\nCombine AutoGen, LangChain, and PlayHT to create a speaking super AI agent.\ntoolsapp\n![AutoGen Flow with FastAPI and Nextjs](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen Flow with FastAPI and Nextjs\nA development flow using AutoGen with FastAPI and Next.js.\nui\n![Build Vision-Enabled AI Agents with AutoGen + Llava](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Build Vision-Enabled AI Agents with AutoGen + Llava\nTutorial on building vision-enabled AI agents using AutoGen and llava.\ntoolsapp\n![AutoGen + Chainlit chat interface with multi-agent conversation](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### AutoGen + Chainlit chat interface with multi-agent conversation\nChainlit chat interface with multi-agent conversation between agents to complete a tasks\nui\n![XForce IDE: Build AutoGen based workforces from a drag and drop UI](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/x-force-ide-ui.png)\n##### XForce IDE: Build AutoGen based workforces from a drag and drop UI\nX-Force IDE is a low-code, agent-as-a-service UI framework that lets you create AutoGen-based workforces from a drag-and-drop-like user interface.\nui\n![Multimodal Webagent created with AutoGen and OpenAI's Assistants API](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/webagent.jpg)\n##### Multimodal Webagent created with AutoGen and OpenAI's Assistants API\nA multimodal webbrowsing agent that autonomously browses the web.\ntoolsapp\n![Create Issues from Code Commits - using Autogen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/composio-autogen.png)\n##### Create Issues from Code Commits - using Autogen\nAutomatically creating linear tasks and assigning them to the right person, project, and team from GitHub commits using AutoGen Agents.\ntools\n![Agentok - Autogen Visualized](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Agentok - Autogen Visualized\nOffering intuitive visual tools that streamline the creation and management of complex AutoGen workflows.\ntoolsuiapp\n![Expense Tracker - using Autogen](https://mintlify.s3.us-west-1.amazonaws.com/ag2ai/static/img/gallery/default.png)\n##### Expense Tracker - using Autogen\nTracks personal finance income and expenses then helps the user to analyse it using AutoGen agents.\ntoolsapp\n## \n[​](https://docs.ag2.ai/docs/<#contributing>)\nContributing\nThank you for your interest in contributing! To add your demo to the gallery, please create a Pull Request (PR) with the following details.\n  * Updated `website/snippets/data/GalleryItems.mdx` file with your application entry.\n  * The application image added to the `static/img/gallery` directory if the image is local. If the image is hosted online, just update the `image` property with the URL of the image.\n  * Below is an example of an entry in the `website/snippets/data/GalleryItems.mdx` file:\nCopy\n```\n {\n \"title\": \"AutoGen Playground\", // The title of your demo\n \"link\": \"https://huggingface.co/spaces/thinkall/AutoGen_Playground\", // URL to your demo\n \"description\": \"A space to explore the capabilities of AutoGen.\", // A brief description\n \"image\": \"default.png\", // Filename of the image present in the `static/img/gallery` directory or URL of the hosted image\n \"tags\": [\"ui\"] // Tags to categorize your demo\n }\n\n```\n\n  * Refer to the below table for description of each property:\nProperty| Description  \n---|---  \n`title`| Provide a clear and concise title for your demo.  \n`link`| Include a valid URL linking to your demo.  \n`description`| Write a short description (1-2 sentences) to summarize your demo.  \n`image`| Use the filename of an image stored in the `static/img/gallery` directory if the image is local.  \nIf the image is hosted online, ensure the URL is correctly added to the entry.  \n`tags`| Add up to two tags that best describe your demo for clarity.  \nChoose from the existing tags:  \n- `app`: Using Autogen for specific applications.  \n- `extension`: Enhancing AutoGen beyond the features in the current version.  \n- `ui`: Building a user interface for AutoGen.  \n- `tool`: Strengthening AutoGen Agents with external tools.  \n- `groupchat`: Solving complex tasks with a group of Agents.  \nOr propose new tags if the existing ones do not describe your demo. Ensure they are descriptive and concise.  \n\n\n[x](https://docs.ag2.ai/docs/<https:/x.com/Chi_Wang_>)[github](https://docs.ag2.ai/docs/<https:/github.com/ag2ai/ag2>)[linkedin](https://docs.ag2.ai/docs/<https:/www.linkedin.com/company/ag2ai>)[discord](https://docs.ag2.ai/docs/<https:/discord.gg/pAbnFJrkgZ>)[youtube](https://docs.ag2.ai/docs/<https:/www.youtube.com/@ag2ai>)\n[Powered by Mintlify](https://docs.ag2.ai/docs/<https:/mintlify.com/preview-request?utm_campaign=poweredBy&utm_medium=docs&utm_source=docs.ag2.ai>)\n\n---\n\n# ​\nURL: https://docs.ag2.ai/docs/Home#popular-resources\n\n* [Allowing Human Feedback in Agents](https://docs.ag2.ai/docs/</docs/tutorial/human-in-the-loop>)\n\n  * [Agent Monitoring and Debugging with AgentOps](https://docs.ag2.ai/docs/</docs/ecosystem/agentops>)\n  * [Mem0:Long-Term Memory and Personalization for Agents](https://docs.ag2.ai/docs/</docs/ecosystem/mem0>)\n\nThe Open Source Agent OS\n\n[Getting Started - 3 Minute](https://docs.ag2.ai/docs/</docs/Getting-Started>)\n\nAG2 provides multi-agent conversation framework as a high-level abstraction.\nWith this framework, one can conveniently build LLM workflows.\n\nAG2 offers a collection of working systems spanning a wide range of applications\nfrom various domains and complexities.\n\n[Enhanced LLM Inference & Optimization](https://docs.ag2.ai/docs/</docs/Use-\nCases/enhanced_inference>)\n\nAG2 supports enhanced LLM inference APIs, which can be used to improve inference\nperformance and reduce cost.\n\n[Learn how to get started with AG2. Follow the instruction to quickly build-up\nyour first AG2 application.](https://docs.ag2.ai/docs/</docs/Getting-\nStarted>)[This tutorial introduces basic concepts and building blocks of\nAG2.](https://docs.ag2.ai/docs/</docs/tutorial/introduction>)[Users' guide to\ndifferent functionalities of AG2, including CodeExecution, GroupChat, and\nmore.](https://docs.ag2.ai/docs/</docs/topics>)[Learn different examples\ndemonstrating the usage of AG2 in various\nscenarios.](https://docs.ag2.ai/docs/</docs/Examples>)[A collection of different\napplications built using AG2.](https://docs.ag2.ai/docs/</docs/Gallery>)[Learn\nabout how you can contribute to AG2 and this documentation, including pushing\npatches, code review and more.](https://docs.ag2.ai/docs/</docs/contributor-\nguide/contributing>)\n\n[Foundation Capital Interview with Dr. Chi\nWang](https://docs.ag2.ai/docs/<https:/www.youtube.com/watch?v=RLwyXRVvlNk>)\n\n---\n\n",
  "timestamp": "2025-01-18T21:08:34.284Z",
  "stats": {
    "wordCount": 79754,
    "charCount": 991231
  }
}